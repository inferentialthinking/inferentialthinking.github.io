
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>17.5. The Accuracy of the Classifier &#8212; Computational and Inferential Thinking</title>
    
  <link rel="stylesheet" href="../../../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/sphinx-book-theme.e7340bb3dbd8dde6db86f25597f54a1b.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/book.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/togglebutton.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/sphinx-book-theme.7d483ff0a819d6edff12ce0b1ead3928.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="canonical" href="https://inferentialthinking.org/chapters/17/5/Accuracy_of_the_Classifier.html" />
    <link rel="shortcut icon" href="../../../_static/favicon.png"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="17.6. Multiple Regression" href="../6/Multiple_Regression.html" />
    <link rel="prev" title="17.4. Implementing the Classifier" href="../4/Implementing_the_Classifier.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />


<!-- Opengraph tags -->
<meta property="og:url"         content="https://inferentialthinking.org/chapters/17/5/Accuracy_of_the_Classifier.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="The Accuracy of the Classifier" />
<meta property="og:description" content="The Accuracy of the Classifier  To see how well our classifier does, we might put 50% of the data into the training set and the other 50% into the test set.  Ba" />
<meta property="og:image"       content="https://inferentialthinking.org/_static/favicon.png" />

<meta name="twitter:card" content="summary" />


  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../../index.html">
  
  <img src="../../../_static/favicon.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Computational and Inferential Thinking</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="current nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../01/what-is-data-science.html">
   1. Data Science
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2 collapsible-parent">
    <a class="reference internal" href="../../01/1/intro.html">
     1.1. Introduction
    </a>
    <ul class="collapse-ul">
     <li class="toctree-l3">
      <a class="reference internal" href="../../01/1/1/computational-tools.html">
       1.1.1. Computational Tools
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../01/1/2/statistical-techniques.html">
       1.1.2. Statistical Techniques
      </a>
     </li>
    </ul>
    <i class="fas fa-chevron-down">
    </i>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../01/2/why-data-science.html">
     1.2. Why Data Science?
    </a>
   </li>
   <li class="toctree-l2 collapsible-parent">
    <a class="reference internal" href="../../01/3/Plotting_the_Classics.html">
     1.3. Plotting the Classics
    </a>
    <ul class="collapse-ul">
     <li class="toctree-l3">
      <a class="reference internal" href="../../01/3/1/Literary_Characters.html">
       1.3.1. Literary Characters
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../01/3/2/Another_Kind_Of_Character.html">
       1.3.2. Another Kind of Character
      </a>
     </li>
    </ul>
    <i class="fas fa-chevron-down">
    </i>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../02/causality-and-experiments.html">
   2. Causality and Experiments
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../02/1/observation-and-visualization-john-snow-and-the-broad-street-pump.html">
     2.1. John Snow and the Broad Street Pump
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../02/2/snow-s-grand-experiment.html">
     2.2. Snow’s “Grand Experiment”
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../02/3/establishing-causality.html">
     2.3. Establishing Causality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../02/4/randomization.html">
     2.4. Randomization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../02/5/endnote.html">
     2.5. Endnote
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../03/programming-in-python.html">
   3. Programming in Python
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../03/1/Expressions.html">
     3.1. Expressions
    </a>
   </li>
   <li class="toctree-l2 collapsible-parent">
    <a class="reference internal" href="../../03/2/Names.html">
     3.2. Names
    </a>
    <ul class="collapse-ul">
     <li class="toctree-l3">
      <a class="reference internal" href="../../03/2/1/Growth.html">
       3.2.1. Example: Growth Rates
      </a>
     </li>
    </ul>
    <i class="fas fa-chevron-down">
    </i>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../03/3/Calls.html">
     3.3. Call Expressions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../03/4/Introduction_to_Tables.html">
     3.4. Introduction to Tables
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../04/Data_Types.html">
   4. Data Types
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../04/1/Numbers.html">
     4.1. Numbers
    </a>
   </li>
   <li class="toctree-l2 collapsible-parent">
    <a class="reference internal" href="../../04/2/Strings.html">
     4.2. Strings
    </a>
    <ul class="collapse-ul">
     <li class="toctree-l3">
      <a class="reference internal" href="../../04/2/1/String_Methods.html">
       4.2.1. String Methods
      </a>
     </li>
    </ul>
    <i class="fas fa-chevron-down">
    </i>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../04/3/Comparison.html">
     4.3. Comparisons
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../05/Sequences.html">
   5. Sequences
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../05/1/Arrays.html">
     5.1. Arrays
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../05/2/Ranges.html">
     5.2. Ranges
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../05/3/More_on_Arrays.html">
     5.3. More on Arrays
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../06/Tables.html">
   6. Tables
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../06/1/Sorting_Rows.html">
     6.1. Sorting Rows
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../06/2/Selecting_Rows.html">
     6.2. Selecting Rows
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../06/3/Example_Trends_in_the_Population_of_the_United_States.html">
     6.3. Example: Population Trends
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../06/4/Example_Gender_Ratio_in_the_US_Population.html">
     6.4. Example: Trends in Gender
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../07/Visualization.html">
   7. Visualization
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../07/1/Visualizing_Categorical_Distributions.html">
     7.1. Categorical Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../07/2/Visualizing_Numerical_Distributions.html">
     7.2. Numerical Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../07/3/Overlaid_Graphs.html">
     7.3. Overlaid Graphs
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../08/Functions_and_Tables.html">
   8. Functions and Tables
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../08/1/Applying_a_Function_to_a_Column.html">
     8.1. Applying Functions to Columns
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../08/2/Classifying_by_One_Variable.html">
     8.2. Classifying by One Variable
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../08/3/Cross-Classifying_by_More_than_One_Variable.html">
     8.3. Cross-Classifying
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../08/4/Joining_Tables_by_Columns.html">
     8.4. Joining Tables by Columns
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../08/5/Bike_Sharing_in_the_Bay_Area.html">
     8.5. Bike Sharing in the Bay Area
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../09/Randomness.html">
   9. Randomness
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../09/1/Conditional_Statements.html">
     9.1. Conditional Statements
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../09/2/Iteration.html">
     9.2. Iteration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../09/3/Simulation.html">
     9.3. Simulation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../09/4/Monty_Hall_Problem.html">
     9.4. The Monty Hall Problem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../09/5/Finding_Probabilities.html">
     9.5. Finding Probabilities
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../10/Sampling_and_Empirical_Distributions.html">
   10. Sampling and Empirical Distributions
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../10/1/Empirical_Distributions.html">
     10.1. Empirical Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../10/2/Sampling_from_a_Population.html">
     10.2. Sampling from a Population
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../10/3/Empirical_Distribution_of_a_Statistic.html">
     10.3. Empirical Distibution of a Statistic
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../11/Testing_Hypotheses.html">
   11. Testing Hypotheses
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../11/1/Assessing_Models.html">
     11.1. Assessing Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../11/2/Multiple_Categories.html">
     11.2. Multiple Categories
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../11/3/Decisions_and_Uncertainty.html">
     11.3. Decisions and Uncertainty
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../11/4/Error_Probabilities.html">
     11.4. Error Probabilities
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../12/Comparing_Two_Samples.html">
   12. Comparing Two Samples
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../12/1/AB_Testing.html">
     12.1. A/B Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../12/2/Deflategate.html">
     12.2. Deflategate
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../12/3/Causality.html">
     12.3. Causality
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../13/Estimation.html">
   13. Estimation
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../13/1/Percentiles.html">
     13.1. Percentiles
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../13/2/Bootstrap.html">
     13.2. The Bootstrap
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../13/3/Confidence_Intervals.html">
     13.3. Confidence Intervals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../13/4/Using_Confidence_Intervals.html">
     13.4. Using Confidence Intervals
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../14/Why_the_Mean_Matters.html">
   14. Why the Mean Matters
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../14/1/Properties_of_the_Mean.html">
     14.1. Properties of the Mean
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../14/2/Variability.html">
     14.2. Variability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../14/3/SD_and_the_Normal_Curve.html">
     14.3. The SD and the Normal Curve
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../14/4/Central_Limit_Theorem.html">
     14.4. The Central Limit Theorem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../14/5/Variability_of_the_Sample_Mean.html">
     14.5. The Variability of the Sample Mean
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../14/6/Choosing_a_Sample_Size.html">
     14.6. Choosing a Sample Size
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../15/Prediction.html">
   15. Prediction
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../15/1/Correlation.html">
     15.1. Correlation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../15/2/Regression_Line.html">
     15.2. The Regression Line
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../15/3/Method_of_Least_Squares.html">
     15.3. The Method of Least Squares
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../15/4/Least_Squares_Regression.html">
     15.4. Least Squares Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../15/5/Visual_Diagnostics.html">
     15.5. Visual Diagnostics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../15/6/Numerical_Diagnostics.html">
     15.6. Numerical Diagnostics
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../16/Inference_for_Regression.html">
   16. Inference for Regression
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../16/1/Regression_Model.html">
     16.1. A Regression Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../16/2/Inference_for_the_True_Slope.html">
     16.2. Inference for the True Slope
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../16/3/Prediction_Intervals.html">
     16.3. Prediction Intervals
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="../Classification.html">
   17. Classification
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../1/Nearest_Neighbors.html">
     17.1. Nearest Neighbors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2/Training_and_Testing.html">
     17.2. Training and Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3/Rows_of_Tables.html">
     17.3. Rows of Tables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4/Implementing_the_Classifier.html">
     17.4. Implementing the Classifier
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     17.5. The Accuracy of the Classifier
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6/Multiple_Regression.html">
     17.6. Multiple Regression
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../18/Updating_Predictions.html">
   18. Updating Predictions
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../18/1/More_Likely_than_Not_Binary_Classifier.html">
     18.1. A "More Likely Than Not" Binary Classifier
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../18/2/Making_Decisions.html">
     18.2. Making Decisions
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../../_sources/chapters/17/5/Accuracy_of_the_Classifier.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/data-8/textbook"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>


            <!-- Full screen (wrap in <a> to have style consistency -->
            <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                    data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                    title="Fullscreen mode"><i
                        class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/data-8/textbook/main?urlpath=tree/chapters/17/5/Accuracy_of_the_Classifier.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        <a class="jupyterhub-button" href="https://datahub.berkeley.edu/hub/user-redirect/git-pull?repo=https://github.com/data-8/textbook&urlpath=tree/textbook/chapters/17/5/Accuracy_of_the_Classifier.ipynb&branch=main"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch JupyterHub" data-toggle="tooltip"
                data-placement="left"><img class="jupyterhub-button-logo"
                    src="../../../_static/images/logo_jupyterhub.svg"
                    alt="Interact on JupyterHub">JupyterHub</button></a>
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i>
            Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#measuring-the-accuracy-of-our-wine-classifier">
   17.5.1. Measuring the Accuracy of Our Wine Classifier
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#breast-cancer-diagnosis">
   17.5.2. Breast Cancer Diagnosis
  </a>
 </li>
</ul>

        </nav>
        
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="cell tag_remove-input docutils container">
</div>
<div class="section" id="the-accuracy-of-the-classifier">
<h1><span class="section-number">17.5. </span>The Accuracy of the Classifier<a class="headerlink" href="#the-accuracy-of-the-classifier" title="Permalink to this headline">¶</a></h1>
<p>To see how well our classifier does, we might put 50% of the data into the training set and the other 50% into the test set.  Basically, we are setting aside some data for later use, so we can use it to measure the accuracy of our classifier.  We’ve been calling that the <em>test set</em>. Sometimes people will call the data that you set aside for testing a <em>hold-out set</em>, and they’ll call this strategy for estimating accuracy the <em>hold-out method</em>.</p>
<p>Note that this approach requires great discipline.  Before you start applying machine learning methods, you have to take some of your data and set it aside for testing.  You must avoid using the test set for developing your classifier: you shouldn’t use it to help train your classifier or tweak its settings or for brainstorming ways to improve your classifier.  Instead, you should use it only once, at the very end, after you’ve finalized your classifier, when you want an unbiased estimate of its accuracy.</p>
<div class="cell tag_remove-input docutils container">
</div>
<div class="cell tag_remove-input docutils container">
</div>
<div class="section" id="measuring-the-accuracy-of-our-wine-classifier">
<h2><span class="section-number">17.5.1. </span>Measuring the Accuracy of Our Wine Classifier<a class="headerlink" href="#measuring-the-accuracy-of-our-wine-classifier" title="Permalink to this headline">¶</a></h2>
<p>OK, so let’s apply the hold-out method to evaluate the effectiveness of the <span class="math notranslate nohighlight">\(k\)</span>-nearest neighbor classifier for identifying wines.  The data set has 178 wines, so we’ll randomly permute the data set and put 89 of them in the training set and the remaining 89 in the test set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">shuffled_wine</span> <span class="o">=</span> <span class="n">wine</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">with_replacement</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> 
<span class="n">training_set</span> <span class="o">=</span> <span class="n">shuffled_wine</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">89</span><span class="p">))</span>
<span class="n">test_set</span>  <span class="o">=</span> <span class="n">shuffled_wine</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">89</span><span class="p">,</span> <span class="mi">178</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>We’ll train the classifier using the 89 wines in the training set, and evaluate how well it performs on the test set. To make our lives easier, we’ll write a function to evaluate a classifier on every wine in the test set:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">count_zero</span><span class="p">(</span><span class="n">array</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Counts the number of 0&#39;s in an array&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">array</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">array</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">count_equal</span><span class="p">(</span><span class="n">array1</span><span class="p">,</span> <span class="n">array2</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Takes two numerical arrays of equal length</span>
<span class="sd">    and counts the indices where the two are equal&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">count_zero</span><span class="p">(</span><span class="n">array1</span> <span class="o">-</span> <span class="n">array2</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">evaluate_accuracy</span><span class="p">(</span><span class="n">training</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="n">test_attributes</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;Class&#39;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">classify_testrow</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">classify</span><span class="p">(</span><span class="n">training</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">test_attributes</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">classify_testrow</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">count_equal</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">test</span><span class="o">.</span><span class="n">column</span><span class="p">(</span><span class="s1">&#39;Class&#39;</span><span class="p">))</span> <span class="o">/</span> <span class="n">test</span><span class="o">.</span><span class="n">num_rows</span>
</pre></div>
</div>
</div>
</div>
<p>Now for the grand reveal – let’s see how we did.  We’ll arbitrarily use <span class="math notranslate nohighlight">\(k=5\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">evaluate_accuracy</span><span class="p">(</span><span class="n">training_set</span><span class="p">,</span> <span class="n">test_set</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.898876404494382
</pre></div>
</div>
</div>
</div>
<p>The accuracy rate isn’t bad at all for a simple classifier.</p>
</div>
<div class="section" id="breast-cancer-diagnosis">
<h2><span class="section-number">17.5.2. </span>Breast Cancer Diagnosis<a class="headerlink" href="#breast-cancer-diagnosis" title="Permalink to this headline">¶</a></h2>
<p>Now I want to do an example based on diagnosing breast cancer.  I was inspired by Brittany Wenger, who won the Google national science fair in 2012 as a 17-year old high school student.  Here’s Brittany:</p>
<p><img alt="Brittany Wenger" src="http://i.huffpost.com/gen/701499/thumbs/o-GSF83-570.jpg?3" /></p>
<p>Brittany’s <a class="reference external" href="https://sites.google.com/a/googlesciencefair.com/science-fair-2012-project-64a91af142a459cfb486ed5cb05f803b2eb41354-1333130785-87/home">science fair project</a> was to build a classification algorithm to diagnose breast cancer.  She won grand prize for building an algorithm whose accuracy was almost 99%.</p>
<p>Let’s see how well we can do, with the ideas we’ve learned in this course.</p>
<p>So, let me tell you a little bit about the data set.  Basically, if a woman has a lump in her breast, the doctors may want to take a biopsy to see if it is cancerous.  There are several different procedures for doing that.  Brittany focused on fine needle aspiration (FNA), because it is less invasive than the alternatives.  The doctor gets a sample of the mass, puts it under a microscope, takes a picture, and a trained lab tech analyzes the picture to determine whether it is cancer or not.  We get a picture like one of the following:</p>
<p><img alt="benign" src="../../../_images/benign.png" /></p>
<p><img alt="cancer" src="../../../_images/malignant.png" /></p>
<p>Unfortunately, distinguishing between benign vs malignant can be tricky.  So, researchers have studied the use of machine learning to help with this task.  The idea is that we’ll ask the lab tech to analyze the image and compute various attributes: things like the typical size of a cell, how much variation there is among the cell sizes, and so on.  Then, we’ll try to use this information to predict (classify) whether the sample is malignant or not.  We have a training set of past samples from women where the correct diagnosis is known, and we’ll hope that our machine learning algorithm can use those to learn how to predict the diagnosis for future samples.</p>
<p>We end up with the following data set.  For the “Class” column, 1 means malignant (cancer); 0 means benign (not cancer).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">patients</span> <span class="o">=</span> <span class="n">Table</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span><span class="n">path_data</span> <span class="o">+</span> <span class="s1">&#39;breast-cancer.csv&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;ID&#39;</span><span class="p">)</span>
<span class="n">patients</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table border="1" class="dataframe">
    <thead>
        <tr>
            <th>Clump Thickness</th> <th>Uniformity of Cell Size</th> <th>Uniformity of Cell Shape</th> <th>Marginal Adhesion</th> <th>Single Epithelial Cell Size</th> <th>Bare Nuclei</th> <th>Bland Chromatin</th> <th>Normal Nucleoli</th> <th>Mitoses</th> <th>Class</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>5              </td> <td>1                      </td> <td>1                       </td> <td>1                </td> <td>2                          </td> <td>1          </td> <td>3              </td> <td>1              </td> <td>1      </td> <td>0    </td>
        </tr>
        <tr>
            <td>5              </td> <td>4                      </td> <td>4                       </td> <td>5                </td> <td>7                          </td> <td>10         </td> <td>3              </td> <td>2              </td> <td>1      </td> <td>0    </td>
        </tr>
        <tr>
            <td>3              </td> <td>1                      </td> <td>1                       </td> <td>1                </td> <td>2                          </td> <td>2          </td> <td>3              </td> <td>1              </td> <td>1      </td> <td>0    </td>
        </tr>
        <tr>
            <td>6              </td> <td>8                      </td> <td>8                       </td> <td>1                </td> <td>3                          </td> <td>4          </td> <td>3              </td> <td>7              </td> <td>1      </td> <td>0    </td>
        </tr>
        <tr>
            <td>4              </td> <td>1                      </td> <td>1                       </td> <td>3                </td> <td>2                          </td> <td>1          </td> <td>3              </td> <td>1              </td> <td>1      </td> <td>0    </td>
        </tr>
        <tr>
            <td>8              </td> <td>10                     </td> <td>10                      </td> <td>8                </td> <td>7                          </td> <td>10         </td> <td>9              </td> <td>7              </td> <td>1      </td> <td>1    </td>
        </tr>
        <tr>
            <td>1              </td> <td>1                      </td> <td>1                       </td> <td>1                </td> <td>2                          </td> <td>10         </td> <td>3              </td> <td>1              </td> <td>1      </td> <td>0    </td>
        </tr>
        <tr>
            <td>2              </td> <td>1                      </td> <td>2                       </td> <td>1                </td> <td>2                          </td> <td>1          </td> <td>3              </td> <td>1              </td> <td>1      </td> <td>0    </td>
        </tr>
        <tr>
            <td>2              </td> <td>1                      </td> <td>1                       </td> <td>1                </td> <td>2                          </td> <td>1          </td> <td>1              </td> <td>1              </td> <td>5      </td> <td>0    </td>
        </tr>
        <tr>
            <td>4              </td> <td>2                      </td> <td>1                       </td> <td>1                </td> <td>2                          </td> <td>1          </td> <td>2              </td> <td>1              </td> <td>1      </td> <td>0    </td>
        </tr>
    </tbody>
</table>
<p>... (673 rows omitted)</p></div></div>
</div>
<p>So we have 9 different attributes.  I don’t know how to make a 9-dimensional scatterplot of all of them, so I’m going to pick two and plot them:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">color_table</span> <span class="o">=</span> <span class="n">Table</span><span class="p">()</span><span class="o">.</span><span class="n">with_columns</span><span class="p">(</span>
    <span class="s1">&#39;Class&#39;</span><span class="p">,</span> <span class="n">make_array</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
    <span class="s1">&#39;Color&#39;</span><span class="p">,</span> <span class="n">make_array</span><span class="p">(</span><span class="s1">&#39;darkblue&#39;</span><span class="p">,</span> <span class="s1">&#39;gold&#39;</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">patients_with_colors</span> <span class="o">=</span> <span class="n">patients</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;Class&#39;</span><span class="p">,</span> <span class="n">color_table</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">patients_with_colors</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="s1">&#39;Bland Chromatin&#39;</span><span class="p">,</span> <span class="s1">&#39;Single Epithelial Cell Size&#39;</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="s1">&#39;Color&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/Accuracy_of_the_Classifier_15_0.png" src="../../../_images/Accuracy_of_the_Classifier_15_0.png" />
</div>
</div>
<p>Oops.  That plot is utterly misleading, because there are a bunch of points that have identical values for both the x- and y-coordinates.  To make it easier to see all the data points, I’m going to add a little bit of random jitter to the x- and y-values.  Here’s how that looks:</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="../../../_images/Accuracy_of_the_Classifier_17_0.png" src="../../../_images/Accuracy_of_the_Classifier_17_0.png" />
</div>
</div>
<p>For instance, you can see there are lots of samples with chromatin = 2 and epithelial cell size = 2; all non-cancerous.</p>
<p>Keep in mind that the jittering is just for visualization purposes, to make it easier to get a feeling for the data.  We’re ready to work with the data now, and we’ll use the original (unjittered) data.</p>
<p>First we’ll create a training set and a test set. The data set has 683 patients, so we’ll randomly permute the data set and put 342 of them in the training set and the remaining 341 in the test set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">shuffled_patients</span> <span class="o">=</span> <span class="n">patients</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">683</span><span class="p">,</span> <span class="n">with_replacement</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> 
<span class="n">training_set</span> <span class="o">=</span> <span class="n">shuffled_patients</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">342</span><span class="p">))</span>
<span class="n">test_set</span>  <span class="o">=</span> <span class="n">shuffled_patients</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">342</span><span class="p">,</span> <span class="mi">683</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s stick with 5 nearest neighbors, and see how well our classifier does.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">evaluate_accuracy</span><span class="p">(</span><span class="n">training_set</span><span class="p">,</span> <span class="n">test_set</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.967741935483871
</pre></div>
</div>
</div>
</div>
<p>Over 96% accuracy.  Not bad!  Once again, pretty darn good for such a simple technique.</p>
<p>As a footnote, you might have noticed that Brittany Wenger did even better.  What techniques did she use? One key innovation is that she incorporated a confidence score into her results: her algorithm had a way to determine when it was not able to make a confident prediction, and for those patients, it didn’t even try to predict their diagnosis.  Her algorithm was 99% accurate on the patients where it made a prediction – so that extension seemed to help quite a bit.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./chapters/17/5"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="../4/Implementing_the_Classifier.html" title="previous page"><span class="section-number">17.4. </span>Implementing the Classifier</a>
    <a class='right-next' id="next-link" href="../6/Multiple_Regression.html" title="next page"><span class="section-number">17.6. </span>Multiple Regression</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Ani Adhikari and John DeNero<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../../../_static/js/index.d3f166471bb80abb5163.js"></script>


    
    <!-- Google Analytics -->
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-148221575-1', 'auto');
      ga('set', 'anonymizeIp', true);
      ga('send', 'pageview');
    </script>
    <script async src='https://www.google-analytics.com/analytics.js'></script>
    <!-- End Google Analytics -->
    
  </body>
</html>