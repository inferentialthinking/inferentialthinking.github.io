<!DOCTYPE html><html lang="en" class="" style="scroll-padding:60px"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/><title>The Accuracy of the Classifier - Computational and Inferential Thinking</title><meta property="og:title" content="The Accuracy of the Classifier - Computational and Inferential Thinking"/><meta name="generator" content="mystmd"/><meta name="keywords" content=""/><meta name="image" content="/build/5e548385d4da863b59d51148bd5d0eeb.jpeg"/><meta property="og:image" content="/build/5e548385d4da863b59d51148bd5d0eeb.jpeg"/><link rel="stylesheet" href="/build/_assets/app-IZWEOBHI.css"/><link rel="stylesheet" href="/build/_assets/thebe-core-VKVHG5VY.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jupyter-matplotlib@0.11.3/css/mpl_widget.css"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-148221575-1"></script><script>window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-148221575-1');</script><link rel="icon" href="/favicon.ico"/><link rel="stylesheet" href="/myst-theme.css"/><script>
  const savedTheme = localStorage.getItem("myst:theme");
  const theme = window.matchMedia("(prefers-color-scheme: light)").matches ? 'light' : 'dark';
  const classes = document.documentElement.classList;
  const hasAnyTheme = classes.contains('light') || classes.contains('dark');
  if (!hasAnyTheme) classes.add(savedTheme ?? theme);
</script></head><body class="m-0 transition-colors duration-500 bg-white dark:bg-stone-900"><div class="fixed top-1 left-1 h-[0px] w-[0px] focus-within:z-40 focus-within:h-auto focus-within:w-auto bg-white overflow-hidden focus-within:p-2 focus-within:ring-1" aria-label="skip to content options"><a href="#skip-to-frontmatter" class="block px-2 py-1 text-black underline">Skip to article frontmatter</a><a href="#skip-to-article" class="block px-2 py-1 text-black underline">Skip to article content</a></div><div class="bg-white/80 backdrop-blur dark:bg-stone-900/80 shadow dark:shadow-stone-700 p-3 md:px-8 sticky w-screen top-0 z-30 h-[60px]"><nav class="flex items-center justify-between flex-nowrap max-w-[1440px] mx-auto"><div class="flex flex-row xl:min-w-[19.5rem] mr-2 sm:mr-7 justify-start items-center shrink-0"><div class="block xl:hidden"><button class="flex items-center border-stone-400 text-stone-800 hover:text-stone-900 dark:text-stone-200 hover:dark:text-stone-100"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="m-1"><path fill-rule="evenodd" d="M3 6.75A.75.75 0 0 1 3.75 6h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 6.75ZM3 12a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 12Zm0 5.25a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75a.75.75 0 0 1-.75-.75Z" clip-rule="evenodd"></path></svg><span class="sr-only">Open Menu</span></button></div><a class="flex items-center ml-3 dark:text-white w-fit md:ml-5 xl:ml-7" href="/"><div class="p-1 mr-3 dark:bg-white dark:rounded"><img src="/build/data8logo-7a6c5cd41fe4d513ca7e7f76d46e9670.png" class="h-9" alt="Computational and Inferential Thinking" height="2.25rem"/></div><span class="text-md sm:text-xl tracking-tight sm:mr-5">Computational and Inferential Thinking</span></a></div><div class="flex items-center flex-grow w-auto"><div class="flex-grow hidden text-md lg:block"></div><div class="flex-grow block"></div><button type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R74op:" data-state="closed" class="flex items-center h-10 aspect-square sm:w-64 text-left text-gray-400 border border-gray-300 dark:border-gray-600 rounded-lg bg-gray-50 dark:bg-gray-700 hover:ring-blue-500 dark:hover:ring-blue-500 hover:border-blue-500 dark:hover:border-blue-500"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="p-2.5 h-10 w-10 aspect-square"><path fill-rule="evenodd" d="M10.5 3.75a6.75 6.75 0 1 0 0 13.5 6.75 6.75 0 0 0 0-13.5ZM2.25 10.5a8.25 8.25 0 1 1 14.59 5.28l4.69 4.69a.75.75 0 1 1-1.06 1.06l-4.69-4.69A8.25 8.25 0 0 1 2.25 10.5Z" clip-rule="evenodd"></path></svg><span class="hidden sm:block grow">Search</span><div aria-hidden="true" class="items-center hidden mx-1 font-mono text-sm text-gray-400 sm:flex gap-x-1"><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none hide-mac">CTRL</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none show-mac">⌘</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none ">K</kbd><script>
;(() => {
const script = document.currentScript;
const root = script.parentElement;

const isMac = /mac/i.test(
      window.navigator.userAgentData?.platform ?? window.navigator.userAgent,
    );
root.querySelectorAll(".hide-mac").forEach(node => {node.classList.add(isMac ? "hidden" : "block")});
root.querySelectorAll(".show-mac").forEach(node => {node.classList.add(!isMac ? "hidden" : "block")});
})()</script></div></button><button class="theme rounded-full aspect-square border border-stone-700 dark:border-white hover:bg-neutral-100 border-solid overflow-hidden text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 w-8 h-8 mx-3" title="Toggle theme between light and dark mode" aria-label="Toggle theme between light and dark mode"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 hidden dark:block"><path fill-rule="evenodd" d="M9.528 1.718a.75.75 0 0 1 .162.819A8.97 8.97 0 0 0 9 6a9 9 0 0 0 9 9 8.97 8.97 0 0 0 3.463-.69.75.75 0 0 1 .981.98 10.503 10.503 0 0 1-9.694 6.46c-5.799 0-10.5-4.7-10.5-10.5 0-4.368 2.667-8.112 6.46-9.694a.75.75 0 0 1 .818.162Z" clip-rule="evenodd"></path></svg><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 dark:hidden"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v2.25m6.364.386-1.591 1.591M21 12h-2.25m-.386 6.364-1.591-1.591M12 18.75V21m-4.773-4.227-1.591 1.591M5.25 12H3m4.227-4.773L5.636 5.636M15.75 12a3.75 3.75 0 1 1-7.5 0 3.75 3.75 0 0 1 7.5 0Z"></path></svg></button><div class="block sm:hidden"></div><div class="hidden sm:block"></div></div></nav></div><div class="fixed xl:article-grid grid-gap xl:w-screen xl:pointer-events-none overflow-auto max-xl:min-w-[300px] hidden z-10" style="top:60px"><div class="pointer-events-auto xl:col-margin-left flex-col overflow-hidden hidden xl:flex"><div class="flex-grow py-6 overflow-y-auto primary-scrollbar"><nav aria-label="Navigation" class="overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px] lg:hidden"><div class="w-full px-1 dark:text-white font-medium"></div></nav><div class="my-3 border-b-2 lg:hidden"></div><nav aria-label="Table of Contents" class="flex-grow overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px]"><div class="w-full px-1 dark:text-white"><a title="Computational and Inferential Thinking" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30 font-bold" href="/">Computational and Inferential Thinking</a><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="1 What is Data Science?" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/01/what-is-data-science">1 What is Data Science?</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rmp8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:Rmp8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="2 Causality and Experiments" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/02/causality-and-experiments">2 Causality and Experiments</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rup8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:Rup8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="3 Programming in Python" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/03/programming-in-python">3 Programming in Python</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R16p8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R16p8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="4 Data Types" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/04/data-types">4 Data Types</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R1ep8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R1ep8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="5 Sequences" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/05/sequences">5 Sequences</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R1mp8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R1mp8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="6 Tables" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/06/tables">6 Tables</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R1up8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R1up8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="7 Visualization" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/07/visualization">7 Visualization</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R26p8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R26p8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="8 Functions and Tables" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/08/functions-and-tables">8 Functions and Tables</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R2ep8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R2ep8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="9 Randomness" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/09/randomness">9 Randomness</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R2mp8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R2mp8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="10 Sampling and Empirical Distributions" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/10/sampling-and-empirical-distributions">10 Sampling and Empirical Distributions</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R2up8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R2up8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="11 Testing Hypotheses" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/11/testing-hypotheses">11 Testing Hypotheses</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R36p8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R36p8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="12 Comparing Two Samples" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/12/comparing-two-samples">12 Comparing Two Samples</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R3ep8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R3ep8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="13 Estimation" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/13/estimation">13 Estimation</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R3mp8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R3mp8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="14 Why the Mean Matters" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/14/why-the-mean-matters">14 Why the Mean Matters</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R3up8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R3up8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="15 Prediction" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/15/prediction">15 Prediction</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R46p8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R46p8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="16 Inference for Regression" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/16/inference-for-regression">16 Inference for Regression</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R4ep8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R4ep8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="open" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="17 Classification" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow font-semibold text-blue-800 dark:text-blue-200" href="/chapters/17/classification">17 Classification</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R4mp8p:" aria-expanded="true" data-state="open"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="open" id="radix-:R4mp8p:" class="pl-3 pr-[2px] collapsible-content"><a title="17.1 Nearest Neighbors" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/chapters/17/1/nearest-neighbors">17.1 Nearest Neighbors</a><a title="17.2 Training and Testing" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/chapters/17/2/training-and-testing">17.2 Training and Testing</a><a title="17.3 Rows of Tables" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/chapters/17/3/rows-of-tables">17.3 Rows of Tables</a><a title="17.4 Implementing the Classifier" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/chapters/17/4/implementing-the-classifier">17.4 Implementing the Classifier</a><a title="17.5 The Accuracy of the Classifier" aria-current="page" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg bg-blue-300/30 active" href="/chapters/17/5/accuracy-of-the-classifier">17.5 The Accuracy of the Classifier</a><a title="17.6 Multiple Regression" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/chapters/17/6/multiple-regression">17.6 Multiple Regression</a></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="18 Updating Predictions" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/18/updating-predictions">18 Updating Predictions</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R4up8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R4up8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div></div></nav></div><div class="flex-none py-6 transition-all duration-700 translate-y-6 opacity-0"><a class="flex mx-auto text-gray-700 w-fit hover:text-blue-700 dark:text-gray-200 dark:hover:text-blue-400" href="https://mystmd.org/made-with-myst" target="_blank" rel="noreferrer"><svg style="width:24px;height:24px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" stroke="none"><g id="icon"><path fill="currentColor" d="M23.8,54.8v-3.6l4.7-0.8V17.5l-4.7-0.8V13H36l13.4,31.7h0.2l13-31.7h12.6v3.6l-4.7,0.8v32.9l4.7,0.8v3.6h-15
          v-3.6l4.9-0.8V20.8H65L51.4,53.3h-3.8l-14-32.5h-0.1l0.2,17.4v12.1l5,0.8v3.6H23.8z"></path><path fill="#F37726" d="M47,86.9c0-5.9-3.4-8.8-10.1-8.8h-8.4c-5.2,0-9.4-1.3-12.5-3.8c-3.1-2.5-5.4-6.2-6.8-11l4.8-1.6
          c1.8,5.6,6.4,8.6,13.8,8.8h9.2c6.4,0,10.8,2.5,13.1,7.5c2.3-5,6.7-7.5,13.1-7.5h8.4c7.8,0,12.7-2.9,14.6-8.7l4.8,1.6
          c-1.4,4.9-3.6,8.6-6.8,11.1c-3.1,2.5-7.3,3.7-12.4,3.8H63c-6.7,0-10,2.9-10,8.8"></path></g></svg><span class="self-center ml-2 text-sm">Made with MyST</span></a></div></div></div><main class="article-grid grid-gap"><article class="article-grid subgrid-gap col-screen article content"><div class="hidden"></div><div id="skip-to-frontmatter" aria-label="article frontmatter" class="mb-8 pt-9"><div class="flex items-center mb-5 h-6 text-sm font-light"><div class="flex-grow"></div><a href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" rel="noopener noreferrer" class="opacity-50 hover:opacity-100 text-inherit hover:text-inherit" aria-label="Content License: Creative Commons Attribution Non Commercial No Derivatives 4.0 International (CC-BY-NC-ND-4.0)"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mx-1"><title>Content License: Creative Commons Attribution Non Commercial No Derivatives 4.0 International (CC-BY-NC-ND-4.0)</title><path d="M12 2.2c2.7 0 5 1 7 2.9.9.9 1.6 2 2.1 3.1.5 1.2.7 2.4.7 3.8 0 1.3-.2 2.6-.7 3.8-.5 1.2-1.2 2.2-2.1 3.1-1 .9-2 1.7-3.2 2.2-1.2.5-2.5.7-3.7.7s-2.6-.3-3.8-.8c-1.2-.5-2.2-1.2-3.2-2.1s-1.6-2-2.1-3.2-.8-2.4-.8-3.7c0-1.3.2-2.5.7-3.7S4.2 6 5.1 5.1C7 3.2 9.3 2.2 12 2.2zM12 4c-2.2 0-4.1.8-5.6 2.3C5.6 7.1 5 8 4.6 9c-.4 1-.6 2-.6 3s.2 2.1.6 3c.4 1 1 1.8 1.8 2.6S8 19 9 19.4c1 .4 2 .6 3 .6s2.1-.2 3-.6c1-.4 1.9-1 2.7-1.8 1.5-1.5 2.3-3.3 2.3-5.6 0-1.1-.2-2.1-.6-3.1-.4-1-1-1.8-1.7-2.6C16.1 4.8 14.2 4 12 4zm-.1 6.4l-1.3.7c-.1-.3-.3-.5-.5-.6-.2-.1-.4-.2-.6-.2-.9 0-1.3.6-1.3 1.7 0 .5.1.9.3 1.3.2.3.5.5 1 .5.6 0 1-.3 1.2-.8l1.2.6c-.3.5-.6.9-1.1 1.1-.5.3-1 .4-1.5.4-.9 0-1.6-.3-2.1-.8-.5-.6-.8-1.3-.8-2.3 0-.9.3-1.7.8-2.2.6-.6 1.3-.8 2.1-.8 1.2 0 2.1.4 2.6 1.4zm5.6 0l-1.3.7c-.1-.3-.3-.5-.5-.6-.2-.1-.4-.2-.6-.2-.9 0-1.3.6-1.3 1.7 0 .5.1.9.3 1.3.2.3.5.5 1 .5.6 0 1-.3 1.2-.8l1.2.6c-.3.5-.6.9-1.1 1.1-.4.2-.9.3-1.4.3-.9 0-1.6-.3-2.1-.8s-.8-1.3-.8-2.2c0-.9.3-1.7.8-2.2.5-.5 1.2-.8 2-.8 1.2 0 2.1.4 2.6 1.4z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1"><title>Credit must be given to the creator</title><path d="M12 2.2c2.7 0 5 .9 6.9 2.8 1.9 1.9 2.8 4.2 2.8 6.9s-.9 5-2.8 6.8c-2 1.9-4.3 2.9-7 2.9-2.6 0-4.9-1-6.9-2.9-1.8-1.7-2.8-4-2.8-6.7s1-5 2.9-6.9C7 3.2 9.3 2.2 12 2.2zM12 4c-2.2 0-4.1.8-5.6 2.3C4.8 8 4 9.9 4 12c0 2.2.8 4 2.4 5.6C8 19.2 9.8 20 12 20c2.2 0 4.1-.8 5.7-2.4 1.5-1.5 2.3-3.3 2.3-5.6 0-2.2-.8-4.1-2.3-5.7C16.1 4.8 14.2 4 12 4zm2.6 5.6v4h-1.1v4.7h-3v-4.7H9.4v-4c0-.2.1-.3.2-.4.1-.2.2-.2.4-.2h4c.2 0 .3.1.4.2.2.1.2.2.2.4zm-4-2.5c0-.9.5-1.4 1.4-1.4s1.4.5 1.4 1.4c0 .9-.5 1.4-1.4 1.4s-1.4-.5-1.4-1.4z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1"><title>Only noncommercial uses of the work are permitted</title><path d="M12 2.2c2.7 0 5 .9 6.9 2.8 1.9 1.9 2.8 4.2 2.8 6.9s-.9 5-2.8 6.8c-2 1.9-4.3 2.9-7 2.9-2.6 0-4.9-1-6.9-2.9-1.9-1.9-2.9-4.2-2.9-6.9s1-5 2.9-6.9c2-1.7 4.3-2.7 7-2.7zM4.4 9.4C4.2 10.2 4 11 4 12c0 2.2.8 4 2.4 5.6C8 19.2 9.8 20 12 20c2.2 0 4.1-.8 5.7-2.4.6-.5 1-1.1 1.3-1.7l-3.7-1.6c-.1.6-.4 1.1-.9 1.5-.5.4-1.1.6-1.8.7V18h-1.1v-1.5c-1.1 0-2.1-.4-3-1.2l1.3-1.4c.6.6 1.4.9 2.2.9.3 0 .6-.1.9-.2.2-.2.4-.4.4-.7 0-.2-.1-.4-.3-.6l-.9-.4-1.1-.6-1.5-.7-5.1-2.2zM12 4c-2.2 0-4.1.8-5.6 2.3-.4.4-.7.9-1.1 1.3L9 9.3c.2-.5.5-.9 1-1.2.5-.3 1-.5 1.6-.5V6.1h1.1v1.5c.9 0 1.7.3 2.4.9l-1.3 1.3c-.5-.4-1.1-.6-1.7-.6-.3 0-.6.1-.8.2-.2.1-.3.3-.3.6 0 .1 0 .2.1.2l1.2.6.9.4 1.6.7 5 2.2c.2-.7.2-1.4.2-2.1 0-2.2-.8-4.1-2.3-5.7C16.1 4.8 14.2 4 12 4z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1"><title>No derivatives or adaptations of the work are permitted</title><path d="M12 2.2c2.7 0 5 .9 6.9 2.8 1.9 1.9 2.8 4.2 2.8 6.9s-.9 5-2.8 6.9c-2 1.9-4.3 2.9-7 2.9-2.6 0-4.9-1-6.9-2.9C3.2 17 2.2 14.7 2.2 12s1-5 2.9-6.9C7 3.2 9.3 2.2 12 2.2zM12 4c-2.2 0-4.1.8-5.6 2.4C4.8 8 4 9.9 4 12c0 2.2.8 4 2.4 5.6C8 19.2 9.8 20 12 20c2.2 0 4.1-.8 5.7-2.4 1.5-1.5 2.3-3.3 2.3-5.6 0-2.2-.8-4.1-2.3-5.6C16.1 4.8 14.2 4 12 4zm3.7 5.7v1.7H8.6V9.7h7.1zm0 3.1v1.7H8.6v-1.7h7.1z"></path></svg></a><a href="https://github.com/data-8/textbook" title="GitHub Repository: data-8/textbook" target="_blank" rel="noopener noreferrer" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1 opacity-60 hover:opacity-100"><path d="M12 2.5c-5.4 0-9.8 4.4-9.8 9.7 0 4.3 2.8 8 6.7 9.2.5.1.7-.2.7-.5v-1.8c-2.4.5-3.1-.6-3.3-1.1-.1-.3-.6-1.1-1-1.4-.3-.2-.8-.6 0-.6s1.3.7 1.5 1c.9 1.5 2.3 1.1 2.8.8.1-.6.3-1.1.6-1.3-2.2-.2-4.4-1.1-4.4-4.8 0-1.1.4-1.9 1-2.6-.1-.2-.4-1.2.1-2.6 0 0 .8-.3 2.7 1 .8-.2 1.6-.3 2.4-.3.8 0 1.7.1 2.4.3 1.9-1.3 2.7-1 2.7-1 .5 1.3.2 2.3.1 2.6.6.7 1 1.5 1 2.6 0 3.7-2.3 4.6-4.4 4.8.4.3.7.9.7 1.8V21c0 .3.2.6.7.5 3.9-1.3 6.6-4.9 6.6-9.2 0-5.4-4.4-9.8-9.8-9.8z"></path></svg></a><a href="https://github.com/data-8/textbook/edit/main/chapters/17/5/Accuracy_of_the_Classifier.ipynb" title="Edit This Page" target="_blank" rel="noopener noreferrer" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem" class="inline-block mr-1 opacity-60 hover:opacity-100"><path stroke-linecap="round" stroke-linejoin="round" d="m16.862 4.487 1.687-1.688a1.875 1.875 0 1 1 2.652 2.652L10.582 16.07a4.5 4.5 0 0 1-1.897 1.13L6 18l.8-2.685a4.5 4.5 0 0 1 1.13-1.897l8.932-8.931Zm0 0L19.5 7.125M18 14v4.75A2.25 2.25 0 0 1 15.75 21H5.25A2.25 2.25 0 0 1 3 18.75V8.25A2.25 2.25 0 0 1 5.25 6H10"></path></svg></a><div class="relative flex inline-block mx-1 grow-0" data-headlessui-state=""><button class="relative ml-2 -mr-1" id="headlessui-menu-button-:Rs8top:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Downloads</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem"><title>Download</title><path stroke-linecap="round" stroke-linejoin="round" d="M3 16.5v2.25A2.25 2.25 0 0 0 5.25 21h13.5A2.25 2.25 0 0 0 21 18.75V16.5M16.5 12 12 16.5m0 0L7.5 12m4.5 4.5V3"></path></svg></button></div></div><h1 class="mb-0"><span class="mr-3 select-none">17.5</span>The Accuracy of the Classifier</h1></div><div class="block my-10 lg:sticky lg:z-10 lg:h-0 lg:pt-0 lg:my-0 lg:ml-10 lg:col-margin-right" style="top:60px"><nav></nav></div><div id="skip-to-article"></div><div id="y24HSnUdvp" class="relative group/block"><p>To see how well our classifier does, we might put 50% of the data into the training set and the other 50% into the test set.  Basically, we are setting aside some data for later use, so we can use it to measure the accuracy of our classifier.  We’ve been calling that the <em>test set</em>. Sometimes people will call the data that you set aside for testing a <em>hold-out set</em>, and they’ll call this strategy for estimating accuracy the <em>hold-out method</em>.</p><p>Note that this approach requires great discipline.  Before you start applying machine learning methods, you have to take some of your data and set it aside for testing.  You must avoid using the test set for developing your classifier: you shouldn’t use it to help train your classifier or tweak its settings or for brainstorming ways to improve your classifier.  Instead, you should use it only once, at the very end, after you’ve finalized your classifier, when you want an unbiased estimate of its accuracy.</p></div><div id="F1H65qrMjI" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose hidden my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">import matplotlib
#matplotlib.use(&#x27;Agg&#x27;)
path_data = &#x27;../../../assets/data/&#x27;
from datascience import *
%matplotlib inline
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import numpy as np
import math
import scipy.stats as stats
plt.style.use(&#x27;fivethirtyeight&#x27;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="QU8pe-RBxVbncKQaK3YN4" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="VQkeUsHUUf" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose hidden my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def distance(point1, point2):
    &quot;&quot;&quot;Returns the distance between point1 and point2
    where each argument is an array 
    consisting of the coordinates of the point&quot;&quot;&quot;
    return np.sqrt(np.sum((point1 - point2)**2))

def all_distances(training, new_point):
    &quot;&quot;&quot;Returns an array of distances
    between each point in the training set
    and the new point (which is a row of attributes)&quot;&quot;&quot;
    attributes = training.drop(&#x27;Class&#x27;)
    def distance_from_point(row):
        return distance(np.array(new_point), np.array(row))
    return attributes.apply(distance_from_point)

def table_with_distances(training, new_point):
    &quot;&quot;&quot;Augments the training table 
    with a column of distances from new_point&quot;&quot;&quot;
    return training.with_column(&#x27;Distance&#x27;, all_distances(training, new_point))

def closest(training, new_point, k):
    &quot;&quot;&quot;Returns a table of the k rows of the augmented table
    corresponding to the k smallest distances&quot;&quot;&quot;
    with_dists = table_with_distances(training, new_point)
    sorted_by_distance = with_dists.sort(&#x27;Distance&#x27;)
    topk = sorted_by_distance.take(np.arange(k))
    return topk

def majority(topkclasses):
    ones = topkclasses.where(&#x27;Class&#x27;, are.equal_to(1)).num_rows
    zeros = topkclasses.where(&#x27;Class&#x27;, are.equal_to(0)).num_rows
    if ones &gt; zeros:
        return 1
    else:
        return 0

def classify(training, new_point, k):
    closestk = closest(training, new_point, k)
    topkclasses = closestk.select(&#x27;Class&#x27;)
    return majority(topkclasses)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="AhIZmlJwln1EsYTmZJPDv" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="k2RzX0fDCj" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose hidden my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">wine = Table.read_table(path_data + &#x27;wine.csv&#x27;)

# For converting Class to binary

def is_one(x):
    if x == 1:
        return 1
    else:
        return 0
    
wine = wine.with_column(&#x27;Class&#x27;, wine.apply(is_one, 0))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="-7xq2OL70nPEzUrhK7QnP" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="uukDVi7xCz" class="relative group/block"><h2 id="measuring-the-accuracy-of-our-wine-classifier" class="relative group"><span class="heading-text">Measuring the Accuracy of Our Wine Classifier</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#measuring-the-accuracy-of-our-wine-classifier" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>OK, so let’s apply the hold-out method to evaluate the effectiveness of the <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span></span>-nearest neighbor classifier for identifying wines.  The data set has 178 wines, so we’ll randomly permute the data set and put 89 of them in the training set and the remaining 89 in the test set.</p></div><div id="Sx9CrbA6Wr" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">shuffled_wine = wine.sample(with_replacement=False) 
training_set = shuffled_wine.take(np.arange(89))
test_set  = shuffled_wine.take(np.arange(89, 178))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="rauULiUFzTh5weyQbtFNa" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="yeVpMYNGdU" class="relative group/block"><p>We’ll train the classifier using the 89 wines in the training set, and evaluate how well it performs on the test set. To make our lives easier, we’ll write a function to evaluate a classifier on every wine in the test set:</p></div><div id="gq9D2luTSY" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def count_zero(array):
    &quot;&quot;&quot;Counts the number of 0&#x27;s in an array&quot;&quot;&quot;
    return len(array) - np.count_nonzero(array)

def count_equal(array1, array2):
    &quot;&quot;&quot;Takes two numerical arrays of equal length
    and counts the indices where the two are equal&quot;&quot;&quot;
    return count_zero(array1 - array2)

def evaluate_accuracy(training, test, k):
    test_attributes = test.drop(&#x27;Class&#x27;)
    def classify_testrow(row):
        return classify(training, row, k)
    c = test_attributes.apply(classify_testrow)
    return count_equal(c, test.column(&#x27;Class&#x27;)) / test.num_rows</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="9n_5f6rnWPbUB6MRN2bUf" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="YYenYfqEFG" class="relative group/block"><p>Now for the grand reveal -- let’s see how we did.  We’ll arbitrarily use <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">k=5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">5</span></span></span></span></span>.</p></div><div id="pAwPzWHqw6" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">evaluate_accuracy(training_set, test_set, 5)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="1HqhYEPDzRho3Q2cu7XHU" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><div class="font-mono text-sm whitespace-pre-wrap"><code><span>0.898876404494382</span></code></div></div></div><div id="eACinOLC9F" class="relative group/block"><p>The accuracy rate isn’t bad at all for a simple classifier.</p></div><div id="wXqOrrsqH9" class="relative group/block"><h2 id="breast-cancer-diagnosis" class="relative group"><span class="heading-text">Breast Cancer Diagnosis</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#breast-cancer-diagnosis" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>Now I want to do an example based on diagnosing breast cancer.  I was inspired by Brittany Wenger, who won the Google national science fair in 2012 as a 17-year old high school student.  Here’s Brittany:</p><img id="cerqKRnZCD" style="margin:0 auto" src="/build/5e548385d4da863b59d51148bd5d0eeb.jpeg" alt="Brittany Wenger" data-canonical-url="http://i.huffpost.com/gen/701499/thumbs/o-GSF83-570.jpg?3" class=""/><p>Brittany’s <a target="_blank" rel="noreferrer" href="https://sites.google.com/a/googlesciencefair.com/science-fair-2012-project-64a91af142a459cfb486ed5cb05f803b2eb41354-1333130785-87/home" class="">science fair project</a> was to build a classification algorithm to diagnose breast cancer.  She won grand prize for building an algorithm whose accuracy was almost 99%.</p><p>Let’s see how well we can do, with the ideas we’ve learned in this course.</p><p>So, let me tell you a little bit about the data set.  Basically, if a woman has a lump in her breast, the doctors may want to take a biopsy to see if it is cancerous.  There are several different procedures for doing that.  Brittany focused on fine needle aspiration (FNA), because it is less invasive than the alternatives.  The doctor gets a sample of the mass, puts it under a microscope, takes a picture, and a trained lab tech analyzes the picture to determine whether it is cancer or not.  We get a picture like one of the following:</p><img id="x2SoqamHOw" style="margin:0 auto" src="/build/benign-50c2c6cb85d8163dfef4b98d157d32e3.png" alt="benign" data-canonical-url="../../../images/benign.png" class=""/><img id="M45dPVAURx" style="margin:0 auto" src="/build/malignant-9b0b5ed1785fdc7bfc6c6d5131043cf7.png" alt="cancer" data-canonical-url="../../../images/malignant.png" class=""/><p>Unfortunately, distinguishing between benign vs malignant can be tricky.  So, researchers have studied the use of machine learning to help with this task.  The idea is that we’ll ask the lab tech to analyze the image and compute various attributes: things like the typical size of a cell, how much variation there is among the cell sizes, and so on.  Then, we’ll try to use this information to predict (classify) whether the sample is malignant or not.  We have a training set of past samples from women where the correct diagnosis is known, and we’ll hope that our machine learning algorithm can use those to learn how to predict the diagnosis for future samples.</p><p>We end up with the following data set.  For the “Class” column, 1 means malignant (cancer); 0 means benign (not cancer).</p></div><div id="dhR50f3HJ4" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">patients = Table.read_table(path_data + &#x27;breast-cancer.csv&#x27;).drop(&#x27;ID&#x27;)
patients</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="OqYZJfNKKt3VOy4ZVCbPo" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><div><div class="p-2.5">Loading...</div></div></div></div><div id="ohTVbynrb7" class="relative group/block"><p>So we have 9 different attributes.  I don’t know how to make a 9-dimensional scatterplot of all of them, so I’m going to pick two and plot them:</p></div><div id="mn3FH4PTHv" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">color_table = Table().with_columns(
    &#x27;Class&#x27;, make_array(1, 0),
    &#x27;Color&#x27;, make_array(&#x27;darkblue&#x27;, &#x27;gold&#x27;)
)
patients_with_colors = patients.join(&#x27;Class&#x27;, color_table)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="hzgEIap2hL67zvPej8q8i" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="K7GSFxtkZJ" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">patients_with_colors.scatter(&#x27;Bland Chromatin&#x27;, &#x27;Single Epithelial Cell Size&#x27;, group=&#x27;Color&#x27;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="WJmgHMfjyL8S2zWaa1IbT" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><img src="/build/04414e61459f9c4542b6559190d24a81.png" alt="&lt;Figure size 360x360 with 1 Axes&gt;"/></div></div><div id="hHCneQWUdQ" class="relative group/block"><p>Oops.  That plot is utterly misleading, because there are a bunch of points that have identical values for both the x- and y-coordinates.  To make it easier to see all the data points, I’m going to add a little bit of random jitter to the x- and y-values.  Here’s how that looks:</p></div><div id="JMVFOTdY9L" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose hidden my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def randomize_column(a):
    return a + np.random.normal(0.0, 0.09, size=len(a))
Table().with_columns(
        &#x27;Bland Chromatin (jittered)&#x27;, 
        randomize_column(patients.column(&#x27;Bland Chromatin&#x27;)),
        &#x27;Single Epithelial Cell Size (jittered)&#x27;, 
        randomize_column(patients.column(&#x27;Single Epithelial Cell Size&#x27;)),
        &#x27;Class&#x27;, patients.column(&#x27;Class&#x27;)
    ).join(&#x27;Class&#x27;, color_table).scatter(1, 2, group=&#x27;Color&#x27;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="V5eW9CScVKbKAfHlH1vf7" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><img src="/build/6aec59bee719a99db8a9dab0faa0287c.png" alt="&lt;Figure size 360x360 with 1 Axes&gt;"/></div></div><div id="T2GuZcoL6m" class="relative group/block"><p>For instance, you can see there are lots of samples with chromatin = 2 and epithelial cell size = 2; all non-cancerous.</p><p>Keep in mind that the jittering is just for visualization purposes, to make it easier to get a feeling for the data.  We’re ready to work with the data now, and we’ll use the original (unjittered) data.</p></div><div id="TIOU1YXGaI" class="relative group/block"><p>First we’ll create a training set and a test set. The data set has 683 patients, so we’ll randomly permute the data set and put 342 of them in the training set and the remaining 341 in the test set.</p></div><div id="xyTDDophEr" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">shuffled_patients = patients.sample(683, with_replacement=False) 
training_set = shuffled_patients.take(np.arange(342))
test_set  = shuffled_patients.take(np.arange(342, 683))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="gqBX-ZZg9op6sBg9fGiF1" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="ykj4Khspbv" class="relative group/block"><p>Let’s stick with 5 nearest neighbors, and see how well our classifier does.</p></div><div id="hIUotvkCNF" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">evaluate_accuracy(training_set, test_set, 5)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="bpuIQQ3ETUYt4zGzBgl1n" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><div class="font-mono text-sm whitespace-pre-wrap"><code><span>0.967741935483871</span></code></div></div></div><div id="DztSIGvL6F" class="relative group/block"><p>Over 96% accuracy.  Not bad!  Once again, pretty darn good for such a simple technique.</p><p>As a footnote, you might have noticed that Brittany Wenger did even better.  What techniques did she use? One key innovation is that she incorporated a confidence score into her results: her algorithm had a way to determine when it was not able to make a confident prediction, and for those patients, it didn’t even try to predict their diagnosis.  Her algorithm was 99% accurate on the patients where it made a prediction -- so that extension seemed to help quite a bit.</p></div><div></div><div class="flex pt-10 mb-10 space-x-4"><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/chapters/17/4/implementing-the-classifier"><div class="flex h-full align-middle"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:-translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M10.5 19.5 3 12m0 0 7.5-7.5M3 12h18"></path></svg><div class="flex-grow text-right"><div class="text-xs text-gray-500 dark:text-gray-400">Computational and Inferential Thinking</div>Implementing the Classifier</div></div></a><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/chapters/17/6/multiple-regression"><div class="flex h-full align-middle"><div class="flex-grow"><div class="text-xs text-gray-500 dark:text-gray-400">Computational and Inferential Thinking</div>Multiple Regression</div><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 4.5 21 12m0 0-7.5 7.5M21 12H3"></path></svg></div></a></div></article></main><footer class="article footer article-grid bg-white dark:bg-slate-950 mt-10 shadow-2xl shadow py-10"><p>By Ani Adhikari and John DeNero and David Wagner</p><p><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>©</mtext></mrow><annotation encoding="application/x-tex">\copyright</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;"></span><span class="mord text"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8889em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">c</span></span></span><span style="top:-3.1944em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body accent-full" style="left:0em;top:.2em;"><span class="mord">◯</span></span></span></span></span></span></span></span></span></span></span></span> Copyright 2022.</p></footer><script>((a,d)=>{if(!window.history.state||!window.history.state.key){let h=Math.random().toString(32).slice(2);window.history.replaceState({key:h},"")}try{let f=JSON.parse(sessionStorage.getItem(a)||"{}")[d||window.history.state.key];typeof f=="number"&&window.scrollTo(0,f)}catch(h){console.error(h),sessionStorage.removeItem(a)}})("positions", null)</script><link rel="modulepreload" href="/build/entry.client-UNPC4GT3.js"/><link rel="modulepreload" href="/build/_shared/chunk-OCTKKCIL.js"/><link rel="modulepreload" href="/build/_shared/chunk-UAI5KRM7.js"/><link rel="modulepreload" href="/build/_shared/chunk-2NH4LW52.js"/><link rel="modulepreload" href="/build/_shared/chunk-F7G67JTZ.js"/><link rel="modulepreload" href="/build/_shared/chunk-HBJK6BW3.js"/><link rel="modulepreload" href="/build/_shared/chunk-HYMQ7M2K.js"/><link rel="modulepreload" href="/build/_shared/chunk-OHOXABTA.js"/><link rel="modulepreload" href="/build/_shared/chunk-OCWQY3HK.js"/><link rel="modulepreload" href="/build/_shared/chunk-CPTH56EW.js"/><link rel="modulepreload" href="/build/_shared/chunk-3CVK3PYF.js"/><link rel="modulepreload" href="/build/_shared/chunk-J6FHCSRC.js"/><link rel="modulepreload" href="/build/_shared/chunk-S4SWV34C.js"/><link rel="modulepreload" href="/build/_shared/chunk-GUCIBHGO.js"/><link rel="modulepreload" href="/build/root-7TUVC4ZT.js"/><link rel="modulepreload" href="/build/_shared/chunk-INOWNUZ6.js"/><link rel="modulepreload" href="/build/routes/$-P6PGXPYX.js"/><script>window.__remixContext = {"url":"/chapters/17/5/accuracy-of-the-classifier","state":{"loaderData":{"root":{"config":{"version":2,"myst":"1.6.4","options":{"favicon":"/build/favicon-d41e56db71ddfa209ecfc531bddb86f4.ico","logo":"/build/data8logo-7a6c5cd41fe4d513ca7e7f76d46e9670.png","logo_text":"Computational and Inferential Thinking","analytics_google":"UA-148221575-1","folders":true},"parts":{"footer":{"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"By Ani Adhikari and John DeNero and David Wagner","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"EAaIiCejDm"}],"key":"CJ6XGUzLDM"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"inlineMath","value":"\\copyright","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmtext\u003e©\u003c/mtext\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\copyright\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8889em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord accent\"\u003e\u003cspan class=\"vlist-t\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.8889em;\"\u003e\u003cspan style=\"top:-3em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord\"\u003ec\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.1944em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"accent-body accent-full\" style=\"left:0em;top:.2em;\"\u003e\u003cspan class=\"mord\"\u003e◯\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"iaDNEu5lBo"},{"type":"text","value":" Copyright 2022.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"vcEqeiyODd"}],"key":"msJMbQSF2X"}],"key":"bmiVDYl7ZN"}],"key":"P6Q2SWujj7"},"frontmatter":{"parts":{},"license":{"content":{"id":"CC-BY-NC-ND-4.0","url":"https://creativecommons.org/licenses/by-nc-nd/4.0/","name":"Creative Commons Attribution Non Commercial No Derivatives 4.0 International","CC":true}},"github":"https://github.com/data-8/textbook","numbering":{"title":{"enabled":true}},"source_url":"https://github.com/data-8/textbook/blob/main/footer.md","edit_url":"https://github.com/data-8/textbook/edit/main/footer.md","enumerator":"19"}}},"nav":[],"actions":[],"projects":[{"license":{"content":{"id":"CC-BY-NC-ND-4.0","url":"https://creativecommons.org/licenses/by-nc-nd/4.0/","name":"Creative Commons Attribution Non Commercial No Derivatives 4.0 International","CC":true}},"numbering":{"title":{"enabled":true}},"title":"Computational and Inferential Thinking","authors":[{"nameParsed":{"literal":"Ani Adhikari","given":"Ani","family":"Adhikari"},"name":"Ani Adhikari","id":"contributors-myst-generated-uid-0"},{"nameParsed":{"literal":"John DeNero","given":"John","family":"DeNero"},"name":"John DeNero","id":"contributors-myst-generated-uid-1"},{"nameParsed":{"literal":"David Wagner","given":"David","family":"Wagner"},"name":"David Wagner","id":"contributors-myst-generated-uid-2"}],"github":"https://github.com/data-8/textbook","toc":[{"file":"chapters/intro.md"},{"children":[{"children":[{"file":"chapters/01/1/1/computational-tools.md"},{"file":"chapters/01/1/2/statistical-techniques.md"}],"file":"chapters/01/1/intro.md"},{"file":"chapters/01/2/why-data-science.md"},{"children":[{"file":"chapters/01/3/1/Literary_Characters.ipynb"},{"file":"chapters/01/3/2/Another_Kind_Of_Character.ipynb"}],"file":"chapters/01/3/Plotting_the_Classics.ipynb"}],"file":"chapters/01/what-is-data-science.md"},{"children":[{"file":"chapters/02/1/observation-and-visualization-john-snow-and-the-broad-street-pump.md","title":"John Snow and the Broad Street Pump"},{"file":"chapters/02/2/snow-s-grand-experiment.md"},{"file":"chapters/02/3/establishing-causality.md"},{"file":"chapters/02/4/randomization.md"},{"file":"chapters/02/5/endnote.md"}],"file":"chapters/02/causality-and-experiments.md"},{"children":[{"file":"chapters/03/1/Expressions.ipynb"},{"children":[{"file":"chapters/03/2/1/Growth.ipynb"}],"file":"chapters/03/2/Names.ipynb"},{"file":"chapters/03/3/Calls.ipynb"},{"file":"chapters/03/4/Introduction_to_Tables.ipynb"}],"file":"chapters/03/programming-in-python.md"},{"children":[{"file":"chapters/04/1/Numbers.ipynb"},{"children":[{"file":"chapters/04/2/1/String_Methods.ipynb"}],"file":"chapters/04/2/Strings.ipynb"},{"file":"chapters/04/3/Comparison.ipynb"}],"file":"chapters/04/Data_Types.ipynb"},{"children":[{"file":"chapters/05/1/Arrays.ipynb"},{"file":"chapters/05/2/Ranges.ipynb"},{"file":"chapters/05/3/More_on_Arrays.ipynb"}],"file":"chapters/05/Sequences.ipynb"},{"children":[{"file":"chapters/06/1/Sorting_Rows.ipynb"},{"file":"chapters/06/2/Selecting_Rows.ipynb"},{"file":"chapters/06/3/Example_Population_Trends.ipynb"},{"file":"chapters/06/4/Example_Sex_Ratios.ipynb"}],"file":"chapters/06/Tables.ipynb"},{"children":[{"file":"chapters/07/1/Visualizing_Categorical_Distributions.ipynb"},{"file":"chapters/07/2/Visualizing_Numerical_Distributions.ipynb"},{"file":"chapters/07/3/Overlaid_Graphs.ipynb"}],"file":"chapters/07/Visualization.ipynb"},{"children":[{"file":"chapters/08/1/Applying_a_Function_to_a_Column.ipynb"},{"file":"chapters/08/2/Classifying_by_One_Variable.ipynb"},{"file":"chapters/08/3/Cross-Classifying_by_More_than_One_Variable.ipynb"},{"file":"chapters/08/4/Joining_Tables_by_Columns.ipynb"},{"file":"chapters/08/5/Bike_Sharing_in_the_Bay_Area.ipynb"}],"file":"chapters/08/Functions_and_Tables.ipynb"},{"children":[{"file":"chapters/09/1/Conditional_Statements.ipynb"},{"file":"chapters/09/2/Iteration.ipynb"},{"file":"chapters/09/3/Simulation.ipynb"},{"file":"chapters/09/4/Monty_Hall_Problem.ipynb"},{"file":"chapters/09/5/Finding_Probabilities.ipynb"}],"file":"chapters/09/Randomness.ipynb"},{"children":[{"file":"chapters/10/1/Empirical_Distributions.ipynb"},{"file":"chapters/10/2/Sampling_from_a_Population.ipynb"},{"file":"chapters/10/3/Empirical_Distribution_of_a_Statistic.ipynb"},{"file":"chapters/10/4/Random_Sampling_in_Python.ipynb"}],"file":"chapters/10/Sampling_and_Empirical_Distributions.ipynb"},{"children":[{"file":"chapters/11/1/Assessing_a_Model.ipynb"},{"file":"chapters/11/2/Multiple_Categories.ipynb"},{"file":"chapters/11/3/Decisions_and_Uncertainty.ipynb"},{"file":"chapters/11/4/Error_Probabilities.ipynb"}],"file":"chapters/11/Testing_Hypotheses.md"},{"children":[{"file":"chapters/12/1/AB_Testing.ipynb"},{"file":"chapters/12/2/Causality.ipynb"},{"file":"chapters/12/3/Deflategate.ipynb"}],"file":"chapters/12/Comparing_Two_Samples.md"},{"children":[{"file":"chapters/13/1/Percentiles.ipynb"},{"file":"chapters/13/2/Bootstrap.ipynb"},{"file":"chapters/13/3/Confidence_Intervals.ipynb"},{"file":"chapters/13/4/Using_Confidence_Intervals.ipynb"}],"file":"chapters/13/Estimation.md"},{"children":[{"file":"chapters/14/1/Properties_of_the_Mean.ipynb"},{"file":"chapters/14/2/Variability.ipynb"},{"file":"chapters/14/3/SD_and_the_Normal_Curve.ipynb"},{"file":"chapters/14/4/Central_Limit_Theorem.ipynb"},{"file":"chapters/14/5/Variability_of_the_Sample_Mean.ipynb"},{"file":"chapters/14/6/Choosing_a_Sample_Size.ipynb"}],"file":"chapters/14/Why_the_Mean_Matters.md"},{"children":[{"file":"chapters/15/1/Correlation.ipynb"},{"file":"chapters/15/2/Regression_Line.ipynb"},{"file":"chapters/15/3/Method_of_Least_Squares.ipynb"},{"file":"chapters/15/4/Least_Squares_Regression.ipynb"},{"file":"chapters/15/5/Visual_Diagnostics.ipynb"},{"file":"chapters/15/6/Numerical_Diagnostics.ipynb"}],"file":"chapters/15/Prediction.ipynb"},{"children":[{"file":"chapters/16/1/Regression_Model.ipynb"},{"file":"chapters/16/2/Inference_for_the_True_Slope.ipynb"},{"file":"chapters/16/3/Prediction_Intervals.ipynb"}],"file":"chapters/16/Inference_for_Regression.md"},{"children":[{"file":"chapters/17/1/Nearest_Neighbors.ipynb"},{"file":"chapters/17/2/Training_and_Testing.ipynb"},{"file":"chapters/17/3/Rows_of_Tables.ipynb"},{"file":"chapters/17/4/Implementing_the_Classifier.ipynb"},{"file":"chapters/17/5/Accuracy_of_the_Classifier.ipynb"},{"file":"chapters/17/6/Multiple_Regression.ipynb"}],"file":"chapters/17/Classification.md"},{"children":[{"file":"chapters/18/1/More_Likely_than_Not_Binary_Classifier.ipynb"},{"file":"chapters/18/2/Making_Decisions.ipynb"}],"file":"chapters/18/Updating_Predictions.md"}],"exports":[],"bibliography":[],"index":"index","pages":[{"slug":"chapters.01.what-is-data-science","title":"What is Data Science?","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"1"},{"slug":"chapters.01.1.intro","title":"Introduction","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.1"},{"slug":"chapters.01.1.1.computational-tools","title":"Computational Tools","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.1.1"},{"slug":"chapters.01.1.2.statistical-techniques","title":"Statistical Techniques","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.1.2"},{"slug":"chapters.01.2.why-data-science","title":"Why Data Science?","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.2"},{"slug":"chapters.01.3.plotting-the-classics","title":"Plotting the Classics","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.3"},{"slug":"chapters.01.3.1.literary-characters","title":"Literary Characters","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.3.1"},{"slug":"chapters.01.3.2.another-kind-of-character","title":"Another Kind of Character","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.3.2"},{"slug":"chapters.02.causality-and-experiments","title":"Causality and Experiments","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"2"},{"slug":"chapters.02.1.observation-and-visualization-john-snow-and-the-br","title":"Observation and Visualization: John Snow and the Broad Street Pump","description":"","date":"","thumbnail":"/build/snow_map-a559f894ec65aa589b5d612f39960c8a.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.1"},{"slug":"chapters.02.2.snow-s-grand-experiment","title":"Snow’s “Grand Experiment”","description":"","date":"","thumbnail":"/build/snow_map2-922ad2b5eb1e1af2875642e9371ff78c.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.2"},{"slug":"chapters.02.3.establishing-causality","title":"Establishing Causality","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.3"},{"slug":"chapters.02.4.randomization","title":"Randomization","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.4"},{"slug":"chapters.02.5.endnote","title":"Endnote","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.5"},{"slug":"chapters.03.programming-in-python","title":"Programming in Python","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"3"},{"slug":"chapters.03.1.expressions","title":"Expressions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.1"},{"slug":"chapters.03.2.names","title":"Names","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.2"},{"slug":"chapters.03.2.1.growth","title":"Example: Growth Rates","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"3.2.1"},{"slug":"chapters.03.3.calls","title":"Call Expressions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.3"},{"slug":"chapters.03.4.introduction-to-tables","title":"Introduction to Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.4"},{"slug":"chapters.04.data-types","title":"Data Types","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"4"},{"slug":"chapters.04.1.numbers","title":"Numbers","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.1"},{"slug":"chapters.04.2.strings","title":"Strings","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.2"},{"slug":"chapters.04.2.1.string-methods","title":"String Methods","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"4.2.1"},{"slug":"chapters.04.3.comparison","title":"Comparisons","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.3"},{"slug":"chapters.05.sequences","title":"Sequences","description":"","date":"","thumbnail":"/build/global-land-TMAX-Tre-f4e8046cb3617080ace7162f525d2fdc.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"5"},{"slug":"chapters.05.1.arrays","title":"Arrays","description":"","date":"","thumbnail":"/build/array_arithmetic-21903924b73cec9cb83b421db6b76ed0.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.1"},{"slug":"chapters.05.2.ranges","title":"Ranges","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.2"},{"slug":"chapters.05.3.more-on-arrays","title":"More on Arrays","description":"","date":"","thumbnail":"/build/array_subtraction-a6b41be681a21bc81ed05b4daddb13cd.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.3"},{"slug":"chapters.06.tables","title":"Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"6"},{"slug":"chapters.06.1.sorting-rows","title":"Sorting Rows","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.1"},{"slug":"chapters.06.2.selecting-rows","title":"Selecting Rows","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.2"},{"slug":"chapters.06.3.example-population-trends","title":"Example: Population Trends","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.3"},{"slug":"chapters.06.4.example-sex-ratios","title":"Example: Sex Ratios","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.4"},{"slug":"chapters.07.visualization","title":"Visualization","description":"","date":"","thumbnail":"/build/C-3PO_droid-1fa7c0f010e1bd61cb242418203ccbd9.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"7"},{"slug":"chapters.07.1.visualizing-categorical-distributions","title":"Visualizing Categorical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.1"},{"slug":"chapters.07.2.visualizing-numerical-distributions","title":"Visualizing Numerical Distributions","description":"","date":"","thumbnail":"/build/ipad_battery-eba4b70625634dc8a9b850a43c992c66.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.2"},{"slug":"chapters.07.3.overlaid-graphs","title":"Overlaid Graphs","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.3"},{"slug":"chapters.08.functions-and-tables","title":"Functions and Tables","description":"","date":"","thumbnail":"/build/function_definition-b6e0ca12a5cd8a62fb46784f45744396.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"8"},{"slug":"chapters.08.1.applying-a-function-to-a-column","title":"Applying a Function to a Column","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.1"},{"slug":"chapters.08.2.classifying-by-one-variable","title":"Classifying by One Variable","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.2"},{"slug":"chapters.08.3.cross-classifying-by-more-than-one-variable","title":"Cross-Classifying by More than One Variable","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.3"},{"slug":"chapters.08.4.joining-tables-by-columns","title":"Joining Tables by Columns","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.4"},{"slug":"chapters.08.5.bike-sharing-in-the-bay-area","title":"Bike Sharing in the Bay Area","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.5"},{"slug":"chapters.09.randomness","title":"Randomness","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"9"},{"slug":"chapters.09.1.conditional-statements","title":"Conditional Statements","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.1"},{"slug":"chapters.09.2.iteration","title":"Iteration","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.2"},{"slug":"chapters.09.3.simulation","title":"Simulation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.3"},{"slug":"chapters.09.4.monty-hall-problem","title":"The Monty Hall Problem","description":"","date":"","thumbnail":"/build/monty_hall_goat-b1899404d996b314b7ddc961406d0737.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.4"},{"slug":"chapters.09.5.finding-probabilities","title":"Finding Probabilities","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.5"},{"slug":"chapters.10.sampling-and-empirical-distributions","title":"Sampling and Empirical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"10"},{"slug":"chapters.10.1.empirical-distributions","title":"Empirical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.1"},{"slug":"chapters.10.2.sampling-from-a-population","title":"Sampling from a Population","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.2"},{"slug":"chapters.10.3.empirical-distribution-of-a-statistic","title":"Empirical Distribution of a Statistic","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.3"},{"slug":"chapters.10.4.random-sampling-in-python","title":"Random Sampling in Python","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.4"},{"slug":"chapters.11.testing-hypotheses","title":"Testing Hypotheses","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"11"},{"slug":"chapters.11.1.assessing-a-model","title":"Assessing a Model","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.1"},{"slug":"chapters.11.2.multiple-categories","title":"Multiple Categories","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.2"},{"slug":"chapters.11.3.decisions-and-uncertainty","title":"Decisions and Uncertainty","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.3"},{"slug":"chapters.11.4.error-probabilities","title":"Error Probabilities","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.4"},{"slug":"chapters.12.comparing-two-samples","title":"Comparing Two Samples","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"12"},{"slug":"chapters.12.1.ab-testing","title":"A/B Testing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.1"},{"slug":"chapters.12.2.causality","title":"Causality","description":"","date":"","thumbnail":"/build/causality1-c2b9dd21638c4113770df93b4a9da373.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.2"},{"slug":"chapters.12.3.deflategate","title":"Deflategate","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.3"},{"slug":"chapters.13.estimation","title":"Estimation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"13"},{"slug":"chapters.13.1.percentiles","title":"Percentiles","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.1"},{"slug":"chapters.13.2.bootstrap","title":"The Bootstrap","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.2"},{"slug":"chapters.13.3.confidence-intervals","title":"Confidence Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.3"},{"slug":"chapters.13.4.using-confidence-intervals","title":"Using Confidence Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.4"},{"slug":"chapters.14.why-the-mean-matters","title":"Why the Mean Matters","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"14"},{"slug":"chapters.14.1.properties-of-the-mean","title":"Properties of the Mean","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.1"},{"slug":"chapters.14.2.variability","title":"Variability","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.2"},{"slug":"chapters.14.3.sd-and-the-normal-curve","title":"The SD and the Normal Curve","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.3"},{"slug":"chapters.14.4.central-limit-theorem","title":"The Central Limit Theorem","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.4"},{"slug":"chapters.14.5.variability-of-the-sample-mean","title":"The Variability of the Sample Mean","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.5"},{"slug":"chapters.14.6.choosing-a-sample-size","title":"Choosing a Sample Size","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.6"},{"slug":"chapters.15.prediction","title":"Prediction","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"15"},{"slug":"chapters.15.1.correlation","title":"Correlation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.1"},{"slug":"chapters.15.2.regression-line","title":"The Regression Line","description":"","date":"","thumbnail":"/build/regline-7acefd1a1cb6046b7341e62942ed5611.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.2"},{"slug":"chapters.15.3.method-of-least-squares","title":"The Method of Least Squares","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.3"},{"slug":"chapters.15.4.least-squares-regression","title":"Least Squares Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.4"},{"slug":"chapters.15.5.visual-diagnostics","title":"Visual Diagnostics","description":"","date":"","thumbnail":"/build/5f819b0045c6e81a4265dd506d7aaff9.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.5"},{"slug":"chapters.15.6.numerical-diagnostics","title":"Numerical Diagnostics","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.6"},{"slug":"chapters.16.inference-for-regression","title":"Inference for Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"16"},{"slug":"chapters.16.1.regression-model","title":"A Regression Model","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.1"},{"slug":"chapters.16.2.inference-for-the-true-slope","title":"Inference for the True Slope","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.2"},{"slug":"chapters.16.3.prediction-intervals","title":"Prediction Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.3"},{"slug":"chapters.17.classification","title":"Classification","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"17"},{"slug":"chapters.17.1.nearest-neighbors","title":"Nearest Neighbors","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.1"},{"slug":"chapters.17.2.training-and-testing","title":"Training and Testing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.2"},{"slug":"chapters.17.3.rows-of-tables","title":"Rows of Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.3"},{"slug":"chapters.17.4.implementing-the-classifier","title":"Implementing the Classifier","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.4"},{"slug":"chapters.17.5.accuracy-of-the-classifier","title":"The Accuracy of the Classifier","description":"","date":"","thumbnail":"/build/5e548385d4da863b59d51148bd5d0eeb.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.5"},{"slug":"chapters.17.6.multiple-regression","title":"Multiple Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.6"},{"slug":"chapters.18.updating-predictions","title":"Updating Predictions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"18"},{"slug":"chapters.18.1.more-likely-than-not-binary-classifier","title":"A “More Likely Than Not” Binary Classifier","description":"","date":"","thumbnail":"/build/tree_students-c1d10705c5238230fc0243eb6ba2ea13.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"18.1"},{"slug":"chapters.18.2.making-decisions","title":"Making Decisions","description":"","date":"","thumbnail":"/build/tree_disease_rare-175fa2f39033e58ca8f1110413b91794.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"18.2"}]}]},"CONTENT_CDN_PORT":"3100","MODE":"static"},"routes/$":{"config":{"version":2,"myst":"1.6.4","options":{"favicon":"/build/favicon-d41e56db71ddfa209ecfc531bddb86f4.ico","logo":"/build/data8logo-7a6c5cd41fe4d513ca7e7f76d46e9670.png","logo_text":"Computational and Inferential Thinking","analytics_google":"UA-148221575-1","folders":true},"parts":{"footer":{"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"By Ani Adhikari and John DeNero and David Wagner","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"EAaIiCejDm"}],"key":"CJ6XGUzLDM"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"inlineMath","value":"\\copyright","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmtext\u003e©\u003c/mtext\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\copyright\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8889em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord accent\"\u003e\u003cspan class=\"vlist-t\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.8889em;\"\u003e\u003cspan style=\"top:-3em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord\"\u003ec\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.1944em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"accent-body accent-full\" style=\"left:0em;top:.2em;\"\u003e\u003cspan class=\"mord\"\u003e◯\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"iaDNEu5lBo"},{"type":"text","value":" Copyright 2022.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"vcEqeiyODd"}],"key":"msJMbQSF2X"}],"key":"bmiVDYl7ZN"}],"key":"P6Q2SWujj7"},"frontmatter":{"parts":{},"license":{"content":{"id":"CC-BY-NC-ND-4.0","url":"https://creativecommons.org/licenses/by-nc-nd/4.0/","name":"Creative Commons Attribution Non Commercial No Derivatives 4.0 International","CC":true}},"github":"https://github.com/data-8/textbook","numbering":{"title":{"enabled":true}},"source_url":"https://github.com/data-8/textbook/blob/main/footer.md","edit_url":"https://github.com/data-8/textbook/edit/main/footer.md","enumerator":"19"}}},"nav":[],"actions":[],"projects":[{"license":{"content":{"id":"CC-BY-NC-ND-4.0","url":"https://creativecommons.org/licenses/by-nc-nd/4.0/","name":"Creative Commons Attribution Non Commercial No Derivatives 4.0 International","CC":true}},"numbering":{"title":{"enabled":true}},"title":"Computational and Inferential Thinking","authors":[{"nameParsed":{"literal":"Ani Adhikari","given":"Ani","family":"Adhikari"},"name":"Ani Adhikari","id":"contributors-myst-generated-uid-0"},{"nameParsed":{"literal":"John DeNero","given":"John","family":"DeNero"},"name":"John DeNero","id":"contributors-myst-generated-uid-1"},{"nameParsed":{"literal":"David Wagner","given":"David","family":"Wagner"},"name":"David Wagner","id":"contributors-myst-generated-uid-2"}],"github":"https://github.com/data-8/textbook","toc":[{"file":"chapters/intro.md"},{"children":[{"children":[{"file":"chapters/01/1/1/computational-tools.md"},{"file":"chapters/01/1/2/statistical-techniques.md"}],"file":"chapters/01/1/intro.md"},{"file":"chapters/01/2/why-data-science.md"},{"children":[{"file":"chapters/01/3/1/Literary_Characters.ipynb"},{"file":"chapters/01/3/2/Another_Kind_Of_Character.ipynb"}],"file":"chapters/01/3/Plotting_the_Classics.ipynb"}],"file":"chapters/01/what-is-data-science.md"},{"children":[{"file":"chapters/02/1/observation-and-visualization-john-snow-and-the-broad-street-pump.md","title":"John Snow and the Broad Street Pump"},{"file":"chapters/02/2/snow-s-grand-experiment.md"},{"file":"chapters/02/3/establishing-causality.md"},{"file":"chapters/02/4/randomization.md"},{"file":"chapters/02/5/endnote.md"}],"file":"chapters/02/causality-and-experiments.md"},{"children":[{"file":"chapters/03/1/Expressions.ipynb"},{"children":[{"file":"chapters/03/2/1/Growth.ipynb"}],"file":"chapters/03/2/Names.ipynb"},{"file":"chapters/03/3/Calls.ipynb"},{"file":"chapters/03/4/Introduction_to_Tables.ipynb"}],"file":"chapters/03/programming-in-python.md"},{"children":[{"file":"chapters/04/1/Numbers.ipynb"},{"children":[{"file":"chapters/04/2/1/String_Methods.ipynb"}],"file":"chapters/04/2/Strings.ipynb"},{"file":"chapters/04/3/Comparison.ipynb"}],"file":"chapters/04/Data_Types.ipynb"},{"children":[{"file":"chapters/05/1/Arrays.ipynb"},{"file":"chapters/05/2/Ranges.ipynb"},{"file":"chapters/05/3/More_on_Arrays.ipynb"}],"file":"chapters/05/Sequences.ipynb"},{"children":[{"file":"chapters/06/1/Sorting_Rows.ipynb"},{"file":"chapters/06/2/Selecting_Rows.ipynb"},{"file":"chapters/06/3/Example_Population_Trends.ipynb"},{"file":"chapters/06/4/Example_Sex_Ratios.ipynb"}],"file":"chapters/06/Tables.ipynb"},{"children":[{"file":"chapters/07/1/Visualizing_Categorical_Distributions.ipynb"},{"file":"chapters/07/2/Visualizing_Numerical_Distributions.ipynb"},{"file":"chapters/07/3/Overlaid_Graphs.ipynb"}],"file":"chapters/07/Visualization.ipynb"},{"children":[{"file":"chapters/08/1/Applying_a_Function_to_a_Column.ipynb"},{"file":"chapters/08/2/Classifying_by_One_Variable.ipynb"},{"file":"chapters/08/3/Cross-Classifying_by_More_than_One_Variable.ipynb"},{"file":"chapters/08/4/Joining_Tables_by_Columns.ipynb"},{"file":"chapters/08/5/Bike_Sharing_in_the_Bay_Area.ipynb"}],"file":"chapters/08/Functions_and_Tables.ipynb"},{"children":[{"file":"chapters/09/1/Conditional_Statements.ipynb"},{"file":"chapters/09/2/Iteration.ipynb"},{"file":"chapters/09/3/Simulation.ipynb"},{"file":"chapters/09/4/Monty_Hall_Problem.ipynb"},{"file":"chapters/09/5/Finding_Probabilities.ipynb"}],"file":"chapters/09/Randomness.ipynb"},{"children":[{"file":"chapters/10/1/Empirical_Distributions.ipynb"},{"file":"chapters/10/2/Sampling_from_a_Population.ipynb"},{"file":"chapters/10/3/Empirical_Distribution_of_a_Statistic.ipynb"},{"file":"chapters/10/4/Random_Sampling_in_Python.ipynb"}],"file":"chapters/10/Sampling_and_Empirical_Distributions.ipynb"},{"children":[{"file":"chapters/11/1/Assessing_a_Model.ipynb"},{"file":"chapters/11/2/Multiple_Categories.ipynb"},{"file":"chapters/11/3/Decisions_and_Uncertainty.ipynb"},{"file":"chapters/11/4/Error_Probabilities.ipynb"}],"file":"chapters/11/Testing_Hypotheses.md"},{"children":[{"file":"chapters/12/1/AB_Testing.ipynb"},{"file":"chapters/12/2/Causality.ipynb"},{"file":"chapters/12/3/Deflategate.ipynb"}],"file":"chapters/12/Comparing_Two_Samples.md"},{"children":[{"file":"chapters/13/1/Percentiles.ipynb"},{"file":"chapters/13/2/Bootstrap.ipynb"},{"file":"chapters/13/3/Confidence_Intervals.ipynb"},{"file":"chapters/13/4/Using_Confidence_Intervals.ipynb"}],"file":"chapters/13/Estimation.md"},{"children":[{"file":"chapters/14/1/Properties_of_the_Mean.ipynb"},{"file":"chapters/14/2/Variability.ipynb"},{"file":"chapters/14/3/SD_and_the_Normal_Curve.ipynb"},{"file":"chapters/14/4/Central_Limit_Theorem.ipynb"},{"file":"chapters/14/5/Variability_of_the_Sample_Mean.ipynb"},{"file":"chapters/14/6/Choosing_a_Sample_Size.ipynb"}],"file":"chapters/14/Why_the_Mean_Matters.md"},{"children":[{"file":"chapters/15/1/Correlation.ipynb"},{"file":"chapters/15/2/Regression_Line.ipynb"},{"file":"chapters/15/3/Method_of_Least_Squares.ipynb"},{"file":"chapters/15/4/Least_Squares_Regression.ipynb"},{"file":"chapters/15/5/Visual_Diagnostics.ipynb"},{"file":"chapters/15/6/Numerical_Diagnostics.ipynb"}],"file":"chapters/15/Prediction.ipynb"},{"children":[{"file":"chapters/16/1/Regression_Model.ipynb"},{"file":"chapters/16/2/Inference_for_the_True_Slope.ipynb"},{"file":"chapters/16/3/Prediction_Intervals.ipynb"}],"file":"chapters/16/Inference_for_Regression.md"},{"children":[{"file":"chapters/17/1/Nearest_Neighbors.ipynb"},{"file":"chapters/17/2/Training_and_Testing.ipynb"},{"file":"chapters/17/3/Rows_of_Tables.ipynb"},{"file":"chapters/17/4/Implementing_the_Classifier.ipynb"},{"file":"chapters/17/5/Accuracy_of_the_Classifier.ipynb"},{"file":"chapters/17/6/Multiple_Regression.ipynb"}],"file":"chapters/17/Classification.md"},{"children":[{"file":"chapters/18/1/More_Likely_than_Not_Binary_Classifier.ipynb"},{"file":"chapters/18/2/Making_Decisions.ipynb"}],"file":"chapters/18/Updating_Predictions.md"}],"exports":[],"bibliography":[],"index":"index","pages":[{"slug":"chapters.01.what-is-data-science","title":"What is Data Science?","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"1"},{"slug":"chapters.01.1.intro","title":"Introduction","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.1"},{"slug":"chapters.01.1.1.computational-tools","title":"Computational Tools","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.1.1"},{"slug":"chapters.01.1.2.statistical-techniques","title":"Statistical Techniques","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.1.2"},{"slug":"chapters.01.2.why-data-science","title":"Why Data Science?","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.2"},{"slug":"chapters.01.3.plotting-the-classics","title":"Plotting the Classics","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.3"},{"slug":"chapters.01.3.1.literary-characters","title":"Literary Characters","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.3.1"},{"slug":"chapters.01.3.2.another-kind-of-character","title":"Another Kind of Character","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.3.2"},{"slug":"chapters.02.causality-and-experiments","title":"Causality and Experiments","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"2"},{"slug":"chapters.02.1.observation-and-visualization-john-snow-and-the-br","title":"Observation and Visualization: John Snow and the Broad Street Pump","description":"","date":"","thumbnail":"/build/snow_map-a559f894ec65aa589b5d612f39960c8a.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.1"},{"slug":"chapters.02.2.snow-s-grand-experiment","title":"Snow’s “Grand Experiment”","description":"","date":"","thumbnail":"/build/snow_map2-922ad2b5eb1e1af2875642e9371ff78c.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.2"},{"slug":"chapters.02.3.establishing-causality","title":"Establishing Causality","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.3"},{"slug":"chapters.02.4.randomization","title":"Randomization","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.4"},{"slug":"chapters.02.5.endnote","title":"Endnote","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.5"},{"slug":"chapters.03.programming-in-python","title":"Programming in Python","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"3"},{"slug":"chapters.03.1.expressions","title":"Expressions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.1"},{"slug":"chapters.03.2.names","title":"Names","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.2"},{"slug":"chapters.03.2.1.growth","title":"Example: Growth Rates","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"3.2.1"},{"slug":"chapters.03.3.calls","title":"Call Expressions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.3"},{"slug":"chapters.03.4.introduction-to-tables","title":"Introduction to Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.4"},{"slug":"chapters.04.data-types","title":"Data Types","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"4"},{"slug":"chapters.04.1.numbers","title":"Numbers","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.1"},{"slug":"chapters.04.2.strings","title":"Strings","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.2"},{"slug":"chapters.04.2.1.string-methods","title":"String Methods","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"4.2.1"},{"slug":"chapters.04.3.comparison","title":"Comparisons","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.3"},{"slug":"chapters.05.sequences","title":"Sequences","description":"","date":"","thumbnail":"/build/global-land-TMAX-Tre-f4e8046cb3617080ace7162f525d2fdc.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"5"},{"slug":"chapters.05.1.arrays","title":"Arrays","description":"","date":"","thumbnail":"/build/array_arithmetic-21903924b73cec9cb83b421db6b76ed0.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.1"},{"slug":"chapters.05.2.ranges","title":"Ranges","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.2"},{"slug":"chapters.05.3.more-on-arrays","title":"More on Arrays","description":"","date":"","thumbnail":"/build/array_subtraction-a6b41be681a21bc81ed05b4daddb13cd.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.3"},{"slug":"chapters.06.tables","title":"Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"6"},{"slug":"chapters.06.1.sorting-rows","title":"Sorting Rows","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.1"},{"slug":"chapters.06.2.selecting-rows","title":"Selecting Rows","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.2"},{"slug":"chapters.06.3.example-population-trends","title":"Example: Population Trends","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.3"},{"slug":"chapters.06.4.example-sex-ratios","title":"Example: Sex Ratios","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.4"},{"slug":"chapters.07.visualization","title":"Visualization","description":"","date":"","thumbnail":"/build/C-3PO_droid-1fa7c0f010e1bd61cb242418203ccbd9.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"7"},{"slug":"chapters.07.1.visualizing-categorical-distributions","title":"Visualizing Categorical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.1"},{"slug":"chapters.07.2.visualizing-numerical-distributions","title":"Visualizing Numerical Distributions","description":"","date":"","thumbnail":"/build/ipad_battery-eba4b70625634dc8a9b850a43c992c66.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.2"},{"slug":"chapters.07.3.overlaid-graphs","title":"Overlaid Graphs","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.3"},{"slug":"chapters.08.functions-and-tables","title":"Functions and Tables","description":"","date":"","thumbnail":"/build/function_definition-b6e0ca12a5cd8a62fb46784f45744396.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"8"},{"slug":"chapters.08.1.applying-a-function-to-a-column","title":"Applying a Function to a Column","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.1"},{"slug":"chapters.08.2.classifying-by-one-variable","title":"Classifying by One Variable","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.2"},{"slug":"chapters.08.3.cross-classifying-by-more-than-one-variable","title":"Cross-Classifying by More than One Variable","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.3"},{"slug":"chapters.08.4.joining-tables-by-columns","title":"Joining Tables by Columns","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.4"},{"slug":"chapters.08.5.bike-sharing-in-the-bay-area","title":"Bike Sharing in the Bay Area","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.5"},{"slug":"chapters.09.randomness","title":"Randomness","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"9"},{"slug":"chapters.09.1.conditional-statements","title":"Conditional Statements","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.1"},{"slug":"chapters.09.2.iteration","title":"Iteration","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.2"},{"slug":"chapters.09.3.simulation","title":"Simulation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.3"},{"slug":"chapters.09.4.monty-hall-problem","title":"The Monty Hall Problem","description":"","date":"","thumbnail":"/build/monty_hall_goat-b1899404d996b314b7ddc961406d0737.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.4"},{"slug":"chapters.09.5.finding-probabilities","title":"Finding Probabilities","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.5"},{"slug":"chapters.10.sampling-and-empirical-distributions","title":"Sampling and Empirical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"10"},{"slug":"chapters.10.1.empirical-distributions","title":"Empirical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.1"},{"slug":"chapters.10.2.sampling-from-a-population","title":"Sampling from a Population","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.2"},{"slug":"chapters.10.3.empirical-distribution-of-a-statistic","title":"Empirical Distribution of a Statistic","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.3"},{"slug":"chapters.10.4.random-sampling-in-python","title":"Random Sampling in Python","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.4"},{"slug":"chapters.11.testing-hypotheses","title":"Testing Hypotheses","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"11"},{"slug":"chapters.11.1.assessing-a-model","title":"Assessing a Model","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.1"},{"slug":"chapters.11.2.multiple-categories","title":"Multiple Categories","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.2"},{"slug":"chapters.11.3.decisions-and-uncertainty","title":"Decisions and Uncertainty","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.3"},{"slug":"chapters.11.4.error-probabilities","title":"Error Probabilities","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.4"},{"slug":"chapters.12.comparing-two-samples","title":"Comparing Two Samples","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"12"},{"slug":"chapters.12.1.ab-testing","title":"A/B Testing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.1"},{"slug":"chapters.12.2.causality","title":"Causality","description":"","date":"","thumbnail":"/build/causality1-c2b9dd21638c4113770df93b4a9da373.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.2"},{"slug":"chapters.12.3.deflategate","title":"Deflategate","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.3"},{"slug":"chapters.13.estimation","title":"Estimation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"13"},{"slug":"chapters.13.1.percentiles","title":"Percentiles","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.1"},{"slug":"chapters.13.2.bootstrap","title":"The Bootstrap","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.2"},{"slug":"chapters.13.3.confidence-intervals","title":"Confidence Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.3"},{"slug":"chapters.13.4.using-confidence-intervals","title":"Using Confidence Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.4"},{"slug":"chapters.14.why-the-mean-matters","title":"Why the Mean Matters","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"14"},{"slug":"chapters.14.1.properties-of-the-mean","title":"Properties of the Mean","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.1"},{"slug":"chapters.14.2.variability","title":"Variability","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.2"},{"slug":"chapters.14.3.sd-and-the-normal-curve","title":"The SD and the Normal Curve","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.3"},{"slug":"chapters.14.4.central-limit-theorem","title":"The Central Limit Theorem","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.4"},{"slug":"chapters.14.5.variability-of-the-sample-mean","title":"The Variability of the Sample Mean","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.5"},{"slug":"chapters.14.6.choosing-a-sample-size","title":"Choosing a Sample Size","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.6"},{"slug":"chapters.15.prediction","title":"Prediction","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"15"},{"slug":"chapters.15.1.correlation","title":"Correlation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.1"},{"slug":"chapters.15.2.regression-line","title":"The Regression Line","description":"","date":"","thumbnail":"/build/regline-7acefd1a1cb6046b7341e62942ed5611.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.2"},{"slug":"chapters.15.3.method-of-least-squares","title":"The Method of Least Squares","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.3"},{"slug":"chapters.15.4.least-squares-regression","title":"Least Squares Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.4"},{"slug":"chapters.15.5.visual-diagnostics","title":"Visual Diagnostics","description":"","date":"","thumbnail":"/build/5f819b0045c6e81a4265dd506d7aaff9.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.5"},{"slug":"chapters.15.6.numerical-diagnostics","title":"Numerical Diagnostics","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.6"},{"slug":"chapters.16.inference-for-regression","title":"Inference for Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"16"},{"slug":"chapters.16.1.regression-model","title":"A Regression Model","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.1"},{"slug":"chapters.16.2.inference-for-the-true-slope","title":"Inference for the True Slope","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.2"},{"slug":"chapters.16.3.prediction-intervals","title":"Prediction Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.3"},{"slug":"chapters.17.classification","title":"Classification","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"17"},{"slug":"chapters.17.1.nearest-neighbors","title":"Nearest Neighbors","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.1"},{"slug":"chapters.17.2.training-and-testing","title":"Training and Testing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.2"},{"slug":"chapters.17.3.rows-of-tables","title":"Rows of Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.3"},{"slug":"chapters.17.4.implementing-the-classifier","title":"Implementing the Classifier","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.4"},{"slug":"chapters.17.5.accuracy-of-the-classifier","title":"The Accuracy of the Classifier","description":"","date":"","thumbnail":"/build/5e548385d4da863b59d51148bd5d0eeb.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.5"},{"slug":"chapters.17.6.multiple-regression","title":"Multiple Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.6"},{"slug":"chapters.18.updating-predictions","title":"Updating Predictions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"18"},{"slug":"chapters.18.1.more-likely-than-not-binary-classifier","title":"A “More Likely Than Not” Binary Classifier","description":"","date":"","thumbnail":"/build/tree_students-c1d10705c5238230fc0243eb6ba2ea13.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"18.1"},{"slug":"chapters.18.2.making-decisions","title":"Making Decisions","description":"","date":"","thumbnail":"/build/tree_disease_rare-175fa2f39033e58ca8f1110413b91794.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"18.2"}]}]},"page":{"version":2,"kind":"Notebook","sha256":"7dc7cb7596020241c548d773e22a1998477507871bec64f34da79d9126b9f289","slug":"chapters.17.5.accuracy-of-the-classifier","location":"/chapters/17/5/Accuracy_of_the_Classifier.ipynb","dependencies":[],"frontmatter":{"title":"The Accuracy of the Classifier","content_includes_title":false,"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"license":{"content":{"id":"CC-BY-NC-ND-4.0","url":"https://creativecommons.org/licenses/by-nc-nd/4.0/","name":"Creative Commons Attribution Non Commercial No Derivatives 4.0 International","CC":true}},"github":"https://github.com/data-8/textbook","numbering":{"title":{"enabled":true,"offset":1}},"source_url":"https://github.com/data-8/textbook/blob/main/chapters/17/5/Accuracy_of_the_Classifier.ipynb","edit_url":"https://github.com/data-8/textbook/edit/main/chapters/17/5/Accuracy_of_the_Classifier.ipynb","enumerator":"17.5","thumbnail":"/build/5e548385d4da863b59d51148bd5d0eeb.jpeg","exports":[{"format":"ipynb","filename":"Accuracy_of_the_Classifier.ipynb","url":"/build/Accuracy_of_the_Clas-28b9d46b586c538f69c7e05afbc847c2.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"To see how well our classifier does, we might put 50% of the data into the training set and the other 50% into the test set.  Basically, we are setting aside some data for later use, so we can use it to measure the accuracy of our classifier.  We’ve been calling that the ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"OWXJgfBK3x"},{"type":"emphasis","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"test set","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"hNd8B34dXy"}],"key":"oCwBQOe93h"},{"type":"text","value":". Sometimes people will call the data that you set aside for testing a ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"pZbZNw9B3d"},{"type":"emphasis","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"hold-out set","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"AZ1SBUcOKG"}],"key":"i3ZzImInQN"},{"type":"text","value":", and they’ll call this strategy for estimating accuracy the ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"Q8OJUEZt4j"},{"type":"emphasis","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"hold-out method","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"Cg1tvQ9RDD"}],"key":"U0hW7a4faM"},{"type":"text","value":".","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"hdQrwsJKZg"}],"key":"JiCVyu4SFi"},{"type":"paragraph","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"Note that this approach requires great discipline.  Before you start applying machine learning methods, you have to take some of your data and set it aside for testing.  You must avoid using the test set for developing your classifier: you shouldn’t use it to help train your classifier or tweak its settings or for brainstorming ways to improve your classifier.  Instead, you should use it only once, at the very end, after you’ve finalized your classifier, when you want an unbiased estimate of its accuracy.","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"NtC9D65lqw"}],"key":"UBPOqgUral"}],"key":"y24HSnUdvp"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"import matplotlib\n#matplotlib.use('Agg')\npath_data = '../../../assets/data/'\nfrom datascience import *\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport numpy as np\nimport math\nimport scipy.stats as stats\nplt.style.use('fivethirtyeight')","visibility":"remove","key":"imHWlnatki"},{"type":"output","id":"QU8pe-RBxVbncKQaK3YN4","data":[],"visibility":"show","key":"fLLacHu372"}],"visibility":"show","key":"F1H65qrMjI"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"def distance(point1, point2):\n    \"\"\"Returns the distance between point1 and point2\n    where each argument is an array \n    consisting of the coordinates of the point\"\"\"\n    return np.sqrt(np.sum((point1 - point2)**2))\n\ndef all_distances(training, new_point):\n    \"\"\"Returns an array of distances\n    between each point in the training set\n    and the new point (which is a row of attributes)\"\"\"\n    attributes = training.drop('Class')\n    def distance_from_point(row):\n        return distance(np.array(new_point), np.array(row))\n    return attributes.apply(distance_from_point)\n\ndef table_with_distances(training, new_point):\n    \"\"\"Augments the training table \n    with a column of distances from new_point\"\"\"\n    return training.with_column('Distance', all_distances(training, new_point))\n\ndef closest(training, new_point, k):\n    \"\"\"Returns a table of the k rows of the augmented table\n    corresponding to the k smallest distances\"\"\"\n    with_dists = table_with_distances(training, new_point)\n    sorted_by_distance = with_dists.sort('Distance')\n    topk = sorted_by_distance.take(np.arange(k))\n    return topk\n\ndef majority(topkclasses):\n    ones = topkclasses.where('Class', are.equal_to(1)).num_rows\n    zeros = topkclasses.where('Class', are.equal_to(0)).num_rows\n    if ones \u003e zeros:\n        return 1\n    else:\n        return 0\n\ndef classify(training, new_point, k):\n    closestk = closest(training, new_point, k)\n    topkclasses = closestk.select('Class')\n    return majority(topkclasses)","visibility":"remove","key":"DICFRZFuXR"},{"type":"output","id":"AhIZmlJwln1EsYTmZJPDv","data":[],"visibility":"show","key":"fcMs3GWZE0"}],"visibility":"show","key":"VQkeUsHUUf"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"wine = Table.read_table(path_data + 'wine.csv')\n\n# For converting Class to binary\n\ndef is_one(x):\n    if x == 1:\n        return 1\n    else:\n        return 0\n    \nwine = wine.with_column('Class', wine.apply(is_one, 0))","visibility":"remove","key":"AZ93bCYGCT"},{"type":"output","id":"-7xq2OL70nPEzUrhK7QnP","data":[],"visibility":"show","key":"L4gKe5HiF7"}],"visibility":"show","key":"k2RzX0fDCj"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Measuring the Accuracy of Our Wine Classifier","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"z5AQyrS39s"}],"identifier":"measuring-the-accuracy-of-our-wine-classifier","label":"Measuring the Accuracy of Our Wine Classifier","html_id":"measuring-the-accuracy-of-our-wine-classifier","implicit":true,"key":"L9i3jWyfqF"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"OK, so let’s apply the hold-out method to evaluate the effectiveness of the ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"fwGW7Gpvy7"},{"type":"inlineMath","value":"k","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ek\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ek\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03148em;\"\u003ek\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"aSD99Ndup9"},{"type":"text","value":"-nearest neighbor classifier for identifying wines.  The data set has 178 wines, so we’ll randomly permute the data set and put 89 of them in the training set and the remaining 89 in the test set.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"TpSIh0VcIW"}],"key":"pv6lIjar6Q"}],"key":"uukDVi7xCz"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"shuffled_wine = wine.sample(with_replacement=False) \ntraining_set = shuffled_wine.take(np.arange(89))\ntest_set  = shuffled_wine.take(np.arange(89, 178))","key":"gaDid1OgOJ"},{"type":"output","id":"rauULiUFzTh5weyQbtFNa","data":[],"key":"r0IvoBC23v"}],"key":"Sx9CrbA6Wr"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"We’ll train the classifier using the 89 wines in the training set, and evaluate how well it performs on the test set. To make our lives easier, we’ll write a function to evaluate a classifier on every wine in the test set:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Esh14OvGrm"}],"key":"lmYOPx72OH"}],"key":"yeVpMYNGdU"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def count_zero(array):\n    \"\"\"Counts the number of 0's in an array\"\"\"\n    return len(array) - np.count_nonzero(array)\n\ndef count_equal(array1, array2):\n    \"\"\"Takes two numerical arrays of equal length\n    and counts the indices where the two are equal\"\"\"\n    return count_zero(array1 - array2)\n\ndef evaluate_accuracy(training, test, k):\n    test_attributes = test.drop('Class')\n    def classify_testrow(row):\n        return classify(training, row, k)\n    c = test_attributes.apply(classify_testrow)\n    return count_equal(c, test.column('Class')) / test.num_rows","key":"ymdDRwBjYg"},{"type":"output","id":"9n_5f6rnWPbUB6MRN2bUf","data":[],"key":"ETpSNn40OY"}],"key":"gq9D2luTSY"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Now for the grand reveal -- let’s see how we did.  We’ll arbitrarily use ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"UnNS2WOsWb"},{"type":"inlineMath","value":"k=5","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ek\u003c/mi\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmn\u003e5\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ek=5\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03148em;\"\u003ek\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e5\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"X8FB42wD84"},{"type":"text","value":".","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"C76TVhPiwJ"}],"key":"insBQS0DP4"}],"key":"YYenYfqEFG"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"evaluate_accuracy(training_set, test_set, 5)","key":"mASIHNEhM6"},{"type":"output","id":"1HqhYEPDzRho3Q2cu7XHU","data":[{"output_type":"execute_result","execution_count":6,"metadata":{},"data":{"text/plain":{"content":"0.898876404494382","content_type":"text/plain"}}}],"key":"qT8pr8eaZ7"}],"key":"pAwPzWHqw6"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The accuracy rate isn’t bad at all for a simple classifier.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"l8T3x3NSzi"}],"key":"pXtcr77hTq"}],"key":"eACinOLC9F"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Breast Cancer Diagnosis","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"KG9FLsaeXm"}],"identifier":"breast-cancer-diagnosis","label":"Breast Cancer Diagnosis","html_id":"breast-cancer-diagnosis","implicit":true,"key":"x8oWvEXJ5H"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Now I want to do an example based on diagnosing breast cancer.  I was inspired by Brittany Wenger, who won the Google national science fair in 2012 as a 17-year old high school student.  Here’s Brittany:","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"FFPUIy289n"}],"key":"iAsGFMOp6f"},{"type":"image","url":"/build/5e548385d4da863b59d51148bd5d0eeb.jpeg","alt":"Brittany Wenger","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"cerqKRnZCD","urlSource":"http://i.huffpost.com/gen/701499/thumbs/o-GSF83-570.jpg?3"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Brittany’s ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"Fu5OyjEGJ4"},{"type":"link","url":"https://sites.google.com/a/googlesciencefair.com/science-fair-2012-project-64a91af142a459cfb486ed5cb05f803b2eb41354-1333130785-87/home","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"science fair project","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"JMJqGcSN4O"}],"urlSource":"https://sites.google.com/a/googlesciencefair.com/science-fair-2012-project-64a91af142a459cfb486ed5cb05f803b2eb41354-1333130785-87/home","key":"xxTCYkNHj2"},{"type":"text","value":" was to build a classification algorithm to diagnose breast cancer.  She won grand prize for building an algorithm whose accuracy was almost 99%.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"vm3ssozs02"}],"key":"I0IFqv97OK"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Let’s see how well we can do, with the ideas we’ve learned in this course.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"rdxkG0P6I1"}],"key":"mueWHrKA92"},{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"So, let me tell you a little bit about the data set.  Basically, if a woman has a lump in her breast, the doctors may want to take a biopsy to see if it is cancerous.  There are several different procedures for doing that.  Brittany focused on fine needle aspiration (FNA), because it is less invasive than the alternatives.  The doctor gets a sample of the mass, puts it under a microscope, takes a picture, and a trained lab tech analyzes the picture to determine whether it is cancer or not.  We get a picture like one of the following:","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"gARGsIc4vj"}],"key":"mofjkVvOC9"},{"type":"image","url":"/build/benign-50c2c6cb85d8163dfef4b98d157d32e3.png","alt":"benign","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"x2SoqamHOw","urlSource":"../../../images/benign.png"},{"type":"image","url":"/build/malignant-9b0b5ed1785fdc7bfc6c6d5131043cf7.png","alt":"cancer","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"M45dPVAURx","urlSource":"../../../images/malignant.png"},{"type":"paragraph","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"Unfortunately, distinguishing between benign vs malignant can be tricky.  So, researchers have studied the use of machine learning to help with this task.  The idea is that we’ll ask the lab tech to analyze the image and compute various attributes: things like the typical size of a cell, how much variation there is among the cell sizes, and so on.  Then, we’ll try to use this information to predict (classify) whether the sample is malignant or not.  We have a training set of past samples from women where the correct diagnosis is known, and we’ll hope that our machine learning algorithm can use those to learn how to predict the diagnosis for future samples.","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"DJmKU893Jo"}],"key":"pFktzQjedA"},{"type":"paragraph","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"We end up with the following data set.  For the “Class” column, 1 means malignant (cancer); 0 means benign (not cancer).","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"jeJN2mYRiI"}],"key":"WRpdSYHI11"}],"key":"wXqOrrsqH9"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"patients = Table.read_table(path_data + 'breast-cancer.csv').drop('ID')\npatients","key":"SZ9DFkedBc"},{"type":"output","id":"OqYZJfNKKt3VOy4ZVCbPo","data":[{"output_type":"execute_result","execution_count":7,"metadata":{},"data":{"text/html":{"content":"\u003ctable border=\"1\" class=\"dataframe\"\u003e\n    \u003cthead\u003e\n        \u003ctr\u003e\n            \u003cth\u003eClump Thickness\u003c/th\u003e \u003cth\u003eUniformity of Cell Size\u003c/th\u003e \u003cth\u003eUniformity of Cell Shape\u003c/th\u003e \u003cth\u003eMarginal Adhesion\u003c/th\u003e \u003cth\u003eSingle Epithelial Cell Size\u003c/th\u003e \u003cth\u003eBare Nuclei\u003c/th\u003e \u003cth\u003eBland Chromatin\u003c/th\u003e \u003cth\u003eNormal Nucleoli\u003c/th\u003e \u003cth\u003eMitoses\u003c/th\u003e \u003cth\u003eClass\u003c/th\u003e\n        \u003c/tr\u003e\n    \u003c/thead\u003e\n    \u003ctbody\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e5              \u003c/td\u003e \u003ctd\u003e1                      \u003c/td\u003e \u003ctd\u003e1                       \u003c/td\u003e \u003ctd\u003e1                \u003c/td\u003e \u003ctd\u003e2                          \u003c/td\u003e \u003ctd\u003e1          \u003c/td\u003e \u003ctd\u003e3              \u003c/td\u003e \u003ctd\u003e1              \u003c/td\u003e \u003ctd\u003e1      \u003c/td\u003e \u003ctd\u003e0    \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e5              \u003c/td\u003e \u003ctd\u003e4                      \u003c/td\u003e \u003ctd\u003e4                       \u003c/td\u003e \u003ctd\u003e5                \u003c/td\u003e \u003ctd\u003e7                          \u003c/td\u003e \u003ctd\u003e10         \u003c/td\u003e \u003ctd\u003e3              \u003c/td\u003e \u003ctd\u003e2              \u003c/td\u003e \u003ctd\u003e1      \u003c/td\u003e \u003ctd\u003e0    \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e3              \u003c/td\u003e \u003ctd\u003e1                      \u003c/td\u003e \u003ctd\u003e1                       \u003c/td\u003e \u003ctd\u003e1                \u003c/td\u003e \u003ctd\u003e2                          \u003c/td\u003e \u003ctd\u003e2          \u003c/td\u003e \u003ctd\u003e3              \u003c/td\u003e \u003ctd\u003e1              \u003c/td\u003e \u003ctd\u003e1      \u003c/td\u003e \u003ctd\u003e0    \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e6              \u003c/td\u003e \u003ctd\u003e8                      \u003c/td\u003e \u003ctd\u003e8                       \u003c/td\u003e \u003ctd\u003e1                \u003c/td\u003e \u003ctd\u003e3                          \u003c/td\u003e \u003ctd\u003e4          \u003c/td\u003e \u003ctd\u003e3              \u003c/td\u003e \u003ctd\u003e7              \u003c/td\u003e \u003ctd\u003e1      \u003c/td\u003e \u003ctd\u003e0    \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e4              \u003c/td\u003e \u003ctd\u003e1                      \u003c/td\u003e \u003ctd\u003e1                       \u003c/td\u003e \u003ctd\u003e3                \u003c/td\u003e \u003ctd\u003e2                          \u003c/td\u003e \u003ctd\u003e1          \u003c/td\u003e \u003ctd\u003e3              \u003c/td\u003e \u003ctd\u003e1              \u003c/td\u003e \u003ctd\u003e1      \u003c/td\u003e \u003ctd\u003e0    \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e8              \u003c/td\u003e \u003ctd\u003e10                     \u003c/td\u003e \u003ctd\u003e10                      \u003c/td\u003e \u003ctd\u003e8                \u003c/td\u003e \u003ctd\u003e7                          \u003c/td\u003e \u003ctd\u003e10         \u003c/td\u003e \u003ctd\u003e9              \u003c/td\u003e \u003ctd\u003e7              \u003c/td\u003e \u003ctd\u003e1      \u003c/td\u003e \u003ctd\u003e1    \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e1              \u003c/td\u003e \u003ctd\u003e1                      \u003c/td\u003e \u003ctd\u003e1                       \u003c/td\u003e \u003ctd\u003e1                \u003c/td\u003e \u003ctd\u003e2                          \u003c/td\u003e \u003ctd\u003e10         \u003c/td\u003e \u003ctd\u003e3              \u003c/td\u003e \u003ctd\u003e1              \u003c/td\u003e \u003ctd\u003e1      \u003c/td\u003e \u003ctd\u003e0    \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e2              \u003c/td\u003e \u003ctd\u003e1                      \u003c/td\u003e \u003ctd\u003e2                       \u003c/td\u003e \u003ctd\u003e1                \u003c/td\u003e \u003ctd\u003e2                          \u003c/td\u003e \u003ctd\u003e1          \u003c/td\u003e \u003ctd\u003e3              \u003c/td\u003e \u003ctd\u003e1              \u003c/td\u003e \u003ctd\u003e1      \u003c/td\u003e \u003ctd\u003e0    \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e2              \u003c/td\u003e \u003ctd\u003e1                      \u003c/td\u003e \u003ctd\u003e1                       \u003c/td\u003e \u003ctd\u003e1                \u003c/td\u003e \u003ctd\u003e2                          \u003c/td\u003e \u003ctd\u003e1          \u003c/td\u003e \u003ctd\u003e1              \u003c/td\u003e \u003ctd\u003e1              \u003c/td\u003e \u003ctd\u003e5      \u003c/td\u003e \u003ctd\u003e0    \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e4              \u003c/td\u003e \u003ctd\u003e2                      \u003c/td\u003e \u003ctd\u003e1                       \u003c/td\u003e \u003ctd\u003e1                \u003c/td\u003e \u003ctd\u003e2                          \u003c/td\u003e \u003ctd\u003e1          \u003c/td\u003e \u003ctd\u003e2              \u003c/td\u003e \u003ctd\u003e1              \u003c/td\u003e \u003ctd\u003e1      \u003c/td\u003e \u003ctd\u003e0    \u003c/td\u003e\n        \u003c/tr\u003e\n    \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e... (673 rows omitted)\u003c/p\u003e","content_type":"text/html"},"text/plain":{"content":"Clump Thickness | Uniformity of Cell Size | Uniformity of Cell Shape | Marginal Adhesion | Single Epithelial Cell Size | Bare Nuclei | Bland Chromatin | Normal Nucleoli | Mitoses | Class\n5               | 1                       | 1                        | 1                 | 2                           | 1           | 3               | 1               | 1       | 0\n5               | 4                       | 4                        | 5                 | 7                           | 10          | 3               | 2               | 1       | 0\n3               | 1                       | 1                        | 1                 | 2                           | 2           | 3               | 1               | 1       | 0\n6               | 8                       | 8                        | 1                 | 3                           | 4           | 3               | 7               | 1       | 0\n4               | 1                       | 1                        | 3                 | 2                           | 1           | 3               | 1               | 1       | 0\n8               | 10                      | 10                       | 8                 | 7                           | 10          | 9               | 7               | 1       | 1\n1               | 1                       | 1                        | 1                 | 2                           | 10          | 3               | 1               | 1       | 0\n2               | 1                       | 2                        | 1                 | 2                           | 1           | 3               | 1               | 1       | 0\n2               | 1                       | 1                        | 1                 | 2                           | 1           | 1               | 1               | 5       | 0\n4               | 2                       | 1                        | 1                 | 2                           | 1           | 2               | 1               | 1       | 0\n... (673 rows omitted)","content_type":"text/plain"}}}],"key":"vDYxO890Qe"}],"key":"dhR50f3HJ4"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"So we have 9 different attributes.  I don’t know how to make a 9-dimensional scatterplot of all of them, so I’m going to pick two and plot them:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"qQu5kZq6l9"}],"key":"HWySwmBwKQ"}],"key":"ohTVbynrb7"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"color_table = Table().with_columns(\n    'Class', make_array(1, 0),\n    'Color', make_array('darkblue', 'gold')\n)\npatients_with_colors = patients.join('Class', color_table)","key":"n6Hk9E1toq"},{"type":"output","id":"hzgEIap2hL67zvPej8q8i","data":[],"key":"jrjDKn00BT"}],"key":"mn3FH4PTHv"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"patients_with_colors.scatter('Bland Chromatin', 'Single Epithelial Cell Size', group='Color')","key":"RXPEwROA7K"},{"type":"output","id":"WJmgHMfjyL8S2zWaa1IbT","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"04414e61459f9c4542b6559190d24a81","path":"/build/04414e61459f9c4542b6559190d24a81.png"},"text/plain":{"content":"\u003cFigure size 360x360 with 1 Axes\u003e","content_type":"text/plain"}}}],"key":"WJ62Y6Rlr0"}],"key":"K7GSFxtkZJ"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Oops.  That plot is utterly misleading, because there are a bunch of points that have identical values for both the x- and y-coordinates.  To make it easier to see all the data points, I’m going to add a little bit of random jitter to the x- and y-values.  Here’s how that looks:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ktxDtJG8PS"}],"key":"uBMkcMT4rJ"}],"key":"hHCneQWUdQ"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"def randomize_column(a):\n    return a + np.random.normal(0.0, 0.09, size=len(a))\nTable().with_columns(\n        'Bland Chromatin (jittered)', \n        randomize_column(patients.column('Bland Chromatin')),\n        'Single Epithelial Cell Size (jittered)', \n        randomize_column(patients.column('Single Epithelial Cell Size')),\n        'Class', patients.column('Class')\n    ).join('Class', color_table).scatter(1, 2, group='Color')","visibility":"remove","key":"gbzNRQncqt"},{"type":"output","id":"V5eW9CScVKbKAfHlH1vf7","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"6aec59bee719a99db8a9dab0faa0287c","path":"/build/6aec59bee719a99db8a9dab0faa0287c.png"},"text/plain":{"content":"\u003cFigure size 360x360 with 1 Axes\u003e","content_type":"text/plain"}}}],"visibility":"show","key":"cp6fxaWdqg"}],"visibility":"show","key":"JMVFOTdY9L"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"For instance, you can see there are lots of samples with chromatin = 2 and epithelial cell size = 2; all non-cancerous.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"txnUaVKBYF"}],"key":"KhXgqZm1M1"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Keep in mind that the jittering is just for visualization purposes, to make it easier to get a feeling for the data.  We’re ready to work with the data now, and we’ll use the original (unjittered) data.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"en8GozXuDc"}],"key":"yaY8Mfh2hm"}],"key":"T2GuZcoL6m"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"First we’ll create a training set and a test set. The data set has 683 patients, so we’ll randomly permute the data set and put 342 of them in the training set and the remaining 341 in the test set.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"l6JO06fN5E"}],"key":"m9luufH6j7"}],"key":"TIOU1YXGaI"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"shuffled_patients = patients.sample(683, with_replacement=False) \ntraining_set = shuffled_patients.take(np.arange(342))\ntest_set  = shuffled_patients.take(np.arange(342, 683))","key":"T6LCQpz1I3"},{"type":"output","id":"gqBX-ZZg9op6sBg9fGiF1","data":[],"key":"rBAkKT45zO"}],"key":"xyTDDophEr"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Let’s stick with 5 nearest neighbors, and see how well our classifier does.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"CMgBIkZlTs"}],"key":"TSa274GeJF"}],"key":"ykj4Khspbv"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"evaluate_accuracy(training_set, test_set, 5)","key":"yQYVxv8Ugg"},{"type":"output","id":"bpuIQQ3ETUYt4zGzBgl1n","data":[{"output_type":"execute_result","execution_count":12,"metadata":{},"data":{"text/plain":{"content":"0.967741935483871","content_type":"text/plain"}}}],"key":"attD7t8AQY"}],"key":"hIUotvkCNF"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Over 96% accuracy.  Not bad!  Once again, pretty darn good for such a simple technique.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"FrklMWMFzq"}],"key":"RA2kU00FsU"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"As a footnote, you might have noticed that Brittany Wenger did even better.  What techniques did she use? One key innovation is that she incorporated a confidence score into her results: her algorithm had a way to determine when it was not able to make a confident prediction, and for those patients, it didn’t even try to predict their diagnosis.  Her algorithm was 99% accurate on the patients where it made a prediction -- so that extension seemed to help quite a bit.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"fCR3nw166x"}],"key":"VUizCOg2eg"}],"key":"DztSIGvL6F"}],"key":"q0NdUvY1aB"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"Implementing the Classifier","url":"/chapters/17/4/implementing-the-classifier","group":"Computational and Inferential Thinking"},"next":{"title":"Multiple Regression","url":"/chapters/17/6/multiple-regression","group":"Computational and Inferential Thinking"}}},"domain":"http://localhost:3000"},"project":{"license":{"content":{"id":"CC-BY-NC-ND-4.0","url":"https://creativecommons.org/licenses/by-nc-nd/4.0/","name":"Creative Commons Attribution Non Commercial No Derivatives 4.0 International","CC":true}},"numbering":{"title":{"enabled":true}},"title":"Computational and Inferential Thinking","authors":[{"nameParsed":{"literal":"Ani Adhikari","given":"Ani","family":"Adhikari"},"name":"Ani Adhikari","id":"contributors-myst-generated-uid-0"},{"nameParsed":{"literal":"John DeNero","given":"John","family":"DeNero"},"name":"John DeNero","id":"contributors-myst-generated-uid-1"},{"nameParsed":{"literal":"David Wagner","given":"David","family":"Wagner"},"name":"David Wagner","id":"contributors-myst-generated-uid-2"}],"github":"https://github.com/data-8/textbook","toc":[{"file":"chapters/intro.md"},{"children":[{"children":[{"file":"chapters/01/1/1/computational-tools.md"},{"file":"chapters/01/1/2/statistical-techniques.md"}],"file":"chapters/01/1/intro.md"},{"file":"chapters/01/2/why-data-science.md"},{"children":[{"file":"chapters/01/3/1/Literary_Characters.ipynb"},{"file":"chapters/01/3/2/Another_Kind_Of_Character.ipynb"}],"file":"chapters/01/3/Plotting_the_Classics.ipynb"}],"file":"chapters/01/what-is-data-science.md"},{"children":[{"file":"chapters/02/1/observation-and-visualization-john-snow-and-the-broad-street-pump.md","title":"John Snow and the Broad Street Pump"},{"file":"chapters/02/2/snow-s-grand-experiment.md"},{"file":"chapters/02/3/establishing-causality.md"},{"file":"chapters/02/4/randomization.md"},{"file":"chapters/02/5/endnote.md"}],"file":"chapters/02/causality-and-experiments.md"},{"children":[{"file":"chapters/03/1/Expressions.ipynb"},{"children":[{"file":"chapters/03/2/1/Growth.ipynb"}],"file":"chapters/03/2/Names.ipynb"},{"file":"chapters/03/3/Calls.ipynb"},{"file":"chapters/03/4/Introduction_to_Tables.ipynb"}],"file":"chapters/03/programming-in-python.md"},{"children":[{"file":"chapters/04/1/Numbers.ipynb"},{"children":[{"file":"chapters/04/2/1/String_Methods.ipynb"}],"file":"chapters/04/2/Strings.ipynb"},{"file":"chapters/04/3/Comparison.ipynb"}],"file":"chapters/04/Data_Types.ipynb"},{"children":[{"file":"chapters/05/1/Arrays.ipynb"},{"file":"chapters/05/2/Ranges.ipynb"},{"file":"chapters/05/3/More_on_Arrays.ipynb"}],"file":"chapters/05/Sequences.ipynb"},{"children":[{"file":"chapters/06/1/Sorting_Rows.ipynb"},{"file":"chapters/06/2/Selecting_Rows.ipynb"},{"file":"chapters/06/3/Example_Population_Trends.ipynb"},{"file":"chapters/06/4/Example_Sex_Ratios.ipynb"}],"file":"chapters/06/Tables.ipynb"},{"children":[{"file":"chapters/07/1/Visualizing_Categorical_Distributions.ipynb"},{"file":"chapters/07/2/Visualizing_Numerical_Distributions.ipynb"},{"file":"chapters/07/3/Overlaid_Graphs.ipynb"}],"file":"chapters/07/Visualization.ipynb"},{"children":[{"file":"chapters/08/1/Applying_a_Function_to_a_Column.ipynb"},{"file":"chapters/08/2/Classifying_by_One_Variable.ipynb"},{"file":"chapters/08/3/Cross-Classifying_by_More_than_One_Variable.ipynb"},{"file":"chapters/08/4/Joining_Tables_by_Columns.ipynb"},{"file":"chapters/08/5/Bike_Sharing_in_the_Bay_Area.ipynb"}],"file":"chapters/08/Functions_and_Tables.ipynb"},{"children":[{"file":"chapters/09/1/Conditional_Statements.ipynb"},{"file":"chapters/09/2/Iteration.ipynb"},{"file":"chapters/09/3/Simulation.ipynb"},{"file":"chapters/09/4/Monty_Hall_Problem.ipynb"},{"file":"chapters/09/5/Finding_Probabilities.ipynb"}],"file":"chapters/09/Randomness.ipynb"},{"children":[{"file":"chapters/10/1/Empirical_Distributions.ipynb"},{"file":"chapters/10/2/Sampling_from_a_Population.ipynb"},{"file":"chapters/10/3/Empirical_Distribution_of_a_Statistic.ipynb"},{"file":"chapters/10/4/Random_Sampling_in_Python.ipynb"}],"file":"chapters/10/Sampling_and_Empirical_Distributions.ipynb"},{"children":[{"file":"chapters/11/1/Assessing_a_Model.ipynb"},{"file":"chapters/11/2/Multiple_Categories.ipynb"},{"file":"chapters/11/3/Decisions_and_Uncertainty.ipynb"},{"file":"chapters/11/4/Error_Probabilities.ipynb"}],"file":"chapters/11/Testing_Hypotheses.md"},{"children":[{"file":"chapters/12/1/AB_Testing.ipynb"},{"file":"chapters/12/2/Causality.ipynb"},{"file":"chapters/12/3/Deflategate.ipynb"}],"file":"chapters/12/Comparing_Two_Samples.md"},{"children":[{"file":"chapters/13/1/Percentiles.ipynb"},{"file":"chapters/13/2/Bootstrap.ipynb"},{"file":"chapters/13/3/Confidence_Intervals.ipynb"},{"file":"chapters/13/4/Using_Confidence_Intervals.ipynb"}],"file":"chapters/13/Estimation.md"},{"children":[{"file":"chapters/14/1/Properties_of_the_Mean.ipynb"},{"file":"chapters/14/2/Variability.ipynb"},{"file":"chapters/14/3/SD_and_the_Normal_Curve.ipynb"},{"file":"chapters/14/4/Central_Limit_Theorem.ipynb"},{"file":"chapters/14/5/Variability_of_the_Sample_Mean.ipynb"},{"file":"chapters/14/6/Choosing_a_Sample_Size.ipynb"}],"file":"chapters/14/Why_the_Mean_Matters.md"},{"children":[{"file":"chapters/15/1/Correlation.ipynb"},{"file":"chapters/15/2/Regression_Line.ipynb"},{"file":"chapters/15/3/Method_of_Least_Squares.ipynb"},{"file":"chapters/15/4/Least_Squares_Regression.ipynb"},{"file":"chapters/15/5/Visual_Diagnostics.ipynb"},{"file":"chapters/15/6/Numerical_Diagnostics.ipynb"}],"file":"chapters/15/Prediction.ipynb"},{"children":[{"file":"chapters/16/1/Regression_Model.ipynb"},{"file":"chapters/16/2/Inference_for_the_True_Slope.ipynb"},{"file":"chapters/16/3/Prediction_Intervals.ipynb"}],"file":"chapters/16/Inference_for_Regression.md"},{"children":[{"file":"chapters/17/1/Nearest_Neighbors.ipynb"},{"file":"chapters/17/2/Training_and_Testing.ipynb"},{"file":"chapters/17/3/Rows_of_Tables.ipynb"},{"file":"chapters/17/4/Implementing_the_Classifier.ipynb"},{"file":"chapters/17/5/Accuracy_of_the_Classifier.ipynb"},{"file":"chapters/17/6/Multiple_Regression.ipynb"}],"file":"chapters/17/Classification.md"},{"children":[{"file":"chapters/18/1/More_Likely_than_Not_Binary_Classifier.ipynb"},{"file":"chapters/18/2/Making_Decisions.ipynb"}],"file":"chapters/18/Updating_Predictions.md"}],"exports":[],"bibliography":[],"index":"index","pages":[{"slug":"chapters.01.what-is-data-science","title":"What is Data Science?","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"1"},{"slug":"chapters.01.1.intro","title":"Introduction","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.1"},{"slug":"chapters.01.1.1.computational-tools","title":"Computational Tools","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.1.1"},{"slug":"chapters.01.1.2.statistical-techniques","title":"Statistical Techniques","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.1.2"},{"slug":"chapters.01.2.why-data-science","title":"Why Data Science?","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.2"},{"slug":"chapters.01.3.plotting-the-classics","title":"Plotting the Classics","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.3"},{"slug":"chapters.01.3.1.literary-characters","title":"Literary Characters","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.3.1"},{"slug":"chapters.01.3.2.another-kind-of-character","title":"Another Kind of Character","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.3.2"},{"slug":"chapters.02.causality-and-experiments","title":"Causality and Experiments","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"2"},{"slug":"chapters.02.1.observation-and-visualization-john-snow-and-the-br","title":"Observation and Visualization: John Snow and the Broad Street Pump","description":"","date":"","thumbnail":"/build/snow_map-a559f894ec65aa589b5d612f39960c8a.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.1"},{"slug":"chapters.02.2.snow-s-grand-experiment","title":"Snow’s “Grand Experiment”","description":"","date":"","thumbnail":"/build/snow_map2-922ad2b5eb1e1af2875642e9371ff78c.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.2"},{"slug":"chapters.02.3.establishing-causality","title":"Establishing Causality","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.3"},{"slug":"chapters.02.4.randomization","title":"Randomization","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.4"},{"slug":"chapters.02.5.endnote","title":"Endnote","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.5"},{"slug":"chapters.03.programming-in-python","title":"Programming in Python","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"3"},{"slug":"chapters.03.1.expressions","title":"Expressions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.1"},{"slug":"chapters.03.2.names","title":"Names","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.2"},{"slug":"chapters.03.2.1.growth","title":"Example: Growth Rates","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"3.2.1"},{"slug":"chapters.03.3.calls","title":"Call Expressions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.3"},{"slug":"chapters.03.4.introduction-to-tables","title":"Introduction to Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.4"},{"slug":"chapters.04.data-types","title":"Data Types","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"4"},{"slug":"chapters.04.1.numbers","title":"Numbers","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.1"},{"slug":"chapters.04.2.strings","title":"Strings","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.2"},{"slug":"chapters.04.2.1.string-methods","title":"String Methods","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"4.2.1"},{"slug":"chapters.04.3.comparison","title":"Comparisons","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.3"},{"slug":"chapters.05.sequences","title":"Sequences","description":"","date":"","thumbnail":"/build/global-land-TMAX-Tre-f4e8046cb3617080ace7162f525d2fdc.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"5"},{"slug":"chapters.05.1.arrays","title":"Arrays","description":"","date":"","thumbnail":"/build/array_arithmetic-21903924b73cec9cb83b421db6b76ed0.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.1"},{"slug":"chapters.05.2.ranges","title":"Ranges","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.2"},{"slug":"chapters.05.3.more-on-arrays","title":"More on Arrays","description":"","date":"","thumbnail":"/build/array_subtraction-a6b41be681a21bc81ed05b4daddb13cd.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.3"},{"slug":"chapters.06.tables","title":"Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"6"},{"slug":"chapters.06.1.sorting-rows","title":"Sorting Rows","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.1"},{"slug":"chapters.06.2.selecting-rows","title":"Selecting Rows","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.2"},{"slug":"chapters.06.3.example-population-trends","title":"Example: Population Trends","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.3"},{"slug":"chapters.06.4.example-sex-ratios","title":"Example: Sex Ratios","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.4"},{"slug":"chapters.07.visualization","title":"Visualization","description":"","date":"","thumbnail":"/build/C-3PO_droid-1fa7c0f010e1bd61cb242418203ccbd9.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"7"},{"slug":"chapters.07.1.visualizing-categorical-distributions","title":"Visualizing Categorical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.1"},{"slug":"chapters.07.2.visualizing-numerical-distributions","title":"Visualizing Numerical Distributions","description":"","date":"","thumbnail":"/build/ipad_battery-eba4b70625634dc8a9b850a43c992c66.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.2"},{"slug":"chapters.07.3.overlaid-graphs","title":"Overlaid Graphs","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.3"},{"slug":"chapters.08.functions-and-tables","title":"Functions and Tables","description":"","date":"","thumbnail":"/build/function_definition-b6e0ca12a5cd8a62fb46784f45744396.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"8"},{"slug":"chapters.08.1.applying-a-function-to-a-column","title":"Applying a Function to a Column","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.1"},{"slug":"chapters.08.2.classifying-by-one-variable","title":"Classifying by One Variable","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.2"},{"slug":"chapters.08.3.cross-classifying-by-more-than-one-variable","title":"Cross-Classifying by More than One Variable","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.3"},{"slug":"chapters.08.4.joining-tables-by-columns","title":"Joining Tables by Columns","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.4"},{"slug":"chapters.08.5.bike-sharing-in-the-bay-area","title":"Bike Sharing in the Bay Area","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.5"},{"slug":"chapters.09.randomness","title":"Randomness","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"9"},{"slug":"chapters.09.1.conditional-statements","title":"Conditional Statements","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.1"},{"slug":"chapters.09.2.iteration","title":"Iteration","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.2"},{"slug":"chapters.09.3.simulation","title":"Simulation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.3"},{"slug":"chapters.09.4.monty-hall-problem","title":"The Monty Hall Problem","description":"","date":"","thumbnail":"/build/monty_hall_goat-b1899404d996b314b7ddc961406d0737.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.4"},{"slug":"chapters.09.5.finding-probabilities","title":"Finding Probabilities","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.5"},{"slug":"chapters.10.sampling-and-empirical-distributions","title":"Sampling and Empirical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"10"},{"slug":"chapters.10.1.empirical-distributions","title":"Empirical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.1"},{"slug":"chapters.10.2.sampling-from-a-population","title":"Sampling from a Population","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.2"},{"slug":"chapters.10.3.empirical-distribution-of-a-statistic","title":"Empirical Distribution of a Statistic","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.3"},{"slug":"chapters.10.4.random-sampling-in-python","title":"Random Sampling in Python","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.4"},{"slug":"chapters.11.testing-hypotheses","title":"Testing Hypotheses","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"11"},{"slug":"chapters.11.1.assessing-a-model","title":"Assessing a Model","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.1"},{"slug":"chapters.11.2.multiple-categories","title":"Multiple Categories","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.2"},{"slug":"chapters.11.3.decisions-and-uncertainty","title":"Decisions and Uncertainty","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.3"},{"slug":"chapters.11.4.error-probabilities","title":"Error Probabilities","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.4"},{"slug":"chapters.12.comparing-two-samples","title":"Comparing Two Samples","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"12"},{"slug":"chapters.12.1.ab-testing","title":"A/B Testing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.1"},{"slug":"chapters.12.2.causality","title":"Causality","description":"","date":"","thumbnail":"/build/causality1-c2b9dd21638c4113770df93b4a9da373.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.2"},{"slug":"chapters.12.3.deflategate","title":"Deflategate","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.3"},{"slug":"chapters.13.estimation","title":"Estimation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"13"},{"slug":"chapters.13.1.percentiles","title":"Percentiles","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.1"},{"slug":"chapters.13.2.bootstrap","title":"The Bootstrap","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.2"},{"slug":"chapters.13.3.confidence-intervals","title":"Confidence Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.3"},{"slug":"chapters.13.4.using-confidence-intervals","title":"Using Confidence Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.4"},{"slug":"chapters.14.why-the-mean-matters","title":"Why the Mean Matters","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"14"},{"slug":"chapters.14.1.properties-of-the-mean","title":"Properties of the Mean","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.1"},{"slug":"chapters.14.2.variability","title":"Variability","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.2"},{"slug":"chapters.14.3.sd-and-the-normal-curve","title":"The SD and the Normal Curve","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.3"},{"slug":"chapters.14.4.central-limit-theorem","title":"The Central Limit Theorem","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.4"},{"slug":"chapters.14.5.variability-of-the-sample-mean","title":"The Variability of the Sample Mean","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.5"},{"slug":"chapters.14.6.choosing-a-sample-size","title":"Choosing a Sample Size","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.6"},{"slug":"chapters.15.prediction","title":"Prediction","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"15"},{"slug":"chapters.15.1.correlation","title":"Correlation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.1"},{"slug":"chapters.15.2.regression-line","title":"The Regression Line","description":"","date":"","thumbnail":"/build/regline-7acefd1a1cb6046b7341e62942ed5611.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.2"},{"slug":"chapters.15.3.method-of-least-squares","title":"The Method of Least Squares","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.3"},{"slug":"chapters.15.4.least-squares-regression","title":"Least Squares Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.4"},{"slug":"chapters.15.5.visual-diagnostics","title":"Visual Diagnostics","description":"","date":"","thumbnail":"/build/5f819b0045c6e81a4265dd506d7aaff9.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.5"},{"slug":"chapters.15.6.numerical-diagnostics","title":"Numerical Diagnostics","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.6"},{"slug":"chapters.16.inference-for-regression","title":"Inference for Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"16"},{"slug":"chapters.16.1.regression-model","title":"A Regression Model","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.1"},{"slug":"chapters.16.2.inference-for-the-true-slope","title":"Inference for the True Slope","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.2"},{"slug":"chapters.16.3.prediction-intervals","title":"Prediction Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.3"},{"slug":"chapters.17.classification","title":"Classification","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"17"},{"slug":"chapters.17.1.nearest-neighbors","title":"Nearest Neighbors","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.1"},{"slug":"chapters.17.2.training-and-testing","title":"Training and Testing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.2"},{"slug":"chapters.17.3.rows-of-tables","title":"Rows of Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.3"},{"slug":"chapters.17.4.implementing-the-classifier","title":"Implementing the Classifier","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.4"},{"slug":"chapters.17.5.accuracy-of-the-classifier","title":"The Accuracy of the Classifier","description":"","date":"","thumbnail":"/build/5e548385d4da863b59d51148bd5d0eeb.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.5"},{"slug":"chapters.17.6.multiple-regression","title":"Multiple Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.6"},{"slug":"chapters.18.updating-predictions","title":"Updating Predictions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"18"},{"slug":"chapters.18.1.more-likely-than-not-binary-classifier","title":"A “More Likely Than Not” Binary Classifier","description":"","date":"","thumbnail":"/build/tree_students-c1d10705c5238230fc0243eb6ba2ea13.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"18.1"},{"slug":"chapters.18.2.making-decisions","title":"Making Decisions","description":"","date":"","thumbnail":"/build/tree_disease_rare-175fa2f39033e58ca8f1110413b91794.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"18.2"}]}}},"actionData":null,"errors":null},"future":{"unstable_dev":false,"unstable_postcss":false,"unstable_tailwind":false,"v2_errorBoundary":true,"v2_headers":true,"v2_meta":true,"v2_normalizeFormMethod":true,"v2_routeConvention":true}};</script><script type="module" async="">import "/build/manifest-3481E987.js";
import * as route0 from "/build/root-7TUVC4ZT.js";
import * as route1 from "/build/routes/$-P6PGXPYX.js";
window.__remixRouteModules = {"root":route0,"routes/$":route1};

import("/build/entry.client-UNPC4GT3.js");</script></body></html>