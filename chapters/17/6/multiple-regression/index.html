<!DOCTYPE html><html lang="en" class="" style="scroll-padding:60px"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/><title>Multiple Regression - Computational and Inferential Thinking</title><meta property="og:title" content="Multiple Regression - Computational and Inferential Thinking"/><meta name="generator" content="mystmd"/><meta name="keywords" content=""/><link rel="stylesheet" href="/build/_assets/app-IZWEOBHI.css"/><link rel="stylesheet" href="/build/_assets/thebe-core-VKVHG5VY.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jupyter-matplotlib@0.11.3/css/mpl_widget.css"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-148221575-1"></script><script>window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-148221575-1');</script><link rel="icon" href="/favicon.ico"/><link rel="stylesheet" href="/myst-theme.css"/><script>
  const savedTheme = localStorage.getItem("myst:theme");
  const theme = window.matchMedia("(prefers-color-scheme: light)").matches ? 'light' : 'dark';
  const classes = document.documentElement.classList;
  const hasAnyTheme = classes.contains('light') || classes.contains('dark');
  if (!hasAnyTheme) classes.add(savedTheme ?? theme);
</script></head><body class="m-0 transition-colors duration-500 bg-white dark:bg-stone-900"><div class="fixed top-1 left-1 h-[0px] w-[0px] focus-within:z-40 focus-within:h-auto focus-within:w-auto bg-white overflow-hidden focus-within:p-2 focus-within:ring-1" aria-label="skip to content options"><a href="#skip-to-frontmatter" class="block px-2 py-1 text-black underline">Skip to article frontmatter</a><a href="#skip-to-article" class="block px-2 py-1 text-black underline">Skip to article content</a></div><div class="bg-white/80 backdrop-blur dark:bg-stone-900/80 shadow dark:shadow-stone-700 p-3 md:px-8 sticky w-screen top-0 z-30 h-[60px]"><nav class="flex items-center justify-between flex-nowrap max-w-[1440px] mx-auto"><div class="flex flex-row xl:min-w-[19.5rem] mr-2 sm:mr-7 justify-start items-center shrink-0"><div class="block xl:hidden"><button class="flex items-center border-stone-400 text-stone-800 hover:text-stone-900 dark:text-stone-200 hover:dark:text-stone-100"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="m-1"><path fill-rule="evenodd" d="M3 6.75A.75.75 0 0 1 3.75 6h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 6.75ZM3 12a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 12Zm0 5.25a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75a.75.75 0 0 1-.75-.75Z" clip-rule="evenodd"></path></svg><span class="sr-only">Open Menu</span></button></div><a class="flex items-center ml-3 dark:text-white w-fit md:ml-5 xl:ml-7" href="/"><div class="p-1 mr-3 dark:bg-white dark:rounded"><img src="/build/data8logo-e8cfc0153f6b4ee7c43c8a236cd746b7.png" class="h-9" alt="Computational and Inferential Thinking" height="2.25rem"/></div><span class="text-md sm:text-xl tracking-tight sm:mr-5">Computational and Inferential Thinking</span></a></div><div class="flex items-center flex-grow w-auto"><div class="flex-grow hidden text-md lg:block"></div><div class="flex-grow block"></div><button type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R74op:" data-state="closed" class="flex items-center h-10 aspect-square sm:w-64 text-left text-gray-400 border border-gray-300 dark:border-gray-600 rounded-lg bg-gray-50 dark:bg-gray-700 hover:ring-blue-500 dark:hover:ring-blue-500 hover:border-blue-500 dark:hover:border-blue-500"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="p-2.5 h-10 w-10 aspect-square"><path fill-rule="evenodd" d="M10.5 3.75a6.75 6.75 0 1 0 0 13.5 6.75 6.75 0 0 0 0-13.5ZM2.25 10.5a8.25 8.25 0 1 1 14.59 5.28l4.69 4.69a.75.75 0 1 1-1.06 1.06l-4.69-4.69A8.25 8.25 0 0 1 2.25 10.5Z" clip-rule="evenodd"></path></svg><span class="hidden sm:block grow">Search</span><div aria-hidden="true" class="items-center hidden mx-1 font-mono text-sm text-gray-400 sm:flex gap-x-1"><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none hide-mac">CTRL</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none show-mac">⌘</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none ">K</kbd><script>
;(() => {
const script = document.currentScript;
const root = script.parentElement;

const isMac = /mac/i.test(
      window.navigator.userAgentData?.platform ?? window.navigator.userAgent,
    );
root.querySelectorAll(".hide-mac").forEach(node => {node.classList.add(isMac ? "hidden" : "block")});
root.querySelectorAll(".show-mac").forEach(node => {node.classList.add(!isMac ? "hidden" : "block")});
})()</script></div></button><button class="theme rounded-full aspect-square border border-stone-700 dark:border-white hover:bg-neutral-100 border-solid overflow-hidden text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 w-8 h-8 mx-3" title="Toggle theme between light and dark mode" aria-label="Toggle theme between light and dark mode"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 hidden dark:block"><path fill-rule="evenodd" d="M9.528 1.718a.75.75 0 0 1 .162.819A8.97 8.97 0 0 0 9 6a9 9 0 0 0 9 9 8.97 8.97 0 0 0 3.463-.69.75.75 0 0 1 .981.98 10.503 10.503 0 0 1-9.694 6.46c-5.799 0-10.5-4.7-10.5-10.5 0-4.368 2.667-8.112 6.46-9.694a.75.75 0 0 1 .818.162Z" clip-rule="evenodd"></path></svg><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 dark:hidden"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v2.25m6.364.386-1.591 1.591M21 12h-2.25m-.386 6.364-1.591-1.591M12 18.75V21m-4.773-4.227-1.591 1.591M5.25 12H3m4.227-4.773L5.636 5.636M15.75 12a3.75 3.75 0 1 1-7.5 0 3.75 3.75 0 0 1 7.5 0Z"></path></svg></button><div class="block sm:hidden"></div><div class="hidden sm:block"></div></div></nav></div><div class="fixed xl:article-grid grid-gap xl:w-screen xl:pointer-events-none overflow-auto max-xl:min-w-[300px] hidden z-10" style="top:60px"><div class="pointer-events-auto xl:col-margin-left flex-col overflow-hidden hidden xl:flex"><div class="flex-grow py-6 overflow-y-auto primary-scrollbar"><nav aria-label="Navigation" class="overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px] lg:hidden"><div class="w-full px-1 dark:text-white font-medium"></div></nav><div class="my-3 border-b-2 lg:hidden"></div><nav aria-label="Table of Contents" class="flex-grow overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px]"><div class="w-full px-1 dark:text-white"><a title="Computational and Inferential Thinking" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30 font-bold" href="/">Computational and Inferential Thinking</a><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="1 What is Data Science?" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/01/what-is-data-science">1 What is Data Science?</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rmp8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:Rmp8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="2 Causality and Experiments" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/02/causality-and-experiments">2 Causality and Experiments</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rup8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:Rup8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="3 Programming in Python" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/03/programming-in-python">3 Programming in Python</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R16p8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R16p8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="4 Data Types" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/04/data-types">4 Data Types</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R1ep8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R1ep8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="5 Sequences" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/05/sequences">5 Sequences</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R1mp8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R1mp8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="6 Tables" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/06/tables">6 Tables</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R1up8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R1up8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="7 Visualization" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/07/visualization">7 Visualization</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R26p8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R26p8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="8 Functions and Tables" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/08/functions-and-tables">8 Functions and Tables</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R2ep8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R2ep8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="9 Randomness" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/09/randomness">9 Randomness</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R2mp8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R2mp8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="10 Sampling and Empirical Distributions" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/10/sampling-and-empirical-distributions">10 Sampling and Empirical Distributions</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R2up8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R2up8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="11 Testing Hypotheses" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/11/testing-hypotheses">11 Testing Hypotheses</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R36p8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R36p8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="12 Comparing Two Samples" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/12/comparing-two-samples">12 Comparing Two Samples</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R3ep8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R3ep8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="13 Estimation" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/13/estimation">13 Estimation</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R3mp8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R3mp8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="14 Why the Mean Matters" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/14/why-the-mean-matters">14 Why the Mean Matters</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R3up8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R3up8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="15 Prediction" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/15/prediction">15 Prediction</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R46p8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R46p8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="16 Inference for Regression" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/16/inference-for-regression">16 Inference for Regression</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R4ep8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R4ep8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="open" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="17 Classification" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow font-semibold text-blue-800 dark:text-blue-200" href="/chapters/17/classification">17 Classification</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R4mp8p:" aria-expanded="true" data-state="open"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="open" id="radix-:R4mp8p:" class="pl-3 pr-[2px] collapsible-content"><a title="17.1 Nearest Neighbors" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/chapters/17/1/nearest-neighbors">17.1 Nearest Neighbors</a><a title="17.2 Training and Testing" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/chapters/17/2/training-and-testing">17.2 Training and Testing</a><a title="17.3 Rows of Tables" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/chapters/17/3/rows-of-tables">17.3 Rows of Tables</a><a title="17.4 Implementing the Classifier" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/chapters/17/4/implementing-the-classifier">17.4 Implementing the Classifier</a><a title="17.5 The Accuracy of the Classifier" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/chapters/17/5/accuracy-of-the-classifier">17.5 The Accuracy of the Classifier</a><a title="17.6 Multiple Regression" aria-current="page" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg bg-blue-300/30 active" href="/chapters/17/6/multiple-regression">17.6 Multiple Regression</a></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="18 Updating Predictions" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/18/updating-predictions">18 Updating Predictions</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R4up8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R4up8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div></div></nav></div><div class="flex-none py-6 transition-all duration-700 translate-y-6 opacity-0"><a class="flex mx-auto text-gray-700 w-fit hover:text-blue-700 dark:text-gray-200 dark:hover:text-blue-400" href="https://mystmd.org/made-with-myst" target="_blank" rel="noreferrer"><svg style="width:24px;height:24px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" stroke="none"><g id="icon"><path fill="currentColor" d="M23.8,54.8v-3.6l4.7-0.8V17.5l-4.7-0.8V13H36l13.4,31.7h0.2l13-31.7h12.6v3.6l-4.7,0.8v32.9l4.7,0.8v3.6h-15
          v-3.6l4.9-0.8V20.8H65L51.4,53.3h-3.8l-14-32.5h-0.1l0.2,17.4v12.1l5,0.8v3.6H23.8z"></path><path fill="#F37726" d="M47,86.9c0-5.9-3.4-8.8-10.1-8.8h-8.4c-5.2,0-9.4-1.3-12.5-3.8c-3.1-2.5-5.4-6.2-6.8-11l4.8-1.6
          c1.8,5.6,6.4,8.6,13.8,8.8h9.2c6.4,0,10.8,2.5,13.1,7.5c2.3-5,6.7-7.5,13.1-7.5h8.4c7.8,0,12.7-2.9,14.6-8.7l4.8,1.6
          c-1.4,4.9-3.6,8.6-6.8,11.1c-3.1,2.5-7.3,3.7-12.4,3.8H63c-6.7,0-10,2.9-10,8.8"></path></g></svg><span class="self-center ml-2 text-sm">Made with MyST</span></a></div></div></div><main class="article-grid grid-gap"><article class="article-grid subgrid-gap col-screen article content"><div class="hidden"></div><div id="skip-to-frontmatter" aria-label="article frontmatter" class="mb-8 pt-9"><div class="flex items-center mb-5 h-6 text-sm font-light"><div class="flex-grow"></div><a href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" rel="noopener noreferrer" class="opacity-50 hover:opacity-100 text-inherit hover:text-inherit" aria-label="Content License: Creative Commons Attribution Non Commercial No Derivatives 4.0 International (CC-BY-NC-ND-4.0)"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mx-1"><title>Content License: Creative Commons Attribution Non Commercial No Derivatives 4.0 International (CC-BY-NC-ND-4.0)</title><path d="M12 2.2c2.7 0 5 1 7 2.9.9.9 1.6 2 2.1 3.1.5 1.2.7 2.4.7 3.8 0 1.3-.2 2.6-.7 3.8-.5 1.2-1.2 2.2-2.1 3.1-1 .9-2 1.7-3.2 2.2-1.2.5-2.5.7-3.7.7s-2.6-.3-3.8-.8c-1.2-.5-2.2-1.2-3.2-2.1s-1.6-2-2.1-3.2-.8-2.4-.8-3.7c0-1.3.2-2.5.7-3.7S4.2 6 5.1 5.1C7 3.2 9.3 2.2 12 2.2zM12 4c-2.2 0-4.1.8-5.6 2.3C5.6 7.1 5 8 4.6 9c-.4 1-.6 2-.6 3s.2 2.1.6 3c.4 1 1 1.8 1.8 2.6S8 19 9 19.4c1 .4 2 .6 3 .6s2.1-.2 3-.6c1-.4 1.9-1 2.7-1.8 1.5-1.5 2.3-3.3 2.3-5.6 0-1.1-.2-2.1-.6-3.1-.4-1-1-1.8-1.7-2.6C16.1 4.8 14.2 4 12 4zm-.1 6.4l-1.3.7c-.1-.3-.3-.5-.5-.6-.2-.1-.4-.2-.6-.2-.9 0-1.3.6-1.3 1.7 0 .5.1.9.3 1.3.2.3.5.5 1 .5.6 0 1-.3 1.2-.8l1.2.6c-.3.5-.6.9-1.1 1.1-.5.3-1 .4-1.5.4-.9 0-1.6-.3-2.1-.8-.5-.6-.8-1.3-.8-2.3 0-.9.3-1.7.8-2.2.6-.6 1.3-.8 2.1-.8 1.2 0 2.1.4 2.6 1.4zm5.6 0l-1.3.7c-.1-.3-.3-.5-.5-.6-.2-.1-.4-.2-.6-.2-.9 0-1.3.6-1.3 1.7 0 .5.1.9.3 1.3.2.3.5.5 1 .5.6 0 1-.3 1.2-.8l1.2.6c-.3.5-.6.9-1.1 1.1-.4.2-.9.3-1.4.3-.9 0-1.6-.3-2.1-.8s-.8-1.3-.8-2.2c0-.9.3-1.7.8-2.2.5-.5 1.2-.8 2-.8 1.2 0 2.1.4 2.6 1.4z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1"><title>Credit must be given to the creator</title><path d="M12 2.2c2.7 0 5 .9 6.9 2.8 1.9 1.9 2.8 4.2 2.8 6.9s-.9 5-2.8 6.8c-2 1.9-4.3 2.9-7 2.9-2.6 0-4.9-1-6.9-2.9-1.8-1.7-2.8-4-2.8-6.7s1-5 2.9-6.9C7 3.2 9.3 2.2 12 2.2zM12 4c-2.2 0-4.1.8-5.6 2.3C4.8 8 4 9.9 4 12c0 2.2.8 4 2.4 5.6C8 19.2 9.8 20 12 20c2.2 0 4.1-.8 5.7-2.4 1.5-1.5 2.3-3.3 2.3-5.6 0-2.2-.8-4.1-2.3-5.7C16.1 4.8 14.2 4 12 4zm2.6 5.6v4h-1.1v4.7h-3v-4.7H9.4v-4c0-.2.1-.3.2-.4.1-.2.2-.2.4-.2h4c.2 0 .3.1.4.2.2.1.2.2.2.4zm-4-2.5c0-.9.5-1.4 1.4-1.4s1.4.5 1.4 1.4c0 .9-.5 1.4-1.4 1.4s-1.4-.5-1.4-1.4z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1"><title>Only noncommercial uses of the work are permitted</title><path d="M12 2.2c2.7 0 5 .9 6.9 2.8 1.9 1.9 2.8 4.2 2.8 6.9s-.9 5-2.8 6.8c-2 1.9-4.3 2.9-7 2.9-2.6 0-4.9-1-6.9-2.9-1.9-1.9-2.9-4.2-2.9-6.9s1-5 2.9-6.9c2-1.7 4.3-2.7 7-2.7zM4.4 9.4C4.2 10.2 4 11 4 12c0 2.2.8 4 2.4 5.6C8 19.2 9.8 20 12 20c2.2 0 4.1-.8 5.7-2.4.6-.5 1-1.1 1.3-1.7l-3.7-1.6c-.1.6-.4 1.1-.9 1.5-.5.4-1.1.6-1.8.7V18h-1.1v-1.5c-1.1 0-2.1-.4-3-1.2l1.3-1.4c.6.6 1.4.9 2.2.9.3 0 .6-.1.9-.2.2-.2.4-.4.4-.7 0-.2-.1-.4-.3-.6l-.9-.4-1.1-.6-1.5-.7-5.1-2.2zM12 4c-2.2 0-4.1.8-5.6 2.3-.4.4-.7.9-1.1 1.3L9 9.3c.2-.5.5-.9 1-1.2.5-.3 1-.5 1.6-.5V6.1h1.1v1.5c.9 0 1.7.3 2.4.9l-1.3 1.3c-.5-.4-1.1-.6-1.7-.6-.3 0-.6.1-.8.2-.2.1-.3.3-.3.6 0 .1 0 .2.1.2l1.2.6.9.4 1.6.7 5 2.2c.2-.7.2-1.4.2-2.1 0-2.2-.8-4.1-2.3-5.7C16.1 4.8 14.2 4 12 4z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1"><title>No derivatives or adaptations of the work are permitted</title><path d="M12 2.2c2.7 0 5 .9 6.9 2.8 1.9 1.9 2.8 4.2 2.8 6.9s-.9 5-2.8 6.9c-2 1.9-4.3 2.9-7 2.9-2.6 0-4.9-1-6.9-2.9C3.2 17 2.2 14.7 2.2 12s1-5 2.9-6.9C7 3.2 9.3 2.2 12 2.2zM12 4c-2.2 0-4.1.8-5.6 2.4C4.8 8 4 9.9 4 12c0 2.2.8 4 2.4 5.6C8 19.2 9.8 20 12 20c2.2 0 4.1-.8 5.7-2.4 1.5-1.5 2.3-3.3 2.3-5.6 0-2.2-.8-4.1-2.3-5.6C16.1 4.8 14.2 4 12 4zm3.7 5.7v1.7H8.6V9.7h7.1zm0 3.1v1.7H8.6v-1.7h7.1z"></path></svg></a><a href="https://github.com/data-8/textbook" title="GitHub Repository: data-8/textbook" target="_blank" rel="noopener noreferrer" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1 opacity-60 hover:opacity-100"><path d="M12 2.5c-5.4 0-9.8 4.4-9.8 9.7 0 4.3 2.8 8 6.7 9.2.5.1.7-.2.7-.5v-1.8c-2.4.5-3.1-.6-3.3-1.1-.1-.3-.6-1.1-1-1.4-.3-.2-.8-.6 0-.6s1.3.7 1.5 1c.9 1.5 2.3 1.1 2.8.8.1-.6.3-1.1.6-1.3-2.2-.2-4.4-1.1-4.4-4.8 0-1.1.4-1.9 1-2.6-.1-.2-.4-1.2.1-2.6 0 0 .8-.3 2.7 1 .8-.2 1.6-.3 2.4-.3.8 0 1.7.1 2.4.3 1.9-1.3 2.7-1 2.7-1 .5 1.3.2 2.3.1 2.6.6.7 1 1.5 1 2.6 0 3.7-2.3 4.6-4.4 4.8.4.3.7.9.7 1.8V21c0 .3.2.6.7.5 3.9-1.3 6.6-4.9 6.6-9.2 0-5.4-4.4-9.8-9.8-9.8z"></path></svg></a><a href="https://github.com/data-8/textbook/edit/main/chapters/17/6/Multiple_Regression.ipynb" title="Edit This Page" target="_blank" rel="noopener noreferrer" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem" class="inline-block mr-1 opacity-60 hover:opacity-100"><path stroke-linecap="round" stroke-linejoin="round" d="m16.862 4.487 1.687-1.688a1.875 1.875 0 1 1 2.652 2.652L10.582 16.07a4.5 4.5 0 0 1-1.897 1.13L6 18l.8-2.685a4.5 4.5 0 0 1 1.13-1.897l8.932-8.931Zm0 0L19.5 7.125M18 14v4.75A2.25 2.25 0 0 1 15.75 21H5.25A2.25 2.25 0 0 1 3 18.75V8.25A2.25 2.25 0 0 1 5.25 6H10"></path></svg></a><div class="relative flex inline-block mx-1 grow-0" data-headlessui-state=""><button class="relative ml-2 -mr-1" id="headlessui-menu-button-:Rs8top:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Downloads</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem"><title>Download</title><path stroke-linecap="round" stroke-linejoin="round" d="M3 16.5v2.25A2.25 2.25 0 0 0 5.25 21h13.5A2.25 2.25 0 0 0 21 18.75V16.5M16.5 12 12 16.5m0 0L7.5 12m4.5 4.5V3"></path></svg></button></div></div><h1 class="mb-0"><span class="mr-3 select-none">17.6</span>Multiple Regression</h1></div><div class="block my-10 lg:sticky lg:z-10 lg:h-0 lg:pt-0 lg:my-0 lg:ml-10 lg:col-margin-right" style="top:60px"><nav></nav></div><div id="skip-to-article"></div><div id="DOjzMWY4Eb" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose hidden my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">from datascience import *
path_data = &#x27;../../../assets/data/&#x27;
import numpy as np

%matplotlib inline
import matplotlib.pyplot as plots
plots.style.use(&#x27;fivethirtyeight&#x27;)

np.set_printoptions(suppress=True)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="UTz8lWpTwdjaHbB0an6Ve" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="cN8tHsxJ0l" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose hidden my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def standard_units(any_numbers):
    &quot;Convert any array of numbers to standard units.&quot;
    return (any_numbers - np.mean(any_numbers))/np.std(any_numbers)  

def correlation(t, x, y):
    return np.mean(standard_units(t.column(x))*standard_units(t.column(y)))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="iF0BcRbBU7JUjuHX2jXyh" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="L8yM3MeSl7" class="relative group/block"><p>Now that we have explored ways to use multiple attributes to predict a categorical variable, let us return to predicting a quantitative variable. Predicting a numerical quantity is called regression, and a commonly used method to use multiple attributes for regression is called <em>multiple linear regression</em>.</p><h2 id="home-prices" class="relative group"><span class="heading-text">Home Prices</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#home-prices" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>The following dataset of house prices and attributes was collected over several years for the city of Ames, Iowa. A <a target="_blank" rel="noreferrer" href="http://ww2.amstat.org/publications/jse/v19n3/decock.pdf" class="">description of the dataset appears online</a>. We will focus only a subset of the columns. We will try to predict the sale price column from the other columns.</p></div><div id="paZGQ1UUKK" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">all_sales = Table.read_table(path_data + &#x27;house.csv&#x27;)
sales = all_sales.where(&#x27;Bldg Type&#x27;, &#x27;1Fam&#x27;).where(&#x27;Sale Condition&#x27;, &#x27;Normal&#x27;).select(
    &#x27;SalePrice&#x27;, &#x27;1st Flr SF&#x27;, &#x27;2nd Flr SF&#x27;, 
    &#x27;Total Bsmt SF&#x27;, &#x27;Garage Area&#x27;, 
    &#x27;Wood Deck SF&#x27;, &#x27;Open Porch SF&#x27;, &#x27;Lot Area&#x27;, 
    &#x27;Year Built&#x27;, &#x27;Yr Sold&#x27;)
sales.sort(&#x27;SalePrice&#x27;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="A49dd7aYPyOizqmQigTHt" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><div><div class="p-2.5">Loading...</div></div></div></div><div id="vTIx6OlPOA" class="relative group/block"><p>A histogram of sale prices shows a large amount of variability and a distribution that is clearly not normal. A long tail to the right contains a few houses that had very high prices. The short left tail does not contain any houses that sold for less than $35,000.</p></div><div id="QOe1ktswGL" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">sales.hist(&#x27;SalePrice&#x27;, bins=32, unit=&#x27;$&#x27;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="0nKLfu5363HyWCj_o6D2D" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><img src="/build/9e56dbe90f2334c2b62fe8a77db91ba0.png" alt="&lt;Figure size 432x288 with 1 Axes&gt;"/></div></div><div id="CHMZ1xZrK0" class="relative group/block"><h3 id="correlation" class="relative group"><span class="heading-text">Correlation</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#correlation" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>No single attribute is sufficient to predict the sale price. For example, the area of first floor, measured in square feet, correlates with sale price but only explains some of its variability.</p></div><div id="JKtwRuf52K" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">sales.scatter(&#x27;1st Flr SF&#x27;, &#x27;SalePrice&#x27;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="eVrUlPU8d4pZpVLTkNoDH" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><img src="/build/822e624d7739714520d0b863da2aa118.png" alt="&lt;Figure size 360x360 with 1 Axes&gt;"/></div></div><div id="GJwVInK3Ga" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">correlation(sales, &#x27;SalePrice&#x27;, &#x27;1st Flr SF&#x27;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="_p8v6zpodydC_07Uy7N42" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><div class="font-mono text-sm whitespace-pre-wrap"><code><span>0.6424662541030225</span></code></div></div></div><div id="vDcPbGH7NH" class="relative group/block"><p>In fact, none of the individual attributes have a correlation with sale price that is above 0.7 (except for the sale price itself).</p></div><div id="bA8wl0vLku" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">for label in sales.labels:
    print(&#x27;Correlation of&#x27;, label, &#x27;and SalePrice:\t&#x27;, correlation(sales, label, &#x27;SalePrice&#x27;))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="xmZfSPrV40yxQbZ-qBtQr" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span>Correlation of SalePrice and SalePrice:	 1.0
Correlation of 1st Flr SF and SalePrice:	 0.6424662541030225
Correlation of 2nd Flr SF and SalePrice:	 0.3575218942800824
Correlation of Total Bsmt SF and SalePrice:	 0.652978626757169
Correlation of Garage Area and SalePrice:	 0.6385944852520443
Correlation of Wood Deck SF and SalePrice:	 0.3526986661950492
Correlation of Open Porch SF and SalePrice:	 0.3369094170263733
Correlation of Lot Area and SalePrice:	 0.2908234551157694
Correlation of Year Built and SalePrice:	 0.5651647537135916
Correlation of Yr Sold and SalePrice:	 0.02594857908072111
</span></code></pre></div></div></div><div id="RMi1fxwnRp" class="relative group/block"><p>However, combining attributes can provide higher correlation. In particular, if we sum the first floor and second floor areas, the result has a higher correlation than any single attribute alone.</p></div><div id="CYLb4n5VT5" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">both_floors = sales.column(1) + sales.column(2)
correlation(sales.with_column(&#x27;Both Floors&#x27;, both_floors), &#x27;SalePrice&#x27;, &#x27;Both Floors&#x27;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="VOQcBbgAmR06CNrAsFa1V" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><div class="font-mono text-sm whitespace-pre-wrap"><code><span>0.7821920556134877</span></code></div></div></div><div id="SXdONSspso" class="relative group/block"><p>This high correlation indicates that we should try to use more than one attribute to predict the sale price. In a dataset with multiple observed attributes and a single numerical value to be predicted (the sale price in this case), multiple linear regression can be an effective technique.</p><h2 id="multiple-linear-regression" class="relative group"><span class="heading-text">Multiple Linear Regression</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#multiple-linear-regression" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>In multiple linear regression, a numerical output is predicted from numerical input attributes by multiplying each attribute value by a different slope, then summing the results. In this example, the slope for the <code>1st Flr SF</code> would represent the dollars per square foot of area on the first floor of the house that should be used in our prediction.</p><p>Before we begin prediction, we split our data randomly into a training and test set of equal size.</p></div><div id="dYwAJee3vu" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">train, test = sales.split(1001)
print(train.num_rows, &#x27;training and&#x27;, test.num_rows, &#x27;test instances.&#x27;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="XxO0o0iNV-n8zqwM8x4Xi" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span>1001 training and 1001 test instances.
</span></code></pre></div></div></div><div id="a9vIAtm9p3" class="relative group/block"><p>The slopes in multiple regression is an array that has one slope value for each attribute in an example. Predicting the sale price involves multiplying each attribute by the slope and summing the result.</p></div><div id="Bvufd9Frkk" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def predict(slopes, row):
    return sum(slopes * np.array(row))

example_row = test.drop(&#x27;SalePrice&#x27;).row(0)
print(&#x27;Predicting sale price for:&#x27;, example_row)
example_slopes = np.random.normal(10, 1, len(example_row))
print(&#x27;Using slopes:&#x27;, example_slopes)
print(&#x27;Result:&#x27;, predict(example_slopes, example_row))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="bei6x9ggod0qSTeUGf3_a" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span>Predicting sale price for: Row(1st Flr SF=1207, 2nd Flr SF=0, Total Bsmt SF=1135.0, Garage Area=264.0, Wood Deck SF=0, Open Porch SF=240, Lot Area=9510, Year Built=1962, Yr Sold=2006)
Using slopes: [ 9.52065867  8.58939769 11.48702417  9.50389131  9.09151019  9.86944284
 10.71929443 10.88966608  8.33339346]
Result: 169429.7032316262
</span></code></pre></div></div></div><div id="rXhkQjctjd" class="relative group/block"><p>The result is an estimated sale price, which can be compared to the actual sale price to assess whether the slopes provide accurate predictions. Since the <code>example_slopes</code> above were chosen at random, we should not expect them to provide accurate predictions at all.</p></div><div id="xZSvIrbp5B" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">print(&#x27;Actual sale price:&#x27;, test.column(&#x27;SalePrice&#x27;).item(0))
print(&#x27;Predicted sale price using random slopes:&#x27;, predict(example_slopes, example_row))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="0Zm3z_8HPDvsitHhLCX-2" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span>Actual sale price: 147000
Predicted sale price using random slopes: 169429.7032316262
</span></code></pre></div></div></div><div id="e3iwIaoTCk" class="relative group/block"><h3 id="least-squares-regression" class="relative group"><span class="heading-text">Least Squares Regression</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#least-squares-regression" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>The next step in performing multiple regression is to define the least squares objective. We perform the prediction for each row in the training set, and then compute the root mean squared error (RMSE) of the predictions from the actual prices.</p></div><div id="WfEY87oooA" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">train_prices = train.column(0)
train_attributes = train.drop(0)

def rmse(slopes, attributes, prices):
    errors = []
    for i in np.arange(len(prices)):
        predicted = predict(slopes, attributes.row(i))
        actual = prices.item(i)
        errors.append((predicted - actual) ** 2)
    return np.mean(errors) ** 0.5

def rmse_train(slopes):
    return rmse(slopes, train_attributes, train_prices)

print(&#x27;RMSE of all training examples using random slopes:&#x27;, rmse_train(example_slopes))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="zsp_vyiMAqFB2lirIgu1X" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span>RMSE of all training examples using random slopes: 68153.56796456952
</span></code></pre></div></div></div><div id="payIXOeiAi" class="relative group/block"><p>Finally, we use the <code>minimize</code> function to find the slopes with the lowest RMSE. Since the function we want to minimize, <code>rmse_train</code>, takes an array instead of a number, we must pass the <code>array=True</code> argument to <code>minimize</code>. When this argument is used, <code>minimize</code> also requires an initial guess of the slopes so that it knows the dimension of the input array. Finally, to speed up optimization, we indicate that <code>rmse_train</code> is a smooth function using the <code>smooth=True</code> attribute. Computation of the best slopes may take several minutes.</p></div><div id="ZqOnADNgzt" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">best_slopes = minimize(rmse_train, start=example_slopes, smooth=True, array=True)
print(&#x27;The best slopes for the training set:&#x27;)
Table(train_attributes.labels).with_row(list(best_slopes)).show()
print(&#x27;RMSE of all training examples using the best slopes:&#x27;, rmse_train(best_slopes))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="F3bQf0KkpxmDZkCRIuXfN" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><div><div class="p-2.5">Loading...</div></div></div></div><div id="OQbVmaOrZE" class="relative group/block"><h3 id="interpreting-multiple-regression" class="relative group"><span class="heading-text">Interpreting Multiple Regression</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#interpreting-multiple-regression" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Let’s interpret these results. The best slopes give us a method for estimating the price of a house from its attributes. A square foot of area on the first floor is worth about $75 (the first slope), while one on the second floor is worth about $70 (the second slope). The final negative value describes the market: prices in later years were lower on average.</p><p>The RMSE of around $30,000 means that our best linear prediction of the sale price based on all of the attributes is off by around $30,000 on the training set, on average.  We find a similar error when predicting prices on the test set, which indicates that our prediction method will generalize to other samples from the same population.</p></div><div id="mlY6LOTtAm" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">test_prices = test.column(0)
test_attributes = test.drop(0)

def rmse_test(slopes):
    return rmse(slopes, test_attributes, test_prices)

rmse_linear = rmse_test(best_slopes)
print(&#x27;Test set RMSE for multiple linear regression:&#x27;, rmse_linear)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="0LBjvYCDsrDufFI6QpuOG" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span>Test set RMSE for multiple linear regression: 33025.064938240575
</span></code></pre></div></div></div><div id="AV4tjHqnaP" class="relative group/block"><p>If the predictions were perfect, then a scatter plot of the predicted and actual values would be a straight line with slope 1. We see that most dots fall near that line, but there is some error in the predictions.</p></div><div id="CewPrOTgqu" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def fit(row):
    return sum(best_slopes * np.array(row))

test.with_column(&#x27;Fitted&#x27;, test.drop(0).apply(fit)).scatter(&#x27;Fitted&#x27;, 0)
plots.plot([0, 5e5], [0, 5e5]);</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="2C3ebzubIReZ20L4im87Z" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><img src="/build/c66b366a351a2e0e3129d44985161161.png" alt="&lt;Figure size 360x360 with 1 Axes&gt;"/></div></div><div id="gw8Xam3nHr" class="relative group/block"><p>A residual plot for multiple regression typically compares the errors (residuals) to the actual values of the predicted variable. We see in the residual plot below that we have systematically underestimated the value of expensive houses, shown by the many positive residual values on the right side of the graph.</p></div><div id="IqqPfnnGvJ" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">test.with_column(&#x27;Residual&#x27;, test_prices-test.drop(0).apply(fit)).scatter(0, &#x27;Residual&#x27;)
plots.plot([0, 7e5], [0, 0]);</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="3jZGLakMDgb2-MCbQ-ogZ" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><img src="/build/b742453e45adfd99dfa27daaea6f240d.png" alt="&lt;Figure size 360x360 with 1 Axes&gt;"/></div></div><div id="CeMelpNeKF" class="relative group/block"><p>As with simple linear regression, interpreting the result of a predictor is at least as important as making predictions. There are many lessons about interpreting multiple regression that are not included in this textbook. A natural next step after completing this text would be to study linear modeling and regression in further depth.</p></div><div id="uaAhkfW2dL" class="relative group/block"><h2 id="nearest-neighbors-for-regression" class="relative group"><span class="heading-text">Nearest Neighbors for Regression</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#nearest-neighbors-for-regression" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>Another approach to predicting the sale price of a house is to use the price of similar houses. This <em>nearest neighbor</em> approach is very similar to our classifier. To speed up computation, we will only use the attributes that had the highest correlation with the sale price in our original analysis.</p></div><div id="GYp1LlgSLS" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">train_nn = train.select(0, 1, 2, 3, 4, 8)
test_nn = test.select(0, 1, 2, 3, 4, 8)
train_nn.show(3)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="VdZlIOX2HyMqB30f3gs-_" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><div><div class="p-2.5">Loading...</div></div></div></div><div id="djzZpLUMGP" class="relative group/block"><p>The computation of closest neighbors is identical to a nearest-neighbor classifier. In this case, we will exclude the <code>&#x27;SalePrice&#x27;</code> rather than the <code>&#x27;Class&#x27;</code> column from the distance computation. The five nearest neighbors of the first test row are shown below.</p></div><div id="JszXxlpXJQ" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def distance(pt1, pt2):
    &quot;&quot;&quot;The distance between two points, represented as arrays.&quot;&quot;&quot;
    return np.sqrt(sum((pt1 - pt2) ** 2))

def row_distance(row1, row2):
    &quot;&quot;&quot;The distance between two rows of a table.&quot;&quot;&quot;
    return distance(np.array(row1), np.array(row2))

def distances(training, example, output):
    &quot;&quot;&quot;Compute the distance from example for each row in training.&quot;&quot;&quot;
    dists = []
    attributes = training.drop(output)
    for row in attributes.rows:
        dists.append(row_distance(row, example))
    return training.with_column(&#x27;Distance&#x27;, dists)

def closest(training, example, k, output):
    &quot;&quot;&quot;Return a table of the k closest neighbors to example.&quot;&quot;&quot;
    return distances(training, example, output).sort(&#x27;Distance&#x27;).take(np.arange(k))

example_nn_row = test_nn.drop(0).row(0)
closest(train_nn, example_nn_row, 5, &#x27;SalePrice&#x27;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="mX4mCyTI3qvywfE5jJwAT" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><div><div class="p-2.5">Loading...</div></div></div></div><div id="nNEA3KpeLj" class="relative group/block"><p>One simple method for predicting the price is to average the prices of the nearest neighbors.</p></div><div id="ygMCkWuHba" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def predict_nn(example):
    &quot;&quot;&quot;Return the majority class among the k nearest neighbors.&quot;&quot;&quot;
    return np.average(closest(train_nn, example, 5, &#x27;SalePrice&#x27;).column(&#x27;SalePrice&#x27;))

predict_nn(example_nn_row)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="sAoC46VaL3_DiCKUAKvrx" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><div class="font-mono text-sm whitespace-pre-wrap"><code><span>143415.0</span></code></div></div></div><div id="ZYqn1LHpQL" class="relative group/block"><p>Finally, we can inspect whether our prediction is close to the true sale price for our one test example. Looks reasonable!</p></div><div id="LtCXhcgcUH" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">print(&#x27;Actual sale price:&#x27;, test_nn.column(&#x27;SalePrice&#x27;).item(0))
print(&#x27;Predicted sale price using nearest neighbors:&#x27;, predict_nn(example_nn_row))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="HLXLKwWhNzLxg2lPJJWu1" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span>Actual sale price: 147000
Predicted sale price using nearest neighbors: 143415.0
</span></code></pre></div></div></div><div id="ajkH3U7PhZ" class="relative group/block"><h3 id="evaluation" class="relative group"><span class="heading-text">Evaluation</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#evaluation" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>To evaluate the performance of this approach for the whole test set, we apply <code>predict_nn</code> to each test example, then compute the root mean squared error of the predictions. Computation of the predictions may take several minutes.</p></div><div id="nSpgvHIfXX" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">nn_test_predictions = test_nn.drop(&#x27;SalePrice&#x27;).apply(predict_nn)
rmse_nn = np.mean((test_prices - nn_test_predictions) ** 2) ** 0.5

print(&#x27;Test set RMSE for multiple linear regression: &#x27;, rmse_linear)
print(&#x27;Test set RMSE for nearest neighbor regression:&#x27;, rmse_nn)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="LOZPaRP8HmHYgzAtXwHb8" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span>Test set RMSE for multiple linear regression:  33025.064938240575
Test set RMSE for nearest neighbor regression: 36067.116043510105
</span></code></pre></div></div></div><div id="zo2sIUYfJO" class="relative group/block"><p>For these data, the errors of the two techniques are quite similar! For different data sets, one technique might outperform another. By computing the RMSE of both techniques on the same data, we can compare methods fairly. One note of caution: the difference in performance might not be due to the technique at all; it might be due to the random variation due to sampling the training and test sets in the first place.</p><p>Finally, we can draw a residual plot for these predictions. We still underestimate the prices of the most expensive houses, but the bias does not appear to be as systematic. However, fewer residuals are very close to zero, indicating that fewer prices were predicted with very high accuracy.</p></div><div id="Cikd5y0A8A" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">test.with_column(&#x27;Residual&#x27;, test_prices-nn_test_predictions).scatter(0, &#x27;Residual&#x27;)
plots.plot([0, 7e5], [0, 0]);</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="r7GwWG5ItT_XIKppOIXGA" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><img src="/build/18f71601d626cc44ce3055c3762bf859.png" alt="&lt;Figure size 360x360 with 1 Axes&gt;"/></div></div><div></div><div class="flex pt-10 mb-10 space-x-4"><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/chapters/17/5/accuracy-of-the-classifier"><div class="flex h-full align-middle"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:-translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M10.5 19.5 3 12m0 0 7.5-7.5M3 12h18"></path></svg><div class="flex-grow text-right"><div class="text-xs text-gray-500 dark:text-gray-400">Computational and Inferential Thinking</div>The Accuracy of the Classifier</div></div></a><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/chapters/18/updating-predictions"><div class="flex h-full align-middle"><div class="flex-grow"><div class="text-xs text-gray-500 dark:text-gray-400">Computational and Inferential Thinking</div>Updating Predictions</div><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 4.5 21 12m0 0-7.5 7.5M21 12H3"></path></svg></div></a></div></article></main><footer class="article footer article-grid bg-white dark:bg-slate-950 mt-10 shadow-2xl shadow py-10"><p>By Ani Adhikari and John DeNero and David Wagner</p><p><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>©</mtext></mrow><annotation encoding="application/x-tex">\copyright</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;"></span><span class="mord text"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8889em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">c</span></span></span><span style="top:-3.1944em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body accent-full" style="left:0em;top:.2em;"><span class="mord">◯</span></span></span></span></span></span></span></span></span></span></span></span> Copyright 2022.</p></footer><script>((a,d)=>{if(!window.history.state||!window.history.state.key){let h=Math.random().toString(32).slice(2);window.history.replaceState({key:h},"")}try{let f=JSON.parse(sessionStorage.getItem(a)||"{}")[d||window.history.state.key];typeof f=="number"&&window.scrollTo(0,f)}catch(h){console.error(h),sessionStorage.removeItem(a)}})("positions", null)</script><link rel="modulepreload" href="/build/entry.client-UNPC4GT3.js"/><link rel="modulepreload" href="/build/_shared/chunk-OCTKKCIL.js"/><link rel="modulepreload" href="/build/_shared/chunk-UAI5KRM7.js"/><link rel="modulepreload" href="/build/_shared/chunk-2NH4LW52.js"/><link rel="modulepreload" href="/build/_shared/chunk-F7G67JTZ.js"/><link rel="modulepreload" href="/build/_shared/chunk-HBJK6BW3.js"/><link rel="modulepreload" href="/build/_shared/chunk-HYMQ7M2K.js"/><link rel="modulepreload" href="/build/_shared/chunk-OHOXABTA.js"/><link rel="modulepreload" href="/build/_shared/chunk-OCWQY3HK.js"/><link rel="modulepreload" href="/build/_shared/chunk-CPTH56EW.js"/><link rel="modulepreload" href="/build/_shared/chunk-3CVK3PYF.js"/><link rel="modulepreload" href="/build/_shared/chunk-J6FHCSRC.js"/><link rel="modulepreload" href="/build/_shared/chunk-S4SWV34C.js"/><link rel="modulepreload" href="/build/_shared/chunk-GUCIBHGO.js"/><link rel="modulepreload" href="/build/root-7TUVC4ZT.js"/><link rel="modulepreload" href="/build/_shared/chunk-INOWNUZ6.js"/><link rel="modulepreload" href="/build/routes/$-P6PGXPYX.js"/><script>window.__remixContext = {"url":"/chapters/17/6/multiple-regression","state":{"loaderData":{"root":{"config":{"version":2,"myst":"1.6.4","options":{"favicon":"/build/favicon-c4f2b8aed06e197b8d58618bb6206e83.ico","logo":"/build/data8logo-e8cfc0153f6b4ee7c43c8a236cd746b7.png","logo_text":"Computational and Inferential Thinking","analytics_google":"UA-148221575-1","folders":true},"parts":{"footer":{"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"By Ani Adhikari and John DeNero and David Wagner","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"RZclvp7Rn8"}],"key":"jK7sCWllhj"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"inlineMath","value":"\\copyright","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmtext\u003e©\u003c/mtext\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\copyright\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8889em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord accent\"\u003e\u003cspan class=\"vlist-t\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.8889em;\"\u003e\u003cspan style=\"top:-3em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord\"\u003ec\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.1944em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"accent-body accent-full\" style=\"left:0em;top:.2em;\"\u003e\u003cspan class=\"mord\"\u003e◯\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"UxkpBDWPQV"},{"type":"text","value":" Copyright 2022.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"u7cKahkOqv"}],"key":"xUWs7fjphd"}],"key":"UMiTSje0IS"}],"key":"Dyvcg77WlN"},"frontmatter":{"parts":{},"license":{"content":{"id":"CC-BY-NC-ND-4.0","url":"https://creativecommons.org/licenses/by-nc-nd/4.0/","name":"Creative Commons Attribution Non Commercial No Derivatives 4.0 International","CC":true}},"github":"https://github.com/data-8/textbook","numbering":{"title":{"enabled":true}},"source_url":"https://github.com/data-8/textbook/blob/main/footer.md","edit_url":"https://github.com/data-8/textbook/edit/main/footer.md","enumerator":"19"}}},"nav":[],"actions":[],"projects":[{"license":{"content":{"id":"CC-BY-NC-ND-4.0","url":"https://creativecommons.org/licenses/by-nc-nd/4.0/","name":"Creative Commons Attribution Non Commercial No Derivatives 4.0 International","CC":true}},"numbering":{"title":{"enabled":true}},"title":"Computational and Inferential Thinking","authors":[{"nameParsed":{"literal":"Ani Adhikari","given":"Ani","family":"Adhikari"},"name":"Ani Adhikari","id":"contributors-myst-generated-uid-0"},{"nameParsed":{"literal":"John DeNero","given":"John","family":"DeNero"},"name":"John DeNero","id":"contributors-myst-generated-uid-1"},{"nameParsed":{"literal":"David Wagner","given":"David","family":"Wagner"},"name":"David Wagner","id":"contributors-myst-generated-uid-2"}],"github":"https://github.com/data-8/textbook","toc":[{"file":"chapters/intro.md"},{"children":[{"children":[{"file":"chapters/01/1/1/computational-tools.md"},{"file":"chapters/01/1/2/statistical-techniques.md"}],"file":"chapters/01/1/intro.md"},{"file":"chapters/01/2/why-data-science.md"},{"children":[{"file":"chapters/01/3/1/Literary_Characters.ipynb"},{"file":"chapters/01/3/2/Another_Kind_Of_Character.ipynb"}],"file":"chapters/01/3/Plotting_the_Classics.ipynb"}],"file":"chapters/01/what-is-data-science.md"},{"children":[{"file":"chapters/02/1/observation-and-visualization-john-snow-and-the-broad-street-pump.md","title":"John Snow and the Broad Street Pump"},{"file":"chapters/02/2/snow-s-grand-experiment.md"},{"file":"chapters/02/3/establishing-causality.md"},{"file":"chapters/02/4/randomization.md"},{"file":"chapters/02/5/endnote.md"}],"file":"chapters/02/causality-and-experiments.md"},{"children":[{"file":"chapters/03/1/Expressions.ipynb"},{"children":[{"file":"chapters/03/2/1/Growth.ipynb"}],"file":"chapters/03/2/Names.ipynb"},{"file":"chapters/03/3/Calls.ipynb"},{"file":"chapters/03/4/Introduction_to_Tables.ipynb"}],"file":"chapters/03/programming-in-python.md"},{"children":[{"file":"chapters/04/1/Numbers.ipynb"},{"children":[{"file":"chapters/04/2/1/String_Methods.ipynb"}],"file":"chapters/04/2/Strings.ipynb"},{"file":"chapters/04/3/Comparison.ipynb"}],"file":"chapters/04/Data_Types.ipynb"},{"children":[{"file":"chapters/05/1/Arrays.ipynb"},{"file":"chapters/05/2/Ranges.ipynb"},{"file":"chapters/05/3/More_on_Arrays.ipynb"}],"file":"chapters/05/Sequences.ipynb"},{"children":[{"file":"chapters/06/1/Sorting_Rows.ipynb"},{"file":"chapters/06/2/Selecting_Rows.ipynb"},{"file":"chapters/06/3/Example_Population_Trends.ipynb"},{"file":"chapters/06/4/Example_Sex_Ratios.ipynb"}],"file":"chapters/06/Tables.ipynb"},{"children":[{"file":"chapters/07/1/Visualizing_Categorical_Distributions.ipynb"},{"file":"chapters/07/2/Visualizing_Numerical_Distributions.ipynb"},{"file":"chapters/07/3/Overlaid_Graphs.ipynb"}],"file":"chapters/07/Visualization.ipynb"},{"children":[{"file":"chapters/08/1/Applying_a_Function_to_a_Column.ipynb"},{"file":"chapters/08/2/Classifying_by_One_Variable.ipynb"},{"file":"chapters/08/3/Cross-Classifying_by_More_than_One_Variable.ipynb"},{"file":"chapters/08/4/Joining_Tables_by_Columns.ipynb"},{"file":"chapters/08/5/Bike_Sharing_in_the_Bay_Area.ipynb"}],"file":"chapters/08/Functions_and_Tables.ipynb"},{"children":[{"file":"chapters/09/1/Conditional_Statements.ipynb"},{"file":"chapters/09/2/Iteration.ipynb"},{"file":"chapters/09/3/Simulation.ipynb"},{"file":"chapters/09/4/Monty_Hall_Problem.ipynb"},{"file":"chapters/09/5/Finding_Probabilities.ipynb"}],"file":"chapters/09/Randomness.ipynb"},{"children":[{"file":"chapters/10/1/Empirical_Distributions.ipynb"},{"file":"chapters/10/2/Sampling_from_a_Population.ipynb"},{"file":"chapters/10/3/Empirical_Distribution_of_a_Statistic.ipynb"},{"file":"chapters/10/4/Random_Sampling_in_Python.ipynb"}],"file":"chapters/10/Sampling_and_Empirical_Distributions.ipynb"},{"children":[{"file":"chapters/11/1/Assessing_a_Model.ipynb"},{"file":"chapters/11/2/Multiple_Categories.ipynb"},{"file":"chapters/11/3/Decisions_and_Uncertainty.ipynb"},{"file":"chapters/11/4/Error_Probabilities.ipynb"}],"file":"chapters/11/Testing_Hypotheses.md"},{"children":[{"file":"chapters/12/1/AB_Testing.ipynb"},{"file":"chapters/12/2/Causality.ipynb"},{"file":"chapters/12/3/Deflategate.ipynb"}],"file":"chapters/12/Comparing_Two_Samples.md"},{"children":[{"file":"chapters/13/1/Percentiles.ipynb"},{"file":"chapters/13/2/Bootstrap.ipynb"},{"file":"chapters/13/3/Confidence_Intervals.ipynb"},{"file":"chapters/13/4/Using_Confidence_Intervals.ipynb"}],"file":"chapters/13/Estimation.md"},{"children":[{"file":"chapters/14/1/Properties_of_the_Mean.ipynb"},{"file":"chapters/14/2/Variability.ipynb"},{"file":"chapters/14/3/SD_and_the_Normal_Curve.ipynb"},{"file":"chapters/14/4/Central_Limit_Theorem.ipynb"},{"file":"chapters/14/5/Variability_of_the_Sample_Mean.ipynb"},{"file":"chapters/14/6/Choosing_a_Sample_Size.ipynb"}],"file":"chapters/14/Why_the_Mean_Matters.md"},{"children":[{"file":"chapters/15/1/Correlation.ipynb"},{"file":"chapters/15/2/Regression_Line.ipynb"},{"file":"chapters/15/3/Method_of_Least_Squares.ipynb"},{"file":"chapters/15/4/Least_Squares_Regression.ipynb"},{"file":"chapters/15/5/Visual_Diagnostics.ipynb"},{"file":"chapters/15/6/Numerical_Diagnostics.ipynb"}],"file":"chapters/15/Prediction.ipynb"},{"children":[{"file":"chapters/16/1/Regression_Model.ipynb"},{"file":"chapters/16/2/Inference_for_the_True_Slope.ipynb"},{"file":"chapters/16/3/Prediction_Intervals.ipynb"}],"file":"chapters/16/Inference_for_Regression.md"},{"children":[{"file":"chapters/17/1/Nearest_Neighbors.ipynb"},{"file":"chapters/17/2/Training_and_Testing.ipynb"},{"file":"chapters/17/3/Rows_of_Tables.ipynb"},{"file":"chapters/17/4/Implementing_the_Classifier.ipynb"},{"file":"chapters/17/5/Accuracy_of_the_Classifier.ipynb"},{"file":"chapters/17/6/Multiple_Regression.ipynb"}],"file":"chapters/17/Classification.md"},{"children":[{"file":"chapters/18/1/More_Likely_than_Not_Binary_Classifier.ipynb"},{"file":"chapters/18/2/Making_Decisions.ipynb"}],"file":"chapters/18/Updating_Predictions.md"}],"exports":[],"bibliography":[],"index":"index","pages":[{"slug":"chapters.01.what-is-data-science","title":"What is Data Science?","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"1"},{"slug":"chapters.01.1.intro","title":"Introduction","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.1"},{"slug":"chapters.01.1.1.computational-tools","title":"Computational Tools","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.1.1"},{"slug":"chapters.01.1.2.statistical-techniques","title":"Statistical Techniques","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.1.2"},{"slug":"chapters.01.2.why-data-science","title":"Why Data Science?","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.2"},{"slug":"chapters.01.3.plotting-the-classics","title":"Plotting the Classics","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.3"},{"slug":"chapters.01.3.1.literary-characters","title":"Literary Characters","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.3.1"},{"slug":"chapters.01.3.2.another-kind-of-character","title":"Another Kind of Character","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.3.2"},{"slug":"chapters.02.causality-and-experiments","title":"Causality and Experiments","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"2"},{"slug":"chapters.02.1.observation-and-visualization-john-snow-and-the-br","title":"Observation and Visualization: John Snow and the Broad Street Pump","description":"","date":"","thumbnail":"/build/snow_map-173b7e139b34475013f936d7cc85190c.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.1"},{"slug":"chapters.02.2.snow-s-grand-experiment","title":"Snow’s “Grand Experiment”","description":"","date":"","thumbnail":"/build/snow_map2-2d1199802166135b288a87da3c7a04d2.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.2"},{"slug":"chapters.02.3.establishing-causality","title":"Establishing Causality","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.3"},{"slug":"chapters.02.4.randomization","title":"Randomization","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.4"},{"slug":"chapters.02.5.endnote","title":"Endnote","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.5"},{"slug":"chapters.03.programming-in-python","title":"Programming in Python","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"3"},{"slug":"chapters.03.1.expressions","title":"Expressions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.1"},{"slug":"chapters.03.2.names","title":"Names","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.2"},{"slug":"chapters.03.2.1.growth","title":"Example: Growth Rates","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"3.2.1"},{"slug":"chapters.03.3.calls","title":"Call Expressions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.3"},{"slug":"chapters.03.4.introduction-to-tables","title":"Introduction to Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.4"},{"slug":"chapters.04.data-types","title":"Data Types","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"4"},{"slug":"chapters.04.1.numbers","title":"Numbers","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.1"},{"slug":"chapters.04.2.strings","title":"Strings","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.2"},{"slug":"chapters.04.2.1.string-methods","title":"String Methods","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"4.2.1"},{"slug":"chapters.04.3.comparison","title":"Comparisons","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.3"},{"slug":"chapters.05.sequences","title":"Sequences","description":"","date":"","thumbnail":"/build/global-land-TMAX-Tre-0259f4201a417ecbdbf38a1be53cf6ef.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"5"},{"slug":"chapters.05.1.arrays","title":"Arrays","description":"","date":"","thumbnail":"/build/array_arithmetic-eb90b39844ed099ae7191bcc9214afd7.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.1"},{"slug":"chapters.05.2.ranges","title":"Ranges","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.2"},{"slug":"chapters.05.3.more-on-arrays","title":"More on Arrays","description":"","date":"","thumbnail":"/build/array_subtraction-76924b5aad7bbd046618889ad0790527.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.3"},{"slug":"chapters.06.tables","title":"Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"6"},{"slug":"chapters.06.1.sorting-rows","title":"Sorting Rows","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.1"},{"slug":"chapters.06.2.selecting-rows","title":"Selecting Rows","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.2"},{"slug":"chapters.06.3.example-population-trends","title":"Example: Population Trends","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.3"},{"slug":"chapters.06.4.example-sex-ratios","title":"Example: Sex Ratios","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.4"},{"slug":"chapters.07.visualization","title":"Visualization","description":"","date":"","thumbnail":"/build/C-3PO_droid-b8360dd37f31deba2f98e3a28f126353.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"7"},{"slug":"chapters.07.1.visualizing-categorical-distributions","title":"Visualizing Categorical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.1"},{"slug":"chapters.07.2.visualizing-numerical-distributions","title":"Visualizing Numerical Distributions","description":"","date":"","thumbnail":"/build/ipad_battery-de7d1b7f2bb0e97a5c40be90f62b6014.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.2"},{"slug":"chapters.07.3.overlaid-graphs","title":"Overlaid Graphs","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.3"},{"slug":"chapters.08.functions-and-tables","title":"Functions and Tables","description":"","date":"","thumbnail":"/build/function_definition-4f5161f5d8f15fb47dc855e8d00e57e3.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"8"},{"slug":"chapters.08.1.applying-a-function-to-a-column","title":"Applying a Function to a Column","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.1"},{"slug":"chapters.08.2.classifying-by-one-variable","title":"Classifying by One Variable","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.2"},{"slug":"chapters.08.3.cross-classifying-by-more-than-one-variable","title":"Cross-Classifying by More than One Variable","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.3"},{"slug":"chapters.08.4.joining-tables-by-columns","title":"Joining Tables by Columns","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.4"},{"slug":"chapters.08.5.bike-sharing-in-the-bay-area","title":"Bike Sharing in the Bay Area","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.5"},{"slug":"chapters.09.randomness","title":"Randomness","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"9"},{"slug":"chapters.09.1.conditional-statements","title":"Conditional Statements","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.1"},{"slug":"chapters.09.2.iteration","title":"Iteration","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.2"},{"slug":"chapters.09.3.simulation","title":"Simulation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.3"},{"slug":"chapters.09.4.monty-hall-problem","title":"The Monty Hall Problem","description":"","date":"","thumbnail":"/build/monty_hall_goat-56112fd06fb86f88a6aba432a30f7253.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.4"},{"slug":"chapters.09.5.finding-probabilities","title":"Finding Probabilities","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.5"},{"slug":"chapters.10.sampling-and-empirical-distributions","title":"Sampling and Empirical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"10"},{"slug":"chapters.10.1.empirical-distributions","title":"Empirical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.1"},{"slug":"chapters.10.2.sampling-from-a-population","title":"Sampling from a Population","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.2"},{"slug":"chapters.10.3.empirical-distribution-of-a-statistic","title":"Empirical Distribution of a Statistic","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.3"},{"slug":"chapters.10.4.random-sampling-in-python","title":"Random Sampling in Python","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.4"},{"slug":"chapters.11.testing-hypotheses","title":"Testing Hypotheses","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"11"},{"slug":"chapters.11.1.assessing-a-model","title":"Assessing a Model","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.1"},{"slug":"chapters.11.2.multiple-categories","title":"Multiple Categories","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.2"},{"slug":"chapters.11.3.decisions-and-uncertainty","title":"Decisions and Uncertainty","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.3"},{"slug":"chapters.11.4.error-probabilities","title":"Error Probabilities","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.4"},{"slug":"chapters.12.comparing-two-samples","title":"Comparing Two Samples","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"12"},{"slug":"chapters.12.1.ab-testing","title":"A/B Testing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.1"},{"slug":"chapters.12.2.causality","title":"Causality","description":"","date":"","thumbnail":"/build/causality1-2e59fee82f936dc1e42a61601a813557.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.2"},{"slug":"chapters.12.3.deflategate","title":"Deflategate","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.3"},{"slug":"chapters.13.estimation","title":"Estimation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"13"},{"slug":"chapters.13.1.percentiles","title":"Percentiles","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.1"},{"slug":"chapters.13.2.bootstrap","title":"The Bootstrap","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.2"},{"slug":"chapters.13.3.confidence-intervals","title":"Confidence Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.3"},{"slug":"chapters.13.4.using-confidence-intervals","title":"Using Confidence Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.4"},{"slug":"chapters.14.why-the-mean-matters","title":"Why the Mean Matters","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"14"},{"slug":"chapters.14.1.properties-of-the-mean","title":"Properties of the Mean","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.1"},{"slug":"chapters.14.2.variability","title":"Variability","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.2"},{"slug":"chapters.14.3.sd-and-the-normal-curve","title":"The SD and the Normal Curve","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.3"},{"slug":"chapters.14.4.central-limit-theorem","title":"The Central Limit Theorem","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.4"},{"slug":"chapters.14.5.variability-of-the-sample-mean","title":"The Variability of the Sample Mean","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.5"},{"slug":"chapters.14.6.choosing-a-sample-size","title":"Choosing a Sample Size","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.6"},{"slug":"chapters.15.prediction","title":"Prediction","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"15"},{"slug":"chapters.15.1.correlation","title":"Correlation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.1"},{"slug":"chapters.15.2.regression-line","title":"The Regression Line","description":"","date":"","thumbnail":"/build/regline-6275539e16b9f1a5de8876a751e967a6.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.2"},{"slug":"chapters.15.3.method-of-least-squares","title":"The Method of Least Squares","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.3"},{"slug":"chapters.15.4.least-squares-regression","title":"Least Squares Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.4"},{"slug":"chapters.15.5.visual-diagnostics","title":"Visual Diagnostics","description":"","date":"","thumbnail":"/build/5f819b0045c6e81a4265dd506d7aaff9.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.5"},{"slug":"chapters.15.6.numerical-diagnostics","title":"Numerical Diagnostics","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.6"},{"slug":"chapters.16.inference-for-regression","title":"Inference for Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"16"},{"slug":"chapters.16.1.regression-model","title":"A Regression Model","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.1"},{"slug":"chapters.16.2.inference-for-the-true-slope","title":"Inference for the True Slope","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.2"},{"slug":"chapters.16.3.prediction-intervals","title":"Prediction Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.3"},{"slug":"chapters.17.classification","title":"Classification","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"17"},{"slug":"chapters.17.1.nearest-neighbors","title":"Nearest Neighbors","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.1"},{"slug":"chapters.17.2.training-and-testing","title":"Training and Testing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.2"},{"slug":"chapters.17.3.rows-of-tables","title":"Rows of Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.3"},{"slug":"chapters.17.4.implementing-the-classifier","title":"Implementing the Classifier","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.4"},{"slug":"chapters.17.5.accuracy-of-the-classifier","title":"The Accuracy of the Classifier","description":"","date":"","thumbnail":"/build/5e548385d4da863b59d51148bd5d0eeb.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.5"},{"slug":"chapters.17.6.multiple-regression","title":"Multiple Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.6"},{"slug":"chapters.18.updating-predictions","title":"Updating Predictions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"18"},{"slug":"chapters.18.1.more-likely-than-not-binary-classifier","title":"A “More Likely Than Not” Binary Classifier","description":"","date":"","thumbnail":"/build/tree_students-17a4ad5b4b4daa4f20ca9bf6c8b9a90d.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"18.1"},{"slug":"chapters.18.2.making-decisions","title":"Making Decisions","description":"","date":"","thumbnail":"/build/tree_disease_rare-6392a369221abe1c7bdffbd913bcb033.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"18.2"}]}]},"CONTENT_CDN_PORT":"3100","MODE":"static"},"routes/$":{"config":{"version":2,"myst":"1.6.4","options":{"favicon":"/build/favicon-c4f2b8aed06e197b8d58618bb6206e83.ico","logo":"/build/data8logo-e8cfc0153f6b4ee7c43c8a236cd746b7.png","logo_text":"Computational and Inferential Thinking","analytics_google":"UA-148221575-1","folders":true},"parts":{"footer":{"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"By Ani Adhikari and John DeNero and David Wagner","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"RZclvp7Rn8"}],"key":"jK7sCWllhj"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"inlineMath","value":"\\copyright","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmtext\u003e©\u003c/mtext\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\copyright\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8889em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord accent\"\u003e\u003cspan class=\"vlist-t\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.8889em;\"\u003e\u003cspan style=\"top:-3em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord\"\u003ec\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.1944em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"accent-body accent-full\" style=\"left:0em;top:.2em;\"\u003e\u003cspan class=\"mord\"\u003e◯\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"UxkpBDWPQV"},{"type":"text","value":" Copyright 2022.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"u7cKahkOqv"}],"key":"xUWs7fjphd"}],"key":"UMiTSje0IS"}],"key":"Dyvcg77WlN"},"frontmatter":{"parts":{},"license":{"content":{"id":"CC-BY-NC-ND-4.0","url":"https://creativecommons.org/licenses/by-nc-nd/4.0/","name":"Creative Commons Attribution Non Commercial No Derivatives 4.0 International","CC":true}},"github":"https://github.com/data-8/textbook","numbering":{"title":{"enabled":true}},"source_url":"https://github.com/data-8/textbook/blob/main/footer.md","edit_url":"https://github.com/data-8/textbook/edit/main/footer.md","enumerator":"19"}}},"nav":[],"actions":[],"projects":[{"license":{"content":{"id":"CC-BY-NC-ND-4.0","url":"https://creativecommons.org/licenses/by-nc-nd/4.0/","name":"Creative Commons Attribution Non Commercial No Derivatives 4.0 International","CC":true}},"numbering":{"title":{"enabled":true}},"title":"Computational and Inferential Thinking","authors":[{"nameParsed":{"literal":"Ani Adhikari","given":"Ani","family":"Adhikari"},"name":"Ani Adhikari","id":"contributors-myst-generated-uid-0"},{"nameParsed":{"literal":"John DeNero","given":"John","family":"DeNero"},"name":"John DeNero","id":"contributors-myst-generated-uid-1"},{"nameParsed":{"literal":"David Wagner","given":"David","family":"Wagner"},"name":"David Wagner","id":"contributors-myst-generated-uid-2"}],"github":"https://github.com/data-8/textbook","toc":[{"file":"chapters/intro.md"},{"children":[{"children":[{"file":"chapters/01/1/1/computational-tools.md"},{"file":"chapters/01/1/2/statistical-techniques.md"}],"file":"chapters/01/1/intro.md"},{"file":"chapters/01/2/why-data-science.md"},{"children":[{"file":"chapters/01/3/1/Literary_Characters.ipynb"},{"file":"chapters/01/3/2/Another_Kind_Of_Character.ipynb"}],"file":"chapters/01/3/Plotting_the_Classics.ipynb"}],"file":"chapters/01/what-is-data-science.md"},{"children":[{"file":"chapters/02/1/observation-and-visualization-john-snow-and-the-broad-street-pump.md","title":"John Snow and the Broad Street Pump"},{"file":"chapters/02/2/snow-s-grand-experiment.md"},{"file":"chapters/02/3/establishing-causality.md"},{"file":"chapters/02/4/randomization.md"},{"file":"chapters/02/5/endnote.md"}],"file":"chapters/02/causality-and-experiments.md"},{"children":[{"file":"chapters/03/1/Expressions.ipynb"},{"children":[{"file":"chapters/03/2/1/Growth.ipynb"}],"file":"chapters/03/2/Names.ipynb"},{"file":"chapters/03/3/Calls.ipynb"},{"file":"chapters/03/4/Introduction_to_Tables.ipynb"}],"file":"chapters/03/programming-in-python.md"},{"children":[{"file":"chapters/04/1/Numbers.ipynb"},{"children":[{"file":"chapters/04/2/1/String_Methods.ipynb"}],"file":"chapters/04/2/Strings.ipynb"},{"file":"chapters/04/3/Comparison.ipynb"}],"file":"chapters/04/Data_Types.ipynb"},{"children":[{"file":"chapters/05/1/Arrays.ipynb"},{"file":"chapters/05/2/Ranges.ipynb"},{"file":"chapters/05/3/More_on_Arrays.ipynb"}],"file":"chapters/05/Sequences.ipynb"},{"children":[{"file":"chapters/06/1/Sorting_Rows.ipynb"},{"file":"chapters/06/2/Selecting_Rows.ipynb"},{"file":"chapters/06/3/Example_Population_Trends.ipynb"},{"file":"chapters/06/4/Example_Sex_Ratios.ipynb"}],"file":"chapters/06/Tables.ipynb"},{"children":[{"file":"chapters/07/1/Visualizing_Categorical_Distributions.ipynb"},{"file":"chapters/07/2/Visualizing_Numerical_Distributions.ipynb"},{"file":"chapters/07/3/Overlaid_Graphs.ipynb"}],"file":"chapters/07/Visualization.ipynb"},{"children":[{"file":"chapters/08/1/Applying_a_Function_to_a_Column.ipynb"},{"file":"chapters/08/2/Classifying_by_One_Variable.ipynb"},{"file":"chapters/08/3/Cross-Classifying_by_More_than_One_Variable.ipynb"},{"file":"chapters/08/4/Joining_Tables_by_Columns.ipynb"},{"file":"chapters/08/5/Bike_Sharing_in_the_Bay_Area.ipynb"}],"file":"chapters/08/Functions_and_Tables.ipynb"},{"children":[{"file":"chapters/09/1/Conditional_Statements.ipynb"},{"file":"chapters/09/2/Iteration.ipynb"},{"file":"chapters/09/3/Simulation.ipynb"},{"file":"chapters/09/4/Monty_Hall_Problem.ipynb"},{"file":"chapters/09/5/Finding_Probabilities.ipynb"}],"file":"chapters/09/Randomness.ipynb"},{"children":[{"file":"chapters/10/1/Empirical_Distributions.ipynb"},{"file":"chapters/10/2/Sampling_from_a_Population.ipynb"},{"file":"chapters/10/3/Empirical_Distribution_of_a_Statistic.ipynb"},{"file":"chapters/10/4/Random_Sampling_in_Python.ipynb"}],"file":"chapters/10/Sampling_and_Empirical_Distributions.ipynb"},{"children":[{"file":"chapters/11/1/Assessing_a_Model.ipynb"},{"file":"chapters/11/2/Multiple_Categories.ipynb"},{"file":"chapters/11/3/Decisions_and_Uncertainty.ipynb"},{"file":"chapters/11/4/Error_Probabilities.ipynb"}],"file":"chapters/11/Testing_Hypotheses.md"},{"children":[{"file":"chapters/12/1/AB_Testing.ipynb"},{"file":"chapters/12/2/Causality.ipynb"},{"file":"chapters/12/3/Deflategate.ipynb"}],"file":"chapters/12/Comparing_Two_Samples.md"},{"children":[{"file":"chapters/13/1/Percentiles.ipynb"},{"file":"chapters/13/2/Bootstrap.ipynb"},{"file":"chapters/13/3/Confidence_Intervals.ipynb"},{"file":"chapters/13/4/Using_Confidence_Intervals.ipynb"}],"file":"chapters/13/Estimation.md"},{"children":[{"file":"chapters/14/1/Properties_of_the_Mean.ipynb"},{"file":"chapters/14/2/Variability.ipynb"},{"file":"chapters/14/3/SD_and_the_Normal_Curve.ipynb"},{"file":"chapters/14/4/Central_Limit_Theorem.ipynb"},{"file":"chapters/14/5/Variability_of_the_Sample_Mean.ipynb"},{"file":"chapters/14/6/Choosing_a_Sample_Size.ipynb"}],"file":"chapters/14/Why_the_Mean_Matters.md"},{"children":[{"file":"chapters/15/1/Correlation.ipynb"},{"file":"chapters/15/2/Regression_Line.ipynb"},{"file":"chapters/15/3/Method_of_Least_Squares.ipynb"},{"file":"chapters/15/4/Least_Squares_Regression.ipynb"},{"file":"chapters/15/5/Visual_Diagnostics.ipynb"},{"file":"chapters/15/6/Numerical_Diagnostics.ipynb"}],"file":"chapters/15/Prediction.ipynb"},{"children":[{"file":"chapters/16/1/Regression_Model.ipynb"},{"file":"chapters/16/2/Inference_for_the_True_Slope.ipynb"},{"file":"chapters/16/3/Prediction_Intervals.ipynb"}],"file":"chapters/16/Inference_for_Regression.md"},{"children":[{"file":"chapters/17/1/Nearest_Neighbors.ipynb"},{"file":"chapters/17/2/Training_and_Testing.ipynb"},{"file":"chapters/17/3/Rows_of_Tables.ipynb"},{"file":"chapters/17/4/Implementing_the_Classifier.ipynb"},{"file":"chapters/17/5/Accuracy_of_the_Classifier.ipynb"},{"file":"chapters/17/6/Multiple_Regression.ipynb"}],"file":"chapters/17/Classification.md"},{"children":[{"file":"chapters/18/1/More_Likely_than_Not_Binary_Classifier.ipynb"},{"file":"chapters/18/2/Making_Decisions.ipynb"}],"file":"chapters/18/Updating_Predictions.md"}],"exports":[],"bibliography":[],"index":"index","pages":[{"slug":"chapters.01.what-is-data-science","title":"What is Data Science?","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"1"},{"slug":"chapters.01.1.intro","title":"Introduction","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.1"},{"slug":"chapters.01.1.1.computational-tools","title":"Computational Tools","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.1.1"},{"slug":"chapters.01.1.2.statistical-techniques","title":"Statistical Techniques","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.1.2"},{"slug":"chapters.01.2.why-data-science","title":"Why Data Science?","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.2"},{"slug":"chapters.01.3.plotting-the-classics","title":"Plotting the Classics","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.3"},{"slug":"chapters.01.3.1.literary-characters","title":"Literary Characters","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.3.1"},{"slug":"chapters.01.3.2.another-kind-of-character","title":"Another Kind of Character","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.3.2"},{"slug":"chapters.02.causality-and-experiments","title":"Causality and Experiments","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"2"},{"slug":"chapters.02.1.observation-and-visualization-john-snow-and-the-br","title":"Observation and Visualization: John Snow and the Broad Street Pump","description":"","date":"","thumbnail":"/build/snow_map-173b7e139b34475013f936d7cc85190c.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.1"},{"slug":"chapters.02.2.snow-s-grand-experiment","title":"Snow’s “Grand Experiment”","description":"","date":"","thumbnail":"/build/snow_map2-2d1199802166135b288a87da3c7a04d2.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.2"},{"slug":"chapters.02.3.establishing-causality","title":"Establishing Causality","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.3"},{"slug":"chapters.02.4.randomization","title":"Randomization","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.4"},{"slug":"chapters.02.5.endnote","title":"Endnote","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.5"},{"slug":"chapters.03.programming-in-python","title":"Programming in Python","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"3"},{"slug":"chapters.03.1.expressions","title":"Expressions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.1"},{"slug":"chapters.03.2.names","title":"Names","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.2"},{"slug":"chapters.03.2.1.growth","title":"Example: Growth Rates","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"3.2.1"},{"slug":"chapters.03.3.calls","title":"Call Expressions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.3"},{"slug":"chapters.03.4.introduction-to-tables","title":"Introduction to Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.4"},{"slug":"chapters.04.data-types","title":"Data Types","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"4"},{"slug":"chapters.04.1.numbers","title":"Numbers","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.1"},{"slug":"chapters.04.2.strings","title":"Strings","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.2"},{"slug":"chapters.04.2.1.string-methods","title":"String Methods","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"4.2.1"},{"slug":"chapters.04.3.comparison","title":"Comparisons","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.3"},{"slug":"chapters.05.sequences","title":"Sequences","description":"","date":"","thumbnail":"/build/global-land-TMAX-Tre-0259f4201a417ecbdbf38a1be53cf6ef.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"5"},{"slug":"chapters.05.1.arrays","title":"Arrays","description":"","date":"","thumbnail":"/build/array_arithmetic-eb90b39844ed099ae7191bcc9214afd7.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.1"},{"slug":"chapters.05.2.ranges","title":"Ranges","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.2"},{"slug":"chapters.05.3.more-on-arrays","title":"More on Arrays","description":"","date":"","thumbnail":"/build/array_subtraction-76924b5aad7bbd046618889ad0790527.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.3"},{"slug":"chapters.06.tables","title":"Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"6"},{"slug":"chapters.06.1.sorting-rows","title":"Sorting Rows","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.1"},{"slug":"chapters.06.2.selecting-rows","title":"Selecting Rows","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.2"},{"slug":"chapters.06.3.example-population-trends","title":"Example: Population Trends","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.3"},{"slug":"chapters.06.4.example-sex-ratios","title":"Example: Sex Ratios","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.4"},{"slug":"chapters.07.visualization","title":"Visualization","description":"","date":"","thumbnail":"/build/C-3PO_droid-b8360dd37f31deba2f98e3a28f126353.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"7"},{"slug":"chapters.07.1.visualizing-categorical-distributions","title":"Visualizing Categorical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.1"},{"slug":"chapters.07.2.visualizing-numerical-distributions","title":"Visualizing Numerical Distributions","description":"","date":"","thumbnail":"/build/ipad_battery-de7d1b7f2bb0e97a5c40be90f62b6014.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.2"},{"slug":"chapters.07.3.overlaid-graphs","title":"Overlaid Graphs","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.3"},{"slug":"chapters.08.functions-and-tables","title":"Functions and Tables","description":"","date":"","thumbnail":"/build/function_definition-4f5161f5d8f15fb47dc855e8d00e57e3.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"8"},{"slug":"chapters.08.1.applying-a-function-to-a-column","title":"Applying a Function to a Column","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.1"},{"slug":"chapters.08.2.classifying-by-one-variable","title":"Classifying by One Variable","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.2"},{"slug":"chapters.08.3.cross-classifying-by-more-than-one-variable","title":"Cross-Classifying by More than One Variable","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.3"},{"slug":"chapters.08.4.joining-tables-by-columns","title":"Joining Tables by Columns","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.4"},{"slug":"chapters.08.5.bike-sharing-in-the-bay-area","title":"Bike Sharing in the Bay Area","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.5"},{"slug":"chapters.09.randomness","title":"Randomness","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"9"},{"slug":"chapters.09.1.conditional-statements","title":"Conditional Statements","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.1"},{"slug":"chapters.09.2.iteration","title":"Iteration","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.2"},{"slug":"chapters.09.3.simulation","title":"Simulation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.3"},{"slug":"chapters.09.4.monty-hall-problem","title":"The Monty Hall Problem","description":"","date":"","thumbnail":"/build/monty_hall_goat-56112fd06fb86f88a6aba432a30f7253.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.4"},{"slug":"chapters.09.5.finding-probabilities","title":"Finding Probabilities","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.5"},{"slug":"chapters.10.sampling-and-empirical-distributions","title":"Sampling and Empirical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"10"},{"slug":"chapters.10.1.empirical-distributions","title":"Empirical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.1"},{"slug":"chapters.10.2.sampling-from-a-population","title":"Sampling from a Population","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.2"},{"slug":"chapters.10.3.empirical-distribution-of-a-statistic","title":"Empirical Distribution of a Statistic","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.3"},{"slug":"chapters.10.4.random-sampling-in-python","title":"Random Sampling in Python","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.4"},{"slug":"chapters.11.testing-hypotheses","title":"Testing Hypotheses","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"11"},{"slug":"chapters.11.1.assessing-a-model","title":"Assessing a Model","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.1"},{"slug":"chapters.11.2.multiple-categories","title":"Multiple Categories","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.2"},{"slug":"chapters.11.3.decisions-and-uncertainty","title":"Decisions and Uncertainty","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.3"},{"slug":"chapters.11.4.error-probabilities","title":"Error Probabilities","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.4"},{"slug":"chapters.12.comparing-two-samples","title":"Comparing Two Samples","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"12"},{"slug":"chapters.12.1.ab-testing","title":"A/B Testing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.1"},{"slug":"chapters.12.2.causality","title":"Causality","description":"","date":"","thumbnail":"/build/causality1-2e59fee82f936dc1e42a61601a813557.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.2"},{"slug":"chapters.12.3.deflategate","title":"Deflategate","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.3"},{"slug":"chapters.13.estimation","title":"Estimation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"13"},{"slug":"chapters.13.1.percentiles","title":"Percentiles","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.1"},{"slug":"chapters.13.2.bootstrap","title":"The Bootstrap","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.2"},{"slug":"chapters.13.3.confidence-intervals","title":"Confidence Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.3"},{"slug":"chapters.13.4.using-confidence-intervals","title":"Using Confidence Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.4"},{"slug":"chapters.14.why-the-mean-matters","title":"Why the Mean Matters","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"14"},{"slug":"chapters.14.1.properties-of-the-mean","title":"Properties of the Mean","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.1"},{"slug":"chapters.14.2.variability","title":"Variability","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.2"},{"slug":"chapters.14.3.sd-and-the-normal-curve","title":"The SD and the Normal Curve","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.3"},{"slug":"chapters.14.4.central-limit-theorem","title":"The Central Limit Theorem","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.4"},{"slug":"chapters.14.5.variability-of-the-sample-mean","title":"The Variability of the Sample Mean","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.5"},{"slug":"chapters.14.6.choosing-a-sample-size","title":"Choosing a Sample Size","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.6"},{"slug":"chapters.15.prediction","title":"Prediction","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"15"},{"slug":"chapters.15.1.correlation","title":"Correlation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.1"},{"slug":"chapters.15.2.regression-line","title":"The Regression Line","description":"","date":"","thumbnail":"/build/regline-6275539e16b9f1a5de8876a751e967a6.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.2"},{"slug":"chapters.15.3.method-of-least-squares","title":"The Method of Least Squares","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.3"},{"slug":"chapters.15.4.least-squares-regression","title":"Least Squares Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.4"},{"slug":"chapters.15.5.visual-diagnostics","title":"Visual Diagnostics","description":"","date":"","thumbnail":"/build/5f819b0045c6e81a4265dd506d7aaff9.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.5"},{"slug":"chapters.15.6.numerical-diagnostics","title":"Numerical Diagnostics","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.6"},{"slug":"chapters.16.inference-for-regression","title":"Inference for Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"16"},{"slug":"chapters.16.1.regression-model","title":"A Regression Model","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.1"},{"slug":"chapters.16.2.inference-for-the-true-slope","title":"Inference for the True Slope","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.2"},{"slug":"chapters.16.3.prediction-intervals","title":"Prediction Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.3"},{"slug":"chapters.17.classification","title":"Classification","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"17"},{"slug":"chapters.17.1.nearest-neighbors","title":"Nearest Neighbors","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.1"},{"slug":"chapters.17.2.training-and-testing","title":"Training and Testing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.2"},{"slug":"chapters.17.3.rows-of-tables","title":"Rows of Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.3"},{"slug":"chapters.17.4.implementing-the-classifier","title":"Implementing the Classifier","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.4"},{"slug":"chapters.17.5.accuracy-of-the-classifier","title":"The Accuracy of the Classifier","description":"","date":"","thumbnail":"/build/5e548385d4da863b59d51148bd5d0eeb.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.5"},{"slug":"chapters.17.6.multiple-regression","title":"Multiple Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.6"},{"slug":"chapters.18.updating-predictions","title":"Updating Predictions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"18"},{"slug":"chapters.18.1.more-likely-than-not-binary-classifier","title":"A “More Likely Than Not” Binary Classifier","description":"","date":"","thumbnail":"/build/tree_students-17a4ad5b4b4daa4f20ca9bf6c8b9a90d.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"18.1"},{"slug":"chapters.18.2.making-decisions","title":"Making Decisions","description":"","date":"","thumbnail":"/build/tree_disease_rare-6392a369221abe1c7bdffbd913bcb033.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"18.2"}]}]},"page":{"version":2,"kind":"Notebook","sha256":"96bfa1d8699036657d988ab990e61a72dc848c8d5df27c967195eb909a39054b","slug":"chapters.17.6.multiple-regression","location":"/chapters/17/6/Multiple_Regression.ipynb","dependencies":[],"frontmatter":{"title":"Multiple Regression","content_includes_title":false,"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"license":{"content":{"id":"CC-BY-NC-ND-4.0","url":"https://creativecommons.org/licenses/by-nc-nd/4.0/","name":"Creative Commons Attribution Non Commercial No Derivatives 4.0 International","CC":true}},"github":"https://github.com/data-8/textbook","numbering":{"title":{"enabled":true,"offset":1}},"source_url":"https://github.com/data-8/textbook/blob/main/chapters/17/6/Multiple_Regression.ipynb","edit_url":"https://github.com/data-8/textbook/edit/main/chapters/17/6/Multiple_Regression.ipynb","enumerator":"17.6","exports":[{"format":"ipynb","filename":"Multiple_Regression.ipynb","url":"/build/Multiple_Regression-3bd24270b729fe2cbcefccccb484be26.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"from datascience import *\npath_data = '../../../assets/data/'\nimport numpy as np\n\n%matplotlib inline\nimport matplotlib.pyplot as plots\nplots.style.use('fivethirtyeight')\n\nnp.set_printoptions(suppress=True)","visibility":"remove","key":"itlbbPzbRS"},{"type":"output","id":"UTz8lWpTwdjaHbB0an6Ve","data":[],"visibility":"show","key":"SWPHUYooYy"}],"visibility":"show","key":"DOjzMWY4Eb"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"def standard_units(any_numbers):\n    \"Convert any array of numbers to standard units.\"\n    return (any_numbers - np.mean(any_numbers))/np.std(any_numbers)  \n\ndef correlation(t, x, y):\n    return np.mean(standard_units(t.column(x))*standard_units(t.column(y)))","visibility":"remove","key":"jdWnZf0Ywg"},{"type":"output","id":"iF0BcRbBU7JUjuHX2jXyh","data":[],"visibility":"show","key":"Ul4rZTH8ed"}],"visibility":"show","key":"cN8tHsxJ0l"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Now that we have explored ways to use multiple attributes to predict a categorical variable, let us return to predicting a quantitative variable. Predicting a numerical quantity is called regression, and a commonly used method to use multiple attributes for regression is called ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"nEEWCTK8rz"},{"type":"emphasis","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"multiple linear regression","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"jV6rQNEAi4"}],"key":"CpTqoa4U9s"},{"type":"text","value":".","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"L7jCVnDKjU"}],"key":"cJuzrMy8OZ"},{"type":"heading","depth":2,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Home Prices","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"zNw8HUNQzl"}],"identifier":"home-prices","label":"Home Prices","html_id":"home-prices","implicit":true,"key":"Gh506gUmdj"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"The following dataset of house prices and attributes was collected over several years for the city of Ames, Iowa. A ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"mov4PwlKgJ"},{"type":"link","url":"http://ww2.amstat.org/publications/jse/v19n3/decock.pdf","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"description of the dataset appears online","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"biNfaN2lUE"}],"urlSource":"http://ww2.amstat.org/publications/jse/v19n3/decock.pdf","key":"EWGcCaZ7o5"},{"type":"text","value":". We will focus only a subset of the columns. We will try to predict the sale price column from the other columns.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"zOm9PcxlkN"}],"key":"HGUShKy4mW"}],"key":"L8yM3MeSl7"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"all_sales = Table.read_table(path_data + 'house.csv')\nsales = all_sales.where('Bldg Type', '1Fam').where('Sale Condition', 'Normal').select(\n    'SalePrice', '1st Flr SF', '2nd Flr SF', \n    'Total Bsmt SF', 'Garage Area', \n    'Wood Deck SF', 'Open Porch SF', 'Lot Area', \n    'Year Built', 'Yr Sold')\nsales.sort('SalePrice')","key":"GMuEs4vsU6"},{"type":"output","id":"A49dd7aYPyOizqmQigTHt","data":[{"output_type":"execute_result","execution_count":3,"metadata":{},"data":{"text/html":{"content":"\u003ctable border=\"1\" class=\"dataframe\"\u003e\n    \u003cthead\u003e\n        \u003ctr\u003e\n            \u003cth\u003eSalePrice\u003c/th\u003e \u003cth\u003e1st Flr SF\u003c/th\u003e \u003cth\u003e2nd Flr SF\u003c/th\u003e \u003cth\u003eTotal Bsmt SF\u003c/th\u003e \u003cth\u003eGarage Area\u003c/th\u003e \u003cth\u003eWood Deck SF\u003c/th\u003e \u003cth\u003eOpen Porch SF\u003c/th\u003e \u003cth\u003eLot Area\u003c/th\u003e \u003cth\u003eYear Built\u003c/th\u003e \u003cth\u003eYr Sold\u003c/th\u003e\n        \u003c/tr\u003e\n    \u003c/thead\u003e\n    \u003ctbody\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e35000    \u003c/td\u003e \u003ctd\u003e498       \u003c/td\u003e \u003ctd\u003e0         \u003c/td\u003e \u003ctd\u003e498          \u003c/td\u003e \u003ctd\u003e216        \u003c/td\u003e \u003ctd\u003e0           \u003c/td\u003e \u003ctd\u003e0            \u003c/td\u003e \u003ctd\u003e8088    \u003c/td\u003e \u003ctd\u003e1922      \u003c/td\u003e \u003ctd\u003e2006   \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e39300    \u003c/td\u003e \u003ctd\u003e334       \u003c/td\u003e \u003ctd\u003e0         \u003c/td\u003e \u003ctd\u003e0            \u003c/td\u003e \u003ctd\u003e0          \u003c/td\u003e \u003ctd\u003e0           \u003c/td\u003e \u003ctd\u003e0            \u003c/td\u003e \u003ctd\u003e5000    \u003c/td\u003e \u003ctd\u003e1946      \u003c/td\u003e \u003ctd\u003e2007   \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e40000    \u003c/td\u003e \u003ctd\u003e649       \u003c/td\u003e \u003ctd\u003e668       \u003c/td\u003e \u003ctd\u003e649          \u003c/td\u003e \u003ctd\u003e250        \u003c/td\u003e \u003ctd\u003e0           \u003c/td\u003e \u003ctd\u003e54           \u003c/td\u003e \u003ctd\u003e8500    \u003c/td\u003e \u003ctd\u003e1920      \u003c/td\u003e \u003ctd\u003e2008   \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e45000    \u003c/td\u003e \u003ctd\u003e612       \u003c/td\u003e \u003ctd\u003e0         \u003c/td\u003e \u003ctd\u003e0            \u003c/td\u003e \u003ctd\u003e308        \u003c/td\u003e \u003ctd\u003e0           \u003c/td\u003e \u003ctd\u003e0            \u003c/td\u003e \u003ctd\u003e5925    \u003c/td\u003e \u003ctd\u003e1940      \u003c/td\u003e \u003ctd\u003e2009   \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e52000    \u003c/td\u003e \u003ctd\u003e729       \u003c/td\u003e \u003ctd\u003e0         \u003c/td\u003e \u003ctd\u003e270          \u003c/td\u003e \u003ctd\u003e0          \u003c/td\u003e \u003ctd\u003e0           \u003c/td\u003e \u003ctd\u003e0            \u003c/td\u003e \u003ctd\u003e4130    \u003c/td\u003e \u003ctd\u003e1935      \u003c/td\u003e \u003ctd\u003e2008   \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e52500    \u003c/td\u003e \u003ctd\u003e693       \u003c/td\u003e \u003ctd\u003e0         \u003c/td\u003e \u003ctd\u003e693          \u003c/td\u003e \u003ctd\u003e0          \u003c/td\u003e \u003ctd\u003e0           \u003c/td\u003e \u003ctd\u003e20           \u003c/td\u003e \u003ctd\u003e4118    \u003c/td\u003e \u003ctd\u003e1941      \u003c/td\u003e \u003ctd\u003e2006   \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e55000    \u003c/td\u003e \u003ctd\u003e723       \u003c/td\u003e \u003ctd\u003e363       \u003c/td\u003e \u003ctd\u003e723          \u003c/td\u003e \u003ctd\u003e400        \u003c/td\u003e \u003ctd\u003e0           \u003c/td\u003e \u003ctd\u003e24           \u003c/td\u003e \u003ctd\u003e11340   \u003c/td\u003e \u003ctd\u003e1920      \u003c/td\u003e \u003ctd\u003e2008   \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e55000    \u003c/td\u003e \u003ctd\u003e796       \u003c/td\u003e \u003ctd\u003e0         \u003c/td\u003e \u003ctd\u003e796          \u003c/td\u003e \u003ctd\u003e0          \u003c/td\u003e \u003ctd\u003e0           \u003c/td\u003e \u003ctd\u003e0            \u003c/td\u003e \u003ctd\u003e3636    \u003c/td\u003e \u003ctd\u003e1922      \u003c/td\u003e \u003ctd\u003e2008   \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e57625    \u003c/td\u003e \u003ctd\u003e810       \u003c/td\u003e \u003ctd\u003e0         \u003c/td\u003e \u003ctd\u003e0            \u003c/td\u003e \u003ctd\u003e280        \u003c/td\u003e \u003ctd\u003e119         \u003c/td\u003e \u003ctd\u003e24           \u003c/td\u003e \u003ctd\u003e21780   \u003c/td\u003e \u003ctd\u003e1910      \u003c/td\u003e \u003ctd\u003e2009   \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e58500    \u003c/td\u003e \u003ctd\u003e864       \u003c/td\u003e \u003ctd\u003e0         \u003c/td\u003e \u003ctd\u003e864          \u003c/td\u003e \u003ctd\u003e200        \u003c/td\u003e \u003ctd\u003e0           \u003c/td\u003e \u003ctd\u003e0            \u003c/td\u003e \u003ctd\u003e8212    \u003c/td\u003e \u003ctd\u003e1914      \u003c/td\u003e \u003ctd\u003e2010   \u003c/td\u003e\n        \u003c/tr\u003e\n    \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e... (1992 rows omitted)\u003c/p\u003e","content_type":"text/html"},"text/plain":{"content":"SalePrice | 1st Flr SF | 2nd Flr SF | Total Bsmt SF | Garage Area | Wood Deck SF | Open Porch SF | Lot Area | Year Built | Yr Sold\n35000     | 498        | 0          | 498           | 216         | 0            | 0             | 8088     | 1922       | 2006\n39300     | 334        | 0          | 0             | 0           | 0            | 0             | 5000     | 1946       | 2007\n40000     | 649        | 668        | 649           | 250         | 0            | 54            | 8500     | 1920       | 2008\n45000     | 612        | 0          | 0             | 308         | 0            | 0             | 5925     | 1940       | 2009\n52000     | 729        | 0          | 270           | 0           | 0            | 0             | 4130     | 1935       | 2008\n52500     | 693        | 0          | 693           | 0           | 0            | 20            | 4118     | 1941       | 2006\n55000     | 723        | 363        | 723           | 400         | 0            | 24            | 11340    | 1920       | 2008\n55000     | 796        | 0          | 796           | 0           | 0            | 0             | 3636     | 1922       | 2008\n57625     | 810        | 0          | 0             | 280         | 119          | 24            | 21780    | 1910       | 2009\n58500     | 864        | 0          | 864           | 200         | 0            | 0             | 8212     | 1914       | 2010\n... (1992 rows omitted)","content_type":"text/plain"}}}],"key":"bVec6DMwYi"}],"key":"paZGQ1UUKK"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"A histogram of sale prices shows a large amount of variability and a distribution that is clearly not normal. A long tail to the right contains a few houses that had very high prices. The short left tail does not contain any houses that sold for less than $35,000.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Pycx6iBADo"}],"key":"lXritXmYG4"}],"key":"vTIx6OlPOA"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"sales.hist('SalePrice', bins=32, unit='$')","key":"cXG6gsVi52"},{"type":"output","id":"0nKLfu5363HyWCj_o6D2D","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"9e56dbe90f2334c2b62fe8a77db91ba0","path":"/build/9e56dbe90f2334c2b62fe8a77db91ba0.png"},"text/plain":{"content":"\u003cFigure size 432x288 with 1 Axes\u003e","content_type":"text/plain"}}}],"key":"J8aO8V1Rcg"}],"key":"QOe1ktswGL"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Correlation","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"gX3d7N0DFj"}],"identifier":"correlation","label":"Correlation","html_id":"correlation","implicit":true,"key":"Cy5STp2lr1"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"No single attribute is sufficient to predict the sale price. For example, the area of first floor, measured in square feet, correlates with sale price but only explains some of its variability.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"NWP9oj0Ejk"}],"key":"xpYTaGVBwm"}],"key":"CHMZ1xZrK0"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"sales.scatter('1st Flr SF', 'SalePrice')","key":"P0S0lqFxGC"},{"type":"output","id":"eVrUlPU8d4pZpVLTkNoDH","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"822e624d7739714520d0b863da2aa118","path":"/build/822e624d7739714520d0b863da2aa118.png"},"text/plain":{"content":"\u003cFigure size 360x360 with 1 Axes\u003e","content_type":"text/plain"}}}],"key":"tJAnGVypor"}],"key":"JKtwRuf52K"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"correlation(sales, 'SalePrice', '1st Flr SF')","key":"Dql0pZ8WPn"},{"type":"output","id":"_p8v6zpodydC_07Uy7N42","data":[{"output_type":"execute_result","execution_count":6,"metadata":{},"data":{"text/plain":{"content":"0.6424662541030225","content_type":"text/plain"}}}],"key":"cBAfGHMY6w"}],"key":"GJwVInK3Ga"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"In fact, none of the individual attributes have a correlation with sale price that is above 0.7 (except for the sale price itself).","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ANkLEDX5xG"}],"key":"msGGCPQX2M"}],"key":"vDcPbGH7NH"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"for label in sales.labels:\n    print('Correlation of', label, 'and SalePrice:\\t', correlation(sales, label, 'SalePrice'))","key":"ylMkk5sJd6"},{"type":"output","id":"xmZfSPrV40yxQbZ-qBtQr","data":[{"name":"stdout","output_type":"stream","text":"Correlation of SalePrice and SalePrice:\t 1.0\nCorrelation of 1st Flr SF and SalePrice:\t 0.6424662541030225\nCorrelation of 2nd Flr SF and SalePrice:\t 0.3575218942800824\nCorrelation of Total Bsmt SF and SalePrice:\t 0.652978626757169\nCorrelation of Garage Area and SalePrice:\t 0.6385944852520443\nCorrelation of Wood Deck SF and SalePrice:\t 0.3526986661950492\nCorrelation of Open Porch SF and SalePrice:\t 0.3369094170263733\nCorrelation of Lot Area and SalePrice:\t 0.2908234551157694\nCorrelation of Year Built and SalePrice:\t 0.5651647537135916\nCorrelation of Yr Sold and SalePrice:\t 0.02594857908072111\n"}],"key":"qmI5QgfKwS"}],"key":"bA8wl0vLku"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"However, combining attributes can provide higher correlation. In particular, if we sum the first floor and second floor areas, the result has a higher correlation than any single attribute alone.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"vb0WEnLQW3"}],"key":"JgqOqfaCp2"}],"key":"RMi1fxwnRp"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"both_floors = sales.column(1) + sales.column(2)\ncorrelation(sales.with_column('Both Floors', both_floors), 'SalePrice', 'Both Floors')","key":"t7DddHC6FL"},{"type":"output","id":"VOQcBbgAmR06CNrAsFa1V","data":[{"output_type":"execute_result","execution_count":8,"metadata":{},"data":{"text/plain":{"content":"0.7821920556134877","content_type":"text/plain"}}}],"key":"Lh1ZkEXYjr"}],"key":"CYLb4n5VT5"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"This high correlation indicates that we should try to use more than one attribute to predict the sale price. In a dataset with multiple observed attributes and a single numerical value to be predicted (the sale price in this case), multiple linear regression can be an effective technique.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"omLmWFCKEs"}],"key":"Dq8gzNo9Sn"},{"type":"heading","depth":2,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Multiple Linear Regression","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"ynA9D3EI2l"}],"identifier":"multiple-linear-regression","label":"Multiple Linear Regression","html_id":"multiple-linear-regression","implicit":true,"key":"mzpULFanjL"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"In multiple linear regression, a numerical output is predicted from numerical input attributes by multiplying each attribute value by a different slope, then summing the results. In this example, the slope for the ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"RyO49FinG5"},{"type":"inlineCode","value":"1st Flr SF","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"y5HGoZhwx1"},{"type":"text","value":" would represent the dollars per square foot of area on the first floor of the house that should be used in our prediction.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"A7cr8gmBNW"}],"key":"BFKMlxTZR6"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Before we begin prediction, we split our data randomly into a training and test set of equal size.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"AMYJzYAz2j"}],"key":"wnzQBrEb6A"}],"key":"SXdONSspso"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"train, test = sales.split(1001)\nprint(train.num_rows, 'training and', test.num_rows, 'test instances.')","key":"y3PYhhLmfZ"},{"type":"output","id":"XxO0o0iNV-n8zqwM8x4Xi","data":[{"name":"stdout","output_type":"stream","text":"1001 training and 1001 test instances.\n"}],"key":"VfdjM8SXLm"}],"key":"dYwAJee3vu"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The slopes in multiple regression is an array that has one slope value for each attribute in an example. Predicting the sale price involves multiplying each attribute by the slope and summing the result.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"TeNtVSfmXT"}],"key":"GDhzaCvtsC"}],"key":"a9vIAtm9p3"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def predict(slopes, row):\n    return sum(slopes * np.array(row))\n\nexample_row = test.drop('SalePrice').row(0)\nprint('Predicting sale price for:', example_row)\nexample_slopes = np.random.normal(10, 1, len(example_row))\nprint('Using slopes:', example_slopes)\nprint('Result:', predict(example_slopes, example_row))","key":"U7actx2FGp"},{"type":"output","id":"bei6x9ggod0qSTeUGf3_a","data":[{"name":"stdout","output_type":"stream","text":"Predicting sale price for: Row(1st Flr SF=1207, 2nd Flr SF=0, Total Bsmt SF=1135.0, Garage Area=264.0, Wood Deck SF=0, Open Porch SF=240, Lot Area=9510, Year Built=1962, Yr Sold=2006)\nUsing slopes: [ 9.52065867  8.58939769 11.48702417  9.50389131  9.09151019  9.86944284\n 10.71929443 10.88966608  8.33339346]\nResult: 169429.7032316262\n"}],"key":"qqsbqwDsv8"}],"key":"Bvufd9Frkk"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The result is an estimated sale price, which can be compared to the actual sale price to assess whether the slopes provide accurate predictions. Since the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"c3Z6kexzSM"},{"type":"inlineCode","value":"example_slopes","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"bGgyZeXatM"},{"type":"text","value":" above were chosen at random, we should not expect them to provide accurate predictions at all.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"JsFseYklqb"}],"key":"OIeNlDmG8G"}],"key":"rXhkQjctjd"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"print('Actual sale price:', test.column('SalePrice').item(0))\nprint('Predicted sale price using random slopes:', predict(example_slopes, example_row))","key":"ha4Xwq2NZ1"},{"type":"output","id":"0Zm3z_8HPDvsitHhLCX-2","data":[{"name":"stdout","output_type":"stream","text":"Actual sale price: 147000\nPredicted sale price using random slopes: 169429.7032316262\n"}],"key":"VimN2GrVBP"}],"key":"xZSvIrbp5B"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Least Squares Regression","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"GcxePj5dLp"}],"identifier":"least-squares-regression","label":"Least Squares Regression","html_id":"least-squares-regression","implicit":true,"key":"dxB6IPrqCS"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"The next step in performing multiple regression is to define the least squares objective. We perform the prediction for each row in the training set, and then compute the root mean squared error (RMSE) of the predictions from the actual prices.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"aw1UWL8rwS"}],"key":"JE3nNq4ih1"}],"key":"e3iwIaoTCk"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"train_prices = train.column(0)\ntrain_attributes = train.drop(0)\n\ndef rmse(slopes, attributes, prices):\n    errors = []\n    for i in np.arange(len(prices)):\n        predicted = predict(slopes, attributes.row(i))\n        actual = prices.item(i)\n        errors.append((predicted - actual) ** 2)\n    return np.mean(errors) ** 0.5\n\ndef rmse_train(slopes):\n    return rmse(slopes, train_attributes, train_prices)\n\nprint('RMSE of all training examples using random slopes:', rmse_train(example_slopes))","key":"JmuRF8OcMt"},{"type":"output","id":"zsp_vyiMAqFB2lirIgu1X","data":[{"name":"stdout","output_type":"stream","text":"RMSE of all training examples using random slopes: 68153.56796456952\n"}],"key":"ONDHSAioqW"}],"key":"WfEY87oooA"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Finally, we use the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"KgJPwrw7wl"},{"type":"inlineCode","value":"minimize","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"v9NeJHzLpC"},{"type":"text","value":" function to find the slopes with the lowest RMSE. Since the function we want to minimize, ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"EsK4Y2kpUX"},{"type":"inlineCode","value":"rmse_train","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"fUCywWhmLo"},{"type":"text","value":", takes an array instead of a number, we must pass the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"PWjNJqnG0l"},{"type":"inlineCode","value":"array=True","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"DPRpDT239R"},{"type":"text","value":" argument to ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"VC9ssL4k9a"},{"type":"inlineCode","value":"minimize","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"rcc8F1xGLX"},{"type":"text","value":". When this argument is used, ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"LqdEpDKREN"},{"type":"inlineCode","value":"minimize","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"VPyRZMopKc"},{"type":"text","value":" also requires an initial guess of the slopes so that it knows the dimension of the input array. Finally, to speed up optimization, we indicate that ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"II5TnNNrCH"},{"type":"inlineCode","value":"rmse_train","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"FsLWrg0zNn"},{"type":"text","value":" is a smooth function using the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"zaVszMh4jp"},{"type":"inlineCode","value":"smooth=True","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"jmXnnfev2m"},{"type":"text","value":" attribute. Computation of the best slopes may take several minutes.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"PNvPdwaaci"}],"key":"i4dZjj72hq"}],"key":"payIXOeiAi"},{"type":"block","kind":"notebook-code","data":{"scrolled":true},"children":[{"type":"code","lang":"python","executable":true,"value":"best_slopes = minimize(rmse_train, start=example_slopes, smooth=True, array=True)\nprint('The best slopes for the training set:')\nTable(train_attributes.labels).with_row(list(best_slopes)).show()\nprint('RMSE of all training examples using the best slopes:', rmse_train(best_slopes))","key":"YCmWTlGx5t"},{"type":"output","id":"F3bQf0KkpxmDZkCRIuXfN","data":[{"name":"stdout","output_type":"stream","text":"The best slopes for the training set:\n"},{"output_type":"display_data","metadata":{},"data":{"text/html":{"content":"\u003ctable border=\"1\" class=\"dataframe\"\u003e\n    \u003cthead\u003e\n        \u003ctr\u003e\n            \u003cth\u003e1st Flr SF\u003c/th\u003e \u003cth\u003e2nd Flr SF\u003c/th\u003e \u003cth\u003eTotal Bsmt SF\u003c/th\u003e \u003cth\u003eGarage Area\u003c/th\u003e \u003cth\u003eWood Deck SF\u003c/th\u003e \u003cth\u003eOpen Porch SF\u003c/th\u003e \u003cth\u003eLot Area\u003c/th\u003e \u003cth\u003eYear Built\u003c/th\u003e \u003cth\u003eYr Sold\u003c/th\u003e\n        \u003c/tr\u003e\n    \u003c/thead\u003e\n    \u003ctbody\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e68.7068   \u003c/td\u003e \u003ctd\u003e74.3857   \u003c/td\u003e \u003ctd\u003e56.0494      \u003c/td\u003e \u003ctd\u003e36.1706    \u003c/td\u003e \u003ctd\u003e26.4397     \u003c/td\u003e \u003ctd\u003e21.4779      \u003c/td\u003e \u003ctd\u003e0.558904\u003c/td\u003e \u003ctd\u003e534.101   \u003c/td\u003e \u003ctd\u003e-528.216\u003c/td\u003e\n        \u003c/tr\u003e\n    \u003c/tbody\u003e\n\u003c/table\u003e","content_type":"text/html"},"text/plain":{"content":"\u003cIPython.core.display.HTML object\u003e","content_type":"text/plain"}}},{"name":"stdout","output_type":"stream","text":"RMSE of all training examples using the best slopes: 29311.117940347867\n"}],"key":"AgoUReeKIr"}],"key":"ZqOnADNgzt"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Interpreting Multiple Regression","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hLnKvHUIL3"}],"identifier":"interpreting-multiple-regression","label":"Interpreting Multiple Regression","html_id":"interpreting-multiple-regression","implicit":true,"key":"BvxMH2uxa7"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Let’s interpret these results. The best slopes give us a method for estimating the price of a house from its attributes. A square foot of area on the first floor is worth about $75 (the first slope), while one on the second floor is worth about $70 (the second slope). The final negative value describes the market: prices in later years were lower on average.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"fknG7h6EhU"}],"key":"awwfQWq0Ke"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"The RMSE of around $30,000 means that our best linear prediction of the sale price based on all of the attributes is off by around $30,000 on the training set, on average.  We find a similar error when predicting prices on the test set, which indicates that our prediction method will generalize to other samples from the same population.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"A5dZvRFZNw"}],"key":"eukJAB2QmN"}],"key":"OQbVmaOrZE"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"test_prices = test.column(0)\ntest_attributes = test.drop(0)\n\ndef rmse_test(slopes):\n    return rmse(slopes, test_attributes, test_prices)\n\nrmse_linear = rmse_test(best_slopes)\nprint('Test set RMSE for multiple linear regression:', rmse_linear)","key":"c6NpBwSgOf"},{"type":"output","id":"0LBjvYCDsrDufFI6QpuOG","data":[{"name":"stdout","output_type":"stream","text":"Test set RMSE for multiple linear regression: 33025.064938240575\n"}],"key":"eTagfmeLsx"}],"key":"mlY6LOTtAm"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"If the predictions were perfect, then a scatter plot of the predicted and actual values would be a straight line with slope 1. We see that most dots fall near that line, but there is some error in the predictions.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"qfee4mIRb0"}],"key":"QylAT44wVl"}],"key":"AV4tjHqnaP"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def fit(row):\n    return sum(best_slopes * np.array(row))\n\ntest.with_column('Fitted', test.drop(0).apply(fit)).scatter('Fitted', 0)\nplots.plot([0, 5e5], [0, 5e5]);","key":"fitNYgsC3V"},{"type":"output","id":"2C3ebzubIReZ20L4im87Z","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"c66b366a351a2e0e3129d44985161161","path":"/build/c66b366a351a2e0e3129d44985161161.png"},"text/plain":{"content":"\u003cFigure size 360x360 with 1 Axes\u003e","content_type":"text/plain"}}}],"key":"NqGY9OjNUR"}],"key":"CewPrOTgqu"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"A residual plot for multiple regression typically compares the errors (residuals) to the actual values of the predicted variable. We see in the residual plot below that we have systematically underestimated the value of expensive houses, shown by the many positive residual values on the right side of the graph.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"oxl25iRebK"}],"key":"fGP7xn5D7F"}],"key":"gw8Xam3nHr"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"test.with_column('Residual', test_prices-test.drop(0).apply(fit)).scatter(0, 'Residual')\nplots.plot([0, 7e5], [0, 0]);","key":"yvvuLAV2VJ"},{"type":"output","id":"3jZGLakMDgb2-MCbQ-ogZ","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"b742453e45adfd99dfa27daaea6f240d","path":"/build/b742453e45adfd99dfa27daaea6f240d.png"},"text/plain":{"content":"\u003cFigure size 360x360 with 1 Axes\u003e","content_type":"text/plain"}}}],"key":"fC2JGsGrjK"}],"key":"IqqPfnnGvJ"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"As with simple linear regression, interpreting the result of a predictor is at least as important as making predictions. There are many lessons about interpreting multiple regression that are not included in this textbook. A natural next step after completing this text would be to study linear modeling and regression in further depth.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"mIxgZqUUQS"}],"key":"ImMv4IJ8Je"}],"key":"CeMelpNeKF"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Nearest Neighbors for Regression","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"D1NPoYtD1z"}],"identifier":"nearest-neighbors-for-regression","label":"Nearest Neighbors for Regression","html_id":"nearest-neighbors-for-regression","implicit":true,"key":"fVsJne2BCa"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Another approach to predicting the sale price of a house is to use the price of similar houses. This ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"iCKi2Y50kN"},{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"nearest neighbor","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"FE3dFuN9NI"}],"key":"ZIjFjac2Qs"},{"type":"text","value":" approach is very similar to our classifier. To speed up computation, we will only use the attributes that had the highest correlation with the sale price in our original analysis.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"KXr8eGtrx1"}],"key":"rYz2Sf4sLl"}],"key":"uaAhkfW2dL"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"train_nn = train.select(0, 1, 2, 3, 4, 8)\ntest_nn = test.select(0, 1, 2, 3, 4, 8)\ntrain_nn.show(3)","key":"gJ7FjjmAm2"},{"type":"output","id":"VdZlIOX2HyMqB30f3gs-_","data":[{"output_type":"display_data","metadata":{},"data":{"text/html":{"content":"\u003ctable border=\"1\" class=\"dataframe\"\u003e\n    \u003cthead\u003e\n        \u003ctr\u003e\n            \u003cth\u003eSalePrice\u003c/th\u003e \u003cth\u003e1st Flr SF\u003c/th\u003e \u003cth\u003e2nd Flr SF\u003c/th\u003e \u003cth\u003eTotal Bsmt SF\u003c/th\u003e \u003cth\u003eGarage Area\u003c/th\u003e \u003cth\u003eYear Built\u003c/th\u003e\n        \u003c/tr\u003e\n    \u003c/thead\u003e\n    \u003ctbody\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e270000   \u003c/td\u003e \u003ctd\u003e1673      \u003c/td\u003e \u003ctd\u003e0         \u003c/td\u003e \u003ctd\u003e1673         \u003c/td\u003e \u003ctd\u003e583        \u003c/td\u003e \u003ctd\u003e2000      \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e158000   \u003c/td\u003e \u003ctd\u003e986       \u003c/td\u003e \u003ctd\u003e537       \u003c/td\u003e \u003ctd\u003e1067         \u003c/td\u003e \u003ctd\u003e295        \u003c/td\u003e \u003ctd\u003e1949      \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e249000   \u003c/td\u003e \u003ctd\u003e1506      \u003c/td\u003e \u003ctd\u003e0         \u003c/td\u003e \u003ctd\u003e1494         \u003c/td\u003e \u003ctd\u003e672        \u003c/td\u003e \u003ctd\u003e2005      \u003c/td\u003e\n        \u003c/tr\u003e\n    \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e... (998 rows omitted)\u003c/p\u003e","content_type":"text/html"},"text/plain":{"content":"\u003cIPython.core.display.HTML object\u003e","content_type":"text/plain"}}}],"key":"WQMQzMRPDw"}],"key":"GYp1LlgSLS"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The computation of closest neighbors is identical to a nearest-neighbor classifier. In this case, we will exclude the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"JltGFG0UrP"},{"type":"inlineCode","value":"'SalePrice'","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"mLyaK0SvUU"},{"type":"text","value":" rather than the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Zpz5OianEU"},{"type":"inlineCode","value":"'Class'","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"HgJ6jJx5vq"},{"type":"text","value":" column from the distance computation. The five nearest neighbors of the first test row are shown below.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IPoYYEvUPh"}],"key":"xZznBcgYFj"}],"key":"djzZpLUMGP"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def distance(pt1, pt2):\n    \"\"\"The distance between two points, represented as arrays.\"\"\"\n    return np.sqrt(sum((pt1 - pt2) ** 2))\n\ndef row_distance(row1, row2):\n    \"\"\"The distance between two rows of a table.\"\"\"\n    return distance(np.array(row1), np.array(row2))\n\ndef distances(training, example, output):\n    \"\"\"Compute the distance from example for each row in training.\"\"\"\n    dists = []\n    attributes = training.drop(output)\n    for row in attributes.rows:\n        dists.append(row_distance(row, example))\n    return training.with_column('Distance', dists)\n\ndef closest(training, example, k, output):\n    \"\"\"Return a table of the k closest neighbors to example.\"\"\"\n    return distances(training, example, output).sort('Distance').take(np.arange(k))\n\nexample_nn_row = test_nn.drop(0).row(0)\nclosest(train_nn, example_nn_row, 5, 'SalePrice')","key":"TSWyEAfbTg"},{"type":"output","id":"mX4mCyTI3qvywfE5jJwAT","data":[{"output_type":"execute_result","execution_count":18,"metadata":{},"data":{"text/html":{"content":"\u003ctable border=\"1\" class=\"dataframe\"\u003e\n    \u003cthead\u003e\n        \u003ctr\u003e\n            \u003cth\u003eSalePrice\u003c/th\u003e \u003cth\u003e1st Flr SF\u003c/th\u003e \u003cth\u003e2nd Flr SF\u003c/th\u003e \u003cth\u003eTotal Bsmt SF\u003c/th\u003e \u003cth\u003eGarage Area\u003c/th\u003e \u003cth\u003eYear Built\u003c/th\u003e \u003cth\u003eDistance\u003c/th\u003e\n        \u003c/tr\u003e\n    \u003c/thead\u003e\n    \u003ctbody\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e137000   \u003c/td\u003e \u003ctd\u003e1176      \u003c/td\u003e \u003ctd\u003e0         \u003c/td\u003e \u003ctd\u003e1158         \u003c/td\u003e \u003ctd\u003e303        \u003c/td\u003e \u003ctd\u003e1958      \u003c/td\u003e \u003ctd\u003e55.0182 \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e146000   \u003c/td\u003e \u003ctd\u003e1150      \u003c/td\u003e \u003ctd\u003e0         \u003c/td\u003e \u003ctd\u003e1150         \u003c/td\u003e \u003ctd\u003e288        \u003c/td\u003e \u003ctd\u003e1961      \u003c/td\u003e \u003ctd\u003e63.6475 \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e126175   \u003c/td\u003e \u003ctd\u003e1163      \u003c/td\u003e \u003ctd\u003e0         \u003c/td\u003e \u003ctd\u003e1162         \u003c/td\u003e \u003ctd\u003e220        \u003c/td\u003e \u003ctd\u003e1955      \u003c/td\u003e \u003ctd\u003e68.1909 \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e157900   \u003c/td\u003e \u003ctd\u003e1188      \u003c/td\u003e \u003ctd\u003e0         \u003c/td\u003e \u003ctd\u003e1188         \u003c/td\u003e \u003ctd\u003e312        \u003c/td\u003e \u003ctd\u003e1962      \u003c/td\u003e \u003ctd\u003e73.9865 \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e150000   \u003c/td\u003e \u003ctd\u003e1144      \u003c/td\u003e \u003ctd\u003e0         \u003c/td\u003e \u003ctd\u003e1169         \u003c/td\u003e \u003ctd\u003e286        \u003c/td\u003e \u003ctd\u003e1956      \u003c/td\u003e \u003ctd\u003e75.1332 \u003c/td\u003e\n        \u003c/tr\u003e\n    \u003c/tbody\u003e\n\u003c/table\u003e","content_type":"text/html"},"text/plain":{"content":"SalePrice | 1st Flr SF | 2nd Flr SF | Total Bsmt SF | Garage Area | Year Built | Distance\n137000    | 1176       | 0          | 1158          | 303         | 1958       | 55.0182\n146000    | 1150       | 0          | 1150          | 288         | 1961       | 63.6475\n126175    | 1163       | 0          | 1162          | 220         | 1955       | 68.1909\n157900    | 1188       | 0          | 1188          | 312         | 1962       | 73.9865\n150000    | 1144       | 0          | 1169          | 286         | 1956       | 75.1332","content_type":"text/plain"}}}],"key":"FHGOz57qIe"}],"key":"JszXxlpXJQ"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"One simple method for predicting the price is to average the prices of the nearest neighbors.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"XIa7VUFiFg"}],"key":"VPINpT8wHE"}],"key":"nNEA3KpeLj"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def predict_nn(example):\n    \"\"\"Return the majority class among the k nearest neighbors.\"\"\"\n    return np.average(closest(train_nn, example, 5, 'SalePrice').column('SalePrice'))\n\npredict_nn(example_nn_row)","key":"VwXwu8BUEl"},{"type":"output","id":"sAoC46VaL3_DiCKUAKvrx","data":[{"output_type":"execute_result","execution_count":19,"metadata":{},"data":{"text/plain":{"content":"143415.0","content_type":"text/plain"}}}],"key":"WefowdsB4G"}],"key":"ygMCkWuHba"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Finally, we can inspect whether our prediction is close to the true sale price for our one test example. Looks reasonable!","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dtTwvXMv7c"}],"key":"iR0UWO7Mmz"}],"key":"ZYqn1LHpQL"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"print('Actual sale price:', test_nn.column('SalePrice').item(0))\nprint('Predicted sale price using nearest neighbors:', predict_nn(example_nn_row))","key":"yknOdgrZ2S"},{"type":"output","id":"HLXLKwWhNzLxg2lPJJWu1","data":[{"name":"stdout","output_type":"stream","text":"Actual sale price: 147000\nPredicted sale price using nearest neighbors: 143415.0\n"}],"key":"SR4GFRyVL8"}],"key":"LtCXhcgcUH"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Evaluation","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Llm2oToC85"}],"identifier":"evaluation","label":"Evaluation","html_id":"evaluation","implicit":true,"key":"srJiBJ1tHl"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"To evaluate the performance of this approach for the whole test set, we apply ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"KvF8vx4hK0"},{"type":"inlineCode","value":"predict_nn","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"PcX21Gc7uI"},{"type":"text","value":" to each test example, then compute the root mean squared error of the predictions. Computation of the predictions may take several minutes.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"ANWq0KECgj"}],"key":"hMXVotwmH6"}],"key":"ajkH3U7PhZ"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"nn_test_predictions = test_nn.drop('SalePrice').apply(predict_nn)\nrmse_nn = np.mean((test_prices - nn_test_predictions) ** 2) ** 0.5\n\nprint('Test set RMSE for multiple linear regression: ', rmse_linear)\nprint('Test set RMSE for nearest neighbor regression:', rmse_nn)","key":"DmAhSSvu9E"},{"type":"output","id":"LOZPaRP8HmHYgzAtXwHb8","data":[{"name":"stdout","output_type":"stream","text":"Test set RMSE for multiple linear regression:  33025.064938240575\nTest set RMSE for nearest neighbor regression: 36067.116043510105\n"}],"key":"FZHt7kSqYM"}],"key":"nSpgvHIfXX"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"For these data, the errors of the two techniques are quite similar! For different data sets, one technique might outperform another. By computing the RMSE of both techniques on the same data, we can compare methods fairly. One note of caution: the difference in performance might not be due to the technique at all; it might be due to the random variation due to sampling the training and test sets in the first place.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"e2MNwDSEpZ"}],"key":"nlQcmxDcJv"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Finally, we can draw a residual plot for these predictions. We still underestimate the prices of the most expensive houses, but the bias does not appear to be as systematic. However, fewer residuals are very close to zero, indicating that fewer prices were predicted with very high accuracy.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"XGF2DjMpBD"}],"key":"b0PPo41SJb"}],"key":"zo2sIUYfJO"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"test.with_column('Residual', test_prices-nn_test_predictions).scatter(0, 'Residual')\nplots.plot([0, 7e5], [0, 0]);","key":"mkJBskB1bj"},{"type":"output","id":"r7GwWG5ItT_XIKppOIXGA","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"18f71601d626cc44ce3055c3762bf859","path":"/build/18f71601d626cc44ce3055c3762bf859.png"},"text/plain":{"content":"\u003cFigure size 360x360 with 1 Axes\u003e","content_type":"text/plain"}}}],"key":"gr61DyjQFL"}],"key":"Cikd5y0A8A"}],"key":"iy44nnTApY"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"The Accuracy of the Classifier","url":"/chapters/17/5/accuracy-of-the-classifier","group":"Computational and Inferential Thinking"},"next":{"title":"Updating Predictions","url":"/chapters/18/updating-predictions","group":"Computational and Inferential Thinking"}}},"domain":"http://localhost:3000"},"project":{"license":{"content":{"id":"CC-BY-NC-ND-4.0","url":"https://creativecommons.org/licenses/by-nc-nd/4.0/","name":"Creative Commons Attribution Non Commercial No Derivatives 4.0 International","CC":true}},"numbering":{"title":{"enabled":true}},"title":"Computational and Inferential Thinking","authors":[{"nameParsed":{"literal":"Ani Adhikari","given":"Ani","family":"Adhikari"},"name":"Ani Adhikari","id":"contributors-myst-generated-uid-0"},{"nameParsed":{"literal":"John DeNero","given":"John","family":"DeNero"},"name":"John DeNero","id":"contributors-myst-generated-uid-1"},{"nameParsed":{"literal":"David Wagner","given":"David","family":"Wagner"},"name":"David Wagner","id":"contributors-myst-generated-uid-2"}],"github":"https://github.com/data-8/textbook","toc":[{"file":"chapters/intro.md"},{"children":[{"children":[{"file":"chapters/01/1/1/computational-tools.md"},{"file":"chapters/01/1/2/statistical-techniques.md"}],"file":"chapters/01/1/intro.md"},{"file":"chapters/01/2/why-data-science.md"},{"children":[{"file":"chapters/01/3/1/Literary_Characters.ipynb"},{"file":"chapters/01/3/2/Another_Kind_Of_Character.ipynb"}],"file":"chapters/01/3/Plotting_the_Classics.ipynb"}],"file":"chapters/01/what-is-data-science.md"},{"children":[{"file":"chapters/02/1/observation-and-visualization-john-snow-and-the-broad-street-pump.md","title":"John Snow and the Broad Street Pump"},{"file":"chapters/02/2/snow-s-grand-experiment.md"},{"file":"chapters/02/3/establishing-causality.md"},{"file":"chapters/02/4/randomization.md"},{"file":"chapters/02/5/endnote.md"}],"file":"chapters/02/causality-and-experiments.md"},{"children":[{"file":"chapters/03/1/Expressions.ipynb"},{"children":[{"file":"chapters/03/2/1/Growth.ipynb"}],"file":"chapters/03/2/Names.ipynb"},{"file":"chapters/03/3/Calls.ipynb"},{"file":"chapters/03/4/Introduction_to_Tables.ipynb"}],"file":"chapters/03/programming-in-python.md"},{"children":[{"file":"chapters/04/1/Numbers.ipynb"},{"children":[{"file":"chapters/04/2/1/String_Methods.ipynb"}],"file":"chapters/04/2/Strings.ipynb"},{"file":"chapters/04/3/Comparison.ipynb"}],"file":"chapters/04/Data_Types.ipynb"},{"children":[{"file":"chapters/05/1/Arrays.ipynb"},{"file":"chapters/05/2/Ranges.ipynb"},{"file":"chapters/05/3/More_on_Arrays.ipynb"}],"file":"chapters/05/Sequences.ipynb"},{"children":[{"file":"chapters/06/1/Sorting_Rows.ipynb"},{"file":"chapters/06/2/Selecting_Rows.ipynb"},{"file":"chapters/06/3/Example_Population_Trends.ipynb"},{"file":"chapters/06/4/Example_Sex_Ratios.ipynb"}],"file":"chapters/06/Tables.ipynb"},{"children":[{"file":"chapters/07/1/Visualizing_Categorical_Distributions.ipynb"},{"file":"chapters/07/2/Visualizing_Numerical_Distributions.ipynb"},{"file":"chapters/07/3/Overlaid_Graphs.ipynb"}],"file":"chapters/07/Visualization.ipynb"},{"children":[{"file":"chapters/08/1/Applying_a_Function_to_a_Column.ipynb"},{"file":"chapters/08/2/Classifying_by_One_Variable.ipynb"},{"file":"chapters/08/3/Cross-Classifying_by_More_than_One_Variable.ipynb"},{"file":"chapters/08/4/Joining_Tables_by_Columns.ipynb"},{"file":"chapters/08/5/Bike_Sharing_in_the_Bay_Area.ipynb"}],"file":"chapters/08/Functions_and_Tables.ipynb"},{"children":[{"file":"chapters/09/1/Conditional_Statements.ipynb"},{"file":"chapters/09/2/Iteration.ipynb"},{"file":"chapters/09/3/Simulation.ipynb"},{"file":"chapters/09/4/Monty_Hall_Problem.ipynb"},{"file":"chapters/09/5/Finding_Probabilities.ipynb"}],"file":"chapters/09/Randomness.ipynb"},{"children":[{"file":"chapters/10/1/Empirical_Distributions.ipynb"},{"file":"chapters/10/2/Sampling_from_a_Population.ipynb"},{"file":"chapters/10/3/Empirical_Distribution_of_a_Statistic.ipynb"},{"file":"chapters/10/4/Random_Sampling_in_Python.ipynb"}],"file":"chapters/10/Sampling_and_Empirical_Distributions.ipynb"},{"children":[{"file":"chapters/11/1/Assessing_a_Model.ipynb"},{"file":"chapters/11/2/Multiple_Categories.ipynb"},{"file":"chapters/11/3/Decisions_and_Uncertainty.ipynb"},{"file":"chapters/11/4/Error_Probabilities.ipynb"}],"file":"chapters/11/Testing_Hypotheses.md"},{"children":[{"file":"chapters/12/1/AB_Testing.ipynb"},{"file":"chapters/12/2/Causality.ipynb"},{"file":"chapters/12/3/Deflategate.ipynb"}],"file":"chapters/12/Comparing_Two_Samples.md"},{"children":[{"file":"chapters/13/1/Percentiles.ipynb"},{"file":"chapters/13/2/Bootstrap.ipynb"},{"file":"chapters/13/3/Confidence_Intervals.ipynb"},{"file":"chapters/13/4/Using_Confidence_Intervals.ipynb"}],"file":"chapters/13/Estimation.md"},{"children":[{"file":"chapters/14/1/Properties_of_the_Mean.ipynb"},{"file":"chapters/14/2/Variability.ipynb"},{"file":"chapters/14/3/SD_and_the_Normal_Curve.ipynb"},{"file":"chapters/14/4/Central_Limit_Theorem.ipynb"},{"file":"chapters/14/5/Variability_of_the_Sample_Mean.ipynb"},{"file":"chapters/14/6/Choosing_a_Sample_Size.ipynb"}],"file":"chapters/14/Why_the_Mean_Matters.md"},{"children":[{"file":"chapters/15/1/Correlation.ipynb"},{"file":"chapters/15/2/Regression_Line.ipynb"},{"file":"chapters/15/3/Method_of_Least_Squares.ipynb"},{"file":"chapters/15/4/Least_Squares_Regression.ipynb"},{"file":"chapters/15/5/Visual_Diagnostics.ipynb"},{"file":"chapters/15/6/Numerical_Diagnostics.ipynb"}],"file":"chapters/15/Prediction.ipynb"},{"children":[{"file":"chapters/16/1/Regression_Model.ipynb"},{"file":"chapters/16/2/Inference_for_the_True_Slope.ipynb"},{"file":"chapters/16/3/Prediction_Intervals.ipynb"}],"file":"chapters/16/Inference_for_Regression.md"},{"children":[{"file":"chapters/17/1/Nearest_Neighbors.ipynb"},{"file":"chapters/17/2/Training_and_Testing.ipynb"},{"file":"chapters/17/3/Rows_of_Tables.ipynb"},{"file":"chapters/17/4/Implementing_the_Classifier.ipynb"},{"file":"chapters/17/5/Accuracy_of_the_Classifier.ipynb"},{"file":"chapters/17/6/Multiple_Regression.ipynb"}],"file":"chapters/17/Classification.md"},{"children":[{"file":"chapters/18/1/More_Likely_than_Not_Binary_Classifier.ipynb"},{"file":"chapters/18/2/Making_Decisions.ipynb"}],"file":"chapters/18/Updating_Predictions.md"}],"exports":[],"bibliography":[],"index":"index","pages":[{"slug":"chapters.01.what-is-data-science","title":"What is Data Science?","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"1"},{"slug":"chapters.01.1.intro","title":"Introduction","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.1"},{"slug":"chapters.01.1.1.computational-tools","title":"Computational Tools","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.1.1"},{"slug":"chapters.01.1.2.statistical-techniques","title":"Statistical Techniques","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.1.2"},{"slug":"chapters.01.2.why-data-science","title":"Why Data Science?","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.2"},{"slug":"chapters.01.3.plotting-the-classics","title":"Plotting the Classics","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.3"},{"slug":"chapters.01.3.1.literary-characters","title":"Literary Characters","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.3.1"},{"slug":"chapters.01.3.2.another-kind-of-character","title":"Another Kind of Character","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.3.2"},{"slug":"chapters.02.causality-and-experiments","title":"Causality and Experiments","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"2"},{"slug":"chapters.02.1.observation-and-visualization-john-snow-and-the-br","title":"Observation and Visualization: John Snow and the Broad Street Pump","description":"","date":"","thumbnail":"/build/snow_map-173b7e139b34475013f936d7cc85190c.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.1"},{"slug":"chapters.02.2.snow-s-grand-experiment","title":"Snow’s “Grand Experiment”","description":"","date":"","thumbnail":"/build/snow_map2-2d1199802166135b288a87da3c7a04d2.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.2"},{"slug":"chapters.02.3.establishing-causality","title":"Establishing Causality","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.3"},{"slug":"chapters.02.4.randomization","title":"Randomization","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.4"},{"slug":"chapters.02.5.endnote","title":"Endnote","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.5"},{"slug":"chapters.03.programming-in-python","title":"Programming in Python","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"3"},{"slug":"chapters.03.1.expressions","title":"Expressions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.1"},{"slug":"chapters.03.2.names","title":"Names","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.2"},{"slug":"chapters.03.2.1.growth","title":"Example: Growth Rates","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"3.2.1"},{"slug":"chapters.03.3.calls","title":"Call Expressions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.3"},{"slug":"chapters.03.4.introduction-to-tables","title":"Introduction to Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.4"},{"slug":"chapters.04.data-types","title":"Data Types","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"4"},{"slug":"chapters.04.1.numbers","title":"Numbers","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.1"},{"slug":"chapters.04.2.strings","title":"Strings","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.2"},{"slug":"chapters.04.2.1.string-methods","title":"String Methods","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"4.2.1"},{"slug":"chapters.04.3.comparison","title":"Comparisons","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.3"},{"slug":"chapters.05.sequences","title":"Sequences","description":"","date":"","thumbnail":"/build/global-land-TMAX-Tre-0259f4201a417ecbdbf38a1be53cf6ef.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"5"},{"slug":"chapters.05.1.arrays","title":"Arrays","description":"","date":"","thumbnail":"/build/array_arithmetic-eb90b39844ed099ae7191bcc9214afd7.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.1"},{"slug":"chapters.05.2.ranges","title":"Ranges","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.2"},{"slug":"chapters.05.3.more-on-arrays","title":"More on Arrays","description":"","date":"","thumbnail":"/build/array_subtraction-76924b5aad7bbd046618889ad0790527.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.3"},{"slug":"chapters.06.tables","title":"Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"6"},{"slug":"chapters.06.1.sorting-rows","title":"Sorting Rows","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.1"},{"slug":"chapters.06.2.selecting-rows","title":"Selecting Rows","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.2"},{"slug":"chapters.06.3.example-population-trends","title":"Example: Population Trends","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.3"},{"slug":"chapters.06.4.example-sex-ratios","title":"Example: Sex Ratios","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.4"},{"slug":"chapters.07.visualization","title":"Visualization","description":"","date":"","thumbnail":"/build/C-3PO_droid-b8360dd37f31deba2f98e3a28f126353.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"7"},{"slug":"chapters.07.1.visualizing-categorical-distributions","title":"Visualizing Categorical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.1"},{"slug":"chapters.07.2.visualizing-numerical-distributions","title":"Visualizing Numerical Distributions","description":"","date":"","thumbnail":"/build/ipad_battery-de7d1b7f2bb0e97a5c40be90f62b6014.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.2"},{"slug":"chapters.07.3.overlaid-graphs","title":"Overlaid Graphs","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.3"},{"slug":"chapters.08.functions-and-tables","title":"Functions and Tables","description":"","date":"","thumbnail":"/build/function_definition-4f5161f5d8f15fb47dc855e8d00e57e3.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"8"},{"slug":"chapters.08.1.applying-a-function-to-a-column","title":"Applying a Function to a Column","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.1"},{"slug":"chapters.08.2.classifying-by-one-variable","title":"Classifying by One Variable","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.2"},{"slug":"chapters.08.3.cross-classifying-by-more-than-one-variable","title":"Cross-Classifying by More than One Variable","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.3"},{"slug":"chapters.08.4.joining-tables-by-columns","title":"Joining Tables by Columns","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.4"},{"slug":"chapters.08.5.bike-sharing-in-the-bay-area","title":"Bike Sharing in the Bay Area","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.5"},{"slug":"chapters.09.randomness","title":"Randomness","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"9"},{"slug":"chapters.09.1.conditional-statements","title":"Conditional Statements","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.1"},{"slug":"chapters.09.2.iteration","title":"Iteration","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.2"},{"slug":"chapters.09.3.simulation","title":"Simulation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.3"},{"slug":"chapters.09.4.monty-hall-problem","title":"The Monty Hall Problem","description":"","date":"","thumbnail":"/build/monty_hall_goat-56112fd06fb86f88a6aba432a30f7253.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.4"},{"slug":"chapters.09.5.finding-probabilities","title":"Finding Probabilities","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.5"},{"slug":"chapters.10.sampling-and-empirical-distributions","title":"Sampling and Empirical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"10"},{"slug":"chapters.10.1.empirical-distributions","title":"Empirical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.1"},{"slug":"chapters.10.2.sampling-from-a-population","title":"Sampling from a Population","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.2"},{"slug":"chapters.10.3.empirical-distribution-of-a-statistic","title":"Empirical Distribution of a Statistic","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.3"},{"slug":"chapters.10.4.random-sampling-in-python","title":"Random Sampling in Python","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.4"},{"slug":"chapters.11.testing-hypotheses","title":"Testing Hypotheses","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"11"},{"slug":"chapters.11.1.assessing-a-model","title":"Assessing a Model","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.1"},{"slug":"chapters.11.2.multiple-categories","title":"Multiple Categories","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.2"},{"slug":"chapters.11.3.decisions-and-uncertainty","title":"Decisions and Uncertainty","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.3"},{"slug":"chapters.11.4.error-probabilities","title":"Error Probabilities","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.4"},{"slug":"chapters.12.comparing-two-samples","title":"Comparing Two Samples","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"12"},{"slug":"chapters.12.1.ab-testing","title":"A/B Testing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.1"},{"slug":"chapters.12.2.causality","title":"Causality","description":"","date":"","thumbnail":"/build/causality1-2e59fee82f936dc1e42a61601a813557.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.2"},{"slug":"chapters.12.3.deflategate","title":"Deflategate","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.3"},{"slug":"chapters.13.estimation","title":"Estimation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"13"},{"slug":"chapters.13.1.percentiles","title":"Percentiles","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.1"},{"slug":"chapters.13.2.bootstrap","title":"The Bootstrap","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.2"},{"slug":"chapters.13.3.confidence-intervals","title":"Confidence Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.3"},{"slug":"chapters.13.4.using-confidence-intervals","title":"Using Confidence Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.4"},{"slug":"chapters.14.why-the-mean-matters","title":"Why the Mean Matters","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"14"},{"slug":"chapters.14.1.properties-of-the-mean","title":"Properties of the Mean","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.1"},{"slug":"chapters.14.2.variability","title":"Variability","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.2"},{"slug":"chapters.14.3.sd-and-the-normal-curve","title":"The SD and the Normal Curve","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.3"},{"slug":"chapters.14.4.central-limit-theorem","title":"The Central Limit Theorem","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.4"},{"slug":"chapters.14.5.variability-of-the-sample-mean","title":"The Variability of the Sample Mean","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.5"},{"slug":"chapters.14.6.choosing-a-sample-size","title":"Choosing a Sample Size","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.6"},{"slug":"chapters.15.prediction","title":"Prediction","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"15"},{"slug":"chapters.15.1.correlation","title":"Correlation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.1"},{"slug":"chapters.15.2.regression-line","title":"The Regression Line","description":"","date":"","thumbnail":"/build/regline-6275539e16b9f1a5de8876a751e967a6.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.2"},{"slug":"chapters.15.3.method-of-least-squares","title":"The Method of Least Squares","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.3"},{"slug":"chapters.15.4.least-squares-regression","title":"Least Squares Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.4"},{"slug":"chapters.15.5.visual-diagnostics","title":"Visual Diagnostics","description":"","date":"","thumbnail":"/build/5f819b0045c6e81a4265dd506d7aaff9.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.5"},{"slug":"chapters.15.6.numerical-diagnostics","title":"Numerical Diagnostics","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.6"},{"slug":"chapters.16.inference-for-regression","title":"Inference for Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"16"},{"slug":"chapters.16.1.regression-model","title":"A Regression Model","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.1"},{"slug":"chapters.16.2.inference-for-the-true-slope","title":"Inference for the True Slope","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.2"},{"slug":"chapters.16.3.prediction-intervals","title":"Prediction Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.3"},{"slug":"chapters.17.classification","title":"Classification","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"17"},{"slug":"chapters.17.1.nearest-neighbors","title":"Nearest Neighbors","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.1"},{"slug":"chapters.17.2.training-and-testing","title":"Training and Testing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.2"},{"slug":"chapters.17.3.rows-of-tables","title":"Rows of Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.3"},{"slug":"chapters.17.4.implementing-the-classifier","title":"Implementing the Classifier","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.4"},{"slug":"chapters.17.5.accuracy-of-the-classifier","title":"The Accuracy of the Classifier","description":"","date":"","thumbnail":"/build/5e548385d4da863b59d51148bd5d0eeb.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.5"},{"slug":"chapters.17.6.multiple-regression","title":"Multiple Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.6"},{"slug":"chapters.18.updating-predictions","title":"Updating Predictions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"18"},{"slug":"chapters.18.1.more-likely-than-not-binary-classifier","title":"A “More Likely Than Not” Binary Classifier","description":"","date":"","thumbnail":"/build/tree_students-17a4ad5b4b4daa4f20ca9bf6c8b9a90d.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"18.1"},{"slug":"chapters.18.2.making-decisions","title":"Making Decisions","description":"","date":"","thumbnail":"/build/tree_disease_rare-6392a369221abe1c7bdffbd913bcb033.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"18.2"}]}}},"actionData":null,"errors":null},"future":{"unstable_dev":false,"unstable_postcss":false,"unstable_tailwind":false,"v2_errorBoundary":true,"v2_headers":true,"v2_meta":true,"v2_normalizeFormMethod":true,"v2_routeConvention":true}};</script><script type="module" async="">import "/build/manifest-3481E987.js";
import * as route0 from "/build/root-7TUVC4ZT.js";
import * as route1 from "/build/routes/$-P6PGXPYX.js";
window.__remixRouteModules = {"root":route0,"routes/$":route1};

import("/build/entry.client-UNPC4GT3.js");</script></body></html>