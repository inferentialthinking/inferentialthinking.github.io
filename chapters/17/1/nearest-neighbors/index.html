<!DOCTYPE html><html lang="en" class="" style="scroll-padding:60px"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/><title>Nearest Neighbors - Computational and Inferential Thinking</title><meta property="og:title" content="Nearest Neighbors - Computational and Inferential Thinking"/><meta name="generator" content="mystmd"/><meta name="keywords" content=""/><link rel="stylesheet" href="/build/_assets/app-IZWEOBHI.css"/><link rel="stylesheet" href="/build/_assets/thebe-core-VKVHG5VY.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jupyter-matplotlib@0.11.3/css/mpl_widget.css"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-148221575-1"></script><script>window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-148221575-1');</script><link rel="icon" href="/favicon.ico"/><link rel="stylesheet" href="/myst-theme.css"/><script>
  const savedTheme = localStorage.getItem("myst:theme");
  const theme = window.matchMedia("(prefers-color-scheme: light)").matches ? 'light' : 'dark';
  const classes = document.documentElement.classList;
  const hasAnyTheme = classes.contains('light') || classes.contains('dark');
  if (!hasAnyTheme) classes.add(savedTheme ?? theme);
</script></head><body class="m-0 transition-colors duration-500 bg-white dark:bg-stone-900"><div class="fixed top-1 left-1 h-[0px] w-[0px] focus-within:z-40 focus-within:h-auto focus-within:w-auto bg-white overflow-hidden focus-within:p-2 focus-within:ring-1" aria-label="skip to content options"><a href="#skip-to-frontmatter" class="block px-2 py-1 text-black underline">Skip to article frontmatter</a><a href="#skip-to-article" class="block px-2 py-1 text-black underline">Skip to article content</a></div><div class="bg-white/80 backdrop-blur dark:bg-stone-900/80 shadow dark:shadow-stone-700 p-3 md:px-8 sticky w-screen top-0 z-30 h-[60px]"><nav class="flex items-center justify-between flex-nowrap max-w-[1440px] mx-auto"><div class="flex flex-row xl:min-w-[19.5rem] mr-2 sm:mr-7 justify-start items-center shrink-0"><div class="block xl:hidden"><button class="flex items-center border-stone-400 text-stone-800 hover:text-stone-900 dark:text-stone-200 hover:dark:text-stone-100"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="m-1"><path fill-rule="evenodd" d="M3 6.75A.75.75 0 0 1 3.75 6h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 6.75ZM3 12a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 12Zm0 5.25a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75a.75.75 0 0 1-.75-.75Z" clip-rule="evenodd"></path></svg><span class="sr-only">Open Menu</span></button></div><a class="flex items-center ml-3 dark:text-white w-fit md:ml-5 xl:ml-7" href="/"><div class="p-1 mr-3 dark:bg-white dark:rounded"><img src="/build/data8logo-7a6c5cd41fe4d513ca7e7f76d46e9670.png" class="h-9" alt="Computational and Inferential Thinking" height="2.25rem"/></div><span class="text-md sm:text-xl tracking-tight sm:mr-5">Computational and Inferential Thinking</span></a></div><div class="flex items-center flex-grow w-auto"><div class="flex-grow hidden text-md lg:block"></div><div class="flex-grow block"></div><button type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R74op:" data-state="closed" class="flex items-center h-10 aspect-square sm:w-64 text-left text-gray-400 border border-gray-300 dark:border-gray-600 rounded-lg bg-gray-50 dark:bg-gray-700 hover:ring-blue-500 dark:hover:ring-blue-500 hover:border-blue-500 dark:hover:border-blue-500"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="p-2.5 h-10 w-10 aspect-square"><path fill-rule="evenodd" d="M10.5 3.75a6.75 6.75 0 1 0 0 13.5 6.75 6.75 0 0 0 0-13.5ZM2.25 10.5a8.25 8.25 0 1 1 14.59 5.28l4.69 4.69a.75.75 0 1 1-1.06 1.06l-4.69-4.69A8.25 8.25 0 0 1 2.25 10.5Z" clip-rule="evenodd"></path></svg><span class="hidden sm:block grow">Search</span><div aria-hidden="true" class="items-center hidden mx-1 font-mono text-sm text-gray-400 sm:flex gap-x-1"><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none hide-mac">CTRL</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none show-mac">⌘</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none ">K</kbd><script>
;(() => {
const script = document.currentScript;
const root = script.parentElement;

const isMac = /mac/i.test(
      window.navigator.userAgentData?.platform ?? window.navigator.userAgent,
    );
root.querySelectorAll(".hide-mac").forEach(node => {node.classList.add(isMac ? "hidden" : "block")});
root.querySelectorAll(".show-mac").forEach(node => {node.classList.add(!isMac ? "hidden" : "block")});
})()</script></div></button><button class="theme rounded-full aspect-square border border-stone-700 dark:border-white hover:bg-neutral-100 border-solid overflow-hidden text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 w-8 h-8 mx-3" title="Toggle theme between light and dark mode" aria-label="Toggle theme between light and dark mode"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 hidden dark:block"><path fill-rule="evenodd" d="M9.528 1.718a.75.75 0 0 1 .162.819A8.97 8.97 0 0 0 9 6a9 9 0 0 0 9 9 8.97 8.97 0 0 0 3.463-.69.75.75 0 0 1 .981.98 10.503 10.503 0 0 1-9.694 6.46c-5.799 0-10.5-4.7-10.5-10.5 0-4.368 2.667-8.112 6.46-9.694a.75.75 0 0 1 .818.162Z" clip-rule="evenodd"></path></svg><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 dark:hidden"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v2.25m6.364.386-1.591 1.591M21 12h-2.25m-.386 6.364-1.591-1.591M12 18.75V21m-4.773-4.227-1.591 1.591M5.25 12H3m4.227-4.773L5.636 5.636M15.75 12a3.75 3.75 0 1 1-7.5 0 3.75 3.75 0 0 1 7.5 0Z"></path></svg></button><div class="block sm:hidden"></div><div class="hidden sm:block"></div></div></nav></div><div class="fixed xl:article-grid grid-gap xl:w-screen xl:pointer-events-none overflow-auto max-xl:min-w-[300px] hidden z-10" style="top:60px"><div class="pointer-events-auto xl:col-margin-left flex-col overflow-hidden hidden xl:flex"><div class="flex-grow py-6 overflow-y-auto primary-scrollbar"><nav aria-label="Navigation" class="overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px] lg:hidden"><div class="w-full px-1 dark:text-white font-medium"></div></nav><div class="my-3 border-b-2 lg:hidden"></div><nav aria-label="Table of Contents" class="flex-grow overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px]"><div class="w-full px-1 dark:text-white"><a title="Computational and Inferential Thinking" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30 font-bold" href="/">Computational and Inferential Thinking</a><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="1 What is Data Science?" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/01/what-is-data-science">1 What is Data Science?</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rmp8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:Rmp8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="2 Causality and Experiments" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/02/causality-and-experiments">2 Causality and Experiments</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rup8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:Rup8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="3 Programming in Python" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/03/programming-in-python">3 Programming in Python</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R16p8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R16p8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="4 Data Types" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/04/data-types">4 Data Types</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R1ep8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R1ep8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="5 Sequences" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/05/sequences">5 Sequences</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R1mp8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R1mp8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="6 Tables" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/06/tables">6 Tables</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R1up8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R1up8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="7 Visualization" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/07/visualization">7 Visualization</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R26p8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R26p8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="8 Functions and Tables" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/08/functions-and-tables">8 Functions and Tables</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R2ep8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R2ep8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="9 Randomness" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/09/randomness">9 Randomness</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R2mp8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R2mp8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="10 Sampling and Empirical Distributions" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/10/sampling-and-empirical-distributions">10 Sampling and Empirical Distributions</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R2up8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R2up8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="11 Testing Hypotheses" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/11/testing-hypotheses">11 Testing Hypotheses</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R36p8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R36p8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="12 Comparing Two Samples" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/12/comparing-two-samples">12 Comparing Two Samples</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R3ep8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R3ep8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="13 Estimation" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/13/estimation">13 Estimation</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R3mp8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R3mp8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="14 Why the Mean Matters" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/14/why-the-mean-matters">14 Why the Mean Matters</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R3up8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R3up8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="15 Prediction" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/15/prediction">15 Prediction</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R46p8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R46p8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="16 Inference for Regression" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/16/inference-for-regression">16 Inference for Regression</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R4ep8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R4ep8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="open" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="17 Classification" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow font-semibold text-blue-800 dark:text-blue-200" href="/chapters/17/classification">17 Classification</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R4mp8p:" aria-expanded="true" data-state="open"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="open" id="radix-:R4mp8p:" class="pl-3 pr-[2px] collapsible-content"><a title="17.1 Nearest Neighbors" aria-current="page" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg bg-blue-300/30 active" href="/chapters/17/1/nearest-neighbors">17.1 Nearest Neighbors</a><a title="17.2 Training and Testing" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/chapters/17/2/training-and-testing">17.2 Training and Testing</a><a title="17.3 Rows of Tables" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/chapters/17/3/rows-of-tables">17.3 Rows of Tables</a><a title="17.4 Implementing the Classifier" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/chapters/17/4/implementing-the-classifier">17.4 Implementing the Classifier</a><a title="17.5 The Accuracy of the Classifier" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/chapters/17/5/accuracy-of-the-classifier">17.5 The Accuracy of the Classifier</a><a title="17.6 Multiple Regression" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/chapters/17/6/multiple-regression">17.6 Multiple Regression</a></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="18 Updating Predictions" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/18/updating-predictions">18 Updating Predictions</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R4up8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R4up8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div></div></nav></div><div class="flex-none py-6 transition-all duration-700 translate-y-6 opacity-0"><a class="flex mx-auto text-gray-700 w-fit hover:text-blue-700 dark:text-gray-200 dark:hover:text-blue-400" href="https://mystmd.org/made-with-myst" target="_blank" rel="noreferrer"><svg style="width:24px;height:24px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" stroke="none"><g id="icon"><path fill="currentColor" d="M23.8,54.8v-3.6l4.7-0.8V17.5l-4.7-0.8V13H36l13.4,31.7h0.2l13-31.7h12.6v3.6l-4.7,0.8v32.9l4.7,0.8v3.6h-15
          v-3.6l4.9-0.8V20.8H65L51.4,53.3h-3.8l-14-32.5h-0.1l0.2,17.4v12.1l5,0.8v3.6H23.8z"></path><path fill="#F37726" d="M47,86.9c0-5.9-3.4-8.8-10.1-8.8h-8.4c-5.2,0-9.4-1.3-12.5-3.8c-3.1-2.5-5.4-6.2-6.8-11l4.8-1.6
          c1.8,5.6,6.4,8.6,13.8,8.8h9.2c6.4,0,10.8,2.5,13.1,7.5c2.3-5,6.7-7.5,13.1-7.5h8.4c7.8,0,12.7-2.9,14.6-8.7l4.8,1.6
          c-1.4,4.9-3.6,8.6-6.8,11.1c-3.1,2.5-7.3,3.7-12.4,3.8H63c-6.7,0-10,2.9-10,8.8"></path></g></svg><span class="self-center ml-2 text-sm">Made with MyST</span></a></div></div></div><main class="article-grid grid-gap"><article class="article-grid subgrid-gap col-screen article content"><div class="hidden"></div><div id="skip-to-frontmatter" aria-label="article frontmatter" class="mb-8 pt-9"><div class="flex items-center mb-5 h-6 text-sm font-light"><div class="flex-grow"></div><a href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" rel="noopener noreferrer" class="opacity-50 hover:opacity-100 text-inherit hover:text-inherit" aria-label="Content License: Creative Commons Attribution Non Commercial No Derivatives 4.0 International (CC-BY-NC-ND-4.0)"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mx-1"><title>Content License: Creative Commons Attribution Non Commercial No Derivatives 4.0 International (CC-BY-NC-ND-4.0)</title><path d="M12 2.2c2.7 0 5 1 7 2.9.9.9 1.6 2 2.1 3.1.5 1.2.7 2.4.7 3.8 0 1.3-.2 2.6-.7 3.8-.5 1.2-1.2 2.2-2.1 3.1-1 .9-2 1.7-3.2 2.2-1.2.5-2.5.7-3.7.7s-2.6-.3-3.8-.8c-1.2-.5-2.2-1.2-3.2-2.1s-1.6-2-2.1-3.2-.8-2.4-.8-3.7c0-1.3.2-2.5.7-3.7S4.2 6 5.1 5.1C7 3.2 9.3 2.2 12 2.2zM12 4c-2.2 0-4.1.8-5.6 2.3C5.6 7.1 5 8 4.6 9c-.4 1-.6 2-.6 3s.2 2.1.6 3c.4 1 1 1.8 1.8 2.6S8 19 9 19.4c1 .4 2 .6 3 .6s2.1-.2 3-.6c1-.4 1.9-1 2.7-1.8 1.5-1.5 2.3-3.3 2.3-5.6 0-1.1-.2-2.1-.6-3.1-.4-1-1-1.8-1.7-2.6C16.1 4.8 14.2 4 12 4zm-.1 6.4l-1.3.7c-.1-.3-.3-.5-.5-.6-.2-.1-.4-.2-.6-.2-.9 0-1.3.6-1.3 1.7 0 .5.1.9.3 1.3.2.3.5.5 1 .5.6 0 1-.3 1.2-.8l1.2.6c-.3.5-.6.9-1.1 1.1-.5.3-1 .4-1.5.4-.9 0-1.6-.3-2.1-.8-.5-.6-.8-1.3-.8-2.3 0-.9.3-1.7.8-2.2.6-.6 1.3-.8 2.1-.8 1.2 0 2.1.4 2.6 1.4zm5.6 0l-1.3.7c-.1-.3-.3-.5-.5-.6-.2-.1-.4-.2-.6-.2-.9 0-1.3.6-1.3 1.7 0 .5.1.9.3 1.3.2.3.5.5 1 .5.6 0 1-.3 1.2-.8l1.2.6c-.3.5-.6.9-1.1 1.1-.4.2-.9.3-1.4.3-.9 0-1.6-.3-2.1-.8s-.8-1.3-.8-2.2c0-.9.3-1.7.8-2.2.5-.5 1.2-.8 2-.8 1.2 0 2.1.4 2.6 1.4z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1"><title>Credit must be given to the creator</title><path d="M12 2.2c2.7 0 5 .9 6.9 2.8 1.9 1.9 2.8 4.2 2.8 6.9s-.9 5-2.8 6.8c-2 1.9-4.3 2.9-7 2.9-2.6 0-4.9-1-6.9-2.9-1.8-1.7-2.8-4-2.8-6.7s1-5 2.9-6.9C7 3.2 9.3 2.2 12 2.2zM12 4c-2.2 0-4.1.8-5.6 2.3C4.8 8 4 9.9 4 12c0 2.2.8 4 2.4 5.6C8 19.2 9.8 20 12 20c2.2 0 4.1-.8 5.7-2.4 1.5-1.5 2.3-3.3 2.3-5.6 0-2.2-.8-4.1-2.3-5.7C16.1 4.8 14.2 4 12 4zm2.6 5.6v4h-1.1v4.7h-3v-4.7H9.4v-4c0-.2.1-.3.2-.4.1-.2.2-.2.4-.2h4c.2 0 .3.1.4.2.2.1.2.2.2.4zm-4-2.5c0-.9.5-1.4 1.4-1.4s1.4.5 1.4 1.4c0 .9-.5 1.4-1.4 1.4s-1.4-.5-1.4-1.4z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1"><title>Only noncommercial uses of the work are permitted</title><path d="M12 2.2c2.7 0 5 .9 6.9 2.8 1.9 1.9 2.8 4.2 2.8 6.9s-.9 5-2.8 6.8c-2 1.9-4.3 2.9-7 2.9-2.6 0-4.9-1-6.9-2.9-1.9-1.9-2.9-4.2-2.9-6.9s1-5 2.9-6.9c2-1.7 4.3-2.7 7-2.7zM4.4 9.4C4.2 10.2 4 11 4 12c0 2.2.8 4 2.4 5.6C8 19.2 9.8 20 12 20c2.2 0 4.1-.8 5.7-2.4.6-.5 1-1.1 1.3-1.7l-3.7-1.6c-.1.6-.4 1.1-.9 1.5-.5.4-1.1.6-1.8.7V18h-1.1v-1.5c-1.1 0-2.1-.4-3-1.2l1.3-1.4c.6.6 1.4.9 2.2.9.3 0 .6-.1.9-.2.2-.2.4-.4.4-.7 0-.2-.1-.4-.3-.6l-.9-.4-1.1-.6-1.5-.7-5.1-2.2zM12 4c-2.2 0-4.1.8-5.6 2.3-.4.4-.7.9-1.1 1.3L9 9.3c.2-.5.5-.9 1-1.2.5-.3 1-.5 1.6-.5V6.1h1.1v1.5c.9 0 1.7.3 2.4.9l-1.3 1.3c-.5-.4-1.1-.6-1.7-.6-.3 0-.6.1-.8.2-.2.1-.3.3-.3.6 0 .1 0 .2.1.2l1.2.6.9.4 1.6.7 5 2.2c.2-.7.2-1.4.2-2.1 0-2.2-.8-4.1-2.3-5.7C16.1 4.8 14.2 4 12 4z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1"><title>No derivatives or adaptations of the work are permitted</title><path d="M12 2.2c2.7 0 5 .9 6.9 2.8 1.9 1.9 2.8 4.2 2.8 6.9s-.9 5-2.8 6.9c-2 1.9-4.3 2.9-7 2.9-2.6 0-4.9-1-6.9-2.9C3.2 17 2.2 14.7 2.2 12s1-5 2.9-6.9C7 3.2 9.3 2.2 12 2.2zM12 4c-2.2 0-4.1.8-5.6 2.4C4.8 8 4 9.9 4 12c0 2.2.8 4 2.4 5.6C8 19.2 9.8 20 12 20c2.2 0 4.1-.8 5.7-2.4 1.5-1.5 2.3-3.3 2.3-5.6 0-2.2-.8-4.1-2.3-5.6C16.1 4.8 14.2 4 12 4zm3.7 5.7v1.7H8.6V9.7h7.1zm0 3.1v1.7H8.6v-1.7h7.1z"></path></svg></a><a href="https://github.com/data-8/textbook" title="GitHub Repository: data-8/textbook" target="_blank" rel="noopener noreferrer" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1 opacity-60 hover:opacity-100"><path d="M12 2.5c-5.4 0-9.8 4.4-9.8 9.7 0 4.3 2.8 8 6.7 9.2.5.1.7-.2.7-.5v-1.8c-2.4.5-3.1-.6-3.3-1.1-.1-.3-.6-1.1-1-1.4-.3-.2-.8-.6 0-.6s1.3.7 1.5 1c.9 1.5 2.3 1.1 2.8.8.1-.6.3-1.1.6-1.3-2.2-.2-4.4-1.1-4.4-4.8 0-1.1.4-1.9 1-2.6-.1-.2-.4-1.2.1-2.6 0 0 .8-.3 2.7 1 .8-.2 1.6-.3 2.4-.3.8 0 1.7.1 2.4.3 1.9-1.3 2.7-1 2.7-1 .5 1.3.2 2.3.1 2.6.6.7 1 1.5 1 2.6 0 3.7-2.3 4.6-4.4 4.8.4.3.7.9.7 1.8V21c0 .3.2.6.7.5 3.9-1.3 6.6-4.9 6.6-9.2 0-5.4-4.4-9.8-9.8-9.8z"></path></svg></a><a href="https://github.com/data-8/textbook/edit/main/chapters/17/1/Nearest_Neighbors.ipynb" title="Edit This Page" target="_blank" rel="noopener noreferrer" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem" class="inline-block mr-1 opacity-60 hover:opacity-100"><path stroke-linecap="round" stroke-linejoin="round" d="m16.862 4.487 1.687-1.688a1.875 1.875 0 1 1 2.652 2.652L10.582 16.07a4.5 4.5 0 0 1-1.897 1.13L6 18l.8-2.685a4.5 4.5 0 0 1 1.13-1.897l8.932-8.931Zm0 0L19.5 7.125M18 14v4.75A2.25 2.25 0 0 1 15.75 21H5.25A2.25 2.25 0 0 1 3 18.75V8.25A2.25 2.25 0 0 1 5.25 6H10"></path></svg></a><div class="relative flex inline-block mx-1 grow-0" data-headlessui-state=""><button class="relative ml-2 -mr-1" id="headlessui-menu-button-:Rs8top:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Downloads</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem"><title>Download</title><path stroke-linecap="round" stroke-linejoin="round" d="M3 16.5v2.25A2.25 2.25 0 0 0 5.25 21h13.5A2.25 2.25 0 0 0 21 18.75V16.5M16.5 12 12 16.5m0 0L7.5 12m4.5 4.5V3"></path></svg></button></div></div><h1 class="mb-0"><span class="mr-3 select-none">17.1</span>Nearest Neighbors</h1></div><div class="block my-10 lg:sticky lg:z-10 lg:h-0 lg:pt-0 lg:my-0 lg:ml-10 lg:col-margin-right" style="top:60px"><nav></nav></div><div id="skip-to-article"></div><div id="XTuSqdN3tS" class="relative group/block"><p>In this section we’ll develop the <em>nearest neighbor</em> method of classification. Just focus on the ideas for now and don’t worry if some of the code is mysterious. Later in the chapter we’ll see how to organize our ideas into code that performs the classification.</p></div><div id="yWDUci0Ui4" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose hidden my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">import matplotlib
#matplotlib.use(&#x27;Agg&#x27;)
path_data = &#x27;../../../assets/data/&#x27;
from datascience import *
%matplotlib inline
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import numpy as np
import math
import scipy.stats as stats
plt.style.use(&#x27;fivethirtyeight&#x27;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="2i6uXx86Bo74KBiYeamdu" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="luARiu6Jov" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose hidden my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def standard_units(x):
    return (x - np.mean(x))/np.std(x)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="PbGpulJagmvx3sjHPdhJ6" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="Xx2tOCMPBB" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose hidden my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def distance(point1, point2):
    &quot;&quot;&quot;The distance between two arrays of numbers.&quot;&quot;&quot;
    return np.sqrt(np.sum((point1 - point2)**2))

def all_distances(training, point):
    &quot;&quot;&quot;The distance between p (an array of numbers) and the numbers in row i of attribute_table.&quot;&quot;&quot;
    attributes = training.drop(&#x27;Class&#x27;)
    def distance_from_point(row):
        return distance(point, np.array(row))
    return attributes.apply(distance_from_point)

def table_with_distances(training, point):
    &quot;&quot;&quot;A copy of the training table with the distance from each row to array p.&quot;&quot;&quot;
    return training.with_column(&#x27;Distance&#x27;, all_distances(training, point))

def closest(training, point, k):
    &quot;&quot;&quot;A table containing the k closest rows in the training table to array p.&quot;&quot;&quot;
    with_dists = table_with_distances(training, point)
    sorted_by_distance = with_dists.sort(&#x27;Distance&#x27;)
    topk = sorted_by_distance.take(np.arange(k))
    return topk

def majority(topkclasses):
    &quot;&quot;&quot;1 if the majority of the &quot;Class&quot; column is 1s, and 0 otherwise.&quot;&quot;&quot;
    ones = topkclasses.where(&#x27;Class&#x27;, are.equal_to(1)).num_rows
    zeros = topkclasses.where(&#x27;Class&#x27;, are.equal_to(0)).num_rows
    if ones &gt; zeros:
        return 1
    else:
        return 0

def classify(training, p, k):
    &quot;&quot;&quot;Classify an example with attributes p using k-nearest neighbor classification with the given training table.&quot;&quot;&quot;
    closestk = closest(training, p, k)
    topkclasses = closestk.select(&#x27;Class&#x27;)
    return majority(topkclasses)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="z5rSdyPjJbqblHoVdRKKW" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="TGGx6s29YU" class="relative group/block"><h2 id="chronic-kidney-disease" class="relative group"><span class="heading-text">Chronic kidney disease</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#chronic-kidney-disease" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>Let’s work through an example.  We’re going to work with a data set that was collected to help doctors diagnose chronic kidney disease (CKD).  Each row in the data set represents a single patient who was treated in the past and whose diagnosis is known.  For each patient, we have a bunch of measurements from a blood test.  We’d like to find which measurements are most useful for diagnosing CKD, and develop a way to classify future patients as “has CKD” or “doesn’t have CKD” based on their blood test results.</p></div><div id="zdukudY877" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">ckd = Table.read_table(path_data + &#x27;ckd.csv&#x27;).relabeled(&#x27;Blood Glucose Random&#x27;, &#x27;Glucose&#x27;)
ckd</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="TUeY8sfRWcE1srjZn27Ov" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><div><div class="p-2.5">Loading...</div></div></div></div><div id="PDKJlwj97h" class="relative group/block"><p>Some of the variables are categorical (words like “abnormal”), and some quantitative. The quantitative variables all have different scales. We’re going to want to make comparisons and estimate distances, often by eye, so let’s select just a few of the variables and work in standard units. Then we won’t have to worry about the scale of each of the different variables.</p></div><div id="HNDLEmvWO7" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">ckd = Table().with_columns(
    &#x27;Hemoglobin&#x27;, standard_units(ckd.column(&#x27;Hemoglobin&#x27;)),
    &#x27;Glucose&#x27;, standard_units(ckd.column(&#x27;Glucose&#x27;)),
    &#x27;White Blood Cell Count&#x27;, standard_units(ckd.column(&#x27;White Blood Cell Count&#x27;)),
    &#x27;Class&#x27;, ckd.column(&#x27;Class&#x27;)
)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="2qAfvscaji-txwHvG1_tr" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="o0z4T6Fbyd" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">ckd</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="ncL2IiPFC9GPWAUGdI46j" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><div><div class="p-2.5">Loading...</div></div></div></div><div id="PbhmtUcrCj" class="relative group/block"><p>Let’s look at two columns in particular: the hemoglobin level (in the patient’s blood), and the blood glucose level (at a random time in the day; without fasting specially for the blood test).</p><p>We’ll draw a scatter plot to visualize the relation between the two variables. Blue dots are patients with CKD; gold dots are patients without CKD.  What kind of medical test results seem to indicate CKD?</p></div><div id="WkHEQ9jv5y" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">color_table = Table().with_columns(
    &#x27;Class&#x27;, make_array(1, 0),
    &#x27;Color&#x27;, make_array(&#x27;darkblue&#x27;, &#x27;gold&#x27;)
)
ckd = ckd.join(&#x27;Class&#x27;, color_table)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="dlETkQKpV0tkF0wMS66Dt" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="iMLlxYS81i" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">ckd.scatter(&#x27;Hemoglobin&#x27;, &#x27;Glucose&#x27;, group=&#x27;Color&#x27;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="vHLo_Lo4MEZlcddw7fpyI" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><img src="/build/953f828d6abb1a12d3c40926ab449b5b.png" alt="&lt;Figure size 360x360 with 1 Axes&gt;"/></div></div><div id="fsXoEIpGWn" class="relative group/block"><p>Suppose Alice is a new patient who is not in the data set.  If I tell you Alice’s hemoglobin level and blood glucose level, could you predict whether she has CKD?  It sure looks like it!  You can see a very clear pattern here: points in the lower-right tend to represent people who don’t have CKD, and the rest tend to be folks with CKD.  To a human, the pattern is obvious.  But how can we program a computer to automatically detect patterns such as this one?</p></div><div id="ywvUPoBRVn" class="relative group/block"><h2 id="a-nearest-neighbor-classifier" class="relative group"><span class="heading-text">A Nearest Neighbor Classifier</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#a-nearest-neighbor-classifier" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>There are lots of kinds of patterns one might look for, and lots of algorithms for classification.  But I’m going to tell you about one that turns out to be surprisingly effective.  It is called <em>nearest neighbor classification</em>.  Here’s the idea.  If we have Alice’s hemoglobin and glucose numbers, we can put her somewhere on this scatterplot; the hemoglobin is her x-coordinate, and the glucose is her y-coordinate.  Now, to predict whether she has CKD or not, we find the nearest point in the scatterplot and check whether it is blue or gold; we predict that Alice should receive the same diagnosis as that patient.</p><p>In other words, to classify Alice as CKD or not, we find the patient in the training set who is “nearest” to Alice, and then use that patient’s diagnosis as our prediction for Alice.  The intuition is that if two points are near each other in the scatterplot, then the corresponding measurements are pretty similar, so we might expect them to receive the same diagnosis (more likely than not).  We don’t know Alice’s diagnosis, but we do know the diagnosis of all the patients in the training set, so we find the patient in the training set who is most similar to Alice, and use that patient’s diagnosis to predict Alice’s diagnosis.</p></div><div id="OlrFv8mAkP" class="relative group/block"><p>In the graph below, the red dot represents Alice. It is joined with a black line to the point that is nearest to it – its <em>nearest neighbor</em> in the training set. The figure is drawn by a function called <code>show_closest</code>. It takes an array that represents the <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span></span> and <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span></span> coordinates of Alice’s point. Vary those to see how the closest point changes! Note especially when the closest point is blue and when it is gold.</p></div><div id="pXtaRgpTty" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose hidden my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def show_closest(point):
    &quot;&quot;&quot;point = array([x,y]) 
    gives the coordinates of a new point
    shown in red&quot;&quot;&quot;
    
    HemoGl = ckd.drop(&#x27;White Blood Cell Count&#x27;, &#x27;Color&#x27;)
    t = closest(HemoGl, point, 1)
    x_closest = t.row(0).item(1)
    y_closest = t.row(0).item(2)
    ckd.scatter(&#x27;Hemoglobin&#x27;, &#x27;Glucose&#x27;, group=&#x27;Color&#x27;)
    plt.scatter(point.item(0), point.item(1), color=&#x27;red&#x27;, s=30)
    plt.plot(make_array(point.item(0), x_closest), make_array(point.item(1), y_closest), color=&#x27;k&#x27;, lw=2);</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="wBROZLdF99_GQWlyKXu0B" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="PJGtqdaU4S" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># In this example, Alice&#x27;s Hemoglobin attribute is 0 and her Glucose is 1.5.
alice = make_array(0, 1.5)
show_closest(alice)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="y7AbH3zxE2JBv6O8lQrG6" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><img src="/build/26f4729c2561e5bd5d3853aa7c622a1c.png" alt="&lt;Figure size 360x360 with 1 Axes&gt;"/></div></div><div id="mYlASi4yJt" class="relative group/block"><p>Thus our <em>nearest neighbor classifier</em> works like this:</p><ul><li><p>Find the point in the training set that is nearest to the new point.</p></li><li><p>If that nearest point is a “CKD” point, classify the new point as “CKD”. If the nearest point is a “not CKD” point, classify the new point as “not CKD”.</p></li></ul><p>The scatterplot suggests that this nearest neighbor classifier should be pretty accurate.  Points in the lower-right will tend to receive a “no CKD” diagnosis, as their nearest neighbor will be a gold point.  The rest of the points will tend to receive a “CKD” diagnosis, as their nearest neighbor will be a blue point.  So the nearest neighbor strategy seems to capture our intuition pretty well, for this example.</p></div><div id="YIib2COOSW" class="relative group/block"><h2 id="decision-boundary" class="relative group"><span class="heading-text">Decision boundary</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#decision-boundary" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>Sometimes a helpful way to visualize a classifier is to map out the kinds of attributes where the classifier would predict ‘CKD’, and the kinds where it would predict ‘not CKD’.  We end up with some boundary between the two, where points on one side of the boundary will be classified ‘CKD’ and points on the other side will be classified ‘not CKD’.  This boundary is called the <em>decision boundary</em>.  Each different classifier will have a different decision boundary; the decision boundary is just a way to visualize what criteria the classifier is using to classify points.</p><p>For example, suppose the coordinates of Alice’s point are (0, 1.5). Notice that the nearest neighbor is blue. Now try reducing the height (the <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span></span>-coordinate) of the point. You’ll see that at around <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>=</mo><mn>0.95</mn></mrow><annotation encoding="application/x-tex">y = 0.95</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.95</span></span></span></span></span> the nearest neighbor turns from blue to gold.</p></div><div id="j93etcUJ9M" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">alice = make_array(0, 0.97)
show_closest(alice)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="IFbclnaFBrZ-XPMf9urVM" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><img src="/build/d232a31ef0e4409260a0eeafe5d71864.png" alt="&lt;Figure size 360x360 with 1 Axes&gt;"/></div></div><div id="F0GbmMiZBB" class="relative group/block"><p>Here are hundreds of new unclassified points, all in red.</p></div><div id="GOGvxr7FKC" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose hidden my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">x_array = make_array()
y_array = make_array()
for x in np.arange(-2, 2.1, 0.1):
    for y in np.arange(-2, 2.1, 0.1):
        x_array = np.append(x_array, x)
        y_array = np.append(y_array, y)
        
test_grid = Table().with_columns(
    &#x27;Hemoglobin&#x27;, x_array,
    &#x27;Glucose&#x27;, y_array
)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="ONQc6uGPTrI-FjvFYFTqX" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="lo9AEPIBQr" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose hidden my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">test_grid.scatter(&#x27;Hemoglobin&#x27;, &#x27;Glucose&#x27;, color=&#x27;red&#x27;, alpha=0.4, s=30)

plt.scatter(ckd.column(&#x27;Hemoglobin&#x27;), ckd.column(&#x27;Glucose&#x27;), c=ckd.column(&#x27;Color&#x27;), edgecolor=&#x27;k&#x27;)

plt.xlim(-2, 2)
plt.ylim(-2, 2);</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="x55j4B7DcJtXgIxL_9J-T" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><img src="/build/9ded977b720879a2f45b1778823adf5a.png" alt="&lt;Figure size 360x360 with 1 Axes&gt;"/></div></div><div id="IZFeVnT2sh" class="relative group/block"><p>Each of the red points has a nearest neighbor in the training set (the same blue and gold points as before). For some red points you can easily tell whether the nearest neighbor is blue or gold. For others, it’s a little more tricky to make the decision by eye. Those are the points near the decision boundary.</p><p>But the computer can easily determine the nearest neighbor of each point. So let’s get it to apply our nearest neighbor classifier to each of the red points:</p><p>For each red point, it must find the closest point in the training set; it must then change the color of the red point to become the color of the nearest neighbor.</p><p>The resulting graph shows which points will get classified as ‘CKD’ (all the blue ones), and which as ‘not CKD’ (all the gold ones).</p></div><div id="BEbV4aANOL" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose hidden my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def classify_grid(training, test, k):
    c = make_array()
    for i in range(test.num_rows):
        # Run the classifier on the ith patient in the test set
        c = np.append(c, classify(training, make_array(test.row(i)), k))   
    return c</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="RgfErAveWJJj4-TZZmvL9" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="IHvAHFPvSU" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose hidden my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">c = classify_grid(ckd.drop(&#x27;White Blood Cell Count&#x27;, &#x27;Color&#x27;), test_grid, 1)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="hZ0GD_8aawjQJUew-PDYg" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="kzLOqwnjra" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose hidden my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">test_grid = test_grid.with_column(&#x27;Class&#x27;, c).join(&#x27;Class&#x27;, color_table)
test_grid.scatter(&#x27;Hemoglobin&#x27;, &#x27;Glucose&#x27;, group=&#x27;Color&#x27;, alpha=0.4, s=30)

plt.scatter(ckd.column(&#x27;Hemoglobin&#x27;), ckd.column(&#x27;Glucose&#x27;), c=ckd.column(&#x27;Color&#x27;), edgecolor=&#x27;k&#x27;)

plt.xlim(-2, 2)
plt.ylim(-2, 2);</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="elAYacdW5J7DaIiSmwU2_" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><img src="/build/36ddf46aaa2cd26d26a5efa73fed21a9.png" alt="&lt;Figure size 360x360 with 1 Axes&gt;"/></div></div><div id="JCxFhAMkw9" class="relative group/block"><p>The decision boundary is where the classifier switches from turning the red points blue to turning them gold.</p></div><div id="uKijxrYrfa" class="relative group/block"><h2 id="k-nearest-neighbors" class="relative group"><span class="heading-text">k-Nearest Neighbors</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#k-nearest-neighbors" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>However, the separation between the two classes won’t always be quite so clean.  For instance, suppose that instead of hemoglobin levels we were to look at white blood cell count.  Look at what happens:</p></div><div id="DZD3V5cpsh" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">ckd.scatter(&#x27;White Blood Cell Count&#x27;, &#x27;Glucose&#x27;, group=&#x27;Color&#x27;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="rU72BCRSjcCszq7x_pGxi" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><img src="/build/06c787dc3c67c9e56ebcb425bd0f094d.png" alt="&lt;Figure size 360x360 with 1 Axes&gt;"/></div></div><div id="DIw4n157HL" class="relative group/block"><p>As you can see, non-CKD individuals are all clustered in the lower-left.  Most of the patients with CKD are above or to the right of that cluster... but not all.  There are some patients with CKD who are in the lower left of the above figure (as indicated by the handful of blue dots scattered among the gold cluster).  What this means is that you can’t tell for certain whether someone has CKD from just these two blood test measurements.</p><p>If we are given Alice’s glucose level and white blood cell count, can we predict whether she has CKD?  Yes, we can make a prediction, but we shouldn’t expect it to be 100% accurate.  Intuitively, it seems like there’s a natural strategy for predicting: plot where Alice lands in the scatter plot; if she is in the lower-left, predict that she doesn’t have CKD, otherwise predict she has CKD.</p><p>This isn’t perfect -- our predictions will sometimes be wrong.  (Take a minute and think it through: for which patients will it make a mistake?)  As the scatterplot above indicates, sometimes people with CKD have glucose and white blood cell levels that look identical to those of someone without CKD, so any classifier is inevitably going to make the wrong prediction for them.</p><p>Can we automate this on a computer?  Well, the nearest neighbor classifier would be a reasonable choice here too.  Take a minute and think it through: how will its predictions compare to those from the intuitive strategy above?  When will they differ?</p><p>Its predictions will be pretty similar to our intuitive strategy, but occasionally it will make a different prediction.  In particular, if Alice’s blood test results happen to put her right near one of the blue dots in the lower-left, the intuitive strategy would predict ‘not CKD’, whereas the nearest neighbor classifier will predict ‘CKD’.</p><p>There is a simple generalization of the nearest neighbor classifier that fixes this anomaly.  It is called the <em>k-nearest neighbor classifier</em>.  To predict Alice’s diagnosis, rather than looking at just the one neighbor closest to her, we can look at the 3 points that are closest to her, and use the diagnosis for each of those 3 points to predict Alice’s diagnosis.  In particular, we’ll use the majority value among those 3 diagnoses as our prediction for Alice’s diagnosis.  Of course, there’s nothing special about the number 3: we could use 4, or 5, or more.  (It’s often convenient to pick an odd number, so that we don’t have to deal with ties.)  In general, we pick a number <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span></span>, and our predicted diagnosis for Alice is based on the <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span></span> patients in the training set who are closest to Alice.  Intuitively, these are the <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span></span> patients whose blood test results were most similar to Alice, so it seems reasonable to use their diagnoses to predict Alice’s diagnosis.</p><p>The <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span></span>-nearest neighbor classifier will now behave just like our intuitive strategy above.</p></div><div></div><div class="flex pt-10 mb-10 space-x-4"><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/chapters/17/classification"><div class="flex h-full align-middle"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:-translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M10.5 19.5 3 12m0 0 7.5-7.5M3 12h18"></path></svg><div class="flex-grow text-right"><div class="text-xs text-gray-500 dark:text-gray-400">Computational and Inferential Thinking</div>Classification</div></div></a><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/chapters/17/2/training-and-testing"><div class="flex h-full align-middle"><div class="flex-grow"><div class="text-xs text-gray-500 dark:text-gray-400">Computational and Inferential Thinking</div>Training and Testing</div><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 4.5 21 12m0 0-7.5 7.5M21 12H3"></path></svg></div></a></div></article></main><footer class="article footer article-grid bg-white dark:bg-slate-950 mt-10 shadow-2xl shadow py-10"><p>By Ani Adhikari and John DeNero and David Wagner</p><p><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>©</mtext></mrow><annotation encoding="application/x-tex">\copyright</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;"></span><span class="mord text"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8889em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">c</span></span></span><span style="top:-3.1944em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body accent-full" style="left:0em;top:.2em;"><span class="mord">◯</span></span></span></span></span></span></span></span></span></span></span></span> Copyright 2022.</p></footer><script>((a,d)=>{if(!window.history.state||!window.history.state.key){let h=Math.random().toString(32).slice(2);window.history.replaceState({key:h},"")}try{let f=JSON.parse(sessionStorage.getItem(a)||"{}")[d||window.history.state.key];typeof f=="number"&&window.scrollTo(0,f)}catch(h){console.error(h),sessionStorage.removeItem(a)}})("positions", null)</script><link rel="modulepreload" href="/build/entry.client-UNPC4GT3.js"/><link rel="modulepreload" href="/build/_shared/chunk-OCTKKCIL.js"/><link rel="modulepreload" href="/build/_shared/chunk-UAI5KRM7.js"/><link rel="modulepreload" href="/build/_shared/chunk-2NH4LW52.js"/><link rel="modulepreload" href="/build/_shared/chunk-F7G67JTZ.js"/><link rel="modulepreload" href="/build/_shared/chunk-HBJK6BW3.js"/><link rel="modulepreload" href="/build/_shared/chunk-HYMQ7M2K.js"/><link rel="modulepreload" href="/build/_shared/chunk-OHOXABTA.js"/><link rel="modulepreload" href="/build/_shared/chunk-OCWQY3HK.js"/><link rel="modulepreload" href="/build/_shared/chunk-CPTH56EW.js"/><link rel="modulepreload" href="/build/_shared/chunk-3CVK3PYF.js"/><link rel="modulepreload" href="/build/_shared/chunk-J6FHCSRC.js"/><link rel="modulepreload" href="/build/_shared/chunk-S4SWV34C.js"/><link rel="modulepreload" href="/build/_shared/chunk-GUCIBHGO.js"/><link rel="modulepreload" href="/build/root-7TUVC4ZT.js"/><link rel="modulepreload" href="/build/_shared/chunk-INOWNUZ6.js"/><link rel="modulepreload" href="/build/routes/$-P6PGXPYX.js"/><script>window.__remixContext = {"url":"/chapters/17/1/nearest-neighbors","state":{"loaderData":{"root":{"config":{"version":2,"myst":"1.6.4","options":{"favicon":"/build/favicon-d41e56db71ddfa209ecfc531bddb86f4.ico","logo":"/build/data8logo-7a6c5cd41fe4d513ca7e7f76d46e9670.png","logo_text":"Computational and Inferential Thinking","analytics_google":"UA-148221575-1","folders":true},"parts":{"footer":{"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"By Ani Adhikari and John DeNero and David Wagner","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"EAaIiCejDm"}],"key":"CJ6XGUzLDM"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"inlineMath","value":"\\copyright","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmtext\u003e©\u003c/mtext\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\copyright\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8889em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord accent\"\u003e\u003cspan class=\"vlist-t\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.8889em;\"\u003e\u003cspan style=\"top:-3em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord\"\u003ec\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.1944em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"accent-body accent-full\" style=\"left:0em;top:.2em;\"\u003e\u003cspan class=\"mord\"\u003e◯\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"iaDNEu5lBo"},{"type":"text","value":" Copyright 2022.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"vcEqeiyODd"}],"key":"msJMbQSF2X"}],"key":"bmiVDYl7ZN"}],"key":"P6Q2SWujj7"},"frontmatter":{"parts":{},"license":{"content":{"id":"CC-BY-NC-ND-4.0","url":"https://creativecommons.org/licenses/by-nc-nd/4.0/","name":"Creative Commons Attribution Non Commercial No Derivatives 4.0 International","CC":true}},"github":"https://github.com/data-8/textbook","numbering":{"title":{"enabled":true}},"source_url":"https://github.com/data-8/textbook/blob/main/footer.md","edit_url":"https://github.com/data-8/textbook/edit/main/footer.md","enumerator":"19"}}},"nav":[],"actions":[],"projects":[{"license":{"content":{"id":"CC-BY-NC-ND-4.0","url":"https://creativecommons.org/licenses/by-nc-nd/4.0/","name":"Creative Commons Attribution Non Commercial No Derivatives 4.0 International","CC":true}},"numbering":{"title":{"enabled":true}},"title":"Computational and Inferential Thinking","authors":[{"nameParsed":{"literal":"Ani Adhikari","given":"Ani","family":"Adhikari"},"name":"Ani Adhikari","id":"contributors-myst-generated-uid-0"},{"nameParsed":{"literal":"John DeNero","given":"John","family":"DeNero"},"name":"John DeNero","id":"contributors-myst-generated-uid-1"},{"nameParsed":{"literal":"David Wagner","given":"David","family":"Wagner"},"name":"David Wagner","id":"contributors-myst-generated-uid-2"}],"github":"https://github.com/data-8/textbook","toc":[{"file":"chapters/intro.md"},{"children":[{"children":[{"file":"chapters/01/1/1/computational-tools.md"},{"file":"chapters/01/1/2/statistical-techniques.md"}],"file":"chapters/01/1/intro.md"},{"file":"chapters/01/2/why-data-science.md"},{"children":[{"file":"chapters/01/3/1/Literary_Characters.ipynb"},{"file":"chapters/01/3/2/Another_Kind_Of_Character.ipynb"}],"file":"chapters/01/3/Plotting_the_Classics.ipynb"}],"file":"chapters/01/what-is-data-science.md"},{"children":[{"file":"chapters/02/1/observation-and-visualization-john-snow-and-the-broad-street-pump.md","title":"John Snow and the Broad Street Pump"},{"file":"chapters/02/2/snow-s-grand-experiment.md"},{"file":"chapters/02/3/establishing-causality.md"},{"file":"chapters/02/4/randomization.md"},{"file":"chapters/02/5/endnote.md"}],"file":"chapters/02/causality-and-experiments.md"},{"children":[{"file":"chapters/03/1/Expressions.ipynb"},{"children":[{"file":"chapters/03/2/1/Growth.ipynb"}],"file":"chapters/03/2/Names.ipynb"},{"file":"chapters/03/3/Calls.ipynb"},{"file":"chapters/03/4/Introduction_to_Tables.ipynb"}],"file":"chapters/03/programming-in-python.md"},{"children":[{"file":"chapters/04/1/Numbers.ipynb"},{"children":[{"file":"chapters/04/2/1/String_Methods.ipynb"}],"file":"chapters/04/2/Strings.ipynb"},{"file":"chapters/04/3/Comparison.ipynb"}],"file":"chapters/04/Data_Types.ipynb"},{"children":[{"file":"chapters/05/1/Arrays.ipynb"},{"file":"chapters/05/2/Ranges.ipynb"},{"file":"chapters/05/3/More_on_Arrays.ipynb"}],"file":"chapters/05/Sequences.ipynb"},{"children":[{"file":"chapters/06/1/Sorting_Rows.ipynb"},{"file":"chapters/06/2/Selecting_Rows.ipynb"},{"file":"chapters/06/3/Example_Population_Trends.ipynb"},{"file":"chapters/06/4/Example_Sex_Ratios.ipynb"}],"file":"chapters/06/Tables.ipynb"},{"children":[{"file":"chapters/07/1/Visualizing_Categorical_Distributions.ipynb"},{"file":"chapters/07/2/Visualizing_Numerical_Distributions.ipynb"},{"file":"chapters/07/3/Overlaid_Graphs.ipynb"}],"file":"chapters/07/Visualization.ipynb"},{"children":[{"file":"chapters/08/1/Applying_a_Function_to_a_Column.ipynb"},{"file":"chapters/08/2/Classifying_by_One_Variable.ipynb"},{"file":"chapters/08/3/Cross-Classifying_by_More_than_One_Variable.ipynb"},{"file":"chapters/08/4/Joining_Tables_by_Columns.ipynb"},{"file":"chapters/08/5/Bike_Sharing_in_the_Bay_Area.ipynb"}],"file":"chapters/08/Functions_and_Tables.ipynb"},{"children":[{"file":"chapters/09/1/Conditional_Statements.ipynb"},{"file":"chapters/09/2/Iteration.ipynb"},{"file":"chapters/09/3/Simulation.ipynb"},{"file":"chapters/09/4/Monty_Hall_Problem.ipynb"},{"file":"chapters/09/5/Finding_Probabilities.ipynb"}],"file":"chapters/09/Randomness.ipynb"},{"children":[{"file":"chapters/10/1/Empirical_Distributions.ipynb"},{"file":"chapters/10/2/Sampling_from_a_Population.ipynb"},{"file":"chapters/10/3/Empirical_Distribution_of_a_Statistic.ipynb"},{"file":"chapters/10/4/Random_Sampling_in_Python.ipynb"}],"file":"chapters/10/Sampling_and_Empirical_Distributions.ipynb"},{"children":[{"file":"chapters/11/1/Assessing_a_Model.ipynb"},{"file":"chapters/11/2/Multiple_Categories.ipynb"},{"file":"chapters/11/3/Decisions_and_Uncertainty.ipynb"},{"file":"chapters/11/4/Error_Probabilities.ipynb"}],"file":"chapters/11/Testing_Hypotheses.md"},{"children":[{"file":"chapters/12/1/AB_Testing.ipynb"},{"file":"chapters/12/2/Causality.ipynb"},{"file":"chapters/12/3/Deflategate.ipynb"}],"file":"chapters/12/Comparing_Two_Samples.md"},{"children":[{"file":"chapters/13/1/Percentiles.ipynb"},{"file":"chapters/13/2/Bootstrap.ipynb"},{"file":"chapters/13/3/Confidence_Intervals.ipynb"},{"file":"chapters/13/4/Using_Confidence_Intervals.ipynb"}],"file":"chapters/13/Estimation.md"},{"children":[{"file":"chapters/14/1/Properties_of_the_Mean.ipynb"},{"file":"chapters/14/2/Variability.ipynb"},{"file":"chapters/14/3/SD_and_the_Normal_Curve.ipynb"},{"file":"chapters/14/4/Central_Limit_Theorem.ipynb"},{"file":"chapters/14/5/Variability_of_the_Sample_Mean.ipynb"},{"file":"chapters/14/6/Choosing_a_Sample_Size.ipynb"}],"file":"chapters/14/Why_the_Mean_Matters.md"},{"children":[{"file":"chapters/15/1/Correlation.ipynb"},{"file":"chapters/15/2/Regression_Line.ipynb"},{"file":"chapters/15/3/Method_of_Least_Squares.ipynb"},{"file":"chapters/15/4/Least_Squares_Regression.ipynb"},{"file":"chapters/15/5/Visual_Diagnostics.ipynb"},{"file":"chapters/15/6/Numerical_Diagnostics.ipynb"}],"file":"chapters/15/Prediction.ipynb"},{"children":[{"file":"chapters/16/1/Regression_Model.ipynb"},{"file":"chapters/16/2/Inference_for_the_True_Slope.ipynb"},{"file":"chapters/16/3/Prediction_Intervals.ipynb"}],"file":"chapters/16/Inference_for_Regression.md"},{"children":[{"file":"chapters/17/1/Nearest_Neighbors.ipynb"},{"file":"chapters/17/2/Training_and_Testing.ipynb"},{"file":"chapters/17/3/Rows_of_Tables.ipynb"},{"file":"chapters/17/4/Implementing_the_Classifier.ipynb"},{"file":"chapters/17/5/Accuracy_of_the_Classifier.ipynb"},{"file":"chapters/17/6/Multiple_Regression.ipynb"}],"file":"chapters/17/Classification.md"},{"children":[{"file":"chapters/18/1/More_Likely_than_Not_Binary_Classifier.ipynb"},{"file":"chapters/18/2/Making_Decisions.ipynb"}],"file":"chapters/18/Updating_Predictions.md"}],"exports":[],"bibliography":[],"index":"index","pages":[{"slug":"chapters.01.what-is-data-science","title":"What is Data Science?","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"1"},{"slug":"chapters.01.1.intro","title":"Introduction","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.1"},{"slug":"chapters.01.1.1.computational-tools","title":"Computational Tools","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.1.1"},{"slug":"chapters.01.1.2.statistical-techniques","title":"Statistical Techniques","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.1.2"},{"slug":"chapters.01.2.why-data-science","title":"Why Data Science?","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.2"},{"slug":"chapters.01.3.plotting-the-classics","title":"Plotting the Classics","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.3"},{"slug":"chapters.01.3.1.literary-characters","title":"Literary Characters","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.3.1"},{"slug":"chapters.01.3.2.another-kind-of-character","title":"Another Kind of Character","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.3.2"},{"slug":"chapters.02.causality-and-experiments","title":"Causality and Experiments","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"2"},{"slug":"chapters.02.1.observation-and-visualization-john-snow-and-the-br","title":"Observation and Visualization: John Snow and the Broad Street Pump","description":"","date":"","thumbnail":"/build/snow_map-a559f894ec65aa589b5d612f39960c8a.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.1"},{"slug":"chapters.02.2.snow-s-grand-experiment","title":"Snow’s “Grand Experiment”","description":"","date":"","thumbnail":"/build/snow_map2-922ad2b5eb1e1af2875642e9371ff78c.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.2"},{"slug":"chapters.02.3.establishing-causality","title":"Establishing Causality","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.3"},{"slug":"chapters.02.4.randomization","title":"Randomization","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.4"},{"slug":"chapters.02.5.endnote","title":"Endnote","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.5"},{"slug":"chapters.03.programming-in-python","title":"Programming in Python","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"3"},{"slug":"chapters.03.1.expressions","title":"Expressions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.1"},{"slug":"chapters.03.2.names","title":"Names","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.2"},{"slug":"chapters.03.2.1.growth","title":"Example: Growth Rates","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"3.2.1"},{"slug":"chapters.03.3.calls","title":"Call Expressions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.3"},{"slug":"chapters.03.4.introduction-to-tables","title":"Introduction to Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.4"},{"slug":"chapters.04.data-types","title":"Data Types","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"4"},{"slug":"chapters.04.1.numbers","title":"Numbers","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.1"},{"slug":"chapters.04.2.strings","title":"Strings","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.2"},{"slug":"chapters.04.2.1.string-methods","title":"String Methods","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"4.2.1"},{"slug":"chapters.04.3.comparison","title":"Comparisons","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.3"},{"slug":"chapters.05.sequences","title":"Sequences","description":"","date":"","thumbnail":"/build/global-land-TMAX-Tre-f4e8046cb3617080ace7162f525d2fdc.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"5"},{"slug":"chapters.05.1.arrays","title":"Arrays","description":"","date":"","thumbnail":"/build/array_arithmetic-21903924b73cec9cb83b421db6b76ed0.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.1"},{"slug":"chapters.05.2.ranges","title":"Ranges","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.2"},{"slug":"chapters.05.3.more-on-arrays","title":"More on Arrays","description":"","date":"","thumbnail":"/build/array_subtraction-a6b41be681a21bc81ed05b4daddb13cd.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.3"},{"slug":"chapters.06.tables","title":"Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"6"},{"slug":"chapters.06.1.sorting-rows","title":"Sorting Rows","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.1"},{"slug":"chapters.06.2.selecting-rows","title":"Selecting Rows","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.2"},{"slug":"chapters.06.3.example-population-trends","title":"Example: Population Trends","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.3"},{"slug":"chapters.06.4.example-sex-ratios","title":"Example: Sex Ratios","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.4"},{"slug":"chapters.07.visualization","title":"Visualization","description":"","date":"","thumbnail":"/build/C-3PO_droid-1fa7c0f010e1bd61cb242418203ccbd9.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"7"},{"slug":"chapters.07.1.visualizing-categorical-distributions","title":"Visualizing Categorical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.1"},{"slug":"chapters.07.2.visualizing-numerical-distributions","title":"Visualizing Numerical Distributions","description":"","date":"","thumbnail":"/build/ipad_battery-eba4b70625634dc8a9b850a43c992c66.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.2"},{"slug":"chapters.07.3.overlaid-graphs","title":"Overlaid Graphs","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.3"},{"slug":"chapters.08.functions-and-tables","title":"Functions and Tables","description":"","date":"","thumbnail":"/build/function_definition-b6e0ca12a5cd8a62fb46784f45744396.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"8"},{"slug":"chapters.08.1.applying-a-function-to-a-column","title":"Applying a Function to a Column","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.1"},{"slug":"chapters.08.2.classifying-by-one-variable","title":"Classifying by One Variable","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.2"},{"slug":"chapters.08.3.cross-classifying-by-more-than-one-variable","title":"Cross-Classifying by More than One Variable","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.3"},{"slug":"chapters.08.4.joining-tables-by-columns","title":"Joining Tables by Columns","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.4"},{"slug":"chapters.08.5.bike-sharing-in-the-bay-area","title":"Bike Sharing in the Bay Area","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.5"},{"slug":"chapters.09.randomness","title":"Randomness","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"9"},{"slug":"chapters.09.1.conditional-statements","title":"Conditional Statements","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.1"},{"slug":"chapters.09.2.iteration","title":"Iteration","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.2"},{"slug":"chapters.09.3.simulation","title":"Simulation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.3"},{"slug":"chapters.09.4.monty-hall-problem","title":"The Monty Hall Problem","description":"","date":"","thumbnail":"/build/monty_hall_goat-b1899404d996b314b7ddc961406d0737.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.4"},{"slug":"chapters.09.5.finding-probabilities","title":"Finding Probabilities","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.5"},{"slug":"chapters.10.sampling-and-empirical-distributions","title":"Sampling and Empirical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"10"},{"slug":"chapters.10.1.empirical-distributions","title":"Empirical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.1"},{"slug":"chapters.10.2.sampling-from-a-population","title":"Sampling from a Population","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.2"},{"slug":"chapters.10.3.empirical-distribution-of-a-statistic","title":"Empirical Distribution of a Statistic","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.3"},{"slug":"chapters.10.4.random-sampling-in-python","title":"Random Sampling in Python","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.4"},{"slug":"chapters.11.testing-hypotheses","title":"Testing Hypotheses","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"11"},{"slug":"chapters.11.1.assessing-a-model","title":"Assessing a Model","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.1"},{"slug":"chapters.11.2.multiple-categories","title":"Multiple Categories","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.2"},{"slug":"chapters.11.3.decisions-and-uncertainty","title":"Decisions and Uncertainty","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.3"},{"slug":"chapters.11.4.error-probabilities","title":"Error Probabilities","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.4"},{"slug":"chapters.12.comparing-two-samples","title":"Comparing Two Samples","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"12"},{"slug":"chapters.12.1.ab-testing","title":"A/B Testing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.1"},{"slug":"chapters.12.2.causality","title":"Causality","description":"","date":"","thumbnail":"/build/causality1-c2b9dd21638c4113770df93b4a9da373.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.2"},{"slug":"chapters.12.3.deflategate","title":"Deflategate","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.3"},{"slug":"chapters.13.estimation","title":"Estimation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"13"},{"slug":"chapters.13.1.percentiles","title":"Percentiles","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.1"},{"slug":"chapters.13.2.bootstrap","title":"The Bootstrap","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.2"},{"slug":"chapters.13.3.confidence-intervals","title":"Confidence Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.3"},{"slug":"chapters.13.4.using-confidence-intervals","title":"Using Confidence Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.4"},{"slug":"chapters.14.why-the-mean-matters","title":"Why the Mean Matters","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"14"},{"slug":"chapters.14.1.properties-of-the-mean","title":"Properties of the Mean","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.1"},{"slug":"chapters.14.2.variability","title":"Variability","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.2"},{"slug":"chapters.14.3.sd-and-the-normal-curve","title":"The SD and the Normal Curve","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.3"},{"slug":"chapters.14.4.central-limit-theorem","title":"The Central Limit Theorem","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.4"},{"slug":"chapters.14.5.variability-of-the-sample-mean","title":"The Variability of the Sample Mean","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.5"},{"slug":"chapters.14.6.choosing-a-sample-size","title":"Choosing a Sample Size","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.6"},{"slug":"chapters.15.prediction","title":"Prediction","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"15"},{"slug":"chapters.15.1.correlation","title":"Correlation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.1"},{"slug":"chapters.15.2.regression-line","title":"The Regression Line","description":"","date":"","thumbnail":"/build/regline-7acefd1a1cb6046b7341e62942ed5611.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.2"},{"slug":"chapters.15.3.method-of-least-squares","title":"The Method of Least Squares","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.3"},{"slug":"chapters.15.4.least-squares-regression","title":"Least Squares Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.4"},{"slug":"chapters.15.5.visual-diagnostics","title":"Visual Diagnostics","description":"","date":"","thumbnail":"/build/5f819b0045c6e81a4265dd506d7aaff9.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.5"},{"slug":"chapters.15.6.numerical-diagnostics","title":"Numerical Diagnostics","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.6"},{"slug":"chapters.16.inference-for-regression","title":"Inference for Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"16"},{"slug":"chapters.16.1.regression-model","title":"A Regression Model","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.1"},{"slug":"chapters.16.2.inference-for-the-true-slope","title":"Inference for the True Slope","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.2"},{"slug":"chapters.16.3.prediction-intervals","title":"Prediction Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.3"},{"slug":"chapters.17.classification","title":"Classification","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"17"},{"slug":"chapters.17.1.nearest-neighbors","title":"Nearest Neighbors","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.1"},{"slug":"chapters.17.2.training-and-testing","title":"Training and Testing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.2"},{"slug":"chapters.17.3.rows-of-tables","title":"Rows of Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.3"},{"slug":"chapters.17.4.implementing-the-classifier","title":"Implementing the Classifier","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.4"},{"slug":"chapters.17.5.accuracy-of-the-classifier","title":"The Accuracy of the Classifier","description":"","date":"","thumbnail":"/build/5e548385d4da863b59d51148bd5d0eeb.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.5"},{"slug":"chapters.17.6.multiple-regression","title":"Multiple Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.6"},{"slug":"chapters.18.updating-predictions","title":"Updating Predictions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"18"},{"slug":"chapters.18.1.more-likely-than-not-binary-classifier","title":"A “More Likely Than Not” Binary Classifier","description":"","date":"","thumbnail":"/build/tree_students-c1d10705c5238230fc0243eb6ba2ea13.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"18.1"},{"slug":"chapters.18.2.making-decisions","title":"Making Decisions","description":"","date":"","thumbnail":"/build/tree_disease_rare-175fa2f39033e58ca8f1110413b91794.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"18.2"}]}]},"CONTENT_CDN_PORT":"3100","MODE":"static"},"routes/$":{"config":{"version":2,"myst":"1.6.4","options":{"favicon":"/build/favicon-d41e56db71ddfa209ecfc531bddb86f4.ico","logo":"/build/data8logo-7a6c5cd41fe4d513ca7e7f76d46e9670.png","logo_text":"Computational and Inferential Thinking","analytics_google":"UA-148221575-1","folders":true},"parts":{"footer":{"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"By Ani Adhikari and John DeNero and David Wagner","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"EAaIiCejDm"}],"key":"CJ6XGUzLDM"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"inlineMath","value":"\\copyright","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmtext\u003e©\u003c/mtext\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\copyright\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8889em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord accent\"\u003e\u003cspan class=\"vlist-t\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.8889em;\"\u003e\u003cspan style=\"top:-3em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord\"\u003ec\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.1944em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"accent-body accent-full\" style=\"left:0em;top:.2em;\"\u003e\u003cspan class=\"mord\"\u003e◯\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"iaDNEu5lBo"},{"type":"text","value":" Copyright 2022.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"vcEqeiyODd"}],"key":"msJMbQSF2X"}],"key":"bmiVDYl7ZN"}],"key":"P6Q2SWujj7"},"frontmatter":{"parts":{},"license":{"content":{"id":"CC-BY-NC-ND-4.0","url":"https://creativecommons.org/licenses/by-nc-nd/4.0/","name":"Creative Commons Attribution Non Commercial No Derivatives 4.0 International","CC":true}},"github":"https://github.com/data-8/textbook","numbering":{"title":{"enabled":true}},"source_url":"https://github.com/data-8/textbook/blob/main/footer.md","edit_url":"https://github.com/data-8/textbook/edit/main/footer.md","enumerator":"19"}}},"nav":[],"actions":[],"projects":[{"license":{"content":{"id":"CC-BY-NC-ND-4.0","url":"https://creativecommons.org/licenses/by-nc-nd/4.0/","name":"Creative Commons Attribution Non Commercial No Derivatives 4.0 International","CC":true}},"numbering":{"title":{"enabled":true}},"title":"Computational and Inferential Thinking","authors":[{"nameParsed":{"literal":"Ani Adhikari","given":"Ani","family":"Adhikari"},"name":"Ani Adhikari","id":"contributors-myst-generated-uid-0"},{"nameParsed":{"literal":"John DeNero","given":"John","family":"DeNero"},"name":"John DeNero","id":"contributors-myst-generated-uid-1"},{"nameParsed":{"literal":"David Wagner","given":"David","family":"Wagner"},"name":"David Wagner","id":"contributors-myst-generated-uid-2"}],"github":"https://github.com/data-8/textbook","toc":[{"file":"chapters/intro.md"},{"children":[{"children":[{"file":"chapters/01/1/1/computational-tools.md"},{"file":"chapters/01/1/2/statistical-techniques.md"}],"file":"chapters/01/1/intro.md"},{"file":"chapters/01/2/why-data-science.md"},{"children":[{"file":"chapters/01/3/1/Literary_Characters.ipynb"},{"file":"chapters/01/3/2/Another_Kind_Of_Character.ipynb"}],"file":"chapters/01/3/Plotting_the_Classics.ipynb"}],"file":"chapters/01/what-is-data-science.md"},{"children":[{"file":"chapters/02/1/observation-and-visualization-john-snow-and-the-broad-street-pump.md","title":"John Snow and the Broad Street Pump"},{"file":"chapters/02/2/snow-s-grand-experiment.md"},{"file":"chapters/02/3/establishing-causality.md"},{"file":"chapters/02/4/randomization.md"},{"file":"chapters/02/5/endnote.md"}],"file":"chapters/02/causality-and-experiments.md"},{"children":[{"file":"chapters/03/1/Expressions.ipynb"},{"children":[{"file":"chapters/03/2/1/Growth.ipynb"}],"file":"chapters/03/2/Names.ipynb"},{"file":"chapters/03/3/Calls.ipynb"},{"file":"chapters/03/4/Introduction_to_Tables.ipynb"}],"file":"chapters/03/programming-in-python.md"},{"children":[{"file":"chapters/04/1/Numbers.ipynb"},{"children":[{"file":"chapters/04/2/1/String_Methods.ipynb"}],"file":"chapters/04/2/Strings.ipynb"},{"file":"chapters/04/3/Comparison.ipynb"}],"file":"chapters/04/Data_Types.ipynb"},{"children":[{"file":"chapters/05/1/Arrays.ipynb"},{"file":"chapters/05/2/Ranges.ipynb"},{"file":"chapters/05/3/More_on_Arrays.ipynb"}],"file":"chapters/05/Sequences.ipynb"},{"children":[{"file":"chapters/06/1/Sorting_Rows.ipynb"},{"file":"chapters/06/2/Selecting_Rows.ipynb"},{"file":"chapters/06/3/Example_Population_Trends.ipynb"},{"file":"chapters/06/4/Example_Sex_Ratios.ipynb"}],"file":"chapters/06/Tables.ipynb"},{"children":[{"file":"chapters/07/1/Visualizing_Categorical_Distributions.ipynb"},{"file":"chapters/07/2/Visualizing_Numerical_Distributions.ipynb"},{"file":"chapters/07/3/Overlaid_Graphs.ipynb"}],"file":"chapters/07/Visualization.ipynb"},{"children":[{"file":"chapters/08/1/Applying_a_Function_to_a_Column.ipynb"},{"file":"chapters/08/2/Classifying_by_One_Variable.ipynb"},{"file":"chapters/08/3/Cross-Classifying_by_More_than_One_Variable.ipynb"},{"file":"chapters/08/4/Joining_Tables_by_Columns.ipynb"},{"file":"chapters/08/5/Bike_Sharing_in_the_Bay_Area.ipynb"}],"file":"chapters/08/Functions_and_Tables.ipynb"},{"children":[{"file":"chapters/09/1/Conditional_Statements.ipynb"},{"file":"chapters/09/2/Iteration.ipynb"},{"file":"chapters/09/3/Simulation.ipynb"},{"file":"chapters/09/4/Monty_Hall_Problem.ipynb"},{"file":"chapters/09/5/Finding_Probabilities.ipynb"}],"file":"chapters/09/Randomness.ipynb"},{"children":[{"file":"chapters/10/1/Empirical_Distributions.ipynb"},{"file":"chapters/10/2/Sampling_from_a_Population.ipynb"},{"file":"chapters/10/3/Empirical_Distribution_of_a_Statistic.ipynb"},{"file":"chapters/10/4/Random_Sampling_in_Python.ipynb"}],"file":"chapters/10/Sampling_and_Empirical_Distributions.ipynb"},{"children":[{"file":"chapters/11/1/Assessing_a_Model.ipynb"},{"file":"chapters/11/2/Multiple_Categories.ipynb"},{"file":"chapters/11/3/Decisions_and_Uncertainty.ipynb"},{"file":"chapters/11/4/Error_Probabilities.ipynb"}],"file":"chapters/11/Testing_Hypotheses.md"},{"children":[{"file":"chapters/12/1/AB_Testing.ipynb"},{"file":"chapters/12/2/Causality.ipynb"},{"file":"chapters/12/3/Deflategate.ipynb"}],"file":"chapters/12/Comparing_Two_Samples.md"},{"children":[{"file":"chapters/13/1/Percentiles.ipynb"},{"file":"chapters/13/2/Bootstrap.ipynb"},{"file":"chapters/13/3/Confidence_Intervals.ipynb"},{"file":"chapters/13/4/Using_Confidence_Intervals.ipynb"}],"file":"chapters/13/Estimation.md"},{"children":[{"file":"chapters/14/1/Properties_of_the_Mean.ipynb"},{"file":"chapters/14/2/Variability.ipynb"},{"file":"chapters/14/3/SD_and_the_Normal_Curve.ipynb"},{"file":"chapters/14/4/Central_Limit_Theorem.ipynb"},{"file":"chapters/14/5/Variability_of_the_Sample_Mean.ipynb"},{"file":"chapters/14/6/Choosing_a_Sample_Size.ipynb"}],"file":"chapters/14/Why_the_Mean_Matters.md"},{"children":[{"file":"chapters/15/1/Correlation.ipynb"},{"file":"chapters/15/2/Regression_Line.ipynb"},{"file":"chapters/15/3/Method_of_Least_Squares.ipynb"},{"file":"chapters/15/4/Least_Squares_Regression.ipynb"},{"file":"chapters/15/5/Visual_Diagnostics.ipynb"},{"file":"chapters/15/6/Numerical_Diagnostics.ipynb"}],"file":"chapters/15/Prediction.ipynb"},{"children":[{"file":"chapters/16/1/Regression_Model.ipynb"},{"file":"chapters/16/2/Inference_for_the_True_Slope.ipynb"},{"file":"chapters/16/3/Prediction_Intervals.ipynb"}],"file":"chapters/16/Inference_for_Regression.md"},{"children":[{"file":"chapters/17/1/Nearest_Neighbors.ipynb"},{"file":"chapters/17/2/Training_and_Testing.ipynb"},{"file":"chapters/17/3/Rows_of_Tables.ipynb"},{"file":"chapters/17/4/Implementing_the_Classifier.ipynb"},{"file":"chapters/17/5/Accuracy_of_the_Classifier.ipynb"},{"file":"chapters/17/6/Multiple_Regression.ipynb"}],"file":"chapters/17/Classification.md"},{"children":[{"file":"chapters/18/1/More_Likely_than_Not_Binary_Classifier.ipynb"},{"file":"chapters/18/2/Making_Decisions.ipynb"}],"file":"chapters/18/Updating_Predictions.md"}],"exports":[],"bibliography":[],"index":"index","pages":[{"slug":"chapters.01.what-is-data-science","title":"What is Data Science?","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"1"},{"slug":"chapters.01.1.intro","title":"Introduction","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.1"},{"slug":"chapters.01.1.1.computational-tools","title":"Computational Tools","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.1.1"},{"slug":"chapters.01.1.2.statistical-techniques","title":"Statistical Techniques","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.1.2"},{"slug":"chapters.01.2.why-data-science","title":"Why Data Science?","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.2"},{"slug":"chapters.01.3.plotting-the-classics","title":"Plotting the Classics","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.3"},{"slug":"chapters.01.3.1.literary-characters","title":"Literary Characters","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.3.1"},{"slug":"chapters.01.3.2.another-kind-of-character","title":"Another Kind of Character","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.3.2"},{"slug":"chapters.02.causality-and-experiments","title":"Causality and Experiments","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"2"},{"slug":"chapters.02.1.observation-and-visualization-john-snow-and-the-br","title":"Observation and Visualization: John Snow and the Broad Street Pump","description":"","date":"","thumbnail":"/build/snow_map-a559f894ec65aa589b5d612f39960c8a.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.1"},{"slug":"chapters.02.2.snow-s-grand-experiment","title":"Snow’s “Grand Experiment”","description":"","date":"","thumbnail":"/build/snow_map2-922ad2b5eb1e1af2875642e9371ff78c.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.2"},{"slug":"chapters.02.3.establishing-causality","title":"Establishing Causality","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.3"},{"slug":"chapters.02.4.randomization","title":"Randomization","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.4"},{"slug":"chapters.02.5.endnote","title":"Endnote","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.5"},{"slug":"chapters.03.programming-in-python","title":"Programming in Python","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"3"},{"slug":"chapters.03.1.expressions","title":"Expressions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.1"},{"slug":"chapters.03.2.names","title":"Names","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.2"},{"slug":"chapters.03.2.1.growth","title":"Example: Growth Rates","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"3.2.1"},{"slug":"chapters.03.3.calls","title":"Call Expressions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.3"},{"slug":"chapters.03.4.introduction-to-tables","title":"Introduction to Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.4"},{"slug":"chapters.04.data-types","title":"Data Types","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"4"},{"slug":"chapters.04.1.numbers","title":"Numbers","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.1"},{"slug":"chapters.04.2.strings","title":"Strings","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.2"},{"slug":"chapters.04.2.1.string-methods","title":"String Methods","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"4.2.1"},{"slug":"chapters.04.3.comparison","title":"Comparisons","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.3"},{"slug":"chapters.05.sequences","title":"Sequences","description":"","date":"","thumbnail":"/build/global-land-TMAX-Tre-f4e8046cb3617080ace7162f525d2fdc.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"5"},{"slug":"chapters.05.1.arrays","title":"Arrays","description":"","date":"","thumbnail":"/build/array_arithmetic-21903924b73cec9cb83b421db6b76ed0.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.1"},{"slug":"chapters.05.2.ranges","title":"Ranges","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.2"},{"slug":"chapters.05.3.more-on-arrays","title":"More on Arrays","description":"","date":"","thumbnail":"/build/array_subtraction-a6b41be681a21bc81ed05b4daddb13cd.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.3"},{"slug":"chapters.06.tables","title":"Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"6"},{"slug":"chapters.06.1.sorting-rows","title":"Sorting Rows","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.1"},{"slug":"chapters.06.2.selecting-rows","title":"Selecting Rows","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.2"},{"slug":"chapters.06.3.example-population-trends","title":"Example: Population Trends","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.3"},{"slug":"chapters.06.4.example-sex-ratios","title":"Example: Sex Ratios","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.4"},{"slug":"chapters.07.visualization","title":"Visualization","description":"","date":"","thumbnail":"/build/C-3PO_droid-1fa7c0f010e1bd61cb242418203ccbd9.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"7"},{"slug":"chapters.07.1.visualizing-categorical-distributions","title":"Visualizing Categorical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.1"},{"slug":"chapters.07.2.visualizing-numerical-distributions","title":"Visualizing Numerical Distributions","description":"","date":"","thumbnail":"/build/ipad_battery-eba4b70625634dc8a9b850a43c992c66.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.2"},{"slug":"chapters.07.3.overlaid-graphs","title":"Overlaid Graphs","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.3"},{"slug":"chapters.08.functions-and-tables","title":"Functions and Tables","description":"","date":"","thumbnail":"/build/function_definition-b6e0ca12a5cd8a62fb46784f45744396.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"8"},{"slug":"chapters.08.1.applying-a-function-to-a-column","title":"Applying a Function to a Column","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.1"},{"slug":"chapters.08.2.classifying-by-one-variable","title":"Classifying by One Variable","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.2"},{"slug":"chapters.08.3.cross-classifying-by-more-than-one-variable","title":"Cross-Classifying by More than One Variable","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.3"},{"slug":"chapters.08.4.joining-tables-by-columns","title":"Joining Tables by Columns","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.4"},{"slug":"chapters.08.5.bike-sharing-in-the-bay-area","title":"Bike Sharing in the Bay Area","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.5"},{"slug":"chapters.09.randomness","title":"Randomness","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"9"},{"slug":"chapters.09.1.conditional-statements","title":"Conditional Statements","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.1"},{"slug":"chapters.09.2.iteration","title":"Iteration","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.2"},{"slug":"chapters.09.3.simulation","title":"Simulation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.3"},{"slug":"chapters.09.4.monty-hall-problem","title":"The Monty Hall Problem","description":"","date":"","thumbnail":"/build/monty_hall_goat-b1899404d996b314b7ddc961406d0737.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.4"},{"slug":"chapters.09.5.finding-probabilities","title":"Finding Probabilities","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.5"},{"slug":"chapters.10.sampling-and-empirical-distributions","title":"Sampling and Empirical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"10"},{"slug":"chapters.10.1.empirical-distributions","title":"Empirical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.1"},{"slug":"chapters.10.2.sampling-from-a-population","title":"Sampling from a Population","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.2"},{"slug":"chapters.10.3.empirical-distribution-of-a-statistic","title":"Empirical Distribution of a Statistic","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.3"},{"slug":"chapters.10.4.random-sampling-in-python","title":"Random Sampling in Python","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.4"},{"slug":"chapters.11.testing-hypotheses","title":"Testing Hypotheses","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"11"},{"slug":"chapters.11.1.assessing-a-model","title":"Assessing a Model","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.1"},{"slug":"chapters.11.2.multiple-categories","title":"Multiple Categories","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.2"},{"slug":"chapters.11.3.decisions-and-uncertainty","title":"Decisions and Uncertainty","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.3"},{"slug":"chapters.11.4.error-probabilities","title":"Error Probabilities","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.4"},{"slug":"chapters.12.comparing-two-samples","title":"Comparing Two Samples","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"12"},{"slug":"chapters.12.1.ab-testing","title":"A/B Testing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.1"},{"slug":"chapters.12.2.causality","title":"Causality","description":"","date":"","thumbnail":"/build/causality1-c2b9dd21638c4113770df93b4a9da373.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.2"},{"slug":"chapters.12.3.deflategate","title":"Deflategate","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.3"},{"slug":"chapters.13.estimation","title":"Estimation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"13"},{"slug":"chapters.13.1.percentiles","title":"Percentiles","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.1"},{"slug":"chapters.13.2.bootstrap","title":"The Bootstrap","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.2"},{"slug":"chapters.13.3.confidence-intervals","title":"Confidence Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.3"},{"slug":"chapters.13.4.using-confidence-intervals","title":"Using Confidence Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.4"},{"slug":"chapters.14.why-the-mean-matters","title":"Why the Mean Matters","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"14"},{"slug":"chapters.14.1.properties-of-the-mean","title":"Properties of the Mean","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.1"},{"slug":"chapters.14.2.variability","title":"Variability","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.2"},{"slug":"chapters.14.3.sd-and-the-normal-curve","title":"The SD and the Normal Curve","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.3"},{"slug":"chapters.14.4.central-limit-theorem","title":"The Central Limit Theorem","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.4"},{"slug":"chapters.14.5.variability-of-the-sample-mean","title":"The Variability of the Sample Mean","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.5"},{"slug":"chapters.14.6.choosing-a-sample-size","title":"Choosing a Sample Size","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.6"},{"slug":"chapters.15.prediction","title":"Prediction","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"15"},{"slug":"chapters.15.1.correlation","title":"Correlation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.1"},{"slug":"chapters.15.2.regression-line","title":"The Regression Line","description":"","date":"","thumbnail":"/build/regline-7acefd1a1cb6046b7341e62942ed5611.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.2"},{"slug":"chapters.15.3.method-of-least-squares","title":"The Method of Least Squares","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.3"},{"slug":"chapters.15.4.least-squares-regression","title":"Least Squares Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.4"},{"slug":"chapters.15.5.visual-diagnostics","title":"Visual Diagnostics","description":"","date":"","thumbnail":"/build/5f819b0045c6e81a4265dd506d7aaff9.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.5"},{"slug":"chapters.15.6.numerical-diagnostics","title":"Numerical Diagnostics","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.6"},{"slug":"chapters.16.inference-for-regression","title":"Inference for Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"16"},{"slug":"chapters.16.1.regression-model","title":"A Regression Model","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.1"},{"slug":"chapters.16.2.inference-for-the-true-slope","title":"Inference for the True Slope","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.2"},{"slug":"chapters.16.3.prediction-intervals","title":"Prediction Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.3"},{"slug":"chapters.17.classification","title":"Classification","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"17"},{"slug":"chapters.17.1.nearest-neighbors","title":"Nearest Neighbors","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.1"},{"slug":"chapters.17.2.training-and-testing","title":"Training and Testing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.2"},{"slug":"chapters.17.3.rows-of-tables","title":"Rows of Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.3"},{"slug":"chapters.17.4.implementing-the-classifier","title":"Implementing the Classifier","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.4"},{"slug":"chapters.17.5.accuracy-of-the-classifier","title":"The Accuracy of the Classifier","description":"","date":"","thumbnail":"/build/5e548385d4da863b59d51148bd5d0eeb.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.5"},{"slug":"chapters.17.6.multiple-regression","title":"Multiple Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.6"},{"slug":"chapters.18.updating-predictions","title":"Updating Predictions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"18"},{"slug":"chapters.18.1.more-likely-than-not-binary-classifier","title":"A “More Likely Than Not” Binary Classifier","description":"","date":"","thumbnail":"/build/tree_students-c1d10705c5238230fc0243eb6ba2ea13.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"18.1"},{"slug":"chapters.18.2.making-decisions","title":"Making Decisions","description":"","date":"","thumbnail":"/build/tree_disease_rare-175fa2f39033e58ca8f1110413b91794.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"18.2"}]}]},"page":{"version":2,"kind":"Notebook","sha256":"f6a9a7ec4fffb2972fd200f0e61c9f2a6c6ffd15d0ea28488e06f301155450b8","slug":"chapters.17.1.nearest-neighbors","location":"/chapters/17/1/Nearest_Neighbors.ipynb","dependencies":[],"frontmatter":{"title":"Nearest Neighbors","content_includes_title":false,"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"license":{"content":{"id":"CC-BY-NC-ND-4.0","url":"https://creativecommons.org/licenses/by-nc-nd/4.0/","name":"Creative Commons Attribution Non Commercial No Derivatives 4.0 International","CC":true}},"github":"https://github.com/data-8/textbook","numbering":{"title":{"enabled":true,"offset":1}},"source_url":"https://github.com/data-8/textbook/blob/main/chapters/17/1/Nearest_Neighbors.ipynb","edit_url":"https://github.com/data-8/textbook/edit/main/chapters/17/1/Nearest_Neighbors.ipynb","enumerator":"17.1","exports":[{"format":"ipynb","filename":"Nearest_Neighbors.ipynb","url":"/build/Nearest_Neighbors-a44e5371fb20f930681feecad0cf88f8.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"In this section we’ll develop the ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"msUjL3eXTC"},{"type":"emphasis","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"nearest neighbor","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"rHt2frQr74"}],"key":"yLZYA5c5KM"},{"type":"text","value":" method of classification. Just focus on the ideas for now and don’t worry if some of the code is mysterious. Later in the chapter we’ll see how to organize our ideas into code that performs the classification.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"u80VSqLwx6"}],"key":"NtM3v4zrTI"}],"key":"XTuSqdN3tS"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"import matplotlib\n#matplotlib.use('Agg')\npath_data = '../../../assets/data/'\nfrom datascience import *\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport numpy as np\nimport math\nimport scipy.stats as stats\nplt.style.use('fivethirtyeight')","visibility":"remove","key":"OgJaSpGEpj"},{"type":"output","id":"2i6uXx86Bo74KBiYeamdu","data":[],"visibility":"show","key":"PiCtVsoTst"}],"visibility":"show","key":"yWDUci0Ui4"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"def standard_units(x):\n    return (x - np.mean(x))/np.std(x)","visibility":"remove","key":"n8n43EtnPe"},{"type":"output","id":"PbGpulJagmvx3sjHPdhJ6","data":[],"visibility":"show","key":"Z1EQqMJ5Xm"}],"visibility":"show","key":"luARiu6Jov"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"def distance(point1, point2):\n    \"\"\"The distance between two arrays of numbers.\"\"\"\n    return np.sqrt(np.sum((point1 - point2)**2))\n\ndef all_distances(training, point):\n    \"\"\"The distance between p (an array of numbers) and the numbers in row i of attribute_table.\"\"\"\n    attributes = training.drop('Class')\n    def distance_from_point(row):\n        return distance(point, np.array(row))\n    return attributes.apply(distance_from_point)\n\ndef table_with_distances(training, point):\n    \"\"\"A copy of the training table with the distance from each row to array p.\"\"\"\n    return training.with_column('Distance', all_distances(training, point))\n\ndef closest(training, point, k):\n    \"\"\"A table containing the k closest rows in the training table to array p.\"\"\"\n    with_dists = table_with_distances(training, point)\n    sorted_by_distance = with_dists.sort('Distance')\n    topk = sorted_by_distance.take(np.arange(k))\n    return topk\n\ndef majority(topkclasses):\n    \"\"\"1 if the majority of the \"Class\" column is 1s, and 0 otherwise.\"\"\"\n    ones = topkclasses.where('Class', are.equal_to(1)).num_rows\n    zeros = topkclasses.where('Class', are.equal_to(0)).num_rows\n    if ones \u003e zeros:\n        return 1\n    else:\n        return 0\n\ndef classify(training, p, k):\n    \"\"\"Classify an example with attributes p using k-nearest neighbor classification with the given training table.\"\"\"\n    closestk = closest(training, p, k)\n    topkclasses = closestk.select('Class')\n    return majority(topkclasses)","visibility":"remove","key":"JJlG7PSvqE"},{"type":"output","id":"z5rSdyPjJbqblHoVdRKKW","data":[],"visibility":"show","key":"UZkzB3vGZH"}],"visibility":"show","key":"Xx2tOCMPBB"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Chronic kidney disease","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"sp6VHu2lry"}],"identifier":"chronic-kidney-disease","label":"Chronic kidney disease","html_id":"chronic-kidney-disease","implicit":true,"key":"qSb1C444vi"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Let’s work through an example.  We’re going to work with a data set that was collected to help doctors diagnose chronic kidney disease (CKD).  Each row in the data set represents a single patient who was treated in the past and whose diagnosis is known.  For each patient, we have a bunch of measurements from a blood test.  We’d like to find which measurements are most useful for diagnosing CKD, and develop a way to classify future patients as “has CKD” or “doesn’t have CKD” based on their blood test results.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"jjCpUZPrbY"}],"key":"YOBPTYfqIW"}],"key":"TGGx6s29YU"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"ckd = Table.read_table(path_data + 'ckd.csv').relabeled('Blood Glucose Random', 'Glucose')\nckd","key":"rxZkKQhvZc"},{"type":"output","id":"TUeY8sfRWcE1srjZn27Ov","data":[{"output_type":"execute_result","execution_count":4,"metadata":{},"data":{"text/html":{"content":"\u003ctable border=\"1\" class=\"dataframe\"\u003e\n    \u003cthead\u003e\n        \u003ctr\u003e\n            \u003cth\u003eAge\u003c/th\u003e \u003cth\u003eBlood Pressure\u003c/th\u003e \u003cth\u003eSpecific Gravity\u003c/th\u003e \u003cth\u003eAlbumin\u003c/th\u003e \u003cth\u003eSugar\u003c/th\u003e \u003cth\u003eRed Blood Cells\u003c/th\u003e \u003cth\u003ePus Cell\u003c/th\u003e \u003cth\u003ePus Cell clumps\u003c/th\u003e \u003cth\u003eBacteria\u003c/th\u003e \u003cth\u003eGlucose\u003c/th\u003e \u003cth\u003eBlood Urea\u003c/th\u003e \u003cth\u003eSerum Creatinine\u003c/th\u003e \u003cth\u003eSodium\u003c/th\u003e \u003cth\u003ePotassium\u003c/th\u003e \u003cth\u003eHemoglobin\u003c/th\u003e \u003cth\u003ePacked Cell Volume\u003c/th\u003e \u003cth\u003eWhite Blood Cell Count\u003c/th\u003e \u003cth\u003eRed Blood Cell Count\u003c/th\u003e \u003cth\u003eHypertension\u003c/th\u003e \u003cth\u003eDiabetes Mellitus\u003c/th\u003e \u003cth\u003eCoronary Artery Disease\u003c/th\u003e \u003cth\u003eAppetite\u003c/th\u003e \u003cth\u003ePedal Edema\u003c/th\u003e \u003cth\u003eAnemia\u003c/th\u003e \u003cth\u003eClass\u003c/th\u003e\n        \u003c/tr\u003e\n    \u003c/thead\u003e\n    \u003ctbody\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e48  \u003c/td\u003e \u003ctd\u003e70            \u003c/td\u003e \u003ctd\u003e1.005           \u003c/td\u003e \u003ctd\u003e4      \u003c/td\u003e \u003ctd\u003e0    \u003c/td\u003e \u003ctd\u003enormal         \u003c/td\u003e \u003ctd\u003eabnormal\u003c/td\u003e \u003ctd\u003epresent        \u003c/td\u003e \u003ctd\u003enotpresent\u003c/td\u003e \u003ctd\u003e117    \u003c/td\u003e \u003ctd\u003e56        \u003c/td\u003e \u003ctd\u003e3.8             \u003c/td\u003e \u003ctd\u003e111   \u003c/td\u003e \u003ctd\u003e2.5      \u003c/td\u003e \u003ctd\u003e11.2      \u003c/td\u003e \u003ctd\u003e32                \u003c/td\u003e \u003ctd\u003e6700                  \u003c/td\u003e \u003ctd\u003e3.9                 \u003c/td\u003e \u003ctd\u003eyes         \u003c/td\u003e \u003ctd\u003eno               \u003c/td\u003e \u003ctd\u003eno                     \u003c/td\u003e \u003ctd\u003epoor    \u003c/td\u003e \u003ctd\u003eyes        \u003c/td\u003e \u003ctd\u003eyes   \u003c/td\u003e \u003ctd\u003e1    \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e53  \u003c/td\u003e \u003ctd\u003e90            \u003c/td\u003e \u003ctd\u003e1.02            \u003c/td\u003e \u003ctd\u003e2      \u003c/td\u003e \u003ctd\u003e0    \u003c/td\u003e \u003ctd\u003eabnormal       \u003c/td\u003e \u003ctd\u003eabnormal\u003c/td\u003e \u003ctd\u003epresent        \u003c/td\u003e \u003ctd\u003enotpresent\u003c/td\u003e \u003ctd\u003e70     \u003c/td\u003e \u003ctd\u003e107       \u003c/td\u003e \u003ctd\u003e7.2             \u003c/td\u003e \u003ctd\u003e114   \u003c/td\u003e \u003ctd\u003e3.7      \u003c/td\u003e \u003ctd\u003e9.5       \u003c/td\u003e \u003ctd\u003e29                \u003c/td\u003e \u003ctd\u003e12100                 \u003c/td\u003e \u003ctd\u003e3.7                 \u003c/td\u003e \u003ctd\u003eyes         \u003c/td\u003e \u003ctd\u003eyes              \u003c/td\u003e \u003ctd\u003eno                     \u003c/td\u003e \u003ctd\u003epoor    \u003c/td\u003e \u003ctd\u003eno         \u003c/td\u003e \u003ctd\u003eyes   \u003c/td\u003e \u003ctd\u003e1    \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e63  \u003c/td\u003e \u003ctd\u003e70            \u003c/td\u003e \u003ctd\u003e1.01            \u003c/td\u003e \u003ctd\u003e3      \u003c/td\u003e \u003ctd\u003e0    \u003c/td\u003e \u003ctd\u003eabnormal       \u003c/td\u003e \u003ctd\u003eabnormal\u003c/td\u003e \u003ctd\u003epresent        \u003c/td\u003e \u003ctd\u003enotpresent\u003c/td\u003e \u003ctd\u003e380    \u003c/td\u003e \u003ctd\u003e60        \u003c/td\u003e \u003ctd\u003e2.7             \u003c/td\u003e \u003ctd\u003e131   \u003c/td\u003e \u003ctd\u003e4.2      \u003c/td\u003e \u003ctd\u003e10.8      \u003c/td\u003e \u003ctd\u003e32                \u003c/td\u003e \u003ctd\u003e4500                  \u003c/td\u003e \u003ctd\u003e3.8                 \u003c/td\u003e \u003ctd\u003eyes         \u003c/td\u003e \u003ctd\u003eyes              \u003c/td\u003e \u003ctd\u003eno                     \u003c/td\u003e \u003ctd\u003epoor    \u003c/td\u003e \u003ctd\u003eyes        \u003c/td\u003e \u003ctd\u003eno    \u003c/td\u003e \u003ctd\u003e1    \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e68  \u003c/td\u003e \u003ctd\u003e80            \u003c/td\u003e \u003ctd\u003e1.01            \u003c/td\u003e \u003ctd\u003e3      \u003c/td\u003e \u003ctd\u003e2    \u003c/td\u003e \u003ctd\u003enormal         \u003c/td\u003e \u003ctd\u003eabnormal\u003c/td\u003e \u003ctd\u003epresent        \u003c/td\u003e \u003ctd\u003epresent   \u003c/td\u003e \u003ctd\u003e157    \u003c/td\u003e \u003ctd\u003e90        \u003c/td\u003e \u003ctd\u003e4.1             \u003c/td\u003e \u003ctd\u003e130   \u003c/td\u003e \u003ctd\u003e6.4      \u003c/td\u003e \u003ctd\u003e5.6       \u003c/td\u003e \u003ctd\u003e16                \u003c/td\u003e \u003ctd\u003e11000                 \u003c/td\u003e \u003ctd\u003e2.6                 \u003c/td\u003e \u003ctd\u003eyes         \u003c/td\u003e \u003ctd\u003eyes              \u003c/td\u003e \u003ctd\u003eyes                    \u003c/td\u003e \u003ctd\u003epoor    \u003c/td\u003e \u003ctd\u003eyes        \u003c/td\u003e \u003ctd\u003eno    \u003c/td\u003e \u003ctd\u003e1    \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e61  \u003c/td\u003e \u003ctd\u003e80            \u003c/td\u003e \u003ctd\u003e1.015           \u003c/td\u003e \u003ctd\u003e2      \u003c/td\u003e \u003ctd\u003e0    \u003c/td\u003e \u003ctd\u003eabnormal       \u003c/td\u003e \u003ctd\u003eabnormal\u003c/td\u003e \u003ctd\u003enotpresent     \u003c/td\u003e \u003ctd\u003enotpresent\u003c/td\u003e \u003ctd\u003e173    \u003c/td\u003e \u003ctd\u003e148       \u003c/td\u003e \u003ctd\u003e3.9             \u003c/td\u003e \u003ctd\u003e135   \u003c/td\u003e \u003ctd\u003e5.2      \u003c/td\u003e \u003ctd\u003e7.7       \u003c/td\u003e \u003ctd\u003e24                \u003c/td\u003e \u003ctd\u003e9200                  \u003c/td\u003e \u003ctd\u003e3.2                 \u003c/td\u003e \u003ctd\u003eyes         \u003c/td\u003e \u003ctd\u003eyes              \u003c/td\u003e \u003ctd\u003eyes                    \u003c/td\u003e \u003ctd\u003epoor    \u003c/td\u003e \u003ctd\u003eyes        \u003c/td\u003e \u003ctd\u003eyes   \u003c/td\u003e \u003ctd\u003e1    \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e48  \u003c/td\u003e \u003ctd\u003e80            \u003c/td\u003e \u003ctd\u003e1.025           \u003c/td\u003e \u003ctd\u003e4      \u003c/td\u003e \u003ctd\u003e0    \u003c/td\u003e \u003ctd\u003enormal         \u003c/td\u003e \u003ctd\u003eabnormal\u003c/td\u003e \u003ctd\u003enotpresent     \u003c/td\u003e \u003ctd\u003enotpresent\u003c/td\u003e \u003ctd\u003e95     \u003c/td\u003e \u003ctd\u003e163       \u003c/td\u003e \u003ctd\u003e7.7             \u003c/td\u003e \u003ctd\u003e136   \u003c/td\u003e \u003ctd\u003e3.8      \u003c/td\u003e \u003ctd\u003e9.8       \u003c/td\u003e \u003ctd\u003e32                \u003c/td\u003e \u003ctd\u003e6900                  \u003c/td\u003e \u003ctd\u003e3.4                 \u003c/td\u003e \u003ctd\u003eyes         \u003c/td\u003e \u003ctd\u003eno               \u003c/td\u003e \u003ctd\u003eno                     \u003c/td\u003e \u003ctd\u003egood    \u003c/td\u003e \u003ctd\u003eno         \u003c/td\u003e \u003ctd\u003eyes   \u003c/td\u003e \u003ctd\u003e1    \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e69  \u003c/td\u003e \u003ctd\u003e70            \u003c/td\u003e \u003ctd\u003e1.01            \u003c/td\u003e \u003ctd\u003e3      \u003c/td\u003e \u003ctd\u003e4    \u003c/td\u003e \u003ctd\u003enormal         \u003c/td\u003e \u003ctd\u003eabnormal\u003c/td\u003e \u003ctd\u003enotpresent     \u003c/td\u003e \u003ctd\u003enotpresent\u003c/td\u003e \u003ctd\u003e264    \u003c/td\u003e \u003ctd\u003e87        \u003c/td\u003e \u003ctd\u003e2.7             \u003c/td\u003e \u003ctd\u003e130   \u003c/td\u003e \u003ctd\u003e4        \u003c/td\u003e \u003ctd\u003e12.5      \u003c/td\u003e \u003ctd\u003e37                \u003c/td\u003e \u003ctd\u003e9600                  \u003c/td\u003e \u003ctd\u003e4.1                 \u003c/td\u003e \u003ctd\u003eyes         \u003c/td\u003e \u003ctd\u003eyes              \u003c/td\u003e \u003ctd\u003eyes                    \u003c/td\u003e \u003ctd\u003egood    \u003c/td\u003e \u003ctd\u003eyes        \u003c/td\u003e \u003ctd\u003eno    \u003c/td\u003e \u003ctd\u003e1    \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e73  \u003c/td\u003e \u003ctd\u003e70            \u003c/td\u003e \u003ctd\u003e1.005           \u003c/td\u003e \u003ctd\u003e0      \u003c/td\u003e \u003ctd\u003e0    \u003c/td\u003e \u003ctd\u003enormal         \u003c/td\u003e \u003ctd\u003enormal  \u003c/td\u003e \u003ctd\u003enotpresent     \u003c/td\u003e \u003ctd\u003enotpresent\u003c/td\u003e \u003ctd\u003e70     \u003c/td\u003e \u003ctd\u003e32        \u003c/td\u003e \u003ctd\u003e0.9             \u003c/td\u003e \u003ctd\u003e125   \u003c/td\u003e \u003ctd\u003e4        \u003c/td\u003e \u003ctd\u003e10        \u003c/td\u003e \u003ctd\u003e29                \u003c/td\u003e \u003ctd\u003e18900                 \u003c/td\u003e \u003ctd\u003e3.5                 \u003c/td\u003e \u003ctd\u003eyes         \u003c/td\u003e \u003ctd\u003eyes              \u003c/td\u003e \u003ctd\u003eno                     \u003c/td\u003e \u003ctd\u003egood    \u003c/td\u003e \u003ctd\u003eyes        \u003c/td\u003e \u003ctd\u003eno    \u003c/td\u003e \u003ctd\u003e1    \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e73  \u003c/td\u003e \u003ctd\u003e80            \u003c/td\u003e \u003ctd\u003e1.02            \u003c/td\u003e \u003ctd\u003e2      \u003c/td\u003e \u003ctd\u003e0    \u003c/td\u003e \u003ctd\u003eabnormal       \u003c/td\u003e \u003ctd\u003eabnormal\u003c/td\u003e \u003ctd\u003enotpresent     \u003c/td\u003e \u003ctd\u003enotpresent\u003c/td\u003e \u003ctd\u003e253    \u003c/td\u003e \u003ctd\u003e142       \u003c/td\u003e \u003ctd\u003e4.6             \u003c/td\u003e \u003ctd\u003e138   \u003c/td\u003e \u003ctd\u003e5.8      \u003c/td\u003e \u003ctd\u003e10.5      \u003c/td\u003e \u003ctd\u003e33                \u003c/td\u003e \u003ctd\u003e7200                  \u003c/td\u003e \u003ctd\u003e4.3                 \u003c/td\u003e \u003ctd\u003eyes         \u003c/td\u003e \u003ctd\u003eyes              \u003c/td\u003e \u003ctd\u003eyes                    \u003c/td\u003e \u003ctd\u003egood    \u003c/td\u003e \u003ctd\u003eno         \u003c/td\u003e \u003ctd\u003eno    \u003c/td\u003e \u003ctd\u003e1    \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e46  \u003c/td\u003e \u003ctd\u003e60            \u003c/td\u003e \u003ctd\u003e1.01            \u003c/td\u003e \u003ctd\u003e1      \u003c/td\u003e \u003ctd\u003e0    \u003c/td\u003e \u003ctd\u003enormal         \u003c/td\u003e \u003ctd\u003enormal  \u003c/td\u003e \u003ctd\u003enotpresent     \u003c/td\u003e \u003ctd\u003enotpresent\u003c/td\u003e \u003ctd\u003e163    \u003c/td\u003e \u003ctd\u003e92        \u003c/td\u003e \u003ctd\u003e3.3             \u003c/td\u003e \u003ctd\u003e141   \u003c/td\u003e \u003ctd\u003e4        \u003c/td\u003e \u003ctd\u003e9.8       \u003c/td\u003e \u003ctd\u003e28                \u003c/td\u003e \u003ctd\u003e14600                 \u003c/td\u003e \u003ctd\u003e3.2                 \u003c/td\u003e \u003ctd\u003eyes         \u003c/td\u003e \u003ctd\u003eyes              \u003c/td\u003e \u003ctd\u003eno                     \u003c/td\u003e \u003ctd\u003egood    \u003c/td\u003e \u003ctd\u003eno         \u003c/td\u003e \u003ctd\u003eno    \u003c/td\u003e \u003ctd\u003e1    \u003c/td\u003e\n        \u003c/tr\u003e\n    \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e... (148 rows omitted)\u003c/p\u003e","content_type":"text/html"},"text/plain":{"content":"Age  | Blood Pressure | Specific Gravity | Albumin | Sugar | Red Blood Cells | Pus Cell | Pus Cell clumps | Bacteria   | Glucose | Blood Urea | Serum Creatinine | Sodium | Potassium | Hemoglobin | Packed Cell Volume | White Blood Cell Count | Red Blood Cell Count | Hypertension | Diabetes Mellitus | Coronary Artery Disease | Appetite | Pedal Edema | Anemia | Class\n48   | 70             | 1.005            | 4       | 0     | normal          | abnormal | present         | notpresent | 117     | 56         | 3.8              | 111    | 2.5       | 11.2       | 32                 | 6700                   | 3.9                  | yes          | no                | no                      | poor     | yes         | yes    | 1\n53   | 90             | 1.02             | 2       | 0     | abnormal        | abnormal | present         | notpresent | 70      | 107        | 7.2              | 114    | 3.7       | 9.5        | 29                 | 12100                  | 3.7                  | yes          | yes               | no                      | poor     | no          | yes    | 1\n63   | 70             | 1.01             | 3       | 0     | abnormal        | abnormal | present         | notpresent | 380     | 60         | 2.7              | 131    | 4.2       | 10.8       | 32                 | 4500                   | 3.8                  | yes          | yes               | no                      | poor     | yes         | no     | 1\n68   | 80             | 1.01             | 3       | 2     | normal          | abnormal | present         | present    | 157     | 90         | 4.1              | 130    | 6.4       | 5.6        | 16                 | 11000                  | 2.6                  | yes          | yes               | yes                     | poor     | yes         | no     | 1\n61   | 80             | 1.015            | 2       | 0     | abnormal        | abnormal | notpresent      | notpresent | 173     | 148        | 3.9              | 135    | 5.2       | 7.7        | 24                 | 9200                   | 3.2                  | yes          | yes               | yes                     | poor     | yes         | yes    | 1\n48   | 80             | 1.025            | 4       | 0     | normal          | abnormal | notpresent      | notpresent | 95      | 163        | 7.7              | 136    | 3.8       | 9.8        | 32                 | 6900                   | 3.4                  | yes          | no                | no                      | good     | no          | yes    | 1\n69   | 70             | 1.01             | 3       | 4     | normal          | abnormal | notpresent      | notpresent | 264     | 87         | 2.7              | 130    | 4         | 12.5       | 37                 | 9600                   | 4.1                  | yes          | yes               | yes                     | good     | yes         | no     | 1\n73   | 70             | 1.005            | 0       | 0     | normal          | normal   | notpresent      | notpresent | 70      | 32         | 0.9              | 125    | 4         | 10         | 29                 | 18900                  | 3.5                  | yes          | yes               | no                      | good     | yes         | no     | 1\n73   | 80             | 1.02             | 2       | 0     | abnormal        | abnormal | notpresent      | notpresent | 253     | 142        | 4.6              | 138    | 5.8       | 10.5       | 33                 | 7200                   | 4.3                  | yes          | yes               | yes                     | good     | no          | no     | 1\n46   | 60             | 1.01             | 1       | 0     | normal          | normal   | notpresent      | notpresent | 163     | 92         | 3.3              | 141    | 4         | 9.8        | 28                 | 14600                  | 3.2                  | yes          | yes               | no                      | good     | no          | no     | 1\n... (148 rows omitted)","content_type":"text/plain"}}}],"key":"sM7DlCwNjL"}],"key":"zdukudY877"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Some of the variables are categorical (words like “abnormal”), and some quantitative. The quantitative variables all have different scales. We’re going to want to make comparisons and estimate distances, often by eye, so let’s select just a few of the variables and work in standard units. Then we won’t have to worry about the scale of each of the different variables.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"o74GamXPOR"}],"key":"lgOXOaVzy9"}],"key":"PDKJlwj97h"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"ckd = Table().with_columns(\n    'Hemoglobin', standard_units(ckd.column('Hemoglobin')),\n    'Glucose', standard_units(ckd.column('Glucose')),\n    'White Blood Cell Count', standard_units(ckd.column('White Blood Cell Count')),\n    'Class', ckd.column('Class')\n)","key":"G8LBfeOsCK"},{"type":"output","id":"2qAfvscaji-txwHvG1_tr","data":[],"key":"Oy0VkGqD4H"}],"key":"HNDLEmvWO7"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"ckd","key":"ozX6htxEH1"},{"type":"output","id":"ncL2IiPFC9GPWAUGdI46j","data":[{"output_type":"execute_result","execution_count":6,"metadata":{},"data":{"text/html":{"content":"\u003ctable border=\"1\" class=\"dataframe\"\u003e\n    \u003cthead\u003e\n        \u003ctr\u003e\n            \u003cth\u003eHemoglobin\u003c/th\u003e \u003cth\u003eGlucose\u003c/th\u003e \u003cth\u003eWhite Blood Cell Count\u003c/th\u003e \u003cth\u003eClass\u003c/th\u003e\n        \u003c/tr\u003e\n    \u003c/thead\u003e\n    \u003ctbody\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e-0.865744 \u003c/td\u003e \u003ctd\u003e-0.221549\u003c/td\u003e \u003ctd\u003e-0.569768             \u003c/td\u003e \u003ctd\u003e1    \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e-1.45745  \u003c/td\u003e \u003ctd\u003e-0.947597\u003c/td\u003e \u003ctd\u003e1.16268               \u003c/td\u003e \u003ctd\u003e1    \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e-1.00497  \u003c/td\u003e \u003ctd\u003e3.84123  \u003c/td\u003e \u003ctd\u003e-1.27558              \u003c/td\u003e \u003ctd\u003e1    \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e-2.81488  \u003c/td\u003e \u003ctd\u003e0.396364 \u003c/td\u003e \u003ctd\u003e0.809777              \u003c/td\u003e \u003ctd\u003e1    \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e-2.08395  \u003c/td\u003e \u003ctd\u003e0.643529 \u003c/td\u003e \u003ctd\u003e0.232293              \u003c/td\u003e \u003ctd\u003e1    \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e-1.35303  \u003c/td\u003e \u003ctd\u003e-0.561402\u003c/td\u003e \u003ctd\u003e-0.505603             \u003c/td\u003e \u003ctd\u003e1    \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e-0.413266 \u003c/td\u003e \u003ctd\u003e2.04928  \u003c/td\u003e \u003ctd\u003e0.360623              \u003c/td\u003e \u003ctd\u003e1    \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e-1.28342  \u003c/td\u003e \u003ctd\u003e-0.947597\u003c/td\u003e \u003ctd\u003e3.34429               \u003c/td\u003e \u003ctd\u003e1    \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e-1.10939  \u003c/td\u003e \u003ctd\u003e1.87936  \u003c/td\u003e \u003ctd\u003e-0.409356             \u003c/td\u003e \u003ctd\u003e1    \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e-1.35303  \u003c/td\u003e \u003ctd\u003e0.489051 \u003c/td\u003e \u003ctd\u003e1.96475               \u003c/td\u003e \u003ctd\u003e1    \u003c/td\u003e\n        \u003c/tr\u003e\n    \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e... (148 rows omitted)\u003c/p\u003e","content_type":"text/html"},"text/plain":{"content":"Hemoglobin | Glucose   | White Blood Cell Count | Class\n-0.865744  | -0.221549 | -0.569768              | 1\n-1.45745   | -0.947597 | 1.16268                | 1\n-1.00497   | 3.84123   | -1.27558               | 1\n-2.81488   | 0.396364  | 0.809777               | 1\n-2.08395   | 0.643529  | 0.232293               | 1\n-1.35303   | -0.561402 | -0.505603              | 1\n-0.413266  | 2.04928   | 0.360623               | 1\n-1.28342   | -0.947597 | 3.34429                | 1\n-1.10939   | 1.87936   | -0.409356              | 1\n-1.35303   | 0.489051  | 1.96475                | 1\n... (148 rows omitted)","content_type":"text/plain"}}}],"key":"AGAzgWWZTo"}],"key":"o0z4T6Fbyd"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Let’s look at two columns in particular: the hemoglobin level (in the patient’s blood), and the blood glucose level (at a random time in the day; without fasting specially for the blood test).","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"PZnoEcQfYA"}],"key":"HMeKbmmcBv"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"We’ll draw a scatter plot to visualize the relation between the two variables. Blue dots are patients with CKD; gold dots are patients without CKD.  What kind of medical test results seem to indicate CKD?","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"GJ5x9ZavZQ"}],"key":"G2HkcSj0kA"}],"key":"PbhmtUcrCj"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"color_table = Table().with_columns(\n    'Class', make_array(1, 0),\n    'Color', make_array('darkblue', 'gold')\n)\nckd = ckd.join('Class', color_table)","key":"Y1b2aRgYDu"},{"type":"output","id":"dlETkQKpV0tkF0wMS66Dt","data":[],"key":"tO6JaEjAWV"}],"key":"WkHEQ9jv5y"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"ckd.scatter('Hemoglobin', 'Glucose', group='Color')","key":"GQnSEzVq6c"},{"type":"output","id":"vHLo_Lo4MEZlcddw7fpyI","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"953f828d6abb1a12d3c40926ab449b5b","path":"/build/953f828d6abb1a12d3c40926ab449b5b.png"},"text/plain":{"content":"\u003cFigure size 360x360 with 1 Axes\u003e","content_type":"text/plain"}}}],"key":"LcoYbOvOjZ"}],"key":"iMLlxYS81i"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Suppose Alice is a new patient who is not in the data set.  If I tell you Alice’s hemoglobin level and blood glucose level, could you predict whether she has CKD?  It sure looks like it!  You can see a very clear pattern here: points in the lower-right tend to represent people who don’t have CKD, and the rest tend to be folks with CKD.  To a human, the pattern is obvious.  But how can we program a computer to automatically detect patterns such as this one?","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"KKP4jpz5ZQ"}],"key":"J139TUNrUZ"}],"key":"fsXoEIpGWn"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"A Nearest Neighbor Classifier","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Ne2zTVcZLF"}],"identifier":"a-nearest-neighbor-classifier","label":"A Nearest Neighbor Classifier","html_id":"a-nearest-neighbor-classifier","implicit":true,"key":"MypGW3R74C"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"There are lots of kinds of patterns one might look for, and lots of algorithms for classification.  But I’m going to tell you about one that turns out to be surprisingly effective.  It is called ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"QW45AToSKg"},{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"nearest neighbor classification","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"cZZp5im3IR"}],"key":"Jv5p5U3BXd"},{"type":"text","value":".  Here’s the idea.  If we have Alice’s hemoglobin and glucose numbers, we can put her somewhere on this scatterplot; the hemoglobin is her x-coordinate, and the glucose is her y-coordinate.  Now, to predict whether she has CKD or not, we find the nearest point in the scatterplot and check whether it is blue or gold; we predict that Alice should receive the same diagnosis as that patient.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"qNaZ9LmxcV"}],"key":"dd0oPIqzUF"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"In other words, to classify Alice as CKD or not, we find the patient in the training set who is “nearest” to Alice, and then use that patient’s diagnosis as our prediction for Alice.  The intuition is that if two points are near each other in the scatterplot, then the corresponding measurements are pretty similar, so we might expect them to receive the same diagnosis (more likely than not).  We don’t know Alice’s diagnosis, but we do know the diagnosis of all the patients in the training set, so we find the patient in the training set who is most similar to Alice, and use that patient’s diagnosis to predict Alice’s diagnosis.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"RMaoUSi0TZ"}],"key":"XiWxTcrnvR"}],"key":"ywvUPoBRVn"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"In the graph below, the red dot represents Alice. It is joined with a black line to the point that is nearest to it – its ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"FNf0iRjWrm"},{"type":"emphasis","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"nearest neighbor","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"TtyHmAPZZm"}],"key":"XLqUqcTnqO"},{"type":"text","value":" in the training set. The figure is drawn by a function called ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Nu4iIWrFNQ"},{"type":"inlineCode","value":"show_closest","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"RYYYdkkMQE"},{"type":"text","value":". It takes an array that represents the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"YfnOoxIa2Q"},{"type":"inlineMath","value":"x","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ex\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ex\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.4306em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ex\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"pO2p1rfEjR"},{"type":"text","value":" and ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"oGuQ9e0obk"},{"type":"inlineMath","value":"y","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ey\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ey\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003ey\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"PqD8kEZYwa"},{"type":"text","value":" coordinates of Alice’s point. Vary those to see how the closest point changes! Note especially when the closest point is blue and when it is gold.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"iaa8pnq6yt"}],"key":"Pb6ExRJI15"}],"key":"OlrFv8mAkP"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"def show_closest(point):\n    \"\"\"point = array([x,y]) \n    gives the coordinates of a new point\n    shown in red\"\"\"\n    \n    HemoGl = ckd.drop('White Blood Cell Count', 'Color')\n    t = closest(HemoGl, point, 1)\n    x_closest = t.row(0).item(1)\n    y_closest = t.row(0).item(2)\n    ckd.scatter('Hemoglobin', 'Glucose', group='Color')\n    plt.scatter(point.item(0), point.item(1), color='red', s=30)\n    plt.plot(make_array(point.item(0), x_closest), make_array(point.item(1), y_closest), color='k', lw=2);","visibility":"remove","key":"rf80aNEGXN"},{"type":"output","id":"wBROZLdF99_GQWlyKXu0B","data":[],"visibility":"show","key":"PmWfAQACnZ"}],"visibility":"show","key":"pXtaRgpTty"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# In this example, Alice's Hemoglobin attribute is 0 and her Glucose is 1.5.\nalice = make_array(0, 1.5)\nshow_closest(alice)","key":"GtUpcYgJ9e"},{"type":"output","id":"y7AbH3zxE2JBv6O8lQrG6","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"26f4729c2561e5bd5d3853aa7c622a1c","path":"/build/26f4729c2561e5bd5d3853aa7c622a1c.png"},"text/plain":{"content":"\u003cFigure size 360x360 with 1 Axes\u003e","content_type":"text/plain"}}}],"key":"dzFl3WHwzO"}],"key":"PJGtqdaU4S"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Thus our ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"NkT3WV1ssz"},{"type":"emphasis","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"nearest neighbor classifier","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"J43OjxReJc"}],"key":"QsHdgmh7Su"},{"type":"text","value":" works like this:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"zaONJVU7Z4"}],"key":"M230V0nu6W"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":2,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Find the point in the training set that is nearest to the new point.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"C39htcH8IP"}],"key":"dwgGcETUyY"}],"key":"PxJ1FYg5CA"},{"type":"listItem","spread":true,"position":{"start":{"line":3,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"If that nearest point is a “CKD” point, classify the new point as “CKD”. If the nearest point is a “not CKD” point, classify the new point as “not CKD”.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"d4HVBJPF1U"}],"key":"Tl05Rd8vEk"}],"key":"WoTR0zmE24"}],"key":"Tqkh8Bvnk1"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"The scatterplot suggests that this nearest neighbor classifier should be pretty accurate.  Points in the lower-right will tend to receive a “no CKD” diagnosis, as their nearest neighbor will be a gold point.  The rest of the points will tend to receive a “CKD” diagnosis, as their nearest neighbor will be a blue point.  So the nearest neighbor strategy seems to capture our intuition pretty well, for this example.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"GiOvPMTqcM"}],"key":"JoQB33iD08"}],"key":"mYlASi4yJt"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Decision boundary","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"XTDvuAiTDF"}],"identifier":"decision-boundary","label":"Decision boundary","html_id":"decision-boundary","implicit":true,"key":"AHkjVcGq6H"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Sometimes a helpful way to visualize a classifier is to map out the kinds of attributes where the classifier would predict ‘CKD’, and the kinds where it would predict ‘not CKD’.  We end up with some boundary between the two, where points on one side of the boundary will be classified ‘CKD’ and points on the other side will be classified ‘not CKD’.  This boundary is called the ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"NTuOrCWLp4"},{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"decision boundary","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"psBp3t15fE"}],"key":"KzaPKx0T4h"},{"type":"text","value":".  Each different classifier will have a different decision boundary; the decision boundary is just a way to visualize what criteria the classifier is using to classify points.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"QyzMUXV12H"}],"key":"PY0N23uJ6j"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"For example, suppose the coordinates of Alice’s point are (0, 1.5). Notice that the nearest neighbor is blue. Now try reducing the height (the ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"nqB91svhMn"},{"type":"inlineMath","value":"y","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ey\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ey\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003ey\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"zK5v4IqceF"},{"type":"text","value":"-coordinate) of the point. You’ll see that at around ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"Wgh4Xdrdaf"},{"type":"inlineMath","value":"y = 0.95","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ey\u003c/mi\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmn\u003e0.95\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ey = 0.95\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003ey\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e0.95\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"xZCF0YslXg"},{"type":"text","value":" the nearest neighbor turns from blue to gold.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"uU27nd9hni"}],"key":"sqIKb0AymH"}],"key":"YIib2COOSW"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"alice = make_array(0, 0.97)\nshow_closest(alice)","key":"oWsx0acc1P"},{"type":"output","id":"IFbclnaFBrZ-XPMf9urVM","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"d232a31ef0e4409260a0eeafe5d71864","path":"/build/d232a31ef0e4409260a0eeafe5d71864.png"},"text/plain":{"content":"\u003cFigure size 360x360 with 1 Axes\u003e","content_type":"text/plain"}}}],"key":"gNXMYfLXqn"}],"key":"j93etcUJ9M"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Here are hundreds of new unclassified points, all in red.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Jtlta1FSQE"}],"key":"exnHW4xfuJ"}],"key":"F0GbmMiZBB"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"x_array = make_array()\ny_array = make_array()\nfor x in np.arange(-2, 2.1, 0.1):\n    for y in np.arange(-2, 2.1, 0.1):\n        x_array = np.append(x_array, x)\n        y_array = np.append(y_array, y)\n        \ntest_grid = Table().with_columns(\n    'Hemoglobin', x_array,\n    'Glucose', y_array\n)","visibility":"remove","key":"Kdj2SRs3mI"},{"type":"output","id":"ONQc6uGPTrI-FjvFYFTqX","data":[],"visibility":"show","key":"EyihJIkrQv"}],"visibility":"show","key":"GOGvxr7FKC"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"test_grid.scatter('Hemoglobin', 'Glucose', color='red', alpha=0.4, s=30)\n\nplt.scatter(ckd.column('Hemoglobin'), ckd.column('Glucose'), c=ckd.column('Color'), edgecolor='k')\n\nplt.xlim(-2, 2)\nplt.ylim(-2, 2);","visibility":"remove","key":"qkP3xM50ac"},{"type":"output","id":"x55j4B7DcJtXgIxL_9J-T","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"9ded977b720879a2f45b1778823adf5a","path":"/build/9ded977b720879a2f45b1778823adf5a.png"},"text/plain":{"content":"\u003cFigure size 360x360 with 1 Axes\u003e","content_type":"text/plain"}}}],"visibility":"show","key":"Q1GiSlh8bd"}],"visibility":"show","key":"lo9AEPIBQr"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Each of the red points has a nearest neighbor in the training set (the same blue and gold points as before). For some red points you can easily tell whether the nearest neighbor is blue or gold. For others, it’s a little more tricky to make the decision by eye. Those are the points near the decision boundary.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"rlrBAmNcEt"}],"key":"JgrbiOMJnH"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"But the computer can easily determine the nearest neighbor of each point. So let’s get it to apply our nearest neighbor classifier to each of the red points:","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"sctG0pB4Cd"}],"key":"eOOiHgONTJ"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"For each red point, it must find the closest point in the training set; it must then change the color of the red point to become the color of the nearest neighbor.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"QLaG8oQsAI"}],"key":"Iy6e3NWvpv"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"The resulting graph shows which points will get classified as ‘CKD’ (all the blue ones), and which as ‘not CKD’ (all the gold ones).","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"SPrVdL3CZi"}],"key":"qIp6O8sbQO"}],"key":"IZFeVnT2sh"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"def classify_grid(training, test, k):\n    c = make_array()\n    for i in range(test.num_rows):\n        # Run the classifier on the ith patient in the test set\n        c = np.append(c, classify(training, make_array(test.row(i)), k))   \n    return c","visibility":"remove","key":"euFQUXkpjp"},{"type":"output","id":"RgfErAveWJJj4-TZZmvL9","data":[],"visibility":"show","key":"mFjW8DeKMd"}],"visibility":"show","key":"BEbV4aANOL"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"c = classify_grid(ckd.drop('White Blood Cell Count', 'Color'), test_grid, 1)","visibility":"remove","key":"uKOxSt5i3C"},{"type":"output","id":"hZ0GD_8aawjQJUew-PDYg","data":[],"visibility":"show","key":"wHwz1CvGuC"}],"visibility":"show","key":"IHvAHFPvSU"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"test_grid = test_grid.with_column('Class', c).join('Class', color_table)\ntest_grid.scatter('Hemoglobin', 'Glucose', group='Color', alpha=0.4, s=30)\n\nplt.scatter(ckd.column('Hemoglobin'), ckd.column('Glucose'), c=ckd.column('Color'), edgecolor='k')\n\nplt.xlim(-2, 2)\nplt.ylim(-2, 2);","visibility":"remove","key":"IFGzUqcbg3"},{"type":"output","id":"elAYacdW5J7DaIiSmwU2_","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"36ddf46aaa2cd26d26a5efa73fed21a9","path":"/build/36ddf46aaa2cd26d26a5efa73fed21a9.png"},"text/plain":{"content":"\u003cFigure size 360x360 with 1 Axes\u003e","content_type":"text/plain"}}}],"visibility":"show","key":"LbPdODdheX"}],"visibility":"show","key":"kzLOqwnjra"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The decision boundary is where the classifier switches from turning the red points blue to turning them gold.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Tczx89cX4t"}],"key":"d48cJ67niI"}],"key":"JCxFhAMkw9"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"k-Nearest Neighbors","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"xph8xyGMD0"}],"identifier":"k-nearest-neighbors","label":"k-Nearest Neighbors","html_id":"k-nearest-neighbors","implicit":true,"key":"evUQbahsOs"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"However, the separation between the two classes won’t always be quite so clean.  For instance, suppose that instead of hemoglobin levels we were to look at white blood cell count.  Look at what happens:","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"dc9Ryw0yqT"}],"key":"IhXU5KMVpi"}],"key":"uKijxrYrfa"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"ckd.scatter('White Blood Cell Count', 'Glucose', group='Color')","key":"vyMWV5gZy6"},{"type":"output","id":"rU72BCRSjcCszq7x_pGxi","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"06c787dc3c67c9e56ebcb425bd0f094d","path":"/build/06c787dc3c67c9e56ebcb425bd0f094d.png"},"text/plain":{"content":"\u003cFigure size 360x360 with 1 Axes\u003e","content_type":"text/plain"}}}],"key":"pjx1aEzp3g"}],"key":"DZD3V5cpsh"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"As you can see, non-CKD individuals are all clustered in the lower-left.  Most of the patients with CKD are above or to the right of that cluster... but not all.  There are some patients with CKD who are in the lower left of the above figure (as indicated by the handful of blue dots scattered among the gold cluster).  What this means is that you can’t tell for certain whether someone has CKD from just these two blood test measurements.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"SRYbnKQpRy"}],"key":"pTxL3cZ7Fc"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"If we are given Alice’s glucose level and white blood cell count, can we predict whether she has CKD?  Yes, we can make a prediction, but we shouldn’t expect it to be 100% accurate.  Intuitively, it seems like there’s a natural strategy for predicting: plot where Alice lands in the scatter plot; if she is in the lower-left, predict that she doesn’t have CKD, otherwise predict she has CKD.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"TrRjGHKVSt"}],"key":"erZrifeiCw"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"This isn’t perfect -- our predictions will sometimes be wrong.  (Take a minute and think it through: for which patients will it make a mistake?)  As the scatterplot above indicates, sometimes people with CKD have glucose and white blood cell levels that look identical to those of someone without CKD, so any classifier is inevitably going to make the wrong prediction for them.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"VKok5CyxZA"}],"key":"nfbuqHDVFt"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Can we automate this on a computer?  Well, the nearest neighbor classifier would be a reasonable choice here too.  Take a minute and think it through: how will its predictions compare to those from the intuitive strategy above?  When will they differ?","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"vaSok7zv4q"}],"key":"DkMOAu9Wps"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Its predictions will be pretty similar to our intuitive strategy, but occasionally it will make a different prediction.  In particular, if Alice’s blood test results happen to put her right near one of the blue dots in the lower-left, the intuitive strategy would predict ‘not CKD’, whereas the nearest neighbor classifier will predict ‘CKD’.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"L0Ur7LvXYh"}],"key":"uReRDQs3KT"},{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"There is a simple generalization of the nearest neighbor classifier that fixes this anomaly.  It is called the ","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"wEapXkGuHP"},{"type":"emphasis","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"k-nearest neighbor classifier","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"RgY7adsdUQ"}],"key":"phAysM5Whp"},{"type":"text","value":".  To predict Alice’s diagnosis, rather than looking at just the one neighbor closest to her, we can look at the 3 points that are closest to her, and use the diagnosis for each of those 3 points to predict Alice’s diagnosis.  In particular, we’ll use the majority value among those 3 diagnoses as our prediction for Alice’s diagnosis.  Of course, there’s nothing special about the number 3: we could use 4, or 5, or more.  (It’s often convenient to pick an odd number, so that we don’t have to deal with ties.)  In general, we pick a number ","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"G2x5U5zqeo"},{"type":"inlineMath","value":"k","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ek\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ek\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03148em;\"\u003ek\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"ZzLAcIPToz"},{"type":"text","value":", and our predicted diagnosis for Alice is based on the ","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"owmjZnMFCm"},{"type":"inlineMath","value":"k","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ek\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ek\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03148em;\"\u003ek\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"FrOe2dcT6X"},{"type":"text","value":" patients in the training set who are closest to Alice.  Intuitively, these are the ","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"Dcn72K3jp0"},{"type":"inlineMath","value":"k","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ek\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ek\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03148em;\"\u003ek\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"HyplpT6giq"},{"type":"text","value":" patients whose blood test results were most similar to Alice, so it seems reasonable to use their diagnoses to predict Alice’s diagnosis.","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"XcvEMRRkBR"}],"key":"aYZ63QSOqJ"},{"type":"paragraph","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"The ","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"Rmqh3tImmi"},{"type":"inlineMath","value":"k","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ek\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ek\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03148em;\"\u003ek\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"ZqvqZvANAo"},{"type":"text","value":"-nearest neighbor classifier will now behave just like our intuitive strategy above.","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"qL5DpbNpn1"}],"key":"BB1SRu8gk0"}],"key":"DIw4n157HL"}],"key":"VO8MhAnnyg"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"Classification","url":"/chapters/17/classification","group":"Computational and Inferential Thinking"},"next":{"title":"Training and Testing","url":"/chapters/17/2/training-and-testing","group":"Computational and Inferential Thinking"}}},"domain":"http://localhost:3000"},"project":{"license":{"content":{"id":"CC-BY-NC-ND-4.0","url":"https://creativecommons.org/licenses/by-nc-nd/4.0/","name":"Creative Commons Attribution Non Commercial No Derivatives 4.0 International","CC":true}},"numbering":{"title":{"enabled":true}},"title":"Computational and Inferential Thinking","authors":[{"nameParsed":{"literal":"Ani Adhikari","given":"Ani","family":"Adhikari"},"name":"Ani Adhikari","id":"contributors-myst-generated-uid-0"},{"nameParsed":{"literal":"John DeNero","given":"John","family":"DeNero"},"name":"John DeNero","id":"contributors-myst-generated-uid-1"},{"nameParsed":{"literal":"David Wagner","given":"David","family":"Wagner"},"name":"David Wagner","id":"contributors-myst-generated-uid-2"}],"github":"https://github.com/data-8/textbook","toc":[{"file":"chapters/intro.md"},{"children":[{"children":[{"file":"chapters/01/1/1/computational-tools.md"},{"file":"chapters/01/1/2/statistical-techniques.md"}],"file":"chapters/01/1/intro.md"},{"file":"chapters/01/2/why-data-science.md"},{"children":[{"file":"chapters/01/3/1/Literary_Characters.ipynb"},{"file":"chapters/01/3/2/Another_Kind_Of_Character.ipynb"}],"file":"chapters/01/3/Plotting_the_Classics.ipynb"}],"file":"chapters/01/what-is-data-science.md"},{"children":[{"file":"chapters/02/1/observation-and-visualization-john-snow-and-the-broad-street-pump.md","title":"John Snow and the Broad Street Pump"},{"file":"chapters/02/2/snow-s-grand-experiment.md"},{"file":"chapters/02/3/establishing-causality.md"},{"file":"chapters/02/4/randomization.md"},{"file":"chapters/02/5/endnote.md"}],"file":"chapters/02/causality-and-experiments.md"},{"children":[{"file":"chapters/03/1/Expressions.ipynb"},{"children":[{"file":"chapters/03/2/1/Growth.ipynb"}],"file":"chapters/03/2/Names.ipynb"},{"file":"chapters/03/3/Calls.ipynb"},{"file":"chapters/03/4/Introduction_to_Tables.ipynb"}],"file":"chapters/03/programming-in-python.md"},{"children":[{"file":"chapters/04/1/Numbers.ipynb"},{"children":[{"file":"chapters/04/2/1/String_Methods.ipynb"}],"file":"chapters/04/2/Strings.ipynb"},{"file":"chapters/04/3/Comparison.ipynb"}],"file":"chapters/04/Data_Types.ipynb"},{"children":[{"file":"chapters/05/1/Arrays.ipynb"},{"file":"chapters/05/2/Ranges.ipynb"},{"file":"chapters/05/3/More_on_Arrays.ipynb"}],"file":"chapters/05/Sequences.ipynb"},{"children":[{"file":"chapters/06/1/Sorting_Rows.ipynb"},{"file":"chapters/06/2/Selecting_Rows.ipynb"},{"file":"chapters/06/3/Example_Population_Trends.ipynb"},{"file":"chapters/06/4/Example_Sex_Ratios.ipynb"}],"file":"chapters/06/Tables.ipynb"},{"children":[{"file":"chapters/07/1/Visualizing_Categorical_Distributions.ipynb"},{"file":"chapters/07/2/Visualizing_Numerical_Distributions.ipynb"},{"file":"chapters/07/3/Overlaid_Graphs.ipynb"}],"file":"chapters/07/Visualization.ipynb"},{"children":[{"file":"chapters/08/1/Applying_a_Function_to_a_Column.ipynb"},{"file":"chapters/08/2/Classifying_by_One_Variable.ipynb"},{"file":"chapters/08/3/Cross-Classifying_by_More_than_One_Variable.ipynb"},{"file":"chapters/08/4/Joining_Tables_by_Columns.ipynb"},{"file":"chapters/08/5/Bike_Sharing_in_the_Bay_Area.ipynb"}],"file":"chapters/08/Functions_and_Tables.ipynb"},{"children":[{"file":"chapters/09/1/Conditional_Statements.ipynb"},{"file":"chapters/09/2/Iteration.ipynb"},{"file":"chapters/09/3/Simulation.ipynb"},{"file":"chapters/09/4/Monty_Hall_Problem.ipynb"},{"file":"chapters/09/5/Finding_Probabilities.ipynb"}],"file":"chapters/09/Randomness.ipynb"},{"children":[{"file":"chapters/10/1/Empirical_Distributions.ipynb"},{"file":"chapters/10/2/Sampling_from_a_Population.ipynb"},{"file":"chapters/10/3/Empirical_Distribution_of_a_Statistic.ipynb"},{"file":"chapters/10/4/Random_Sampling_in_Python.ipynb"}],"file":"chapters/10/Sampling_and_Empirical_Distributions.ipynb"},{"children":[{"file":"chapters/11/1/Assessing_a_Model.ipynb"},{"file":"chapters/11/2/Multiple_Categories.ipynb"},{"file":"chapters/11/3/Decisions_and_Uncertainty.ipynb"},{"file":"chapters/11/4/Error_Probabilities.ipynb"}],"file":"chapters/11/Testing_Hypotheses.md"},{"children":[{"file":"chapters/12/1/AB_Testing.ipynb"},{"file":"chapters/12/2/Causality.ipynb"},{"file":"chapters/12/3/Deflategate.ipynb"}],"file":"chapters/12/Comparing_Two_Samples.md"},{"children":[{"file":"chapters/13/1/Percentiles.ipynb"},{"file":"chapters/13/2/Bootstrap.ipynb"},{"file":"chapters/13/3/Confidence_Intervals.ipynb"},{"file":"chapters/13/4/Using_Confidence_Intervals.ipynb"}],"file":"chapters/13/Estimation.md"},{"children":[{"file":"chapters/14/1/Properties_of_the_Mean.ipynb"},{"file":"chapters/14/2/Variability.ipynb"},{"file":"chapters/14/3/SD_and_the_Normal_Curve.ipynb"},{"file":"chapters/14/4/Central_Limit_Theorem.ipynb"},{"file":"chapters/14/5/Variability_of_the_Sample_Mean.ipynb"},{"file":"chapters/14/6/Choosing_a_Sample_Size.ipynb"}],"file":"chapters/14/Why_the_Mean_Matters.md"},{"children":[{"file":"chapters/15/1/Correlation.ipynb"},{"file":"chapters/15/2/Regression_Line.ipynb"},{"file":"chapters/15/3/Method_of_Least_Squares.ipynb"},{"file":"chapters/15/4/Least_Squares_Regression.ipynb"},{"file":"chapters/15/5/Visual_Diagnostics.ipynb"},{"file":"chapters/15/6/Numerical_Diagnostics.ipynb"}],"file":"chapters/15/Prediction.ipynb"},{"children":[{"file":"chapters/16/1/Regression_Model.ipynb"},{"file":"chapters/16/2/Inference_for_the_True_Slope.ipynb"},{"file":"chapters/16/3/Prediction_Intervals.ipynb"}],"file":"chapters/16/Inference_for_Regression.md"},{"children":[{"file":"chapters/17/1/Nearest_Neighbors.ipynb"},{"file":"chapters/17/2/Training_and_Testing.ipynb"},{"file":"chapters/17/3/Rows_of_Tables.ipynb"},{"file":"chapters/17/4/Implementing_the_Classifier.ipynb"},{"file":"chapters/17/5/Accuracy_of_the_Classifier.ipynb"},{"file":"chapters/17/6/Multiple_Regression.ipynb"}],"file":"chapters/17/Classification.md"},{"children":[{"file":"chapters/18/1/More_Likely_than_Not_Binary_Classifier.ipynb"},{"file":"chapters/18/2/Making_Decisions.ipynb"}],"file":"chapters/18/Updating_Predictions.md"}],"exports":[],"bibliography":[],"index":"index","pages":[{"slug":"chapters.01.what-is-data-science","title":"What is Data Science?","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"1"},{"slug":"chapters.01.1.intro","title":"Introduction","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.1"},{"slug":"chapters.01.1.1.computational-tools","title":"Computational Tools","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.1.1"},{"slug":"chapters.01.1.2.statistical-techniques","title":"Statistical Techniques","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.1.2"},{"slug":"chapters.01.2.why-data-science","title":"Why Data Science?","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.2"},{"slug":"chapters.01.3.plotting-the-classics","title":"Plotting the Classics","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.3"},{"slug":"chapters.01.3.1.literary-characters","title":"Literary Characters","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.3.1"},{"slug":"chapters.01.3.2.another-kind-of-character","title":"Another Kind of Character","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.3.2"},{"slug":"chapters.02.causality-and-experiments","title":"Causality and Experiments","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"2"},{"slug":"chapters.02.1.observation-and-visualization-john-snow-and-the-br","title":"Observation and Visualization: John Snow and the Broad Street Pump","description":"","date":"","thumbnail":"/build/snow_map-a559f894ec65aa589b5d612f39960c8a.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.1"},{"slug":"chapters.02.2.snow-s-grand-experiment","title":"Snow’s “Grand Experiment”","description":"","date":"","thumbnail":"/build/snow_map2-922ad2b5eb1e1af2875642e9371ff78c.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.2"},{"slug":"chapters.02.3.establishing-causality","title":"Establishing Causality","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.3"},{"slug":"chapters.02.4.randomization","title":"Randomization","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.4"},{"slug":"chapters.02.5.endnote","title":"Endnote","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.5"},{"slug":"chapters.03.programming-in-python","title":"Programming in Python","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"3"},{"slug":"chapters.03.1.expressions","title":"Expressions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.1"},{"slug":"chapters.03.2.names","title":"Names","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.2"},{"slug":"chapters.03.2.1.growth","title":"Example: Growth Rates","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"3.2.1"},{"slug":"chapters.03.3.calls","title":"Call Expressions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.3"},{"slug":"chapters.03.4.introduction-to-tables","title":"Introduction to Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.4"},{"slug":"chapters.04.data-types","title":"Data Types","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"4"},{"slug":"chapters.04.1.numbers","title":"Numbers","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.1"},{"slug":"chapters.04.2.strings","title":"Strings","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.2"},{"slug":"chapters.04.2.1.string-methods","title":"String Methods","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"4.2.1"},{"slug":"chapters.04.3.comparison","title":"Comparisons","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.3"},{"slug":"chapters.05.sequences","title":"Sequences","description":"","date":"","thumbnail":"/build/global-land-TMAX-Tre-f4e8046cb3617080ace7162f525d2fdc.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"5"},{"slug":"chapters.05.1.arrays","title":"Arrays","description":"","date":"","thumbnail":"/build/array_arithmetic-21903924b73cec9cb83b421db6b76ed0.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.1"},{"slug":"chapters.05.2.ranges","title":"Ranges","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.2"},{"slug":"chapters.05.3.more-on-arrays","title":"More on Arrays","description":"","date":"","thumbnail":"/build/array_subtraction-a6b41be681a21bc81ed05b4daddb13cd.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.3"},{"slug":"chapters.06.tables","title":"Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"6"},{"slug":"chapters.06.1.sorting-rows","title":"Sorting Rows","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.1"},{"slug":"chapters.06.2.selecting-rows","title":"Selecting Rows","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.2"},{"slug":"chapters.06.3.example-population-trends","title":"Example: Population Trends","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.3"},{"slug":"chapters.06.4.example-sex-ratios","title":"Example: Sex Ratios","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.4"},{"slug":"chapters.07.visualization","title":"Visualization","description":"","date":"","thumbnail":"/build/C-3PO_droid-1fa7c0f010e1bd61cb242418203ccbd9.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"7"},{"slug":"chapters.07.1.visualizing-categorical-distributions","title":"Visualizing Categorical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.1"},{"slug":"chapters.07.2.visualizing-numerical-distributions","title":"Visualizing Numerical Distributions","description":"","date":"","thumbnail":"/build/ipad_battery-eba4b70625634dc8a9b850a43c992c66.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.2"},{"slug":"chapters.07.3.overlaid-graphs","title":"Overlaid Graphs","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.3"},{"slug":"chapters.08.functions-and-tables","title":"Functions and Tables","description":"","date":"","thumbnail":"/build/function_definition-b6e0ca12a5cd8a62fb46784f45744396.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"8"},{"slug":"chapters.08.1.applying-a-function-to-a-column","title":"Applying a Function to a Column","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.1"},{"slug":"chapters.08.2.classifying-by-one-variable","title":"Classifying by One Variable","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.2"},{"slug":"chapters.08.3.cross-classifying-by-more-than-one-variable","title":"Cross-Classifying by More than One Variable","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.3"},{"slug":"chapters.08.4.joining-tables-by-columns","title":"Joining Tables by Columns","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.4"},{"slug":"chapters.08.5.bike-sharing-in-the-bay-area","title":"Bike Sharing in the Bay Area","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.5"},{"slug":"chapters.09.randomness","title":"Randomness","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"9"},{"slug":"chapters.09.1.conditional-statements","title":"Conditional Statements","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.1"},{"slug":"chapters.09.2.iteration","title":"Iteration","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.2"},{"slug":"chapters.09.3.simulation","title":"Simulation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.3"},{"slug":"chapters.09.4.monty-hall-problem","title":"The Monty Hall Problem","description":"","date":"","thumbnail":"/build/monty_hall_goat-b1899404d996b314b7ddc961406d0737.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.4"},{"slug":"chapters.09.5.finding-probabilities","title":"Finding Probabilities","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.5"},{"slug":"chapters.10.sampling-and-empirical-distributions","title":"Sampling and Empirical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"10"},{"slug":"chapters.10.1.empirical-distributions","title":"Empirical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.1"},{"slug":"chapters.10.2.sampling-from-a-population","title":"Sampling from a Population","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.2"},{"slug":"chapters.10.3.empirical-distribution-of-a-statistic","title":"Empirical Distribution of a Statistic","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.3"},{"slug":"chapters.10.4.random-sampling-in-python","title":"Random Sampling in Python","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.4"},{"slug":"chapters.11.testing-hypotheses","title":"Testing Hypotheses","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"11"},{"slug":"chapters.11.1.assessing-a-model","title":"Assessing a Model","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.1"},{"slug":"chapters.11.2.multiple-categories","title":"Multiple Categories","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.2"},{"slug":"chapters.11.3.decisions-and-uncertainty","title":"Decisions and Uncertainty","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.3"},{"slug":"chapters.11.4.error-probabilities","title":"Error Probabilities","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.4"},{"slug":"chapters.12.comparing-two-samples","title":"Comparing Two Samples","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"12"},{"slug":"chapters.12.1.ab-testing","title":"A/B Testing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.1"},{"slug":"chapters.12.2.causality","title":"Causality","description":"","date":"","thumbnail":"/build/causality1-c2b9dd21638c4113770df93b4a9da373.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.2"},{"slug":"chapters.12.3.deflategate","title":"Deflategate","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.3"},{"slug":"chapters.13.estimation","title":"Estimation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"13"},{"slug":"chapters.13.1.percentiles","title":"Percentiles","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.1"},{"slug":"chapters.13.2.bootstrap","title":"The Bootstrap","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.2"},{"slug":"chapters.13.3.confidence-intervals","title":"Confidence Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.3"},{"slug":"chapters.13.4.using-confidence-intervals","title":"Using Confidence Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.4"},{"slug":"chapters.14.why-the-mean-matters","title":"Why the Mean Matters","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"14"},{"slug":"chapters.14.1.properties-of-the-mean","title":"Properties of the Mean","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.1"},{"slug":"chapters.14.2.variability","title":"Variability","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.2"},{"slug":"chapters.14.3.sd-and-the-normal-curve","title":"The SD and the Normal Curve","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.3"},{"slug":"chapters.14.4.central-limit-theorem","title":"The Central Limit Theorem","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.4"},{"slug":"chapters.14.5.variability-of-the-sample-mean","title":"The Variability of the Sample Mean","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.5"},{"slug":"chapters.14.6.choosing-a-sample-size","title":"Choosing a Sample Size","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.6"},{"slug":"chapters.15.prediction","title":"Prediction","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"15"},{"slug":"chapters.15.1.correlation","title":"Correlation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.1"},{"slug":"chapters.15.2.regression-line","title":"The Regression Line","description":"","date":"","thumbnail":"/build/regline-7acefd1a1cb6046b7341e62942ed5611.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.2"},{"slug":"chapters.15.3.method-of-least-squares","title":"The Method of Least Squares","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.3"},{"slug":"chapters.15.4.least-squares-regression","title":"Least Squares Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.4"},{"slug":"chapters.15.5.visual-diagnostics","title":"Visual Diagnostics","description":"","date":"","thumbnail":"/build/5f819b0045c6e81a4265dd506d7aaff9.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.5"},{"slug":"chapters.15.6.numerical-diagnostics","title":"Numerical Diagnostics","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.6"},{"slug":"chapters.16.inference-for-regression","title":"Inference for Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"16"},{"slug":"chapters.16.1.regression-model","title":"A Regression Model","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.1"},{"slug":"chapters.16.2.inference-for-the-true-slope","title":"Inference for the True Slope","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.2"},{"slug":"chapters.16.3.prediction-intervals","title":"Prediction Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.3"},{"slug":"chapters.17.classification","title":"Classification","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"17"},{"slug":"chapters.17.1.nearest-neighbors","title":"Nearest Neighbors","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.1"},{"slug":"chapters.17.2.training-and-testing","title":"Training and Testing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.2"},{"slug":"chapters.17.3.rows-of-tables","title":"Rows of Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.3"},{"slug":"chapters.17.4.implementing-the-classifier","title":"Implementing the Classifier","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.4"},{"slug":"chapters.17.5.accuracy-of-the-classifier","title":"The Accuracy of the Classifier","description":"","date":"","thumbnail":"/build/5e548385d4da863b59d51148bd5d0eeb.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.5"},{"slug":"chapters.17.6.multiple-regression","title":"Multiple Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.6"},{"slug":"chapters.18.updating-predictions","title":"Updating Predictions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"18"},{"slug":"chapters.18.1.more-likely-than-not-binary-classifier","title":"A “More Likely Than Not” Binary Classifier","description":"","date":"","thumbnail":"/build/tree_students-c1d10705c5238230fc0243eb6ba2ea13.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"18.1"},{"slug":"chapters.18.2.making-decisions","title":"Making Decisions","description":"","date":"","thumbnail":"/build/tree_disease_rare-175fa2f39033e58ca8f1110413b91794.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"18.2"}]}}},"actionData":null,"errors":null},"future":{"unstable_dev":false,"unstable_postcss":false,"unstable_tailwind":false,"v2_errorBoundary":true,"v2_headers":true,"v2_meta":true,"v2_normalizeFormMethod":true,"v2_routeConvention":true}};</script><script type="module" async="">import "/build/manifest-3481E987.js";
import * as route0 from "/build/root-7TUVC4ZT.js";
import * as route1 from "/build/routes/$-P6PGXPYX.js";
window.__remixRouteModules = {"root":route0,"routes/$":route1};

import("/build/entry.client-UNPC4GT3.js");</script></body></html>