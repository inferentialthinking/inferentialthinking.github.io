
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>17.1. Nearest Neighbors &#8212; Computational and Inferential Thinking</title>
    
  <link rel="stylesheet" href="../../../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/sphinx-book-theme.e7340bb3dbd8dde6db86f25597f54a1b.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/book.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/togglebutton.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/sphinx-book-theme.7d483ff0a819d6edff12ce0b1ead3928.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="canonical" href="https://inferentialthinking.org/chapters/17/1/Nearest_Neighbors.html" />
    <link rel="shortcut icon" href="../../../_static/favicon.png"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="17.2. Training and Testing" href="../2/Training_and_Testing.html" />
    <link rel="prev" title="17. Classification" href="../Classification.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />


<!-- Opengraph tags -->
<meta property="og:url"         content="https://inferentialthinking.org/chapters/17/1/Nearest_Neighbors.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="Nearest Neighbors" />
<meta property="og:description" content="Nearest Neighbors  In this section we’ll develop the nearest neighbor method of classification. Just focus on the ideas for now and don’t worry if some of the c" />
<meta property="og:image"       content="https://inferentialthinking.org/_static/favicon.png" />

<meta name="twitter:card" content="summary" />


  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../../index.html">
  
  <img src="../../../_static/favicon.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Computational and Inferential Thinking</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="current nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../01/what-is-data-science.html">
   1. Data Science
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2 collapsible-parent">
    <a class="reference internal" href="../../01/1/intro.html">
     1.1. Introduction
    </a>
    <ul class="collapse-ul">
     <li class="toctree-l3">
      <a class="reference internal" href="../../01/1/1/computational-tools.html">
       1.1.1. Computational Tools
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../01/1/2/statistical-techniques.html">
       1.1.2. Statistical Techniques
      </a>
     </li>
    </ul>
    <i class="fas fa-chevron-down">
    </i>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../01/2/why-data-science.html">
     1.2. Why Data Science?
    </a>
   </li>
   <li class="toctree-l2 collapsible-parent">
    <a class="reference internal" href="../../01/3/Plotting_the_Classics.html">
     1.3. Plotting the Classics
    </a>
    <ul class="collapse-ul">
     <li class="toctree-l3">
      <a class="reference internal" href="../../01/3/1/Literary_Characters.html">
       1.3.1. Literary Characters
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../01/3/2/Another_Kind_Of_Character.html">
       1.3.2. Another Kind of Character
      </a>
     </li>
    </ul>
    <i class="fas fa-chevron-down">
    </i>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../02/causality-and-experiments.html">
   2. Causality and Experiments
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../02/1/observation-and-visualization-john-snow-and-the-broad-street-pump.html">
     2.1. John Snow and the Broad Street Pump
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../02/2/snow-s-grand-experiment.html">
     2.2. Snow’s “Grand Experiment”
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../02/3/establishing-causality.html">
     2.3. Establishing Causality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../02/4/randomization.html">
     2.4. Randomization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../02/5/endnote.html">
     2.5. Endnote
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../03/programming-in-python.html">
   3. Programming in Python
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../03/1/Expressions.html">
     3.1. Expressions
    </a>
   </li>
   <li class="toctree-l2 collapsible-parent">
    <a class="reference internal" href="../../03/2/Names.html">
     3.2. Names
    </a>
    <ul class="collapse-ul">
     <li class="toctree-l3">
      <a class="reference internal" href="../../03/2/1/Growth.html">
       3.2.1. Example: Growth Rates
      </a>
     </li>
    </ul>
    <i class="fas fa-chevron-down">
    </i>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../03/3/Calls.html">
     3.3. Call Expressions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../03/4/Introduction_to_Tables.html">
     3.4. Introduction to Tables
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../04/Data_Types.html">
   4. Data Types
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../04/1/Numbers.html">
     4.1. Numbers
    </a>
   </li>
   <li class="toctree-l2 collapsible-parent">
    <a class="reference internal" href="../../04/2/Strings.html">
     4.2. Strings
    </a>
    <ul class="collapse-ul">
     <li class="toctree-l3">
      <a class="reference internal" href="../../04/2/1/String_Methods.html">
       4.2.1. String Methods
      </a>
     </li>
    </ul>
    <i class="fas fa-chevron-down">
    </i>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../04/3/Comparison.html">
     4.3. Comparisons
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../05/Sequences.html">
   5. Sequences
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../05/1/Arrays.html">
     5.1. Arrays
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../05/2/Ranges.html">
     5.2. Ranges
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../05/3/More_on_Arrays.html">
     5.3. More on Arrays
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../06/Tables.html">
   6. Tables
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../06/1/Sorting_Rows.html">
     6.1. Sorting Rows
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../06/2/Selecting_Rows.html">
     6.2. Selecting Rows
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../06/3/Example_Trends_in_the_Population_of_the_United_States.html">
     6.3. Example: Population Trends
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../06/4/Example_Gender_Ratio_in_the_US_Population.html">
     6.4. Example: Trends in Gender
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../07/Visualization.html">
   7. Visualization
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../07/1/Visualizing_Categorical_Distributions.html">
     7.1. Categorical Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../07/2/Visualizing_Numerical_Distributions.html">
     7.2. Numerical Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../07/3/Overlaid_Graphs.html">
     7.3. Overlaid Graphs
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../08/Functions_and_Tables.html">
   8. Functions and Tables
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../08/1/Applying_a_Function_to_a_Column.html">
     8.1. Applying Functions to Columns
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../08/2/Classifying_by_One_Variable.html">
     8.2. Classifying by One Variable
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../08/3/Cross-Classifying_by_More_than_One_Variable.html">
     8.3. Cross-Classifying
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../08/4/Joining_Tables_by_Columns.html">
     8.4. Joining Tables by Columns
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../08/5/Bike_Sharing_in_the_Bay_Area.html">
     8.5. Bike Sharing in the Bay Area
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../09/Randomness.html">
   9. Randomness
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../09/1/Conditional_Statements.html">
     9.1. Conditional Statements
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../09/2/Iteration.html">
     9.2. Iteration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../09/3/Simulation.html">
     9.3. Simulation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../09/4/Monty_Hall_Problem.html">
     9.4. The Monty Hall Problem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../09/5/Finding_Probabilities.html">
     9.5. Finding Probabilities
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../10/Sampling_and_Empirical_Distributions.html">
   10. Sampling and Empirical Distributions
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../10/1/Empirical_Distributions.html">
     10.1. Empirical Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../10/2/Sampling_from_a_Population.html">
     10.2. Sampling from a Population
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../10/3/Empirical_Distribution_of_a_Statistic.html">
     10.3. Empirical Distibution of a Statistic
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../11/Testing_Hypotheses.html">
   11. Testing Hypotheses
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../11/1/Assessing_Models.html">
     11.1. Assessing Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../11/2/Multiple_Categories.html">
     11.2. Multiple Categories
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../11/3/Decisions_and_Uncertainty.html">
     11.3. Decisions and Uncertainty
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../11/4/Error_Probabilities.html">
     11.4. Error Probabilities
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../12/Comparing_Two_Samples.html">
   12. Comparing Two Samples
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../12/1/AB_Testing.html">
     12.1. A/B Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../12/2/Deflategate.html">
     12.2. Deflategate
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../12/3/Causality.html">
     12.3. Causality
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../13/Estimation.html">
   13. Estimation
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../13/1/Percentiles.html">
     13.1. Percentiles
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../13/2/Bootstrap.html">
     13.2. The Bootstrap
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../13/3/Confidence_Intervals.html">
     13.3. Confidence Intervals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../13/4/Using_Confidence_Intervals.html">
     13.4. Using Confidence Intervals
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../14/Why_the_Mean_Matters.html">
   14. Why the Mean Matters
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../14/1/Properties_of_the_Mean.html">
     14.1. Properties of the Mean
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../14/2/Variability.html">
     14.2. Variability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../14/3/SD_and_the_Normal_Curve.html">
     14.3. The SD and the Normal Curve
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../14/4/Central_Limit_Theorem.html">
     14.4. The Central Limit Theorem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../14/5/Variability_of_the_Sample_Mean.html">
     14.5. The Variability of the Sample Mean
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../14/6/Choosing_a_Sample_Size.html">
     14.6. Choosing a Sample Size
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../15/Prediction.html">
   15. Prediction
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../15/1/Correlation.html">
     15.1. Correlation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../15/2/Regression_Line.html">
     15.2. The Regression Line
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../15/3/Method_of_Least_Squares.html">
     15.3. The Method of Least Squares
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../15/4/Least_Squares_Regression.html">
     15.4. Least Squares Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../15/5/Visual_Diagnostics.html">
     15.5. Visual Diagnostics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../15/6/Numerical_Diagnostics.html">
     15.6. Numerical Diagnostics
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../16/Inference_for_Regression.html">
   16. Inference for Regression
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../16/1/Regression_Model.html">
     16.1. A Regression Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../16/2/Inference_for_the_True_Slope.html">
     16.2. Inference for the True Slope
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../16/3/Prediction_Intervals.html">
     16.3. Prediction Intervals
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="../Classification.html">
   17. Classification
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     17.1. Nearest Neighbors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2/Training_and_Testing.html">
     17.2. Training and Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3/Rows_of_Tables.html">
     17.3. Rows of Tables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4/Implementing_the_Classifier.html">
     17.4. Implementing the Classifier
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../5/Accuracy_of_the_Classifier.html">
     17.5. The Accuracy of the Classifier
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6/Multiple_Regression.html">
     17.6. Multiple Regression
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../18/Updating_Predictions.html">
   18. Updating Predictions
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../18/1/More_Likely_than_Not_Binary_Classifier.html">
     18.1. A "More Likely Than Not" Binary Classifier
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../18/2/Making_Decisions.html">
     18.2. Making Decisions
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../../_sources/chapters/17/1/Nearest_Neighbors.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/data-8/textbook"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>


            <!-- Full screen (wrap in <a> to have style consistency -->
            <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                    data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                    title="Fullscreen mode"><i
                        class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/data-8/textbook/main?urlpath=tree/chapters/17/1/Nearest_Neighbors.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        <a class="jupyterhub-button" href="https://datahub.berkeley.edu/hub/user-redirect/git-pull?repo=https://github.com/data-8/textbook&urlpath=tree/textbook/chapters/17/1/Nearest_Neighbors.ipynb&branch=main"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch JupyterHub" data-toggle="tooltip"
                data-placement="left"><img class="jupyterhub-button-logo"
                    src="../../../_static/images/logo_jupyterhub.svg"
                    alt="Interact on JupyterHub">JupyterHub</button></a>
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i>
            Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#chronic-kidney-disease">
   17.1.1. Chronic kidney disease
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-nearest-neighbor-classifier">
   17.1.2. A Nearest Neighbor Classifier
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#decision-boundary">
   17.1.3. Decision boundary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#k-nearest-neighbors">
   17.1.4. k-Nearest Neighbors
  </a>
 </li>
</ul>

        </nav>
        
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="cell tag_remove-input docutils container">
</div>
<div class="section" id="nearest-neighbors">
<h1><span class="section-number">17.1. </span>Nearest Neighbors<a class="headerlink" href="#nearest-neighbors" title="Permalink to this headline">¶</a></h1>
<p>In this section we’ll develop the <em>nearest neighbor</em> method of classification. Just focus on the ideas for now and don’t worry if some of the code is mysterious. Later in the chapter we’ll see how to organize our ideas into code that performs the classification.</p>
<div class="cell tag_remove-input docutils container">
</div>
<div class="cell tag_remove-input docutils container">
</div>
<div class="section" id="chronic-kidney-disease">
<h2><span class="section-number">17.1.1. </span>Chronic kidney disease<a class="headerlink" href="#chronic-kidney-disease" title="Permalink to this headline">¶</a></h2>
<p>Let’s work through an example.  We’re going to work with a data set that was collected to help doctors diagnose chronic kidney disease (CKD).  Each row in the data set represents a single patient who was treated in the past and whose diagnosis is known.  For each patient, we have a bunch of measurements from a blood test.  We’d like to find which measurements are most useful for diagnosing CKD, and develop a way to classify future patients as “has CKD” or “doesn’t have CKD” based on their blood test results.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ckd</span> <span class="o">=</span> <span class="n">Table</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span><span class="n">path_data</span> <span class="o">+</span> <span class="s1">&#39;ckd.csv&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">relabeled</span><span class="p">(</span><span class="s1">&#39;Blood Glucose Random&#39;</span><span class="p">,</span> <span class="s1">&#39;Glucose&#39;</span><span class="p">)</span>
<span class="n">ckd</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table border="1" class="dataframe">
    <thead>
        <tr>
            <th>Age</th> <th>Blood Pressure</th> <th>Specific Gravity</th> <th>Albumin</th> <th>Sugar</th> <th>Red Blood Cells</th> <th>Pus Cell</th> <th>Pus Cell clumps</th> <th>Bacteria</th> <th>Glucose</th> <th>Blood Urea</th> <th>Serum Creatinine</th> <th>Sodium</th> <th>Potassium</th> <th>Hemoglobin</th> <th>Packed Cell Volume</th> <th>White Blood Cell Count</th> <th>Red Blood Cell Count</th> <th>Hypertension</th> <th>Diabetes Mellitus</th> <th>Coronary Artery Disease</th> <th>Appetite</th> <th>Pedal Edema</th> <th>Anemia</th> <th>Class</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>48  </td> <td>70            </td> <td>1.005           </td> <td>4      </td> <td>0    </td> <td>normal         </td> <td>abnormal</td> <td>present        </td> <td>notpresent</td> <td>117    </td> <td>56        </td> <td>3.8             </td> <td>111   </td> <td>2.5      </td> <td>11.2      </td> <td>32                </td> <td>6700                  </td> <td>3.9                 </td> <td>yes         </td> <td>no               </td> <td>no                     </td> <td>poor    </td> <td>yes        </td> <td>yes   </td> <td>1    </td>
        </tr>
        <tr>
            <td>53  </td> <td>90            </td> <td>1.02            </td> <td>2      </td> <td>0    </td> <td>abnormal       </td> <td>abnormal</td> <td>present        </td> <td>notpresent</td> <td>70     </td> <td>107       </td> <td>7.2             </td> <td>114   </td> <td>3.7      </td> <td>9.5       </td> <td>29                </td> <td>12100                 </td> <td>3.7                 </td> <td>yes         </td> <td>yes              </td> <td>no                     </td> <td>poor    </td> <td>no         </td> <td>yes   </td> <td>1    </td>
        </tr>
        <tr>
            <td>63  </td> <td>70            </td> <td>1.01            </td> <td>3      </td> <td>0    </td> <td>abnormal       </td> <td>abnormal</td> <td>present        </td> <td>notpresent</td> <td>380    </td> <td>60        </td> <td>2.7             </td> <td>131   </td> <td>4.2      </td> <td>10.8      </td> <td>32                </td> <td>4500                  </td> <td>3.8                 </td> <td>yes         </td> <td>yes              </td> <td>no                     </td> <td>poor    </td> <td>yes        </td> <td>no    </td> <td>1    </td>
        </tr>
        <tr>
            <td>68  </td> <td>80            </td> <td>1.01            </td> <td>3      </td> <td>2    </td> <td>normal         </td> <td>abnormal</td> <td>present        </td> <td>present   </td> <td>157    </td> <td>90        </td> <td>4.1             </td> <td>130   </td> <td>6.4      </td> <td>5.6       </td> <td>16                </td> <td>11000                 </td> <td>2.6                 </td> <td>yes         </td> <td>yes              </td> <td>yes                    </td> <td>poor    </td> <td>yes        </td> <td>no    </td> <td>1    </td>
        </tr>
        <tr>
            <td>61  </td> <td>80            </td> <td>1.015           </td> <td>2      </td> <td>0    </td> <td>abnormal       </td> <td>abnormal</td> <td>notpresent     </td> <td>notpresent</td> <td>173    </td> <td>148       </td> <td>3.9             </td> <td>135   </td> <td>5.2      </td> <td>7.7       </td> <td>24                </td> <td>9200                  </td> <td>3.2                 </td> <td>yes         </td> <td>yes              </td> <td>yes                    </td> <td>poor    </td> <td>yes        </td> <td>yes   </td> <td>1    </td>
        </tr>
        <tr>
            <td>48  </td> <td>80            </td> <td>1.025           </td> <td>4      </td> <td>0    </td> <td>normal         </td> <td>abnormal</td> <td>notpresent     </td> <td>notpresent</td> <td>95     </td> <td>163       </td> <td>7.7             </td> <td>136   </td> <td>3.8      </td> <td>9.8       </td> <td>32                </td> <td>6900                  </td> <td>3.4                 </td> <td>yes         </td> <td>no               </td> <td>no                     </td> <td>good    </td> <td>no         </td> <td>yes   </td> <td>1    </td>
        </tr>
        <tr>
            <td>69  </td> <td>70            </td> <td>1.01            </td> <td>3      </td> <td>4    </td> <td>normal         </td> <td>abnormal</td> <td>notpresent     </td> <td>notpresent</td> <td>264    </td> <td>87        </td> <td>2.7             </td> <td>130   </td> <td>4        </td> <td>12.5      </td> <td>37                </td> <td>9600                  </td> <td>4.1                 </td> <td>yes         </td> <td>yes              </td> <td>yes                    </td> <td>good    </td> <td>yes        </td> <td>no    </td> <td>1    </td>
        </tr>
        <tr>
            <td>73  </td> <td>70            </td> <td>1.005           </td> <td>0      </td> <td>0    </td> <td>normal         </td> <td>normal  </td> <td>notpresent     </td> <td>notpresent</td> <td>70     </td> <td>32        </td> <td>0.9             </td> <td>125   </td> <td>4        </td> <td>10        </td> <td>29                </td> <td>18900                 </td> <td>3.5                 </td> <td>yes         </td> <td>yes              </td> <td>no                     </td> <td>good    </td> <td>yes        </td> <td>no    </td> <td>1    </td>
        </tr>
        <tr>
            <td>73  </td> <td>80            </td> <td>1.02            </td> <td>2      </td> <td>0    </td> <td>abnormal       </td> <td>abnormal</td> <td>notpresent     </td> <td>notpresent</td> <td>253    </td> <td>142       </td> <td>4.6             </td> <td>138   </td> <td>5.8      </td> <td>10.5      </td> <td>33                </td> <td>7200                  </td> <td>4.3                 </td> <td>yes         </td> <td>yes              </td> <td>yes                    </td> <td>good    </td> <td>no         </td> <td>no    </td> <td>1    </td>
        </tr>
        <tr>
            <td>46  </td> <td>60            </td> <td>1.01            </td> <td>1      </td> <td>0    </td> <td>normal         </td> <td>normal  </td> <td>notpresent     </td> <td>notpresent</td> <td>163    </td> <td>92        </td> <td>3.3             </td> <td>141   </td> <td>4        </td> <td>9.8       </td> <td>28                </td> <td>14600                 </td> <td>3.2                 </td> <td>yes         </td> <td>yes              </td> <td>no                     </td> <td>good    </td> <td>no         </td> <td>no    </td> <td>1    </td>
        </tr>
    </tbody>
</table>
<p>... (148 rows omitted)</p></div></div>
</div>
<p>Some of the variables are categorical (words like “abnormal”), and some quantitative. The quantitative variables all have different scales. We’re going to want to make comparisons and estimate distances, often by eye, so let’s select just a few of the variables and work in standard units. Then we won’t have to worry about the scale of each of the different variables.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ckd</span> <span class="o">=</span> <span class="n">Table</span><span class="p">()</span><span class="o">.</span><span class="n">with_columns</span><span class="p">(</span>
    <span class="s1">&#39;Hemoglobin&#39;</span><span class="p">,</span> <span class="n">standard_units</span><span class="p">(</span><span class="n">ckd</span><span class="o">.</span><span class="n">column</span><span class="p">(</span><span class="s1">&#39;Hemoglobin&#39;</span><span class="p">)),</span>
    <span class="s1">&#39;Glucose&#39;</span><span class="p">,</span> <span class="n">standard_units</span><span class="p">(</span><span class="n">ckd</span><span class="o">.</span><span class="n">column</span><span class="p">(</span><span class="s1">&#39;Glucose&#39;</span><span class="p">)),</span>
    <span class="s1">&#39;White Blood Cell Count&#39;</span><span class="p">,</span> <span class="n">standard_units</span><span class="p">(</span><span class="n">ckd</span><span class="o">.</span><span class="n">column</span><span class="p">(</span><span class="s1">&#39;White Blood Cell Count&#39;</span><span class="p">)),</span>
    <span class="s1">&#39;Class&#39;</span><span class="p">,</span> <span class="n">ckd</span><span class="o">.</span><span class="n">column</span><span class="p">(</span><span class="s1">&#39;Class&#39;</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ckd</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table border="1" class="dataframe">
    <thead>
        <tr>
            <th>Hemoglobin</th> <th>Glucose</th> <th>White Blood Cell Count</th> <th>Class</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>-0.865744 </td> <td>-0.221549</td> <td>-0.569768             </td> <td>1    </td>
        </tr>
        <tr>
            <td>-1.45745  </td> <td>-0.947597</td> <td>1.16268               </td> <td>1    </td>
        </tr>
        <tr>
            <td>-1.00497  </td> <td>3.84123  </td> <td>-1.27558              </td> <td>1    </td>
        </tr>
        <tr>
            <td>-2.81488  </td> <td>0.396364 </td> <td>0.809777              </td> <td>1    </td>
        </tr>
        <tr>
            <td>-2.08395  </td> <td>0.643529 </td> <td>0.232293              </td> <td>1    </td>
        </tr>
        <tr>
            <td>-1.35303  </td> <td>-0.561402</td> <td>-0.505603             </td> <td>1    </td>
        </tr>
        <tr>
            <td>-0.413266 </td> <td>2.04928  </td> <td>0.360623              </td> <td>1    </td>
        </tr>
        <tr>
            <td>-1.28342  </td> <td>-0.947597</td> <td>3.34429               </td> <td>1    </td>
        </tr>
        <tr>
            <td>-1.10939  </td> <td>1.87936  </td> <td>-0.409356             </td> <td>1    </td>
        </tr>
        <tr>
            <td>-1.35303  </td> <td>0.489051 </td> <td>1.96475               </td> <td>1    </td>
        </tr>
    </tbody>
</table>
<p>... (148 rows omitted)</p></div></div>
</div>
<p>Let’s look at two columns in particular: the hemoglobin level (in the patient’s blood), and the blood glucose level (at a random time in the day; without fasting specially for the blood test).</p>
<p>We’ll draw a scatter plot to visualize the relation between the two variables. Blue dots are patients with CKD; gold dots are patients without CKD.  What kind of medical test results seem to indicate CKD?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">color_table</span> <span class="o">=</span> <span class="n">Table</span><span class="p">()</span><span class="o">.</span><span class="n">with_columns</span><span class="p">(</span>
    <span class="s1">&#39;Class&#39;</span><span class="p">,</span> <span class="n">make_array</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
    <span class="s1">&#39;Color&#39;</span><span class="p">,</span> <span class="n">make_array</span><span class="p">(</span><span class="s1">&#39;darkblue&#39;</span><span class="p">,</span> <span class="s1">&#39;gold&#39;</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">ckd</span> <span class="o">=</span> <span class="n">ckd</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;Class&#39;</span><span class="p">,</span> <span class="n">color_table</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ckd</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="s1">&#39;Hemoglobin&#39;</span><span class="p">,</span> <span class="s1">&#39;Glucose&#39;</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="s1">&#39;Color&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/Nearest_Neighbors_11_0.png" src="../../../_images/Nearest_Neighbors_11_0.png" />
</div>
</div>
<p>Suppose Alice is a new patient who is not in the data set.  If I tell you Alice’s hemoglobin level and blood glucose level, could you predict whether she has CKD?  It sure looks like it!  You can see a very clear pattern here: points in the lower-right tend to represent people who don’t have CKD, and the rest tend to be folks with CKD.  To a human, the pattern is obvious.  But how can we program a computer to automatically detect patterns such as this one?</p>
</div>
<div class="section" id="a-nearest-neighbor-classifier">
<h2><span class="section-number">17.1.2. </span>A Nearest Neighbor Classifier<a class="headerlink" href="#a-nearest-neighbor-classifier" title="Permalink to this headline">¶</a></h2>
<p>There are lots of kinds of patterns one might look for, and lots of algorithms for classification.  But I’m going to tell you about one that turns out to be surprisingly effective.  It is called <em>nearest neighbor classification</em>.  Here’s the idea.  If we have Alice’s hemoglobin and glucose numbers, we can put her somewhere on this scatterplot; the hemoglobin is her x-coordinate, and the glucose is her y-coordinate.  Now, to predict whether she has CKD or not, we find the nearest point in the scatterplot and check whether it is blue or gold; we predict that Alice should receive the same diagnosis as that patient.</p>
<p>In other words, to classify Alice as CKD or not, we find the patient in the training set who is “nearest” to Alice, and then use that patient’s diagnosis as our prediction for Alice.  The intuition is that if two points are near each other in the scatterplot, then the corresponding measurements are pretty similar, so we might expect them to receive the same diagnosis (more likely than not).  We don’t know Alice’s diagnosis, but we do know the diagnosis of all the patients in the training set, so we find the patient in the training set who is most similar to Alice, and use that patient’s diagnosis to predict Alice’s diagnosis.</p>
<p>In the graph below, the red dot represents Alice. It is joined with a black line to the point that is nearest to it – its <em>nearest neighbor</em> in the training set. The figure is drawn by a function called <code class="docutils literal notranslate"><span class="pre">show_closest</span></code>. It takes an array that represents the <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> coordinates of Alice’s point. Vary those to see how the closest point changes! Note especially when the closest point is blue and when it is gold.</p>
<div class="cell tag_remove-input docutils container">
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># In this example, Alice&#39;s Hemoglobin attribute is 0 and her Glucose is 1.5.</span>
<span class="n">alice</span> <span class="o">=</span> <span class="n">make_array</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">)</span>
<span class="n">show_closest</span><span class="p">(</span><span class="n">alice</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/Nearest_Neighbors_16_0.png" src="../../../_images/Nearest_Neighbors_16_0.png" />
</div>
</div>
<p>Thus our <em>nearest neighbor classifier</em> works like this:</p>
<ul class="simple">
<li><p>Find the point in the training set that is nearest to the new point.</p></li>
<li><p>If that nearest point is a “CKD” point, classify the new point as “CKD”. If the nearest point is a “not CKD” point, classify the new point as “not CKD”.</p></li>
</ul>
<p>The scatterplot suggests that this nearest neighbor classifier should be pretty accurate.  Points in the lower-right will tend to receive a “no CKD” diagnosis, as their nearest neighbor will be a gold point.  The rest of the points will tend to receive a “CKD” diagnosis, as their nearest neighbor will be a blue point.  So the nearest neighbor strategy seems to capture our intuition pretty well, for this example.</p>
</div>
<div class="section" id="decision-boundary">
<h2><span class="section-number">17.1.3. </span>Decision boundary<a class="headerlink" href="#decision-boundary" title="Permalink to this headline">¶</a></h2>
<p>Sometimes a helpful way to visualize a classifier is to map out the kinds of attributes where the classifier would predict ‘CKD’, and the kinds where it would predict ‘not CKD’.  We end up with some boundary between the two, where points on one side of the boundary will be classified ‘CKD’ and points on the other side will be classified ‘not CKD’.  This boundary is called the <em>decision boundary</em>.  Each different classifier will have a different decision boundary; the decision boundary is just a way to visualize what criteria the classifier is using to classify points.</p>
<p>For example, suppose the coordinates of Alice’s point are (0, 1.5). Notice that the nearest neighbor is blue. Now try reducing the height (the <span class="math notranslate nohighlight">\(y\)</span>-coordinate) of the point. You’ll see that at around <span class="math notranslate nohighlight">\(y = 0.95\)</span> the nearest neighbor turns from blue to gold.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">alice</span> <span class="o">=</span> <span class="n">make_array</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.97</span><span class="p">)</span>
<span class="n">show_closest</span><span class="p">(</span><span class="n">alice</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/Nearest_Neighbors_19_0.png" src="../../../_images/Nearest_Neighbors_19_0.png" />
</div>
</div>
<p>Here are hundreds of new unclassified points, all in red.</p>
<div class="cell tag_remove-input docutils container">
</div>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="../../../_images/Nearest_Neighbors_22_0.png" src="../../../_images/Nearest_Neighbors_22_0.png" />
</div>
</div>
<p>Each of the red points has a nearest neighbor in the training set (the same blue and gold points as before). For some red points you can easily tell whether the nearest neighbor is blue or gold. For others, it’s a little more tricky to make the decision by eye. Those are the points near the decision boundary.</p>
<p>But the computer can easily determine the nearest neighbor of each point. So let’s get it to apply our nearest neighbor classifier to each of the red points:</p>
<p>For each red point, it must find the closest point in the training set; it must then change the color of the red point to become the color of the nearest neighbor.</p>
<p>The resulting graph shows which points will get classified as ‘CKD’ (all the blue ones), and which as ‘not CKD’ (all the gold ones).</p>
<div class="cell tag_remove-input docutils container">
</div>
<div class="cell tag_remove-input docutils container">
</div>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="../../../_images/Nearest_Neighbors_26_0.png" src="../../../_images/Nearest_Neighbors_26_0.png" />
</div>
</div>
<p>The decision boundary is where the classifier switches from turning the red points blue to turning them gold.</p>
</div>
<div class="section" id="k-nearest-neighbors">
<h2><span class="section-number">17.1.4. </span>k-Nearest Neighbors<a class="headerlink" href="#k-nearest-neighbors" title="Permalink to this headline">¶</a></h2>
<p>However, the separation between the two classes won’t always be quite so clean.  For instance, suppose that instead of hemoglobin levels we were to look at white blood cell count.  Look at what happens:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ckd</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="s1">&#39;White Blood Cell Count&#39;</span><span class="p">,</span> <span class="s1">&#39;Glucose&#39;</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="s1">&#39;Color&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/Nearest_Neighbors_29_0.png" src="../../../_images/Nearest_Neighbors_29_0.png" />
</div>
</div>
<p>As you can see, non-CKD individuals are all clustered in the lower-left.  Most of the patients with CKD are above or to the right of that cluster… but not all.  There are some patients with CKD who are in the lower left of the above figure (as indicated by the handful of blue dots scattered among the gold cluster).  What this means is that you can’t tell for certain whether someone has CKD from just these two blood test measurements.</p>
<p>If we are given Alice’s glucose level and white blood cell count, can we predict whether she has CKD?  Yes, we can make a prediction, but we shouldn’t expect it to be 100% accurate.  Intuitively, it seems like there’s a natural strategy for predicting: plot where Alice lands in the scatter plot; if she is in the lower-left, predict that she doesn’t have CKD, otherwise predict she has CKD.</p>
<p>This isn’t perfect – our predictions will sometimes be wrong.  (Take a minute and think it through: for which patients will it make a mistake?)  As the scatterplot above indicates, sometimes people with CKD have glucose and white blood cell levels that look identical to those of someone without CKD, so any classifier is inevitably going to make the wrong prediction for them.</p>
<p>Can we automate this on a computer?  Well, the nearest neighbor classifier would be a reasonable choice here too.  Take a minute and think it through: how will its predictions compare to those from the intuitive strategy above?  When will they differ?</p>
<p>Its predictions will be pretty similar to our intuitive strategy, but occasionally it will make a different prediction.  In particular, if Alice’s blood test results happen to put her right near one of the blue dots in the lower-left, the intuitive strategy would predict ‘not CKD’, whereas the nearest neighbor classifier will predict ‘CKD’.</p>
<p>There is a simple generalization of the nearest neighbor classifier that fixes this anomaly.  It is called the <em>k-nearest neighbor classifier</em>.  To predict Alice’s diagnosis, rather than looking at just the one neighbor closest to her, we can look at the 3 points that are closest to her, and use the diagnosis for each of those 3 points to predict Alice’s diagnosis.  In particular, we’ll use the majority value among those 3 diagnoses as our prediction for Alice’s diagnosis.  Of course, there’s nothing special about the number 3: we could use 4, or 5, or more.  (It’s often convenient to pick an odd number, so that we don’t have to deal with ties.)  In general, we pick a number <span class="math notranslate nohighlight">\(k\)</span>, and our predicted diagnosis for Alice is based on the <span class="math notranslate nohighlight">\(k\)</span> patients in the training set who are closest to Alice.  Intuitively, these are the <span class="math notranslate nohighlight">\(k\)</span> patients whose blood test results were most similar to Alice, so it seems reasonable to use their diagnoses to predict Alice’s diagnosis.</p>
<p>The <span class="math notranslate nohighlight">\(k\)</span>-nearest neighbor classifier will now behave just like our intuitive strategy above.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./chapters/17/1"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="../Classification.html" title="previous page"><span class="section-number">17. </span>Classification</a>
    <a class='right-next' id="next-link" href="../2/Training_and_Testing.html" title="next page"><span class="section-number">17.2. </span>Training and Testing</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Ani Adhikari and John DeNero<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../../../_static/js/index.d3f166471bb80abb5163.js"></script>


    
    <!-- Google Analytics -->
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-148221575-1', 'auto');
      ga('set', 'anonymizeIp', true);
      ga('send', 'pageview');
    </script>
    <script async src='https://www.google-analytics.com/analytics.js'></script>
    <!-- End Google Analytics -->
    
  </body>
</html>