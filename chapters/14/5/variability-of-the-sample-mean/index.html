<!DOCTYPE html><html lang="en" class="" style="scroll-padding:60px"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/><title>The Variability of the Sample Mean - Computational and Inferential Thinking</title><meta property="og:title" content="The Variability of the Sample Mean - Computational and Inferential Thinking"/><meta name="generator" content="mystmd"/><meta name="keywords" content=""/><link rel="stylesheet" href="/build/_assets/app-IZWEOBHI.css"/><link rel="stylesheet" href="/build/_assets/thebe-core-VKVHG5VY.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jupyter-matplotlib@0.11.3/css/mpl_widget.css"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-148221575-1"></script><script>window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-148221575-1');</script><link rel="icon" href="/favicon.ico"/><link rel="stylesheet" href="/myst-theme.css"/><script>
  const savedTheme = localStorage.getItem("myst:theme");
  const theme = window.matchMedia("(prefers-color-scheme: light)").matches ? 'light' : 'dark';
  const classes = document.documentElement.classList;
  const hasAnyTheme = classes.contains('light') || classes.contains('dark');
  if (!hasAnyTheme) classes.add(savedTheme ?? theme);
</script></head><body class="m-0 transition-colors duration-500 bg-white dark:bg-stone-900"><div class="fixed top-1 left-1 h-[0px] w-[0px] focus-within:z-40 focus-within:h-auto focus-within:w-auto bg-white overflow-hidden focus-within:p-2 focus-within:ring-1" aria-label="skip to content options"><a href="#skip-to-frontmatter" class="block px-2 py-1 text-black underline">Skip to article frontmatter</a><a href="#skip-to-article" class="block px-2 py-1 text-black underline">Skip to article content</a></div><div class="bg-white/80 backdrop-blur dark:bg-stone-900/80 shadow dark:shadow-stone-700 p-3 md:px-8 sticky w-screen top-0 z-30 h-[60px]"><nav class="flex items-center justify-between flex-nowrap max-w-[1440px] mx-auto"><div class="flex flex-row xl:min-w-[19.5rem] mr-2 sm:mr-7 justify-start items-center shrink-0"><div class="block xl:hidden"><button class="flex items-center border-stone-400 text-stone-800 hover:text-stone-900 dark:text-stone-200 hover:dark:text-stone-100"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="m-1"><path fill-rule="evenodd" d="M3 6.75A.75.75 0 0 1 3.75 6h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 6.75ZM3 12a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 12Zm0 5.25a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75a.75.75 0 0 1-.75-.75Z" clip-rule="evenodd"></path></svg><span class="sr-only">Open Menu</span></button></div><a class="flex items-center ml-3 dark:text-white w-fit md:ml-5 xl:ml-7" href="/"><div class="p-1 mr-3 dark:bg-white dark:rounded"><img src="/build/data8logo-e8cfc0153f6b4ee7c43c8a236cd746b7.png" class="h-9" alt="Computational and Inferential Thinking" height="2.25rem"/></div><span class="text-md sm:text-xl tracking-tight sm:mr-5">Computational and Inferential Thinking</span></a></div><div class="flex items-center flex-grow w-auto"><div class="flex-grow hidden text-md lg:block"></div><div class="flex-grow block"></div><button type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R74op:" data-state="closed" class="flex items-center h-10 aspect-square sm:w-64 text-left text-gray-400 border border-gray-300 dark:border-gray-600 rounded-lg bg-gray-50 dark:bg-gray-700 hover:ring-blue-500 dark:hover:ring-blue-500 hover:border-blue-500 dark:hover:border-blue-500"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="p-2.5 h-10 w-10 aspect-square"><path fill-rule="evenodd" d="M10.5 3.75a6.75 6.75 0 1 0 0 13.5 6.75 6.75 0 0 0 0-13.5ZM2.25 10.5a8.25 8.25 0 1 1 14.59 5.28l4.69 4.69a.75.75 0 1 1-1.06 1.06l-4.69-4.69A8.25 8.25 0 0 1 2.25 10.5Z" clip-rule="evenodd"></path></svg><span class="hidden sm:block grow">Search</span><div aria-hidden="true" class="items-center hidden mx-1 font-mono text-sm text-gray-400 sm:flex gap-x-1"><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none hide-mac">CTRL</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none show-mac">⌘</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none ">K</kbd><script>
;(() => {
const script = document.currentScript;
const root = script.parentElement;

const isMac = /mac/i.test(
      window.navigator.userAgentData?.platform ?? window.navigator.userAgent,
    );
root.querySelectorAll(".hide-mac").forEach(node => {node.classList.add(isMac ? "hidden" : "block")});
root.querySelectorAll(".show-mac").forEach(node => {node.classList.add(!isMac ? "hidden" : "block")});
})()</script></div></button><button class="theme rounded-full aspect-square border border-stone-700 dark:border-white hover:bg-neutral-100 border-solid overflow-hidden text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 w-8 h-8 mx-3" title="Toggle theme between light and dark mode" aria-label="Toggle theme between light and dark mode"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 hidden dark:block"><path fill-rule="evenodd" d="M9.528 1.718a.75.75 0 0 1 .162.819A8.97 8.97 0 0 0 9 6a9 9 0 0 0 9 9 8.97 8.97 0 0 0 3.463-.69.75.75 0 0 1 .981.98 10.503 10.503 0 0 1-9.694 6.46c-5.799 0-10.5-4.7-10.5-10.5 0-4.368 2.667-8.112 6.46-9.694a.75.75 0 0 1 .818.162Z" clip-rule="evenodd"></path></svg><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 dark:hidden"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v2.25m6.364.386-1.591 1.591M21 12h-2.25m-.386 6.364-1.591-1.591M12 18.75V21m-4.773-4.227-1.591 1.591M5.25 12H3m4.227-4.773L5.636 5.636M15.75 12a3.75 3.75 0 1 1-7.5 0 3.75 3.75 0 0 1 7.5 0Z"></path></svg></button><div class="block sm:hidden"></div><div class="hidden sm:block"></div></div></nav></div><div class="fixed xl:article-grid grid-gap xl:w-screen xl:pointer-events-none overflow-auto max-xl:min-w-[300px] hidden z-10" style="top:60px"><div class="pointer-events-auto xl:col-margin-left flex-col overflow-hidden hidden xl:flex"><div class="flex-grow py-6 overflow-y-auto primary-scrollbar"><nav aria-label="Navigation" class="overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px] lg:hidden"><div class="w-full px-1 dark:text-white font-medium"></div></nav><div class="my-3 border-b-2 lg:hidden"></div><nav aria-label="Table of Contents" class="flex-grow overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px]"><div class="w-full px-1 dark:text-white"><a title="Computational and Inferential Thinking" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30 font-bold" href="/">Computational and Inferential Thinking</a><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="1 What is Data Science?" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/01/what-is-data-science">1 What is Data Science?</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rmp8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:Rmp8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="2 Causality and Experiments" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/02/causality-and-experiments">2 Causality and Experiments</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rup8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:Rup8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="3 Programming in Python" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/03/programming-in-python">3 Programming in Python</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R16p8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R16p8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="4 Data Types" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/04/data-types">4 Data Types</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R1ep8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R1ep8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="5 Sequences" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/05/sequences">5 Sequences</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R1mp8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R1mp8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="6 Tables" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/06/tables">6 Tables</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R1up8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R1up8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="7 Visualization" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/07/visualization">7 Visualization</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R26p8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R26p8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="8 Functions and Tables" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/08/functions-and-tables">8 Functions and Tables</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R2ep8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R2ep8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="9 Randomness" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/09/randomness">9 Randomness</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R2mp8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R2mp8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="10 Sampling and Empirical Distributions" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/10/sampling-and-empirical-distributions">10 Sampling and Empirical Distributions</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R2up8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R2up8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="11 Testing Hypotheses" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/11/testing-hypotheses">11 Testing Hypotheses</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R36p8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R36p8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="12 Comparing Two Samples" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/12/comparing-two-samples">12 Comparing Two Samples</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R3ep8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R3ep8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="13 Estimation" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/13/estimation">13 Estimation</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R3mp8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R3mp8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="open" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="14 Why the Mean Matters" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow font-semibold text-blue-800 dark:text-blue-200" href="/chapters/14/why-the-mean-matters">14 Why the Mean Matters</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R3up8p:" aria-expanded="true" data-state="open"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="open" id="radix-:R3up8p:" class="pl-3 pr-[2px] collapsible-content"><a title="14.1 Properties of the Mean" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/chapters/14/1/properties-of-the-mean">14.1 Properties of the Mean</a><a title="14.2 Variability" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/chapters/14/2/variability">14.2 Variability</a><a title="14.3 The SD and the Normal Curve" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/chapters/14/3/sd-and-the-normal-curve">14.3 The SD and the Normal Curve</a><a title="14.4 The Central Limit Theorem" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/chapters/14/4/central-limit-theorem">14.4 The Central Limit Theorem</a><a title="14.5 The Variability of the Sample Mean" aria-current="page" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg bg-blue-300/30 active" href="/chapters/14/5/variability-of-the-sample-mean">14.5 The Variability of the Sample Mean</a><a title="14.6 Choosing a Sample Size" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/chapters/14/6/choosing-a-sample-size">14.6 Choosing a Sample Size</a></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="15 Prediction" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/15/prediction">15 Prediction</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R46p8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R46p8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="16 Inference for Regression" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/16/inference-for-regression">16 Inference for Regression</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R4ep8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R4ep8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="17 Classification" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/17/classification">17 Classification</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R4mp8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R4mp8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="18 Updating Predictions" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/18/updating-predictions">18 Updating Predictions</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R4up8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R4up8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div></div></nav></div><div class="flex-none py-6 transition-all duration-700 translate-y-6 opacity-0"><a class="flex mx-auto text-gray-700 w-fit hover:text-blue-700 dark:text-gray-200 dark:hover:text-blue-400" href="https://mystmd.org/made-with-myst" target="_blank" rel="noreferrer"><svg style="width:24px;height:24px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" stroke="none"><g id="icon"><path fill="currentColor" d="M23.8,54.8v-3.6l4.7-0.8V17.5l-4.7-0.8V13H36l13.4,31.7h0.2l13-31.7h12.6v3.6l-4.7,0.8v32.9l4.7,0.8v3.6h-15
          v-3.6l4.9-0.8V20.8H65L51.4,53.3h-3.8l-14-32.5h-0.1l0.2,17.4v12.1l5,0.8v3.6H23.8z"></path><path fill="#F37726" d="M47,86.9c0-5.9-3.4-8.8-10.1-8.8h-8.4c-5.2,0-9.4-1.3-12.5-3.8c-3.1-2.5-5.4-6.2-6.8-11l4.8-1.6
          c1.8,5.6,6.4,8.6,13.8,8.8h9.2c6.4,0,10.8,2.5,13.1,7.5c2.3-5,6.7-7.5,13.1-7.5h8.4c7.8,0,12.7-2.9,14.6-8.7l4.8,1.6
          c-1.4,4.9-3.6,8.6-6.8,11.1c-3.1,2.5-7.3,3.7-12.4,3.8H63c-6.7,0-10,2.9-10,8.8"></path></g></svg><span class="self-center ml-2 text-sm">Made with MyST</span></a></div></div></div><main class="article-grid grid-gap"><article class="article-grid subgrid-gap col-screen article content"><div class="hidden"></div><div id="skip-to-frontmatter" aria-label="article frontmatter" class="mb-8 pt-9"><div class="flex items-center mb-5 h-6 text-sm font-light"><div class="flex-grow"></div><a href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" rel="noopener noreferrer" class="opacity-50 hover:opacity-100 text-inherit hover:text-inherit" aria-label="Content License: Creative Commons Attribution Non Commercial No Derivatives 4.0 International (CC-BY-NC-ND-4.0)"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mx-1"><title>Content License: Creative Commons Attribution Non Commercial No Derivatives 4.0 International (CC-BY-NC-ND-4.0)</title><path d="M12 2.2c2.7 0 5 1 7 2.9.9.9 1.6 2 2.1 3.1.5 1.2.7 2.4.7 3.8 0 1.3-.2 2.6-.7 3.8-.5 1.2-1.2 2.2-2.1 3.1-1 .9-2 1.7-3.2 2.2-1.2.5-2.5.7-3.7.7s-2.6-.3-3.8-.8c-1.2-.5-2.2-1.2-3.2-2.1s-1.6-2-2.1-3.2-.8-2.4-.8-3.7c0-1.3.2-2.5.7-3.7S4.2 6 5.1 5.1C7 3.2 9.3 2.2 12 2.2zM12 4c-2.2 0-4.1.8-5.6 2.3C5.6 7.1 5 8 4.6 9c-.4 1-.6 2-.6 3s.2 2.1.6 3c.4 1 1 1.8 1.8 2.6S8 19 9 19.4c1 .4 2 .6 3 .6s2.1-.2 3-.6c1-.4 1.9-1 2.7-1.8 1.5-1.5 2.3-3.3 2.3-5.6 0-1.1-.2-2.1-.6-3.1-.4-1-1-1.8-1.7-2.6C16.1 4.8 14.2 4 12 4zm-.1 6.4l-1.3.7c-.1-.3-.3-.5-.5-.6-.2-.1-.4-.2-.6-.2-.9 0-1.3.6-1.3 1.7 0 .5.1.9.3 1.3.2.3.5.5 1 .5.6 0 1-.3 1.2-.8l1.2.6c-.3.5-.6.9-1.1 1.1-.5.3-1 .4-1.5.4-.9 0-1.6-.3-2.1-.8-.5-.6-.8-1.3-.8-2.3 0-.9.3-1.7.8-2.2.6-.6 1.3-.8 2.1-.8 1.2 0 2.1.4 2.6 1.4zm5.6 0l-1.3.7c-.1-.3-.3-.5-.5-.6-.2-.1-.4-.2-.6-.2-.9 0-1.3.6-1.3 1.7 0 .5.1.9.3 1.3.2.3.5.5 1 .5.6 0 1-.3 1.2-.8l1.2.6c-.3.5-.6.9-1.1 1.1-.4.2-.9.3-1.4.3-.9 0-1.6-.3-2.1-.8s-.8-1.3-.8-2.2c0-.9.3-1.7.8-2.2.5-.5 1.2-.8 2-.8 1.2 0 2.1.4 2.6 1.4z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1"><title>Credit must be given to the creator</title><path d="M12 2.2c2.7 0 5 .9 6.9 2.8 1.9 1.9 2.8 4.2 2.8 6.9s-.9 5-2.8 6.8c-2 1.9-4.3 2.9-7 2.9-2.6 0-4.9-1-6.9-2.9-1.8-1.7-2.8-4-2.8-6.7s1-5 2.9-6.9C7 3.2 9.3 2.2 12 2.2zM12 4c-2.2 0-4.1.8-5.6 2.3C4.8 8 4 9.9 4 12c0 2.2.8 4 2.4 5.6C8 19.2 9.8 20 12 20c2.2 0 4.1-.8 5.7-2.4 1.5-1.5 2.3-3.3 2.3-5.6 0-2.2-.8-4.1-2.3-5.7C16.1 4.8 14.2 4 12 4zm2.6 5.6v4h-1.1v4.7h-3v-4.7H9.4v-4c0-.2.1-.3.2-.4.1-.2.2-.2.4-.2h4c.2 0 .3.1.4.2.2.1.2.2.2.4zm-4-2.5c0-.9.5-1.4 1.4-1.4s1.4.5 1.4 1.4c0 .9-.5 1.4-1.4 1.4s-1.4-.5-1.4-1.4z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1"><title>Only noncommercial uses of the work are permitted</title><path d="M12 2.2c2.7 0 5 .9 6.9 2.8 1.9 1.9 2.8 4.2 2.8 6.9s-.9 5-2.8 6.8c-2 1.9-4.3 2.9-7 2.9-2.6 0-4.9-1-6.9-2.9-1.9-1.9-2.9-4.2-2.9-6.9s1-5 2.9-6.9c2-1.7 4.3-2.7 7-2.7zM4.4 9.4C4.2 10.2 4 11 4 12c0 2.2.8 4 2.4 5.6C8 19.2 9.8 20 12 20c2.2 0 4.1-.8 5.7-2.4.6-.5 1-1.1 1.3-1.7l-3.7-1.6c-.1.6-.4 1.1-.9 1.5-.5.4-1.1.6-1.8.7V18h-1.1v-1.5c-1.1 0-2.1-.4-3-1.2l1.3-1.4c.6.6 1.4.9 2.2.9.3 0 .6-.1.9-.2.2-.2.4-.4.4-.7 0-.2-.1-.4-.3-.6l-.9-.4-1.1-.6-1.5-.7-5.1-2.2zM12 4c-2.2 0-4.1.8-5.6 2.3-.4.4-.7.9-1.1 1.3L9 9.3c.2-.5.5-.9 1-1.2.5-.3 1-.5 1.6-.5V6.1h1.1v1.5c.9 0 1.7.3 2.4.9l-1.3 1.3c-.5-.4-1.1-.6-1.7-.6-.3 0-.6.1-.8.2-.2.1-.3.3-.3.6 0 .1 0 .2.1.2l1.2.6.9.4 1.6.7 5 2.2c.2-.7.2-1.4.2-2.1 0-2.2-.8-4.1-2.3-5.7C16.1 4.8 14.2 4 12 4z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1"><title>No derivatives or adaptations of the work are permitted</title><path d="M12 2.2c2.7 0 5 .9 6.9 2.8 1.9 1.9 2.8 4.2 2.8 6.9s-.9 5-2.8 6.9c-2 1.9-4.3 2.9-7 2.9-2.6 0-4.9-1-6.9-2.9C3.2 17 2.2 14.7 2.2 12s1-5 2.9-6.9C7 3.2 9.3 2.2 12 2.2zM12 4c-2.2 0-4.1.8-5.6 2.4C4.8 8 4 9.9 4 12c0 2.2.8 4 2.4 5.6C8 19.2 9.8 20 12 20c2.2 0 4.1-.8 5.7-2.4 1.5-1.5 2.3-3.3 2.3-5.6 0-2.2-.8-4.1-2.3-5.6C16.1 4.8 14.2 4 12 4zm3.7 5.7v1.7H8.6V9.7h7.1zm0 3.1v1.7H8.6v-1.7h7.1z"></path></svg></a><a href="https://github.com/data-8/textbook" title="GitHub Repository: data-8/textbook" target="_blank" rel="noopener noreferrer" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1 opacity-60 hover:opacity-100"><path d="M12 2.5c-5.4 0-9.8 4.4-9.8 9.7 0 4.3 2.8 8 6.7 9.2.5.1.7-.2.7-.5v-1.8c-2.4.5-3.1-.6-3.3-1.1-.1-.3-.6-1.1-1-1.4-.3-.2-.8-.6 0-.6s1.3.7 1.5 1c.9 1.5 2.3 1.1 2.8.8.1-.6.3-1.1.6-1.3-2.2-.2-4.4-1.1-4.4-4.8 0-1.1.4-1.9 1-2.6-.1-.2-.4-1.2.1-2.6 0 0 .8-.3 2.7 1 .8-.2 1.6-.3 2.4-.3.8 0 1.7.1 2.4.3 1.9-1.3 2.7-1 2.7-1 .5 1.3.2 2.3.1 2.6.6.7 1 1.5 1 2.6 0 3.7-2.3 4.6-4.4 4.8.4.3.7.9.7 1.8V21c0 .3.2.6.7.5 3.9-1.3 6.6-4.9 6.6-9.2 0-5.4-4.4-9.8-9.8-9.8z"></path></svg></a><a href="https://github.com/data-8/textbook/edit/main/chapters/14/5/Variability_of_the_Sample_Mean.ipynb" title="Edit This Page" target="_blank" rel="noopener noreferrer" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem" class="inline-block mr-1 opacity-60 hover:opacity-100"><path stroke-linecap="round" stroke-linejoin="round" d="m16.862 4.487 1.687-1.688a1.875 1.875 0 1 1 2.652 2.652L10.582 16.07a4.5 4.5 0 0 1-1.897 1.13L6 18l.8-2.685a4.5 4.5 0 0 1 1.13-1.897l8.932-8.931Zm0 0L19.5 7.125M18 14v4.75A2.25 2.25 0 0 1 15.75 21H5.25A2.25 2.25 0 0 1 3 18.75V8.25A2.25 2.25 0 0 1 5.25 6H10"></path></svg></a><div class="relative flex inline-block mx-1 grow-0" data-headlessui-state=""><button class="relative ml-2 -mr-1" id="headlessui-menu-button-:Rs8top:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Downloads</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem"><title>Download</title><path stroke-linecap="round" stroke-linejoin="round" d="M3 16.5v2.25A2.25 2.25 0 0 0 5.25 21h13.5A2.25 2.25 0 0 0 21 18.75V16.5M16.5 12 12 16.5m0 0L7.5 12m4.5 4.5V3"></path></svg></button></div></div><h1 class="mb-0"><span class="mr-3 select-none">14.5</span>The Variability of the Sample Mean</h1></div><div class="block my-10 lg:sticky lg:z-10 lg:h-0 lg:pt-0 lg:my-0 lg:ml-10 lg:col-margin-right" style="top:60px"><nav></nav></div><div id="skip-to-article"></div><div id="DvNnS1CU5K" class="relative group/block"><p>By the Central Limit Theorem, the probability distribution of the mean of a large random sample is roughly normal. The bell curve is centered at the population mean. Some of the sample means are higher, and some lower, but the deviations from the population mean are roughly symmetric on either side, as we have seen repeatedly. Formally, probability theory shows that the sample mean is an <em>unbiased</em> estimate of the population mean.</p><p>In our simulations, we also noticed that the means of larger samples tend to be more tightly clustered around the population mean than means of smaller samples. In this section, we will quantify the variability of the sample mean and develop a relation between the variability and the sample size.</p></div><div id="v93aoS3VnG" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose hidden my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">from datascience import *
import numpy as np
path_data = &#x27;../../../assets/data/&#x27;
%matplotlib inline
import matplotlib.pyplot as plots
plots.style.use(&#x27;fivethirtyeight&#x27;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="Ko5xBR58KjHHO-lexA3Sd" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="WARkj5Qfop" class="relative group/block"><p>Let’s start with our table of flight delays. The mean delay is about 16.7 minutes, and the distribution of delays is skewed to the right.</p></div><div id="QF8UXgqwXp" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">united = Table.read_table(path_data + &#x27;united_summer2015.csv&#x27;)
delay = united.select(&#x27;Delay&#x27;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="LbJI2EfiAIYBG63SJxYyh" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="eMprmg20Do" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">pop_mean = np.mean(delay.column(&#x27;Delay&#x27;))
pop_mean</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="wO5Tajk729jy6OJK295t3" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><div class="font-mono text-sm whitespace-pre-wrap"><code><span>16.658155515370705</span></code></div></div></div><div id="ke9Ky5KNkl" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose hidden my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">delay.hist(bins=np.arange(-20, 300, 10))
plots.scatter(pop_mean, -0.0008, marker=&#x27;^&#x27;, color=&#x27;darkblue&#x27;, s=60)
plots.ylim(-0.004, 0.04);</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="PKBUAVp8QQvRKRv6M4bmM" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><img src="/build/09ab3e94c989e9f23f097c354a9ebb1b.png" alt="&lt;Figure size 432x288 with 1 Axes&gt;"/></div></div><div id="npEV1NEG1b" class="relative group/block"><p>Now let’s take random samples and look at the probability distribution of the sample mean. As usual, we will use simulation to get an empirical approximation to this distribution.</p><p>We will define a function <code>simulate_sample_mean</code> to do this, because we are going to vary the sample size later. The arguments are the name of the table, the label of the column containing the variable, the sample size, and the number of simulations.</p></div><div id="bBdHYwbYGU" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">&quot;&quot;&quot;Empirical distribution of random sample means&quot;&quot;&quot;

def simulate_sample_mean(table, label, sample_size, repetitions):
    
    means = make_array()

    for i in range(repetitions):
        new_sample = table.sample(sample_size)
        new_sample_mean = np.mean(new_sample.column(label))
        means = np.append(means, new_sample_mean)

    sample_means = Table().with_column(&#x27;Sample Means&#x27;, means)
    
    # Display empirical histogram and print all relevant quantities
    sample_means.hist(bins=20)
    plots.xlabel(&#x27;Sample Means&#x27;)
    plots.title(&#x27;Sample Size &#x27; + str(sample_size))
    print(&quot;Sample size: &quot;, sample_size)
    print(&quot;Population mean:&quot;, np.mean(table.column(label)))
    print(&quot;Average of sample means: &quot;, np.mean(means))
    print(&quot;Population SD:&quot;, np.std(table.column(label)))
    print(&quot;SD of sample means:&quot;, np.std(means))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="CugFyAdROomdWAdNlp4XS" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="bu7vjvsySc" class="relative group/block"><p>Let us simulate the mean of a random sample of 100 delays, then of 400 delays, and finally of 625 delays. We will perform 10,000 repetitions of each of these process. The <code>xlim</code> and <code>ylim</code> lines set the axes consistently in all the plots for ease of comparison. You can just ignore those two lines of code in each cell.</p></div><div id="E5DyfHoxTg" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">simulate_sample_mean(delay, &#x27;Delay&#x27;, 100, 10000)
plots.xlim(5, 35)
plots.ylim(0, 0.25);</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="40aUvVOUbJFHtEa51nG1I" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span>Sample size:  100
Population mean: 16.658155515370705
Average of sample means:  16.672836
Population SD: 39.480199851609314
SD of sample means: 3.92467202924066
</span></code></pre></div><img src="/build/c579f01c266e6837f1f0c6c2f637b34b.png" alt="&lt;Figure size 432x288 with 1 Axes&gt;"/></div></div><div id="XhhCHMt6v0" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">simulate_sample_mean(delay, &#x27;Delay&#x27;, 400, 10000)
plots.xlim(5, 35)
plots.ylim(0, 0.25);</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="f_TCHbZKbKYcYLGcs7mxS" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span>Sample size:  400
Population mean: 16.658155515370705
Average of sample means:  16.678091499999997
Population SD: 39.480199851609314
SD of sample means: 1.9474592014668113
</span></code></pre></div><img src="/build/4d3bea99393c96823895257ae8af9b56.png" alt="&lt;Figure size 432x288 with 1 Axes&gt;"/></div></div><div id="uw8f7jOsJH" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">simulate_sample_mean(delay, &#x27;Delay&#x27;, 625, 10000)
plots.xlim(5, 35)
plots.ylim(0, 0.25);</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="GoiCrak-iGg0J-RQmhM4O" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span>Sample size:  625
Population mean: 16.658155515370705
Average of sample means:  16.649224
Population SD: 39.480199851609314
SD of sample means: 1.5883338034053167
</span></code></pre></div><img src="/build/f3e9399c2c76afaf0257c4fbc2fd0fc3.png" alt="&lt;Figure size 432x288 with 1 Axes&gt;"/></div></div><div id="ZD5nnBLNSj" class="relative group/block"><p>You can see the Central Limit Theorem in action – the histograms of the sample means are roughly normal, even though the histogram of the delays themselves is far from normal.</p><p>You can also see that each of the three histograms of the sample means is centered very close to the population mean. In each case, the “average of sample means” is very close to 16.66 minutes, the population mean. Both values are provided in the printout above each histogram. As expected, the sample mean is an unbiased estimate of the population mean.</p></div><div id="VqsGY33MDB" class="relative group/block"><h2 id="the-sd-of-all-the-sample-means" class="relative group"><span class="heading-text">The SD of All the Sample Means</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#the-sd-of-all-the-sample-means" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>You can also see that the histograms get narrower, and hence taller, as the sample size increases. We have seen that before, but now we will pay closer attention to the measure of spread.</p><p>The SD of the population of all delays is about 40 minutes.</p></div><div id="Pb9alONPud" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">pop_sd = np.std(delay.column(&#x27;Delay&#x27;))
pop_sd</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="Lg03Dz193qI6l4JOWbHMc" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><div class="font-mono text-sm whitespace-pre-wrap"><code><span>39.480199851609314</span></code></div></div></div><div id="uc2A2E9NOt" class="relative group/block"><p>Take a look at the SDs in the sample mean histograms above. In all three of them, the SD of the population of delays is about 40 minutes, because all the samples were taken from the same population.</p><p>Now look at the SD of all 10,000 sample means, when the sample size is 100. That SD is about one-tenth of the population SD. When the sample size is 400, the SD of all the sample means is about one-twentieth of the population SD. When the sample size is 625, the SD of the sample means is about one-twentyfifth of the population SD.</p><p>It seems like a good idea to compare the SD of the empirical distribution of the sample means to the quantity “population SD divided by the square root of the sample size.”</p></div><div id="aihyTF0ocB" class="relative group/block"><p>Here are the numerical values. For each sample size in the first column, 10,000 random samples of that size were drawn, and the 10,000 sample means were calculated. The second column contains the SD of those 10,000 sample means. The third column contains the result of the calculation “population SD divided by the square root of the sample size.”</p><p>The cell takes a while to run, as it’s a large simulation. But you’ll soon see that it’s worth the wait.</p></div><div id="ZAwQwHMIzR" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">repetitions = 10000
sample_sizes = np.arange(25, 626, 25)

sd_means = make_array()

for n in sample_sizes:
    means = make_array()
    for i in np.arange(repetitions):
        means = np.append(means, np.mean(delay.sample(n).column(&#x27;Delay&#x27;)))
    sd_means = np.append(sd_means, np.std(means))

sd_comparison = Table().with_columns(
    &#x27;Sample Size n&#x27;, sample_sizes,
    &#x27;SD of 10,000 Sample Means&#x27;, sd_means,
    &#x27;pop_sd/sqrt(n)&#x27;, pop_sd/np.sqrt(sample_sizes)
)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="xiBk3Uj9uNYS8PPFMBx6V" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="awDcvKXhJw" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">sd_comparison</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="RPLSulRChJrmq-AbL4cn7" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><div><div class="p-2.5">Loading...</div></div></div></div><div id="jIm4c7TyVQ" class="relative group/block"><p>The values in the second and third columns are very close. If we plot each of those columns with the sample size on the horizontal axis, the two graphs are essentially indistinguishable.</p></div><div id="qUUxq9DSyI" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">sd_comparison.plot(&#x27;Sample Size n&#x27;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="1e3FtvtWtut4rZ0i0DFCF" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><img src="/build/0dd6de7f277a81b6f9a8abb7af80785a.png" alt="&lt;Figure size 432x288 with 1 Axes&gt;"/></div></div><div id="HRm5yzBVyN" class="relative group/block"><p>There really are two curves there. But they are so close to each other that it looks as though there is just one.</p><p>What we are seeing is an instance of a general result. Remember that the graph above is based on 10,000 replications for each sample size. But there are many more than 10,000 samples of each size. The probability distribution of the sample mean is based on the means of <em>all possible samples</em> of a fixed size.</p><p><strong>Fix a sample size.</strong> If the samples are drawn at random with replacement from the population, then</p><div id="U5HDtfA38B" class="flex my-5 group"><div class="flex-grow overflow-x-auto overflow-y-hidden"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>SD of all possible sample means </mtext><mo>=</mo><mtext> </mtext><mfrac><mtext>Population SD</mtext><msqrt><mtext>sample size</mtext></msqrt></mfrac></mrow><annotation encoding="application/x-tex">{\mbox{SD of all possible sample means}} ~=~
\frac{\mbox{Population SD}}{\sqrt{\mbox{sample size}}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.3014em;vertical-align:-0.93em;"></span><span class="mord"><span class="mord text"><span class="mord">SD of all possible sample means</span></span></span><span class="mspace nobreak"> </span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace nobreak"> </span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.275em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.835em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord text"><span class="mord">sample size</span></span></span></span><span style="top:-2.795em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg xmlns="http://www.w3.org/2000/svg" width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.205em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord">Population SD</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></div><div class="relative self-center flex-none pl-2 m-0 text-right select-none"><a class="no-underline text-inherit hover:text-inherit text-inherit hover:text-inherit select-none hover:underline" href="#U5HDtfA38B" title="Link to this Equation" aria-label="Link to this Equation">(<!-- -->1<!-- -->)</a></div></div><p>This is the standard deviation of the averages of all the possible samples that could be drawn. <strong>It measures roughly how far off the sample means are from the population mean.</strong></p></div><div id="fnsacGfZtw" class="relative group/block"><h2 id="the-central-limit-theorem-for-the-sample-mean" class="relative group"><span class="heading-text">The Central Limit Theorem for the Sample Mean</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#the-central-limit-theorem-for-the-sample-mean" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>If you draw a large random sample with replacement from a population, then, regardless of the distribution of the population, the probability distribution of the sample mean is roughly normal, centered at the population mean, with an SD equal to the population SD divided by the square root of the sample size.</p></div><div id="deDTVB8vIm" class="relative group/block"><h2 id="the-accuracy-of-the-sample-mean" class="relative group"><span class="heading-text">The Accuracy of the Sample Mean</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#the-accuracy-of-the-sample-mean" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>The SD of all possible sample means measures how variable the sample mean can be. As such, it is taken as a measure of the accuracy of the sample mean as an estimate of the population mean. The smaller the SD, the more accurate the estimate.</p><p>The formula shows that:</p><ul><li><p>The population size doesn’t affect the accuracy of the sample mean. The population size doesn’t appear anywhere in the formula.</p></li><li><p>The population SD is a constant; it’s the same for every sample drawn from the population. The sample size can be varied. Because the sample size appears in the denominator, the variability of the sample mean <em>decreases</em> as the sample size increases, and hence the accuracy increases.</p></li></ul></div><div id="eZnzfZuNq5" class="relative group/block"><h2 id="the-square-root-law" class="relative group"><span class="heading-text">The Square Root Law</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#the-square-root-law" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>From the table of SD comparisons, you can see that the SD of the means of random samples of 25 flight delays is about 8 minutes. If you multiply the sample size by 4, you’ll get samples of size 100. The SD of the means of all of those samples is about 4 minutes. That’s smaller than 8 minutes, but it’s not 4 times as small; it’s only 2 times as small. That’s because the sample size in the denominator has a square root over it. The sample size increased by a factor of 4, but the SD went down by a factor of <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mo>=</mo><msqrt><mn>4</mn></msqrt></mrow><annotation encoding="application/x-tex">2 = \sqrt{4}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.04em;vertical-align:-0.1328em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9072em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord">4</span></span></span><span style="top:-2.8672em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg xmlns="http://www.w3.org/2000/svg" width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1328em;"><span></span></span></span></span></span></span></span></span></span>. In other words, the accuracy went up by a factor of <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mo>=</mo><msqrt><mn>4</mn></msqrt></mrow><annotation encoding="application/x-tex">2 = \sqrt{4}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.04em;vertical-align:-0.1328em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9072em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord">4</span></span></span><span style="top:-2.8672em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg xmlns="http://www.w3.org/2000/svg" width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1328em;"><span></span></span></span></span></span></span></span></span></span>.</p><p>In general, when you multiply the sample size by a factor, the accuracy of the sample mean goes up by the square root of that factor.</p><p>So to increase accuracy by a factor of 10, you have to multiply sample size by a factor of 100. Accuracy doesn’t come cheap!</p></div><div></div><div class="flex pt-10 mb-10 space-x-4"><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/chapters/14/4/central-limit-theorem"><div class="flex h-full align-middle"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:-translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M10.5 19.5 3 12m0 0 7.5-7.5M3 12h18"></path></svg><div class="flex-grow text-right"><div class="text-xs text-gray-500 dark:text-gray-400">Computational and Inferential Thinking</div>The Central Limit Theorem</div></div></a><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/chapters/14/6/choosing-a-sample-size"><div class="flex h-full align-middle"><div class="flex-grow"><div class="text-xs text-gray-500 dark:text-gray-400">Computational and Inferential Thinking</div>Choosing a Sample Size</div><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 4.5 21 12m0 0-7.5 7.5M21 12H3"></path></svg></div></a></div></article></main><footer class="article footer article-grid bg-white dark:bg-slate-950 mt-10 shadow-2xl shadow py-10"><p>By Ani Adhikari and John DeNero and David Wagner</p><p><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>©</mtext></mrow><annotation encoding="application/x-tex">\copyright</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;"></span><span class="mord text"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8889em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">c</span></span></span><span style="top:-3.1944em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body accent-full" style="left:0em;top:.2em;"><span class="mord">◯</span></span></span></span></span></span></span></span></span></span></span></span> Copyright 2022.</p></footer><script>((a,d)=>{if(!window.history.state||!window.history.state.key){let h=Math.random().toString(32).slice(2);window.history.replaceState({key:h},"")}try{let f=JSON.parse(sessionStorage.getItem(a)||"{}")[d||window.history.state.key];typeof f=="number"&&window.scrollTo(0,f)}catch(h){console.error(h),sessionStorage.removeItem(a)}})("positions", null)</script><link rel="modulepreload" href="/build/entry.client-UNPC4GT3.js"/><link rel="modulepreload" href="/build/_shared/chunk-OCTKKCIL.js"/><link rel="modulepreload" href="/build/_shared/chunk-UAI5KRM7.js"/><link rel="modulepreload" href="/build/_shared/chunk-2NH4LW52.js"/><link rel="modulepreload" href="/build/_shared/chunk-F7G67JTZ.js"/><link rel="modulepreload" href="/build/_shared/chunk-HBJK6BW3.js"/><link rel="modulepreload" href="/build/_shared/chunk-HYMQ7M2K.js"/><link rel="modulepreload" href="/build/_shared/chunk-OHOXABTA.js"/><link rel="modulepreload" href="/build/_shared/chunk-OCWQY3HK.js"/><link rel="modulepreload" href="/build/_shared/chunk-CPTH56EW.js"/><link rel="modulepreload" href="/build/_shared/chunk-3CVK3PYF.js"/><link rel="modulepreload" href="/build/_shared/chunk-J6FHCSRC.js"/><link rel="modulepreload" href="/build/_shared/chunk-S4SWV34C.js"/><link rel="modulepreload" href="/build/_shared/chunk-GUCIBHGO.js"/><link rel="modulepreload" href="/build/root-7TUVC4ZT.js"/><link rel="modulepreload" href="/build/_shared/chunk-INOWNUZ6.js"/><link rel="modulepreload" href="/build/routes/$-P6PGXPYX.js"/><script>window.__remixContext = {"url":"/chapters/14/5/variability-of-the-sample-mean","state":{"loaderData":{"root":{"config":{"version":2,"myst":"1.6.4","options":{"favicon":"/build/favicon-c4f2b8aed06e197b8d58618bb6206e83.ico","logo":"/build/data8logo-e8cfc0153f6b4ee7c43c8a236cd746b7.png","logo_text":"Computational and Inferential Thinking","analytics_google":"UA-148221575-1","folders":true},"parts":{"footer":{"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"By Ani Adhikari and John DeNero and David Wagner","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"RZclvp7Rn8"}],"key":"jK7sCWllhj"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"inlineMath","value":"\\copyright","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmtext\u003e©\u003c/mtext\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\copyright\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8889em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord accent\"\u003e\u003cspan class=\"vlist-t\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.8889em;\"\u003e\u003cspan style=\"top:-3em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord\"\u003ec\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.1944em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"accent-body accent-full\" style=\"left:0em;top:.2em;\"\u003e\u003cspan class=\"mord\"\u003e◯\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"UxkpBDWPQV"},{"type":"text","value":" Copyright 2022.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"u7cKahkOqv"}],"key":"xUWs7fjphd"}],"key":"UMiTSje0IS"}],"key":"Dyvcg77WlN"},"frontmatter":{"parts":{},"license":{"content":{"id":"CC-BY-NC-ND-4.0","url":"https://creativecommons.org/licenses/by-nc-nd/4.0/","name":"Creative Commons Attribution Non Commercial No Derivatives 4.0 International","CC":true}},"github":"https://github.com/data-8/textbook","numbering":{"title":{"enabled":true}},"source_url":"https://github.com/data-8/textbook/blob/main/footer.md","edit_url":"https://github.com/data-8/textbook/edit/main/footer.md","enumerator":"19"}}},"nav":[],"actions":[],"projects":[{"license":{"content":{"id":"CC-BY-NC-ND-4.0","url":"https://creativecommons.org/licenses/by-nc-nd/4.0/","name":"Creative Commons Attribution Non Commercial No Derivatives 4.0 International","CC":true}},"numbering":{"title":{"enabled":true}},"title":"Computational and Inferential Thinking","authors":[{"nameParsed":{"literal":"Ani Adhikari","given":"Ani","family":"Adhikari"},"name":"Ani Adhikari","id":"contributors-myst-generated-uid-0"},{"nameParsed":{"literal":"John DeNero","given":"John","family":"DeNero"},"name":"John DeNero","id":"contributors-myst-generated-uid-1"},{"nameParsed":{"literal":"David Wagner","given":"David","family":"Wagner"},"name":"David Wagner","id":"contributors-myst-generated-uid-2"}],"github":"https://github.com/data-8/textbook","toc":[{"file":"chapters/intro.md"},{"children":[{"children":[{"file":"chapters/01/1/1/computational-tools.md"},{"file":"chapters/01/1/2/statistical-techniques.md"}],"file":"chapters/01/1/intro.md"},{"file":"chapters/01/2/why-data-science.md"},{"children":[{"file":"chapters/01/3/1/Literary_Characters.ipynb"},{"file":"chapters/01/3/2/Another_Kind_Of_Character.ipynb"}],"file":"chapters/01/3/Plotting_the_Classics.ipynb"}],"file":"chapters/01/what-is-data-science.md"},{"children":[{"file":"chapters/02/1/observation-and-visualization-john-snow-and-the-broad-street-pump.md","title":"John Snow and the Broad Street Pump"},{"file":"chapters/02/2/snow-s-grand-experiment.md"},{"file":"chapters/02/3/establishing-causality.md"},{"file":"chapters/02/4/randomization.md"},{"file":"chapters/02/5/endnote.md"}],"file":"chapters/02/causality-and-experiments.md"},{"children":[{"file":"chapters/03/1/Expressions.ipynb"},{"children":[{"file":"chapters/03/2/1/Growth.ipynb"}],"file":"chapters/03/2/Names.ipynb"},{"file":"chapters/03/3/Calls.ipynb"},{"file":"chapters/03/4/Introduction_to_Tables.ipynb"}],"file":"chapters/03/programming-in-python.md"},{"children":[{"file":"chapters/04/1/Numbers.ipynb"},{"children":[{"file":"chapters/04/2/1/String_Methods.ipynb"}],"file":"chapters/04/2/Strings.ipynb"},{"file":"chapters/04/3/Comparison.ipynb"}],"file":"chapters/04/Data_Types.ipynb"},{"children":[{"file":"chapters/05/1/Arrays.ipynb"},{"file":"chapters/05/2/Ranges.ipynb"},{"file":"chapters/05/3/More_on_Arrays.ipynb"}],"file":"chapters/05/Sequences.ipynb"},{"children":[{"file":"chapters/06/1/Sorting_Rows.ipynb"},{"file":"chapters/06/2/Selecting_Rows.ipynb"},{"file":"chapters/06/3/Example_Population_Trends.ipynb"},{"file":"chapters/06/4/Example_Sex_Ratios.ipynb"}],"file":"chapters/06/Tables.ipynb"},{"children":[{"file":"chapters/07/1/Visualizing_Categorical_Distributions.ipynb"},{"file":"chapters/07/2/Visualizing_Numerical_Distributions.ipynb"},{"file":"chapters/07/3/Overlaid_Graphs.ipynb"}],"file":"chapters/07/Visualization.ipynb"},{"children":[{"file":"chapters/08/1/Applying_a_Function_to_a_Column.ipynb"},{"file":"chapters/08/2/Classifying_by_One_Variable.ipynb"},{"file":"chapters/08/3/Cross-Classifying_by_More_than_One_Variable.ipynb"},{"file":"chapters/08/4/Joining_Tables_by_Columns.ipynb"},{"file":"chapters/08/5/Bike_Sharing_in_the_Bay_Area.ipynb"}],"file":"chapters/08/Functions_and_Tables.ipynb"},{"children":[{"file":"chapters/09/1/Conditional_Statements.ipynb"},{"file":"chapters/09/2/Iteration.ipynb"},{"file":"chapters/09/3/Simulation.ipynb"},{"file":"chapters/09/4/Monty_Hall_Problem.ipynb"},{"file":"chapters/09/5/Finding_Probabilities.ipynb"}],"file":"chapters/09/Randomness.ipynb"},{"children":[{"file":"chapters/10/1/Empirical_Distributions.ipynb"},{"file":"chapters/10/2/Sampling_from_a_Population.ipynb"},{"file":"chapters/10/3/Empirical_Distribution_of_a_Statistic.ipynb"},{"file":"chapters/10/4/Random_Sampling_in_Python.ipynb"}],"file":"chapters/10/Sampling_and_Empirical_Distributions.ipynb"},{"children":[{"file":"chapters/11/1/Assessing_a_Model.ipynb"},{"file":"chapters/11/2/Multiple_Categories.ipynb"},{"file":"chapters/11/3/Decisions_and_Uncertainty.ipynb"},{"file":"chapters/11/4/Error_Probabilities.ipynb"}],"file":"chapters/11/Testing_Hypotheses.md"},{"children":[{"file":"chapters/12/1/AB_Testing.ipynb"},{"file":"chapters/12/2/Causality.ipynb"},{"file":"chapters/12/3/Deflategate.ipynb"}],"file":"chapters/12/Comparing_Two_Samples.md"},{"children":[{"file":"chapters/13/1/Percentiles.ipynb"},{"file":"chapters/13/2/Bootstrap.ipynb"},{"file":"chapters/13/3/Confidence_Intervals.ipynb"},{"file":"chapters/13/4/Using_Confidence_Intervals.ipynb"}],"file":"chapters/13/Estimation.md"},{"children":[{"file":"chapters/14/1/Properties_of_the_Mean.ipynb"},{"file":"chapters/14/2/Variability.ipynb"},{"file":"chapters/14/3/SD_and_the_Normal_Curve.ipynb"},{"file":"chapters/14/4/Central_Limit_Theorem.ipynb"},{"file":"chapters/14/5/Variability_of_the_Sample_Mean.ipynb"},{"file":"chapters/14/6/Choosing_a_Sample_Size.ipynb"}],"file":"chapters/14/Why_the_Mean_Matters.md"},{"children":[{"file":"chapters/15/1/Correlation.ipynb"},{"file":"chapters/15/2/Regression_Line.ipynb"},{"file":"chapters/15/3/Method_of_Least_Squares.ipynb"},{"file":"chapters/15/4/Least_Squares_Regression.ipynb"},{"file":"chapters/15/5/Visual_Diagnostics.ipynb"},{"file":"chapters/15/6/Numerical_Diagnostics.ipynb"}],"file":"chapters/15/Prediction.ipynb"},{"children":[{"file":"chapters/16/1/Regression_Model.ipynb"},{"file":"chapters/16/2/Inference_for_the_True_Slope.ipynb"},{"file":"chapters/16/3/Prediction_Intervals.ipynb"}],"file":"chapters/16/Inference_for_Regression.md"},{"children":[{"file":"chapters/17/1/Nearest_Neighbors.ipynb"},{"file":"chapters/17/2/Training_and_Testing.ipynb"},{"file":"chapters/17/3/Rows_of_Tables.ipynb"},{"file":"chapters/17/4/Implementing_the_Classifier.ipynb"},{"file":"chapters/17/5/Accuracy_of_the_Classifier.ipynb"},{"file":"chapters/17/6/Multiple_Regression.ipynb"}],"file":"chapters/17/Classification.md"},{"children":[{"file":"chapters/18/1/More_Likely_than_Not_Binary_Classifier.ipynb"},{"file":"chapters/18/2/Making_Decisions.ipynb"}],"file":"chapters/18/Updating_Predictions.md"}],"exports":[],"bibliography":[],"index":"index","pages":[{"slug":"chapters.01.what-is-data-science","title":"What is Data Science?","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"1"},{"slug":"chapters.01.1.intro","title":"Introduction","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.1"},{"slug":"chapters.01.1.1.computational-tools","title":"Computational Tools","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.1.1"},{"slug":"chapters.01.1.2.statistical-techniques","title":"Statistical Techniques","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.1.2"},{"slug":"chapters.01.2.why-data-science","title":"Why Data Science?","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.2"},{"slug":"chapters.01.3.plotting-the-classics","title":"Plotting the Classics","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.3"},{"slug":"chapters.01.3.1.literary-characters","title":"Literary Characters","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.3.1"},{"slug":"chapters.01.3.2.another-kind-of-character","title":"Another Kind of Character","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.3.2"},{"slug":"chapters.02.causality-and-experiments","title":"Causality and Experiments","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"2"},{"slug":"chapters.02.1.observation-and-visualization-john-snow-and-the-br","title":"Observation and Visualization: John Snow and the Broad Street Pump","description":"","date":"","thumbnail":"/build/snow_map-173b7e139b34475013f936d7cc85190c.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.1"},{"slug":"chapters.02.2.snow-s-grand-experiment","title":"Snow’s “Grand Experiment”","description":"","date":"","thumbnail":"/build/snow_map2-2d1199802166135b288a87da3c7a04d2.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.2"},{"slug":"chapters.02.3.establishing-causality","title":"Establishing Causality","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.3"},{"slug":"chapters.02.4.randomization","title":"Randomization","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.4"},{"slug":"chapters.02.5.endnote","title":"Endnote","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.5"},{"slug":"chapters.03.programming-in-python","title":"Programming in Python","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"3"},{"slug":"chapters.03.1.expressions","title":"Expressions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.1"},{"slug":"chapters.03.2.names","title":"Names","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.2"},{"slug":"chapters.03.2.1.growth","title":"Example: Growth Rates","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"3.2.1"},{"slug":"chapters.03.3.calls","title":"Call Expressions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.3"},{"slug":"chapters.03.4.introduction-to-tables","title":"Introduction to Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.4"},{"slug":"chapters.04.data-types","title":"Data Types","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"4"},{"slug":"chapters.04.1.numbers","title":"Numbers","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.1"},{"slug":"chapters.04.2.strings","title":"Strings","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.2"},{"slug":"chapters.04.2.1.string-methods","title":"String Methods","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"4.2.1"},{"slug":"chapters.04.3.comparison","title":"Comparisons","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.3"},{"slug":"chapters.05.sequences","title":"Sequences","description":"","date":"","thumbnail":"/build/global-land-TMAX-Tre-0259f4201a417ecbdbf38a1be53cf6ef.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"5"},{"slug":"chapters.05.1.arrays","title":"Arrays","description":"","date":"","thumbnail":"/build/array_arithmetic-eb90b39844ed099ae7191bcc9214afd7.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.1"},{"slug":"chapters.05.2.ranges","title":"Ranges","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.2"},{"slug":"chapters.05.3.more-on-arrays","title":"More on Arrays","description":"","date":"","thumbnail":"/build/array_subtraction-76924b5aad7bbd046618889ad0790527.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.3"},{"slug":"chapters.06.tables","title":"Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"6"},{"slug":"chapters.06.1.sorting-rows","title":"Sorting Rows","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.1"},{"slug":"chapters.06.2.selecting-rows","title":"Selecting Rows","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.2"},{"slug":"chapters.06.3.example-population-trends","title":"Example: Population Trends","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.3"},{"slug":"chapters.06.4.example-sex-ratios","title":"Example: Sex Ratios","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.4"},{"slug":"chapters.07.visualization","title":"Visualization","description":"","date":"","thumbnail":"/build/C-3PO_droid-b8360dd37f31deba2f98e3a28f126353.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"7"},{"slug":"chapters.07.1.visualizing-categorical-distributions","title":"Visualizing Categorical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.1"},{"slug":"chapters.07.2.visualizing-numerical-distributions","title":"Visualizing Numerical Distributions","description":"","date":"","thumbnail":"/build/ipad_battery-de7d1b7f2bb0e97a5c40be90f62b6014.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.2"},{"slug":"chapters.07.3.overlaid-graphs","title":"Overlaid Graphs","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.3"},{"slug":"chapters.08.functions-and-tables","title":"Functions and Tables","description":"","date":"","thumbnail":"/build/function_definition-4f5161f5d8f15fb47dc855e8d00e57e3.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"8"},{"slug":"chapters.08.1.applying-a-function-to-a-column","title":"Applying a Function to a Column","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.1"},{"slug":"chapters.08.2.classifying-by-one-variable","title":"Classifying by One Variable","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.2"},{"slug":"chapters.08.3.cross-classifying-by-more-than-one-variable","title":"Cross-Classifying by More than One Variable","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.3"},{"slug":"chapters.08.4.joining-tables-by-columns","title":"Joining Tables by Columns","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.4"},{"slug":"chapters.08.5.bike-sharing-in-the-bay-area","title":"Bike Sharing in the Bay Area","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.5"},{"slug":"chapters.09.randomness","title":"Randomness","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"9"},{"slug":"chapters.09.1.conditional-statements","title":"Conditional Statements","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.1"},{"slug":"chapters.09.2.iteration","title":"Iteration","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.2"},{"slug":"chapters.09.3.simulation","title":"Simulation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.3"},{"slug":"chapters.09.4.monty-hall-problem","title":"The Monty Hall Problem","description":"","date":"","thumbnail":"/build/monty_hall_goat-56112fd06fb86f88a6aba432a30f7253.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.4"},{"slug":"chapters.09.5.finding-probabilities","title":"Finding Probabilities","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.5"},{"slug":"chapters.10.sampling-and-empirical-distributions","title":"Sampling and Empirical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"10"},{"slug":"chapters.10.1.empirical-distributions","title":"Empirical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.1"},{"slug":"chapters.10.2.sampling-from-a-population","title":"Sampling from a Population","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.2"},{"slug":"chapters.10.3.empirical-distribution-of-a-statistic","title":"Empirical Distribution of a Statistic","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.3"},{"slug":"chapters.10.4.random-sampling-in-python","title":"Random Sampling in Python","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.4"},{"slug":"chapters.11.testing-hypotheses","title":"Testing Hypotheses","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"11"},{"slug":"chapters.11.1.assessing-a-model","title":"Assessing a Model","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.1"},{"slug":"chapters.11.2.multiple-categories","title":"Multiple Categories","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.2"},{"slug":"chapters.11.3.decisions-and-uncertainty","title":"Decisions and Uncertainty","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.3"},{"slug":"chapters.11.4.error-probabilities","title":"Error Probabilities","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.4"},{"slug":"chapters.12.comparing-two-samples","title":"Comparing Two Samples","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"12"},{"slug":"chapters.12.1.ab-testing","title":"A/B Testing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.1"},{"slug":"chapters.12.2.causality","title":"Causality","description":"","date":"","thumbnail":"/build/causality1-2e59fee82f936dc1e42a61601a813557.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.2"},{"slug":"chapters.12.3.deflategate","title":"Deflategate","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.3"},{"slug":"chapters.13.estimation","title":"Estimation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"13"},{"slug":"chapters.13.1.percentiles","title":"Percentiles","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.1"},{"slug":"chapters.13.2.bootstrap","title":"The Bootstrap","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.2"},{"slug":"chapters.13.3.confidence-intervals","title":"Confidence Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.3"},{"slug":"chapters.13.4.using-confidence-intervals","title":"Using Confidence Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.4"},{"slug":"chapters.14.why-the-mean-matters","title":"Why the Mean Matters","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"14"},{"slug":"chapters.14.1.properties-of-the-mean","title":"Properties of the Mean","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.1"},{"slug":"chapters.14.2.variability","title":"Variability","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.2"},{"slug":"chapters.14.3.sd-and-the-normal-curve","title":"The SD and the Normal Curve","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.3"},{"slug":"chapters.14.4.central-limit-theorem","title":"The Central Limit Theorem","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.4"},{"slug":"chapters.14.5.variability-of-the-sample-mean","title":"The Variability of the Sample Mean","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.5"},{"slug":"chapters.14.6.choosing-a-sample-size","title":"Choosing a Sample Size","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.6"},{"slug":"chapters.15.prediction","title":"Prediction","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"15"},{"slug":"chapters.15.1.correlation","title":"Correlation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.1"},{"slug":"chapters.15.2.regression-line","title":"The Regression Line","description":"","date":"","thumbnail":"/build/regline-6275539e16b9f1a5de8876a751e967a6.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.2"},{"slug":"chapters.15.3.method-of-least-squares","title":"The Method of Least Squares","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.3"},{"slug":"chapters.15.4.least-squares-regression","title":"Least Squares Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.4"},{"slug":"chapters.15.5.visual-diagnostics","title":"Visual Diagnostics","description":"","date":"","thumbnail":"/build/5f819b0045c6e81a4265dd506d7aaff9.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.5"},{"slug":"chapters.15.6.numerical-diagnostics","title":"Numerical Diagnostics","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.6"},{"slug":"chapters.16.inference-for-regression","title":"Inference for Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"16"},{"slug":"chapters.16.1.regression-model","title":"A Regression Model","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.1"},{"slug":"chapters.16.2.inference-for-the-true-slope","title":"Inference for the True Slope","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.2"},{"slug":"chapters.16.3.prediction-intervals","title":"Prediction Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.3"},{"slug":"chapters.17.classification","title":"Classification","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"17"},{"slug":"chapters.17.1.nearest-neighbors","title":"Nearest Neighbors","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.1"},{"slug":"chapters.17.2.training-and-testing","title":"Training and Testing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.2"},{"slug":"chapters.17.3.rows-of-tables","title":"Rows of Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.3"},{"slug":"chapters.17.4.implementing-the-classifier","title":"Implementing the Classifier","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.4"},{"slug":"chapters.17.5.accuracy-of-the-classifier","title":"The Accuracy of the Classifier","description":"","date":"","thumbnail":"/build/5e548385d4da863b59d51148bd5d0eeb.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.5"},{"slug":"chapters.17.6.multiple-regression","title":"Multiple Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.6"},{"slug":"chapters.18.updating-predictions","title":"Updating Predictions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"18"},{"slug":"chapters.18.1.more-likely-than-not-binary-classifier","title":"A “More Likely Than Not” Binary Classifier","description":"","date":"","thumbnail":"/build/tree_students-17a4ad5b4b4daa4f20ca9bf6c8b9a90d.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"18.1"},{"slug":"chapters.18.2.making-decisions","title":"Making Decisions","description":"","date":"","thumbnail":"/build/tree_disease_rare-6392a369221abe1c7bdffbd913bcb033.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"18.2"}]}]},"CONTENT_CDN_PORT":"3100","MODE":"static"},"routes/$":{"config":{"version":2,"myst":"1.6.4","options":{"favicon":"/build/favicon-c4f2b8aed06e197b8d58618bb6206e83.ico","logo":"/build/data8logo-e8cfc0153f6b4ee7c43c8a236cd746b7.png","logo_text":"Computational and Inferential Thinking","analytics_google":"UA-148221575-1","folders":true},"parts":{"footer":{"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"By Ani Adhikari and John DeNero and David Wagner","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"RZclvp7Rn8"}],"key":"jK7sCWllhj"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"inlineMath","value":"\\copyright","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmtext\u003e©\u003c/mtext\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\copyright\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8889em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord accent\"\u003e\u003cspan class=\"vlist-t\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.8889em;\"\u003e\u003cspan style=\"top:-3em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord\"\u003ec\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.1944em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"accent-body accent-full\" style=\"left:0em;top:.2em;\"\u003e\u003cspan class=\"mord\"\u003e◯\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"UxkpBDWPQV"},{"type":"text","value":" Copyright 2022.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"u7cKahkOqv"}],"key":"xUWs7fjphd"}],"key":"UMiTSje0IS"}],"key":"Dyvcg77WlN"},"frontmatter":{"parts":{},"license":{"content":{"id":"CC-BY-NC-ND-4.0","url":"https://creativecommons.org/licenses/by-nc-nd/4.0/","name":"Creative Commons Attribution Non Commercial No Derivatives 4.0 International","CC":true}},"github":"https://github.com/data-8/textbook","numbering":{"title":{"enabled":true}},"source_url":"https://github.com/data-8/textbook/blob/main/footer.md","edit_url":"https://github.com/data-8/textbook/edit/main/footer.md","enumerator":"19"}}},"nav":[],"actions":[],"projects":[{"license":{"content":{"id":"CC-BY-NC-ND-4.0","url":"https://creativecommons.org/licenses/by-nc-nd/4.0/","name":"Creative Commons Attribution Non Commercial No Derivatives 4.0 International","CC":true}},"numbering":{"title":{"enabled":true}},"title":"Computational and Inferential Thinking","authors":[{"nameParsed":{"literal":"Ani Adhikari","given":"Ani","family":"Adhikari"},"name":"Ani Adhikari","id":"contributors-myst-generated-uid-0"},{"nameParsed":{"literal":"John DeNero","given":"John","family":"DeNero"},"name":"John DeNero","id":"contributors-myst-generated-uid-1"},{"nameParsed":{"literal":"David Wagner","given":"David","family":"Wagner"},"name":"David Wagner","id":"contributors-myst-generated-uid-2"}],"github":"https://github.com/data-8/textbook","toc":[{"file":"chapters/intro.md"},{"children":[{"children":[{"file":"chapters/01/1/1/computational-tools.md"},{"file":"chapters/01/1/2/statistical-techniques.md"}],"file":"chapters/01/1/intro.md"},{"file":"chapters/01/2/why-data-science.md"},{"children":[{"file":"chapters/01/3/1/Literary_Characters.ipynb"},{"file":"chapters/01/3/2/Another_Kind_Of_Character.ipynb"}],"file":"chapters/01/3/Plotting_the_Classics.ipynb"}],"file":"chapters/01/what-is-data-science.md"},{"children":[{"file":"chapters/02/1/observation-and-visualization-john-snow-and-the-broad-street-pump.md","title":"John Snow and the Broad Street Pump"},{"file":"chapters/02/2/snow-s-grand-experiment.md"},{"file":"chapters/02/3/establishing-causality.md"},{"file":"chapters/02/4/randomization.md"},{"file":"chapters/02/5/endnote.md"}],"file":"chapters/02/causality-and-experiments.md"},{"children":[{"file":"chapters/03/1/Expressions.ipynb"},{"children":[{"file":"chapters/03/2/1/Growth.ipynb"}],"file":"chapters/03/2/Names.ipynb"},{"file":"chapters/03/3/Calls.ipynb"},{"file":"chapters/03/4/Introduction_to_Tables.ipynb"}],"file":"chapters/03/programming-in-python.md"},{"children":[{"file":"chapters/04/1/Numbers.ipynb"},{"children":[{"file":"chapters/04/2/1/String_Methods.ipynb"}],"file":"chapters/04/2/Strings.ipynb"},{"file":"chapters/04/3/Comparison.ipynb"}],"file":"chapters/04/Data_Types.ipynb"},{"children":[{"file":"chapters/05/1/Arrays.ipynb"},{"file":"chapters/05/2/Ranges.ipynb"},{"file":"chapters/05/3/More_on_Arrays.ipynb"}],"file":"chapters/05/Sequences.ipynb"},{"children":[{"file":"chapters/06/1/Sorting_Rows.ipynb"},{"file":"chapters/06/2/Selecting_Rows.ipynb"},{"file":"chapters/06/3/Example_Population_Trends.ipynb"},{"file":"chapters/06/4/Example_Sex_Ratios.ipynb"}],"file":"chapters/06/Tables.ipynb"},{"children":[{"file":"chapters/07/1/Visualizing_Categorical_Distributions.ipynb"},{"file":"chapters/07/2/Visualizing_Numerical_Distributions.ipynb"},{"file":"chapters/07/3/Overlaid_Graphs.ipynb"}],"file":"chapters/07/Visualization.ipynb"},{"children":[{"file":"chapters/08/1/Applying_a_Function_to_a_Column.ipynb"},{"file":"chapters/08/2/Classifying_by_One_Variable.ipynb"},{"file":"chapters/08/3/Cross-Classifying_by_More_than_One_Variable.ipynb"},{"file":"chapters/08/4/Joining_Tables_by_Columns.ipynb"},{"file":"chapters/08/5/Bike_Sharing_in_the_Bay_Area.ipynb"}],"file":"chapters/08/Functions_and_Tables.ipynb"},{"children":[{"file":"chapters/09/1/Conditional_Statements.ipynb"},{"file":"chapters/09/2/Iteration.ipynb"},{"file":"chapters/09/3/Simulation.ipynb"},{"file":"chapters/09/4/Monty_Hall_Problem.ipynb"},{"file":"chapters/09/5/Finding_Probabilities.ipynb"}],"file":"chapters/09/Randomness.ipynb"},{"children":[{"file":"chapters/10/1/Empirical_Distributions.ipynb"},{"file":"chapters/10/2/Sampling_from_a_Population.ipynb"},{"file":"chapters/10/3/Empirical_Distribution_of_a_Statistic.ipynb"},{"file":"chapters/10/4/Random_Sampling_in_Python.ipynb"}],"file":"chapters/10/Sampling_and_Empirical_Distributions.ipynb"},{"children":[{"file":"chapters/11/1/Assessing_a_Model.ipynb"},{"file":"chapters/11/2/Multiple_Categories.ipynb"},{"file":"chapters/11/3/Decisions_and_Uncertainty.ipynb"},{"file":"chapters/11/4/Error_Probabilities.ipynb"}],"file":"chapters/11/Testing_Hypotheses.md"},{"children":[{"file":"chapters/12/1/AB_Testing.ipynb"},{"file":"chapters/12/2/Causality.ipynb"},{"file":"chapters/12/3/Deflategate.ipynb"}],"file":"chapters/12/Comparing_Two_Samples.md"},{"children":[{"file":"chapters/13/1/Percentiles.ipynb"},{"file":"chapters/13/2/Bootstrap.ipynb"},{"file":"chapters/13/3/Confidence_Intervals.ipynb"},{"file":"chapters/13/4/Using_Confidence_Intervals.ipynb"}],"file":"chapters/13/Estimation.md"},{"children":[{"file":"chapters/14/1/Properties_of_the_Mean.ipynb"},{"file":"chapters/14/2/Variability.ipynb"},{"file":"chapters/14/3/SD_and_the_Normal_Curve.ipynb"},{"file":"chapters/14/4/Central_Limit_Theorem.ipynb"},{"file":"chapters/14/5/Variability_of_the_Sample_Mean.ipynb"},{"file":"chapters/14/6/Choosing_a_Sample_Size.ipynb"}],"file":"chapters/14/Why_the_Mean_Matters.md"},{"children":[{"file":"chapters/15/1/Correlation.ipynb"},{"file":"chapters/15/2/Regression_Line.ipynb"},{"file":"chapters/15/3/Method_of_Least_Squares.ipynb"},{"file":"chapters/15/4/Least_Squares_Regression.ipynb"},{"file":"chapters/15/5/Visual_Diagnostics.ipynb"},{"file":"chapters/15/6/Numerical_Diagnostics.ipynb"}],"file":"chapters/15/Prediction.ipynb"},{"children":[{"file":"chapters/16/1/Regression_Model.ipynb"},{"file":"chapters/16/2/Inference_for_the_True_Slope.ipynb"},{"file":"chapters/16/3/Prediction_Intervals.ipynb"}],"file":"chapters/16/Inference_for_Regression.md"},{"children":[{"file":"chapters/17/1/Nearest_Neighbors.ipynb"},{"file":"chapters/17/2/Training_and_Testing.ipynb"},{"file":"chapters/17/3/Rows_of_Tables.ipynb"},{"file":"chapters/17/4/Implementing_the_Classifier.ipynb"},{"file":"chapters/17/5/Accuracy_of_the_Classifier.ipynb"},{"file":"chapters/17/6/Multiple_Regression.ipynb"}],"file":"chapters/17/Classification.md"},{"children":[{"file":"chapters/18/1/More_Likely_than_Not_Binary_Classifier.ipynb"},{"file":"chapters/18/2/Making_Decisions.ipynb"}],"file":"chapters/18/Updating_Predictions.md"}],"exports":[],"bibliography":[],"index":"index","pages":[{"slug":"chapters.01.what-is-data-science","title":"What is Data Science?","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"1"},{"slug":"chapters.01.1.intro","title":"Introduction","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.1"},{"slug":"chapters.01.1.1.computational-tools","title":"Computational Tools","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.1.1"},{"slug":"chapters.01.1.2.statistical-techniques","title":"Statistical Techniques","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.1.2"},{"slug":"chapters.01.2.why-data-science","title":"Why Data Science?","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.2"},{"slug":"chapters.01.3.plotting-the-classics","title":"Plotting the Classics","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.3"},{"slug":"chapters.01.3.1.literary-characters","title":"Literary Characters","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.3.1"},{"slug":"chapters.01.3.2.another-kind-of-character","title":"Another Kind of Character","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.3.2"},{"slug":"chapters.02.causality-and-experiments","title":"Causality and Experiments","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"2"},{"slug":"chapters.02.1.observation-and-visualization-john-snow-and-the-br","title":"Observation and Visualization: John Snow and the Broad Street Pump","description":"","date":"","thumbnail":"/build/snow_map-173b7e139b34475013f936d7cc85190c.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.1"},{"slug":"chapters.02.2.snow-s-grand-experiment","title":"Snow’s “Grand Experiment”","description":"","date":"","thumbnail":"/build/snow_map2-2d1199802166135b288a87da3c7a04d2.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.2"},{"slug":"chapters.02.3.establishing-causality","title":"Establishing Causality","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.3"},{"slug":"chapters.02.4.randomization","title":"Randomization","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.4"},{"slug":"chapters.02.5.endnote","title":"Endnote","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.5"},{"slug":"chapters.03.programming-in-python","title":"Programming in Python","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"3"},{"slug":"chapters.03.1.expressions","title":"Expressions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.1"},{"slug":"chapters.03.2.names","title":"Names","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.2"},{"slug":"chapters.03.2.1.growth","title":"Example: Growth Rates","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"3.2.1"},{"slug":"chapters.03.3.calls","title":"Call Expressions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.3"},{"slug":"chapters.03.4.introduction-to-tables","title":"Introduction to Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.4"},{"slug":"chapters.04.data-types","title":"Data Types","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"4"},{"slug":"chapters.04.1.numbers","title":"Numbers","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.1"},{"slug":"chapters.04.2.strings","title":"Strings","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.2"},{"slug":"chapters.04.2.1.string-methods","title":"String Methods","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"4.2.1"},{"slug":"chapters.04.3.comparison","title":"Comparisons","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.3"},{"slug":"chapters.05.sequences","title":"Sequences","description":"","date":"","thumbnail":"/build/global-land-TMAX-Tre-0259f4201a417ecbdbf38a1be53cf6ef.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"5"},{"slug":"chapters.05.1.arrays","title":"Arrays","description":"","date":"","thumbnail":"/build/array_arithmetic-eb90b39844ed099ae7191bcc9214afd7.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.1"},{"slug":"chapters.05.2.ranges","title":"Ranges","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.2"},{"slug":"chapters.05.3.more-on-arrays","title":"More on Arrays","description":"","date":"","thumbnail":"/build/array_subtraction-76924b5aad7bbd046618889ad0790527.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.3"},{"slug":"chapters.06.tables","title":"Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"6"},{"slug":"chapters.06.1.sorting-rows","title":"Sorting Rows","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.1"},{"slug":"chapters.06.2.selecting-rows","title":"Selecting Rows","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.2"},{"slug":"chapters.06.3.example-population-trends","title":"Example: Population Trends","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.3"},{"slug":"chapters.06.4.example-sex-ratios","title":"Example: Sex Ratios","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.4"},{"slug":"chapters.07.visualization","title":"Visualization","description":"","date":"","thumbnail":"/build/C-3PO_droid-b8360dd37f31deba2f98e3a28f126353.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"7"},{"slug":"chapters.07.1.visualizing-categorical-distributions","title":"Visualizing Categorical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.1"},{"slug":"chapters.07.2.visualizing-numerical-distributions","title":"Visualizing Numerical Distributions","description":"","date":"","thumbnail":"/build/ipad_battery-de7d1b7f2bb0e97a5c40be90f62b6014.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.2"},{"slug":"chapters.07.3.overlaid-graphs","title":"Overlaid Graphs","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.3"},{"slug":"chapters.08.functions-and-tables","title":"Functions and Tables","description":"","date":"","thumbnail":"/build/function_definition-4f5161f5d8f15fb47dc855e8d00e57e3.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"8"},{"slug":"chapters.08.1.applying-a-function-to-a-column","title":"Applying a Function to a Column","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.1"},{"slug":"chapters.08.2.classifying-by-one-variable","title":"Classifying by One Variable","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.2"},{"slug":"chapters.08.3.cross-classifying-by-more-than-one-variable","title":"Cross-Classifying by More than One Variable","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.3"},{"slug":"chapters.08.4.joining-tables-by-columns","title":"Joining Tables by Columns","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.4"},{"slug":"chapters.08.5.bike-sharing-in-the-bay-area","title":"Bike Sharing in the Bay Area","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.5"},{"slug":"chapters.09.randomness","title":"Randomness","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"9"},{"slug":"chapters.09.1.conditional-statements","title":"Conditional Statements","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.1"},{"slug":"chapters.09.2.iteration","title":"Iteration","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.2"},{"slug":"chapters.09.3.simulation","title":"Simulation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.3"},{"slug":"chapters.09.4.monty-hall-problem","title":"The Monty Hall Problem","description":"","date":"","thumbnail":"/build/monty_hall_goat-56112fd06fb86f88a6aba432a30f7253.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.4"},{"slug":"chapters.09.5.finding-probabilities","title":"Finding Probabilities","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.5"},{"slug":"chapters.10.sampling-and-empirical-distributions","title":"Sampling and Empirical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"10"},{"slug":"chapters.10.1.empirical-distributions","title":"Empirical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.1"},{"slug":"chapters.10.2.sampling-from-a-population","title":"Sampling from a Population","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.2"},{"slug":"chapters.10.3.empirical-distribution-of-a-statistic","title":"Empirical Distribution of a Statistic","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.3"},{"slug":"chapters.10.4.random-sampling-in-python","title":"Random Sampling in Python","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.4"},{"slug":"chapters.11.testing-hypotheses","title":"Testing Hypotheses","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"11"},{"slug":"chapters.11.1.assessing-a-model","title":"Assessing a Model","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.1"},{"slug":"chapters.11.2.multiple-categories","title":"Multiple Categories","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.2"},{"slug":"chapters.11.3.decisions-and-uncertainty","title":"Decisions and Uncertainty","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.3"},{"slug":"chapters.11.4.error-probabilities","title":"Error Probabilities","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.4"},{"slug":"chapters.12.comparing-two-samples","title":"Comparing Two Samples","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"12"},{"slug":"chapters.12.1.ab-testing","title":"A/B Testing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.1"},{"slug":"chapters.12.2.causality","title":"Causality","description":"","date":"","thumbnail":"/build/causality1-2e59fee82f936dc1e42a61601a813557.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.2"},{"slug":"chapters.12.3.deflategate","title":"Deflategate","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.3"},{"slug":"chapters.13.estimation","title":"Estimation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"13"},{"slug":"chapters.13.1.percentiles","title":"Percentiles","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.1"},{"slug":"chapters.13.2.bootstrap","title":"The Bootstrap","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.2"},{"slug":"chapters.13.3.confidence-intervals","title":"Confidence Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.3"},{"slug":"chapters.13.4.using-confidence-intervals","title":"Using Confidence Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.4"},{"slug":"chapters.14.why-the-mean-matters","title":"Why the Mean Matters","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"14"},{"slug":"chapters.14.1.properties-of-the-mean","title":"Properties of the Mean","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.1"},{"slug":"chapters.14.2.variability","title":"Variability","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.2"},{"slug":"chapters.14.3.sd-and-the-normal-curve","title":"The SD and the Normal Curve","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.3"},{"slug":"chapters.14.4.central-limit-theorem","title":"The Central Limit Theorem","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.4"},{"slug":"chapters.14.5.variability-of-the-sample-mean","title":"The Variability of the Sample Mean","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.5"},{"slug":"chapters.14.6.choosing-a-sample-size","title":"Choosing a Sample Size","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.6"},{"slug":"chapters.15.prediction","title":"Prediction","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"15"},{"slug":"chapters.15.1.correlation","title":"Correlation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.1"},{"slug":"chapters.15.2.regression-line","title":"The Regression Line","description":"","date":"","thumbnail":"/build/regline-6275539e16b9f1a5de8876a751e967a6.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.2"},{"slug":"chapters.15.3.method-of-least-squares","title":"The Method of Least Squares","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.3"},{"slug":"chapters.15.4.least-squares-regression","title":"Least Squares Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.4"},{"slug":"chapters.15.5.visual-diagnostics","title":"Visual Diagnostics","description":"","date":"","thumbnail":"/build/5f819b0045c6e81a4265dd506d7aaff9.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.5"},{"slug":"chapters.15.6.numerical-diagnostics","title":"Numerical Diagnostics","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.6"},{"slug":"chapters.16.inference-for-regression","title":"Inference for Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"16"},{"slug":"chapters.16.1.regression-model","title":"A Regression Model","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.1"},{"slug":"chapters.16.2.inference-for-the-true-slope","title":"Inference for the True Slope","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.2"},{"slug":"chapters.16.3.prediction-intervals","title":"Prediction Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.3"},{"slug":"chapters.17.classification","title":"Classification","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"17"},{"slug":"chapters.17.1.nearest-neighbors","title":"Nearest Neighbors","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.1"},{"slug":"chapters.17.2.training-and-testing","title":"Training and Testing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.2"},{"slug":"chapters.17.3.rows-of-tables","title":"Rows of Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.3"},{"slug":"chapters.17.4.implementing-the-classifier","title":"Implementing the Classifier","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.4"},{"slug":"chapters.17.5.accuracy-of-the-classifier","title":"The Accuracy of the Classifier","description":"","date":"","thumbnail":"/build/5e548385d4da863b59d51148bd5d0eeb.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.5"},{"slug":"chapters.17.6.multiple-regression","title":"Multiple Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.6"},{"slug":"chapters.18.updating-predictions","title":"Updating Predictions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"18"},{"slug":"chapters.18.1.more-likely-than-not-binary-classifier","title":"A “More Likely Than Not” Binary Classifier","description":"","date":"","thumbnail":"/build/tree_students-17a4ad5b4b4daa4f20ca9bf6c8b9a90d.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"18.1"},{"slug":"chapters.18.2.making-decisions","title":"Making Decisions","description":"","date":"","thumbnail":"/build/tree_disease_rare-6392a369221abe1c7bdffbd913bcb033.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"18.2"}]}]},"page":{"version":2,"kind":"Notebook","sha256":"3ce39d512a0e13496b0ad0f88aaa446037b927e0acc827e93c70d23a05fe8793","slug":"chapters.14.5.variability-of-the-sample-mean","location":"/chapters/14/5/Variability_of_the_Sample_Mean.ipynb","dependencies":[],"frontmatter":{"title":"The Variability of the Sample Mean","content_includes_title":false,"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"license":{"content":{"id":"CC-BY-NC-ND-4.0","url":"https://creativecommons.org/licenses/by-nc-nd/4.0/","name":"Creative Commons Attribution Non Commercial No Derivatives 4.0 International","CC":true}},"github":"https://github.com/data-8/textbook","numbering":{"title":{"enabled":true,"offset":1}},"source_url":"https://github.com/data-8/textbook/blob/main/chapters/14/5/Variability_of_the_Sample_Mean.ipynb","edit_url":"https://github.com/data-8/textbook/edit/main/chapters/14/5/Variability_of_the_Sample_Mean.ipynb","enumerator":"14.5","exports":[{"format":"ipynb","filename":"Variability_of_the_Sample_Mean.ipynb","url":"/build/Variability_of_the_S-d7a0f04940b6501886ede0e232f992ad.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"By the Central Limit Theorem, the probability distribution of the mean of a large random sample is roughly normal. The bell curve is centered at the population mean. Some of the sample means are higher, and some lower, but the deviations from the population mean are roughly symmetric on either side, as we have seen repeatedly. Formally, probability theory shows that the sample mean is an ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"IXuwc52D04"},{"type":"emphasis","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"unbiased","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"RAamCmNARe"}],"key":"XkZFsFrOaP"},{"type":"text","value":" estimate of the population mean.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"nagiTbhy3e"}],"key":"di6vs6kjIu"},{"type":"paragraph","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"In our simulations, we also noticed that the means of larger samples tend to be more tightly clustered around the population mean than means of smaller samples. In this section, we will quantify the variability of the sample mean and develop a relation between the variability and the sample size.","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"nJw0wqwiRb"}],"key":"EZnlhwijOl"}],"key":"DvNnS1CU5K"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"from datascience import *\nimport numpy as np\npath_data = '../../../assets/data/'\n%matplotlib inline\nimport matplotlib.pyplot as plots\nplots.style.use('fivethirtyeight')","visibility":"remove","key":"QqWj9kONOI"},{"type":"output","id":"Ko5xBR58KjHHO-lexA3Sd","data":[],"visibility":"show","key":"hCazPKQezc"}],"visibility":"show","key":"v93aoS3VnG"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Let’s start with our table of flight delays. The mean delay is about 16.7 minutes, and the distribution of delays is skewed to the right.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"FcuVsYdDRw"}],"key":"vnC4qitYIw"}],"key":"WARkj5Qfop"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"united = Table.read_table(path_data + 'united_summer2015.csv')\ndelay = united.select('Delay')","key":"N4fylFgmQg"},{"type":"output","id":"LbJI2EfiAIYBG63SJxYyh","data":[],"key":"NHEakatDYh"}],"key":"QF8UXgqwXp"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"pop_mean = np.mean(delay.column('Delay'))\npop_mean","key":"mIfWqMAUrj"},{"type":"output","id":"wO5Tajk729jy6OJK295t3","data":[{"output_type":"execute_result","execution_count":3,"metadata":{},"data":{"text/plain":{"content":"16.658155515370705","content_type":"text/plain"}}}],"key":"zpbOMCop3M"}],"key":"eMprmg20Do"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"delay.hist(bins=np.arange(-20, 300, 10))\nplots.scatter(pop_mean, -0.0008, marker='^', color='darkblue', s=60)\nplots.ylim(-0.004, 0.04);","visibility":"remove","key":"ds57AcZ7BF"},{"type":"output","id":"PKBUAVp8QQvRKRv6M4bmM","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"09ab3e94c989e9f23f097c354a9ebb1b","path":"/build/09ab3e94c989e9f23f097c354a9ebb1b.png"},"text/plain":{"content":"\u003cFigure size 432x288 with 1 Axes\u003e","content_type":"text/plain"}}}],"visibility":"show","key":"BzhyXBIjM4"}],"visibility":"show","key":"ke9Ky5KNkl"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Now let’s take random samples and look at the probability distribution of the sample mean. As usual, we will use simulation to get an empirical approximation to this distribution.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"GlQxLMt1yu"}],"key":"Lo1xV97dan"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"We will define a function ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"p4OjP3Kpxn"},{"type":"inlineCode","value":"simulate_sample_mean","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"pacfB3UyB6"},{"type":"text","value":" to do this, because we are going to vary the sample size later. The arguments are the name of the table, the label of the column containing the variable, the sample size, and the number of simulations.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"IT1zOwgRYt"}],"key":"feKrC4GjDC"}],"key":"npEV1NEG1b"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"\"\"\"Empirical distribution of random sample means\"\"\"\n\ndef simulate_sample_mean(table, label, sample_size, repetitions):\n    \n    means = make_array()\n\n    for i in range(repetitions):\n        new_sample = table.sample(sample_size)\n        new_sample_mean = np.mean(new_sample.column(label))\n        means = np.append(means, new_sample_mean)\n\n    sample_means = Table().with_column('Sample Means', means)\n    \n    # Display empirical histogram and print all relevant quantities\n    sample_means.hist(bins=20)\n    plots.xlabel('Sample Means')\n    plots.title('Sample Size ' + str(sample_size))\n    print(\"Sample size: \", sample_size)\n    print(\"Population mean:\", np.mean(table.column(label)))\n    print(\"Average of sample means: \", np.mean(means))\n    print(\"Population SD:\", np.std(table.column(label)))\n    print(\"SD of sample means:\", np.std(means))","key":"mnVtRA99Ta"},{"type":"output","id":"CugFyAdROomdWAdNlp4XS","data":[],"key":"vtbsaLCWOx"}],"key":"bBdHYwbYGU"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Let us simulate the mean of a random sample of 100 delays, then of 400 delays, and finally of 625 delays. We will perform 10,000 repetitions of each of these process. The ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"jAp4ygqXGe"},{"type":"inlineCode","value":"xlim","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"BVnSfjIqwT"},{"type":"text","value":" and ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"SBfL7qHAWp"},{"type":"inlineCode","value":"ylim","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"DHbhOVS8zM"},{"type":"text","value":" lines set the axes consistently in all the plots for ease of comparison. You can just ignore those two lines of code in each cell.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"vscby2U9LU"}],"key":"ZufrfY84aI"}],"key":"bu7vjvsySc"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"simulate_sample_mean(delay, 'Delay', 100, 10000)\nplots.xlim(5, 35)\nplots.ylim(0, 0.25);","key":"wyCGcH0tXn"},{"type":"output","id":"40aUvVOUbJFHtEa51nG1I","data":[{"name":"stdout","output_type":"stream","text":"Sample size:  100\nPopulation mean: 16.658155515370705\nAverage of sample means:  16.672836\nPopulation SD: 39.480199851609314\nSD of sample means: 3.92467202924066\n"},{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"c579f01c266e6837f1f0c6c2f637b34b","path":"/build/c579f01c266e6837f1f0c6c2f637b34b.png"},"text/plain":{"content":"\u003cFigure size 432x288 with 1 Axes\u003e","content_type":"text/plain"}}}],"key":"iZBp6opIoE"}],"key":"E5DyfHoxTg"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"simulate_sample_mean(delay, 'Delay', 400, 10000)\nplots.xlim(5, 35)\nplots.ylim(0, 0.25);","key":"Kt8Ie3xtWf"},{"type":"output","id":"f_TCHbZKbKYcYLGcs7mxS","data":[{"name":"stdout","output_type":"stream","text":"Sample size:  400\nPopulation mean: 16.658155515370705\nAverage of sample means:  16.678091499999997\nPopulation SD: 39.480199851609314\nSD of sample means: 1.9474592014668113\n"},{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"4d3bea99393c96823895257ae8af9b56","path":"/build/4d3bea99393c96823895257ae8af9b56.png"},"text/plain":{"content":"\u003cFigure size 432x288 with 1 Axes\u003e","content_type":"text/plain"}}}],"key":"fRCBm6oyv5"}],"key":"XhhCHMt6v0"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"simulate_sample_mean(delay, 'Delay', 625, 10000)\nplots.xlim(5, 35)\nplots.ylim(0, 0.25);","key":"gXcdwQLU0Y"},{"type":"output","id":"GoiCrak-iGg0J-RQmhM4O","data":[{"name":"stdout","output_type":"stream","text":"Sample size:  625\nPopulation mean: 16.658155515370705\nAverage of sample means:  16.649224\nPopulation SD: 39.480199851609314\nSD of sample means: 1.5883338034053167\n"},{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"f3e9399c2c76afaf0257c4fbc2fd0fc3","path":"/build/f3e9399c2c76afaf0257c4fbc2fd0fc3.png"},"text/plain":{"content":"\u003cFigure size 432x288 with 1 Axes\u003e","content_type":"text/plain"}}}],"key":"lq0jW4JNdb"}],"key":"uw8f7jOsJH"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"You can see the Central Limit Theorem in action – the histograms of the sample means are roughly normal, even though the histogram of the delays themselves is far from normal.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"pX8v9QB4eE"}],"key":"wet3LX4Een"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"You can also see that each of the three histograms of the sample means is centered very close to the population mean. In each case, the “average of sample means” is very close to 16.66 minutes, the population mean. Both values are provided in the printout above each histogram. As expected, the sample mean is an unbiased estimate of the population mean.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"c2aognW88k"}],"key":"dgTqye0Smb"}],"key":"ZD5nnBLNSj"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The SD of All the Sample Means","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"OkXbSGwQ18"}],"identifier":"the-sd-of-all-the-sample-means","label":"The SD of All the Sample Means","html_id":"the-sd-of-all-the-sample-means","implicit":true,"key":"SdfdWv7ib5"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"You can also see that the histograms get narrower, and hence taller, as the sample size increases. We have seen that before, but now we will pay closer attention to the measure of spread.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"zr0pgJPOZP"}],"key":"qiQUKjqlNx"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"The SD of the population of all delays is about 40 minutes.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"gR2TW5MKla"}],"key":"FfMDwe4kdK"}],"key":"VqsGY33MDB"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"pop_sd = np.std(delay.column('Delay'))\npop_sd","key":"e7kjLik5nO"},{"type":"output","id":"Lg03Dz193qI6l4JOWbHMc","data":[{"output_type":"execute_result","execution_count":9,"metadata":{},"data":{"text/plain":{"content":"39.480199851609314","content_type":"text/plain"}}}],"key":"PGP1xDxpeR"}],"key":"Pb9alONPud"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Take a look at the SDs in the sample mean histograms above. In all three of them, the SD of the population of delays is about 40 minutes, because all the samples were taken from the same population.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"plHSyLDnEn"}],"key":"cPCgzbTDzO"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Now look at the SD of all 10,000 sample means, when the sample size is 100. That SD is about one-tenth of the population SD. When the sample size is 400, the SD of all the sample means is about one-twentieth of the population SD. When the sample size is 625, the SD of the sample means is about one-twentyfifth of the population SD.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"A5y8iEChIT"}],"key":"akPlFgy9Lm"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"It seems like a good idea to compare the SD of the empirical distribution of the sample means to the quantity “population SD divided by the square root of the sample size.”","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"N1RMING3SN"}],"key":"rVU5TXXuWs"}],"key":"uc2A2E9NOt"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Here are the numerical values. For each sample size in the first column, 10,000 random samples of that size were drawn, and the 10,000 sample means were calculated. The second column contains the SD of those 10,000 sample means. The third column contains the result of the calculation “population SD divided by the square root of the sample size.”","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"yYAvkl8LdY"}],"key":"vgFkxGbijL"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"The cell takes a while to run, as it’s a large simulation. But you’ll soon see that it’s worth the wait.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"g9UHL4gyGF"}],"key":"xn3NsdrGUA"}],"key":"aihyTF0ocB"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"repetitions = 10000\nsample_sizes = np.arange(25, 626, 25)\n\nsd_means = make_array()\n\nfor n in sample_sizes:\n    means = make_array()\n    for i in np.arange(repetitions):\n        means = np.append(means, np.mean(delay.sample(n).column('Delay')))\n    sd_means = np.append(sd_means, np.std(means))\n\nsd_comparison = Table().with_columns(\n    'Sample Size n', sample_sizes,\n    'SD of 10,000 Sample Means', sd_means,\n    'pop_sd/sqrt(n)', pop_sd/np.sqrt(sample_sizes)\n)","key":"WqSh9Kv3sj"},{"type":"output","id":"xiBk3Uj9uNYS8PPFMBx6V","data":[],"key":"iIEEVurn38"}],"key":"ZAwQwHMIzR"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"sd_comparison","key":"QbU5mDRKp6"},{"type":"output","id":"RPLSulRChJrmq-AbL4cn7","data":[{"output_type":"execute_result","execution_count":11,"metadata":{},"data":{"text/html":{"content":"\u003ctable border=\"1\" class=\"dataframe\"\u003e\n    \u003cthead\u003e\n        \u003ctr\u003e\n            \u003cth\u003eSample Size n\u003c/th\u003e \u003cth\u003eSD of 10,000 Sample Means\u003c/th\u003e \u003cth\u003epop_sd/sqrt(n)\u003c/th\u003e\n        \u003c/tr\u003e\n    \u003c/thead\u003e\n    \u003ctbody\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e25           \u003c/td\u003e \u003ctd\u003e7.94482                  \u003c/td\u003e \u003ctd\u003e7.89604       \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e50           \u003c/td\u003e \u003ctd\u003e5.6131                   \u003c/td\u003e \u003ctd\u003e5.58334       \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e75           \u003c/td\u003e \u003ctd\u003e4.57417                  \u003c/td\u003e \u003ctd\u003e4.55878       \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e100          \u003c/td\u003e \u003ctd\u003e3.98687                  \u003c/td\u003e \u003ctd\u003e3.94802       \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e125          \u003c/td\u003e \u003ctd\u003e3.49769                  \u003c/td\u003e \u003ctd\u003e3.53122       \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e150          \u003c/td\u003e \u003ctd\u003e3.22776                  \u003c/td\u003e \u003ctd\u003e3.22354       \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e175          \u003c/td\u003e \u003ctd\u003e3.00675                  \u003c/td\u003e \u003ctd\u003e2.98442       \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e200          \u003c/td\u003e \u003ctd\u003e2.77764                  \u003c/td\u003e \u003ctd\u003e2.79167       \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e225          \u003c/td\u003e \u003ctd\u003e2.64268                  \u003c/td\u003e \u003ctd\u003e2.63201       \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e250          \u003c/td\u003e \u003ctd\u003e2.49447                  \u003c/td\u003e \u003ctd\u003e2.49695       \u003c/td\u003e\n        \u003c/tr\u003e\n    \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e... (15 rows omitted)\u003c/p\u003e","content_type":"text/html"},"text/plain":{"content":"Sample Size n | SD of 10,000 Sample Means | pop_sd/sqrt(n)\n25            | 7.94482                   | 7.89604\n50            | 5.6131                    | 5.58334\n75            | 4.57417                   | 4.55878\n100           | 3.98687                   | 3.94802\n125           | 3.49769                   | 3.53122\n150           | 3.22776                   | 3.22354\n175           | 3.00675                   | 2.98442\n200           | 2.77764                   | 2.79167\n225           | 2.64268                   | 2.63201\n250           | 2.49447                   | 2.49695\n... (15 rows omitted)","content_type":"text/plain"}}}],"key":"rIrhStDUJZ"}],"key":"awDcvKXhJw"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The values in the second and third columns are very close. If we plot each of those columns with the sample size on the horizontal axis, the two graphs are essentially indistinguishable.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Q2Nrw8nHUI"}],"key":"QBM1ZixaqR"}],"key":"jIm4c7TyVQ"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"sd_comparison.plot('Sample Size n')","key":"XBc0HXZuUJ"},{"type":"output","id":"1e3FtvtWtut4rZ0i0DFCF","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"0dd6de7f277a81b6f9a8abb7af80785a","path":"/build/0dd6de7f277a81b6f9a8abb7af80785a.png"},"text/plain":{"content":"\u003cFigure size 432x288 with 1 Axes\u003e","content_type":"text/plain"}}}],"key":"u5deFHhoN1"}],"key":"qUUxq9DSyI"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"There really are two curves there. But they are so close to each other that it looks as though there is just one.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"xowmfojXwY"}],"key":"vZltj9seQd"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"What we are seeing is an instance of a general result. Remember that the graph above is based on 10,000 replications for each sample size. But there are many more than 10,000 samples of each size. The probability distribution of the sample mean is based on the means of ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"HryhE9Q6ED"},{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"all possible samples","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"ty6l0XpazE"}],"key":"L7L5cQfX1G"},{"type":"text","value":" of a fixed size.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"e6EQi1Kdkp"}],"key":"AxgQUbXPA2"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"strong","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Fix a sample size.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"dW9k9SLf03"}],"key":"B6Lr5JNeOp"},{"type":"text","value":" If the samples are drawn at random with replacement from the population, then","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"OoL5iZ3Oyr"}],"key":"zxsHoRwghH"},{"type":"math","value":"{\\mbox{SD of all possible sample means}} ~=~\n\\frac{\\mbox{Population SD}}{\\sqrt{\\mbox{sample size}}}","position":{"start":{"line":7,"column":1},"end":{"line":10,"column":1}},"html":"\u003cspan class=\"katex-display\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmtext\u003eSD of all possible sample means \u003c/mtext\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmtext\u003e \u003c/mtext\u003e\u003cmfrac\u003e\u003cmtext\u003ePopulation SD\u003c/mtext\u003e\u003cmsqrt\u003e\u003cmtext\u003esample size\u003c/mtext\u003e\u003c/msqrt\u003e\u003c/mfrac\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e{\\mbox{SD of all possible sample means}} ~=~\n\\frac{\\mbox{Population SD}}{\\sqrt{\\mbox{sample size}}}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:2.3014em;vertical-align:-0.93em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord\"\u003eSD of all possible sample means\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace nobreak\"\u003e \u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace nobreak\"\u003e \u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mopen nulldelimiter\"\u003e\u003c/span\u003e\u003cspan class=\"mfrac\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:1.3714em;\"\u003e\u003cspan style=\"top:-2.275em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord sqrt\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.835em;\"\u003e\u003cspan class=\"svg-align\" style=\"top:-3em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\" style=\"padding-left:0.833em;\"\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord\"\u003esample size\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-2.795em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'\u003e\u003cpath d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.205em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.23em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"frac-line\" style=\"border-bottom-width:0.04em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.677em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord\"\u003ePopulation SD\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.93em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose nulldelimiter\"\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","enumerator":"1","key":"U5HDtfA38B"},{"type":"paragraph","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"This is the standard deviation of the averages of all the possible samples that could be drawn. ","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"jsXfqCdZl4"},{"type":"strong","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"It measures roughly how far off the sample means are from the population mean.","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"VSEmy7FIef"}],"key":"ppoxVdkTxT"}],"key":"KpT3Sat9VK"}],"key":"HRm5yzBVyN"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The Central Limit Theorem for the Sample Mean","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"StBungEvbE"}],"identifier":"the-central-limit-theorem-for-the-sample-mean","label":"The Central Limit Theorem for the Sample Mean","html_id":"the-central-limit-theorem-for-the-sample-mean","implicit":true,"key":"xyXMOAk9lc"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"If you draw a large random sample with replacement from a population, then, regardless of the distribution of the population, the probability distribution of the sample mean is roughly normal, centered at the population mean, with an SD equal to the population SD divided by the square root of the sample size.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"oECPoku4Aq"}],"key":"m3OPqrD35u"}],"key":"fnsacGfZtw"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The Accuracy of the Sample Mean","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hQA0W2XVKQ"}],"identifier":"the-accuracy-of-the-sample-mean","label":"The Accuracy of the Sample Mean","html_id":"the-accuracy-of-the-sample-mean","implicit":true,"key":"FbVoDPH9SN"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"The SD of all possible sample means measures how variable the sample mean can be. As such, it is taken as a measure of the accuracy of the sample mean as an estimate of the population mean. The smaller the SD, the more accurate the estimate.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"PIFyT0wTGS"}],"key":"Gpq68ztTch"},{"type":"paragraph","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"The formula shows that:","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"gLp2agQOFn"}],"key":"KAWAf4K6vB"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":5,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"The population size doesn’t affect the accuracy of the sample mean. The population size doesn’t appear anywhere in the formula.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"fPXfdlz2mK"}],"key":"aZ8Ro3ClIa"}],"key":"olDrIEYr2Q"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"The population SD is a constant; it’s the same for every sample drawn from the population. The sample size can be varied. Because the sample size appears in the denominator, the variability of the sample mean ","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"sEXXwYu6gL"},{"type":"emphasis","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"decreases","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"HEpM2CKYsI"}],"key":"o95qQVEAMF"},{"type":"text","value":" as the sample size increases, and hence the accuracy increases.","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"r8pmi5JpkU"}],"key":"PLAfqxfyY7"}],"key":"Cwqhhvdtmo"}],"key":"ReAQi2Sege"}],"key":"deDTVB8vIm"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The Square Root Law","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"PqCS5BNK13"}],"identifier":"the-square-root-law","label":"The Square Root Law","html_id":"the-square-root-law","implicit":true,"key":"WS4h5ctEAb"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"From the table of SD comparisons, you can see that the SD of the means of random samples of 25 flight delays is about 8 minutes. If you multiply the sample size by 4, you’ll get samples of size 100. The SD of the means of all of those samples is about 4 minutes. That’s smaller than 8 minutes, but it’s not 4 times as small; it’s only 2 times as small. That’s because the sample size in the denominator has a square root over it. The sample size increased by a factor of 4, but the SD went down by a factor of ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"cu6MDYl92C"},{"type":"inlineMath","value":"2 = \\sqrt{4}","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e2\u003c/mn\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmsqrt\u003e\u003cmn\u003e4\u003c/mn\u003e\u003c/msqrt\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e2 = \\sqrt{4}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e2\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1.04em;vertical-align:-0.1328em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord sqrt\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.9072em;\"\u003e\u003cspan class=\"svg-align\" style=\"top:-3em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\" style=\"padding-left:0.833em;\"\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-2.8672em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'\u003e\u003cpath d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.1328em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"qasMF5w5tP"},{"type":"text","value":". In other words, the accuracy went up by a factor of ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"WPiCCsBkqV"},{"type":"inlineMath","value":"2 = \\sqrt{4}","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e2\u003c/mn\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmsqrt\u003e\u003cmn\u003e4\u003c/mn\u003e\u003c/msqrt\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e2 = \\sqrt{4}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e2\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1.04em;vertical-align:-0.1328em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord sqrt\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.9072em;\"\u003e\u003cspan class=\"svg-align\" style=\"top:-3em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\" style=\"padding-left:0.833em;\"\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-2.8672em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'\u003e\u003cpath d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.1328em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"feA6ZwBSAA"},{"type":"text","value":".","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"ECEPbH3yXd"}],"key":"ki2XWrJFwn"},{"type":"paragraph","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"In general, when you multiply the sample size by a factor, the accuracy of the sample mean goes up by the square root of that factor.","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"G34YXBdp1U"}],"key":"EZyTgPdAGK"},{"type":"paragraph","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"So to increase accuracy by a factor of 10, you have to multiply sample size by a factor of 100. Accuracy doesn’t come cheap!","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"e5dcljBVsw"}],"key":"OIa0NaFchx"}],"key":"eZnzfZuNq5"}],"key":"qdOSNuKFr7"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"The Central Limit Theorem","url":"/chapters/14/4/central-limit-theorem","group":"Computational and Inferential Thinking"},"next":{"title":"Choosing a Sample Size","url":"/chapters/14/6/choosing-a-sample-size","group":"Computational and Inferential Thinking"}}},"domain":"http://localhost:3000"},"project":{"license":{"content":{"id":"CC-BY-NC-ND-4.0","url":"https://creativecommons.org/licenses/by-nc-nd/4.0/","name":"Creative Commons Attribution Non Commercial No Derivatives 4.0 International","CC":true}},"numbering":{"title":{"enabled":true}},"title":"Computational and Inferential Thinking","authors":[{"nameParsed":{"literal":"Ani Adhikari","given":"Ani","family":"Adhikari"},"name":"Ani Adhikari","id":"contributors-myst-generated-uid-0"},{"nameParsed":{"literal":"John DeNero","given":"John","family":"DeNero"},"name":"John DeNero","id":"contributors-myst-generated-uid-1"},{"nameParsed":{"literal":"David Wagner","given":"David","family":"Wagner"},"name":"David Wagner","id":"contributors-myst-generated-uid-2"}],"github":"https://github.com/data-8/textbook","toc":[{"file":"chapters/intro.md"},{"children":[{"children":[{"file":"chapters/01/1/1/computational-tools.md"},{"file":"chapters/01/1/2/statistical-techniques.md"}],"file":"chapters/01/1/intro.md"},{"file":"chapters/01/2/why-data-science.md"},{"children":[{"file":"chapters/01/3/1/Literary_Characters.ipynb"},{"file":"chapters/01/3/2/Another_Kind_Of_Character.ipynb"}],"file":"chapters/01/3/Plotting_the_Classics.ipynb"}],"file":"chapters/01/what-is-data-science.md"},{"children":[{"file":"chapters/02/1/observation-and-visualization-john-snow-and-the-broad-street-pump.md","title":"John Snow and the Broad Street Pump"},{"file":"chapters/02/2/snow-s-grand-experiment.md"},{"file":"chapters/02/3/establishing-causality.md"},{"file":"chapters/02/4/randomization.md"},{"file":"chapters/02/5/endnote.md"}],"file":"chapters/02/causality-and-experiments.md"},{"children":[{"file":"chapters/03/1/Expressions.ipynb"},{"children":[{"file":"chapters/03/2/1/Growth.ipynb"}],"file":"chapters/03/2/Names.ipynb"},{"file":"chapters/03/3/Calls.ipynb"},{"file":"chapters/03/4/Introduction_to_Tables.ipynb"}],"file":"chapters/03/programming-in-python.md"},{"children":[{"file":"chapters/04/1/Numbers.ipynb"},{"children":[{"file":"chapters/04/2/1/String_Methods.ipynb"}],"file":"chapters/04/2/Strings.ipynb"},{"file":"chapters/04/3/Comparison.ipynb"}],"file":"chapters/04/Data_Types.ipynb"},{"children":[{"file":"chapters/05/1/Arrays.ipynb"},{"file":"chapters/05/2/Ranges.ipynb"},{"file":"chapters/05/3/More_on_Arrays.ipynb"}],"file":"chapters/05/Sequences.ipynb"},{"children":[{"file":"chapters/06/1/Sorting_Rows.ipynb"},{"file":"chapters/06/2/Selecting_Rows.ipynb"},{"file":"chapters/06/3/Example_Population_Trends.ipynb"},{"file":"chapters/06/4/Example_Sex_Ratios.ipynb"}],"file":"chapters/06/Tables.ipynb"},{"children":[{"file":"chapters/07/1/Visualizing_Categorical_Distributions.ipynb"},{"file":"chapters/07/2/Visualizing_Numerical_Distributions.ipynb"},{"file":"chapters/07/3/Overlaid_Graphs.ipynb"}],"file":"chapters/07/Visualization.ipynb"},{"children":[{"file":"chapters/08/1/Applying_a_Function_to_a_Column.ipynb"},{"file":"chapters/08/2/Classifying_by_One_Variable.ipynb"},{"file":"chapters/08/3/Cross-Classifying_by_More_than_One_Variable.ipynb"},{"file":"chapters/08/4/Joining_Tables_by_Columns.ipynb"},{"file":"chapters/08/5/Bike_Sharing_in_the_Bay_Area.ipynb"}],"file":"chapters/08/Functions_and_Tables.ipynb"},{"children":[{"file":"chapters/09/1/Conditional_Statements.ipynb"},{"file":"chapters/09/2/Iteration.ipynb"},{"file":"chapters/09/3/Simulation.ipynb"},{"file":"chapters/09/4/Monty_Hall_Problem.ipynb"},{"file":"chapters/09/5/Finding_Probabilities.ipynb"}],"file":"chapters/09/Randomness.ipynb"},{"children":[{"file":"chapters/10/1/Empirical_Distributions.ipynb"},{"file":"chapters/10/2/Sampling_from_a_Population.ipynb"},{"file":"chapters/10/3/Empirical_Distribution_of_a_Statistic.ipynb"},{"file":"chapters/10/4/Random_Sampling_in_Python.ipynb"}],"file":"chapters/10/Sampling_and_Empirical_Distributions.ipynb"},{"children":[{"file":"chapters/11/1/Assessing_a_Model.ipynb"},{"file":"chapters/11/2/Multiple_Categories.ipynb"},{"file":"chapters/11/3/Decisions_and_Uncertainty.ipynb"},{"file":"chapters/11/4/Error_Probabilities.ipynb"}],"file":"chapters/11/Testing_Hypotheses.md"},{"children":[{"file":"chapters/12/1/AB_Testing.ipynb"},{"file":"chapters/12/2/Causality.ipynb"},{"file":"chapters/12/3/Deflategate.ipynb"}],"file":"chapters/12/Comparing_Two_Samples.md"},{"children":[{"file":"chapters/13/1/Percentiles.ipynb"},{"file":"chapters/13/2/Bootstrap.ipynb"},{"file":"chapters/13/3/Confidence_Intervals.ipynb"},{"file":"chapters/13/4/Using_Confidence_Intervals.ipynb"}],"file":"chapters/13/Estimation.md"},{"children":[{"file":"chapters/14/1/Properties_of_the_Mean.ipynb"},{"file":"chapters/14/2/Variability.ipynb"},{"file":"chapters/14/3/SD_and_the_Normal_Curve.ipynb"},{"file":"chapters/14/4/Central_Limit_Theorem.ipynb"},{"file":"chapters/14/5/Variability_of_the_Sample_Mean.ipynb"},{"file":"chapters/14/6/Choosing_a_Sample_Size.ipynb"}],"file":"chapters/14/Why_the_Mean_Matters.md"},{"children":[{"file":"chapters/15/1/Correlation.ipynb"},{"file":"chapters/15/2/Regression_Line.ipynb"},{"file":"chapters/15/3/Method_of_Least_Squares.ipynb"},{"file":"chapters/15/4/Least_Squares_Regression.ipynb"},{"file":"chapters/15/5/Visual_Diagnostics.ipynb"},{"file":"chapters/15/6/Numerical_Diagnostics.ipynb"}],"file":"chapters/15/Prediction.ipynb"},{"children":[{"file":"chapters/16/1/Regression_Model.ipynb"},{"file":"chapters/16/2/Inference_for_the_True_Slope.ipynb"},{"file":"chapters/16/3/Prediction_Intervals.ipynb"}],"file":"chapters/16/Inference_for_Regression.md"},{"children":[{"file":"chapters/17/1/Nearest_Neighbors.ipynb"},{"file":"chapters/17/2/Training_and_Testing.ipynb"},{"file":"chapters/17/3/Rows_of_Tables.ipynb"},{"file":"chapters/17/4/Implementing_the_Classifier.ipynb"},{"file":"chapters/17/5/Accuracy_of_the_Classifier.ipynb"},{"file":"chapters/17/6/Multiple_Regression.ipynb"}],"file":"chapters/17/Classification.md"},{"children":[{"file":"chapters/18/1/More_Likely_than_Not_Binary_Classifier.ipynb"},{"file":"chapters/18/2/Making_Decisions.ipynb"}],"file":"chapters/18/Updating_Predictions.md"}],"exports":[],"bibliography":[],"index":"index","pages":[{"slug":"chapters.01.what-is-data-science","title":"What is Data Science?","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"1"},{"slug":"chapters.01.1.intro","title":"Introduction","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.1"},{"slug":"chapters.01.1.1.computational-tools","title":"Computational Tools","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.1.1"},{"slug":"chapters.01.1.2.statistical-techniques","title":"Statistical Techniques","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.1.2"},{"slug":"chapters.01.2.why-data-science","title":"Why Data Science?","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.2"},{"slug":"chapters.01.3.plotting-the-classics","title":"Plotting the Classics","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.3"},{"slug":"chapters.01.3.1.literary-characters","title":"Literary Characters","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.3.1"},{"slug":"chapters.01.3.2.another-kind-of-character","title":"Another Kind of Character","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.3.2"},{"slug":"chapters.02.causality-and-experiments","title":"Causality and Experiments","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"2"},{"slug":"chapters.02.1.observation-and-visualization-john-snow-and-the-br","title":"Observation and Visualization: John Snow and the Broad Street Pump","description":"","date":"","thumbnail":"/build/snow_map-173b7e139b34475013f936d7cc85190c.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.1"},{"slug":"chapters.02.2.snow-s-grand-experiment","title":"Snow’s “Grand Experiment”","description":"","date":"","thumbnail":"/build/snow_map2-2d1199802166135b288a87da3c7a04d2.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.2"},{"slug":"chapters.02.3.establishing-causality","title":"Establishing Causality","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.3"},{"slug":"chapters.02.4.randomization","title":"Randomization","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.4"},{"slug":"chapters.02.5.endnote","title":"Endnote","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.5"},{"slug":"chapters.03.programming-in-python","title":"Programming in Python","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"3"},{"slug":"chapters.03.1.expressions","title":"Expressions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.1"},{"slug":"chapters.03.2.names","title":"Names","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.2"},{"slug":"chapters.03.2.1.growth","title":"Example: Growth Rates","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"3.2.1"},{"slug":"chapters.03.3.calls","title":"Call Expressions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.3"},{"slug":"chapters.03.4.introduction-to-tables","title":"Introduction to Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.4"},{"slug":"chapters.04.data-types","title":"Data Types","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"4"},{"slug":"chapters.04.1.numbers","title":"Numbers","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.1"},{"slug":"chapters.04.2.strings","title":"Strings","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.2"},{"slug":"chapters.04.2.1.string-methods","title":"String Methods","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"4.2.1"},{"slug":"chapters.04.3.comparison","title":"Comparisons","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.3"},{"slug":"chapters.05.sequences","title":"Sequences","description":"","date":"","thumbnail":"/build/global-land-TMAX-Tre-0259f4201a417ecbdbf38a1be53cf6ef.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"5"},{"slug":"chapters.05.1.arrays","title":"Arrays","description":"","date":"","thumbnail":"/build/array_arithmetic-eb90b39844ed099ae7191bcc9214afd7.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.1"},{"slug":"chapters.05.2.ranges","title":"Ranges","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.2"},{"slug":"chapters.05.3.more-on-arrays","title":"More on Arrays","description":"","date":"","thumbnail":"/build/array_subtraction-76924b5aad7bbd046618889ad0790527.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.3"},{"slug":"chapters.06.tables","title":"Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"6"},{"slug":"chapters.06.1.sorting-rows","title":"Sorting Rows","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.1"},{"slug":"chapters.06.2.selecting-rows","title":"Selecting Rows","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.2"},{"slug":"chapters.06.3.example-population-trends","title":"Example: Population Trends","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.3"},{"slug":"chapters.06.4.example-sex-ratios","title":"Example: Sex Ratios","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.4"},{"slug":"chapters.07.visualization","title":"Visualization","description":"","date":"","thumbnail":"/build/C-3PO_droid-b8360dd37f31deba2f98e3a28f126353.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"7"},{"slug":"chapters.07.1.visualizing-categorical-distributions","title":"Visualizing Categorical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.1"},{"slug":"chapters.07.2.visualizing-numerical-distributions","title":"Visualizing Numerical Distributions","description":"","date":"","thumbnail":"/build/ipad_battery-de7d1b7f2bb0e97a5c40be90f62b6014.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.2"},{"slug":"chapters.07.3.overlaid-graphs","title":"Overlaid Graphs","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.3"},{"slug":"chapters.08.functions-and-tables","title":"Functions and Tables","description":"","date":"","thumbnail":"/build/function_definition-4f5161f5d8f15fb47dc855e8d00e57e3.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"8"},{"slug":"chapters.08.1.applying-a-function-to-a-column","title":"Applying a Function to a Column","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.1"},{"slug":"chapters.08.2.classifying-by-one-variable","title":"Classifying by One Variable","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.2"},{"slug":"chapters.08.3.cross-classifying-by-more-than-one-variable","title":"Cross-Classifying by More than One Variable","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.3"},{"slug":"chapters.08.4.joining-tables-by-columns","title":"Joining Tables by Columns","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.4"},{"slug":"chapters.08.5.bike-sharing-in-the-bay-area","title":"Bike Sharing in the Bay Area","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.5"},{"slug":"chapters.09.randomness","title":"Randomness","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"9"},{"slug":"chapters.09.1.conditional-statements","title":"Conditional Statements","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.1"},{"slug":"chapters.09.2.iteration","title":"Iteration","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.2"},{"slug":"chapters.09.3.simulation","title":"Simulation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.3"},{"slug":"chapters.09.4.monty-hall-problem","title":"The Monty Hall Problem","description":"","date":"","thumbnail":"/build/monty_hall_goat-56112fd06fb86f88a6aba432a30f7253.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.4"},{"slug":"chapters.09.5.finding-probabilities","title":"Finding Probabilities","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.5"},{"slug":"chapters.10.sampling-and-empirical-distributions","title":"Sampling and Empirical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"10"},{"slug":"chapters.10.1.empirical-distributions","title":"Empirical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.1"},{"slug":"chapters.10.2.sampling-from-a-population","title":"Sampling from a Population","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.2"},{"slug":"chapters.10.3.empirical-distribution-of-a-statistic","title":"Empirical Distribution of a Statistic","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.3"},{"slug":"chapters.10.4.random-sampling-in-python","title":"Random Sampling in Python","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.4"},{"slug":"chapters.11.testing-hypotheses","title":"Testing Hypotheses","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"11"},{"slug":"chapters.11.1.assessing-a-model","title":"Assessing a Model","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.1"},{"slug":"chapters.11.2.multiple-categories","title":"Multiple Categories","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.2"},{"slug":"chapters.11.3.decisions-and-uncertainty","title":"Decisions and Uncertainty","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.3"},{"slug":"chapters.11.4.error-probabilities","title":"Error Probabilities","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.4"},{"slug":"chapters.12.comparing-two-samples","title":"Comparing Two Samples","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"12"},{"slug":"chapters.12.1.ab-testing","title":"A/B Testing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.1"},{"slug":"chapters.12.2.causality","title":"Causality","description":"","date":"","thumbnail":"/build/causality1-2e59fee82f936dc1e42a61601a813557.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.2"},{"slug":"chapters.12.3.deflategate","title":"Deflategate","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.3"},{"slug":"chapters.13.estimation","title":"Estimation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"13"},{"slug":"chapters.13.1.percentiles","title":"Percentiles","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.1"},{"slug":"chapters.13.2.bootstrap","title":"The Bootstrap","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.2"},{"slug":"chapters.13.3.confidence-intervals","title":"Confidence Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.3"},{"slug":"chapters.13.4.using-confidence-intervals","title":"Using Confidence Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.4"},{"slug":"chapters.14.why-the-mean-matters","title":"Why the Mean Matters","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"14"},{"slug":"chapters.14.1.properties-of-the-mean","title":"Properties of the Mean","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.1"},{"slug":"chapters.14.2.variability","title":"Variability","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.2"},{"slug":"chapters.14.3.sd-and-the-normal-curve","title":"The SD and the Normal Curve","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.3"},{"slug":"chapters.14.4.central-limit-theorem","title":"The Central Limit Theorem","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.4"},{"slug":"chapters.14.5.variability-of-the-sample-mean","title":"The Variability of the Sample Mean","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.5"},{"slug":"chapters.14.6.choosing-a-sample-size","title":"Choosing a Sample Size","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.6"},{"slug":"chapters.15.prediction","title":"Prediction","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"15"},{"slug":"chapters.15.1.correlation","title":"Correlation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.1"},{"slug":"chapters.15.2.regression-line","title":"The Regression Line","description":"","date":"","thumbnail":"/build/regline-6275539e16b9f1a5de8876a751e967a6.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.2"},{"slug":"chapters.15.3.method-of-least-squares","title":"The Method of Least Squares","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.3"},{"slug":"chapters.15.4.least-squares-regression","title":"Least Squares Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.4"},{"slug":"chapters.15.5.visual-diagnostics","title":"Visual Diagnostics","description":"","date":"","thumbnail":"/build/5f819b0045c6e81a4265dd506d7aaff9.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.5"},{"slug":"chapters.15.6.numerical-diagnostics","title":"Numerical Diagnostics","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.6"},{"slug":"chapters.16.inference-for-regression","title":"Inference for Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"16"},{"slug":"chapters.16.1.regression-model","title":"A Regression Model","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.1"},{"slug":"chapters.16.2.inference-for-the-true-slope","title":"Inference for the True Slope","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.2"},{"slug":"chapters.16.3.prediction-intervals","title":"Prediction Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.3"},{"slug":"chapters.17.classification","title":"Classification","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"17"},{"slug":"chapters.17.1.nearest-neighbors","title":"Nearest Neighbors","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.1"},{"slug":"chapters.17.2.training-and-testing","title":"Training and Testing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.2"},{"slug":"chapters.17.3.rows-of-tables","title":"Rows of Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.3"},{"slug":"chapters.17.4.implementing-the-classifier","title":"Implementing the Classifier","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.4"},{"slug":"chapters.17.5.accuracy-of-the-classifier","title":"The Accuracy of the Classifier","description":"","date":"","thumbnail":"/build/5e548385d4da863b59d51148bd5d0eeb.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.5"},{"slug":"chapters.17.6.multiple-regression","title":"Multiple Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.6"},{"slug":"chapters.18.updating-predictions","title":"Updating Predictions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"18"},{"slug":"chapters.18.1.more-likely-than-not-binary-classifier","title":"A “More Likely Than Not” Binary Classifier","description":"","date":"","thumbnail":"/build/tree_students-17a4ad5b4b4daa4f20ca9bf6c8b9a90d.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"18.1"},{"slug":"chapters.18.2.making-decisions","title":"Making Decisions","description":"","date":"","thumbnail":"/build/tree_disease_rare-6392a369221abe1c7bdffbd913bcb033.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"18.2"}]}}},"actionData":null,"errors":null},"future":{"unstable_dev":false,"unstable_postcss":false,"unstable_tailwind":false,"v2_errorBoundary":true,"v2_headers":true,"v2_meta":true,"v2_normalizeFormMethod":true,"v2_routeConvention":true}};</script><script type="module" async="">import "/build/manifest-3481E987.js";
import * as route0 from "/build/root-7TUVC4ZT.js";
import * as route1 from "/build/routes/$-P6PGXPYX.js";
window.__remixRouteModules = {"root":route0,"routes/$":route1};

import("/build/entry.client-UNPC4GT3.js");</script></body></html>