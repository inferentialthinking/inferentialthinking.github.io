<!DOCTYPE html><html lang="en" class="" style="scroll-padding:60px"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/><title>Decisions and Uncertainty - Computational and Inferential Thinking</title><meta property="og:title" content="Decisions and Uncertainty - Computational and Inferential Thinking"/><meta name="generator" content="mystmd"/><meta name="keywords" content=""/><link rel="stylesheet" href="/build/_assets/app-IZWEOBHI.css"/><link rel="stylesheet" href="/build/_assets/thebe-core-VKVHG5VY.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jupyter-matplotlib@0.11.3/css/mpl_widget.css"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-148221575-1"></script><script>window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-148221575-1');</script><link rel="icon" href="/favicon.ico"/><link rel="stylesheet" href="/myst-theme.css"/><script>
  const savedTheme = localStorage.getItem("myst:theme");
  const theme = window.matchMedia("(prefers-color-scheme: light)").matches ? 'light' : 'dark';
  const classes = document.documentElement.classList;
  const hasAnyTheme = classes.contains('light') || classes.contains('dark');
  if (!hasAnyTheme) classes.add(savedTheme ?? theme);
</script></head><body class="m-0 transition-colors duration-500 bg-white dark:bg-stone-900"><div class="fixed top-1 left-1 h-[0px] w-[0px] focus-within:z-40 focus-within:h-auto focus-within:w-auto bg-white overflow-hidden focus-within:p-2 focus-within:ring-1" aria-label="skip to content options"><a href="#skip-to-frontmatter" class="block px-2 py-1 text-black underline">Skip to article frontmatter</a><a href="#skip-to-article" class="block px-2 py-1 text-black underline">Skip to article content</a></div><div class="bg-white/80 backdrop-blur dark:bg-stone-900/80 shadow dark:shadow-stone-700 p-3 md:px-8 sticky w-screen top-0 z-30 h-[60px]"><nav class="flex items-center justify-between flex-nowrap max-w-[1440px] mx-auto"><div class="flex flex-row xl:min-w-[19.5rem] mr-2 sm:mr-7 justify-start items-center shrink-0"><div class="block xl:hidden"><button class="flex items-center border-stone-400 text-stone-800 hover:text-stone-900 dark:text-stone-200 hover:dark:text-stone-100"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="m-1"><path fill-rule="evenodd" d="M3 6.75A.75.75 0 0 1 3.75 6h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 6.75ZM3 12a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 12Zm0 5.25a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75a.75.75 0 0 1-.75-.75Z" clip-rule="evenodd"></path></svg><span class="sr-only">Open Menu</span></button></div><a class="flex items-center ml-3 dark:text-white w-fit md:ml-5 xl:ml-7" href="/"><div class="p-1 mr-3 dark:bg-white dark:rounded"><img src="/build/data8logo-6c1a7214071a38e61e471875d935bde1.png" class="h-9" alt="Computational and Inferential Thinking" height="2.25rem"/></div><span class="text-md sm:text-xl tracking-tight sm:mr-5">Computational and Inferential Thinking</span></a></div><div class="flex items-center flex-grow w-auto"><div class="flex-grow hidden text-md lg:block"></div><div class="flex-grow block"></div><button type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R74op:" data-state="closed" class="flex items-center h-10 aspect-square sm:w-64 text-left text-gray-400 border border-gray-300 dark:border-gray-600 rounded-lg bg-gray-50 dark:bg-gray-700 hover:ring-blue-500 dark:hover:ring-blue-500 hover:border-blue-500 dark:hover:border-blue-500"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="p-2.5 h-10 w-10 aspect-square"><path fill-rule="evenodd" d="M10.5 3.75a6.75 6.75 0 1 0 0 13.5 6.75 6.75 0 0 0 0-13.5ZM2.25 10.5a8.25 8.25 0 1 1 14.59 5.28l4.69 4.69a.75.75 0 1 1-1.06 1.06l-4.69-4.69A8.25 8.25 0 0 1 2.25 10.5Z" clip-rule="evenodd"></path></svg><span class="hidden sm:block grow">Search</span><div aria-hidden="true" class="items-center hidden mx-1 font-mono text-sm text-gray-400 sm:flex gap-x-1"><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none hide-mac">CTRL</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none show-mac">⌘</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none ">K</kbd><script>
;(() => {
const script = document.currentScript;
const root = script.parentElement;

const isMac = /mac/i.test(
      window.navigator.userAgentData?.platform ?? window.navigator.userAgent,
    );
root.querySelectorAll(".hide-mac").forEach(node => {node.classList.add(isMac ? "hidden" : "block")});
root.querySelectorAll(".show-mac").forEach(node => {node.classList.add(!isMac ? "hidden" : "block")});
})()</script></div></button><button class="theme rounded-full aspect-square border border-stone-700 dark:border-white hover:bg-neutral-100 border-solid overflow-hidden text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 w-8 h-8 mx-3" title="Toggle theme between light and dark mode" aria-label="Toggle theme between light and dark mode"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 hidden dark:block"><path fill-rule="evenodd" d="M9.528 1.718a.75.75 0 0 1 .162.819A8.97 8.97 0 0 0 9 6a9 9 0 0 0 9 9 8.97 8.97 0 0 0 3.463-.69.75.75 0 0 1 .981.98 10.503 10.503 0 0 1-9.694 6.46c-5.799 0-10.5-4.7-10.5-10.5 0-4.368 2.667-8.112 6.46-9.694a.75.75 0 0 1 .818.162Z" clip-rule="evenodd"></path></svg><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 dark:hidden"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v2.25m6.364.386-1.591 1.591M21 12h-2.25m-.386 6.364-1.591-1.591M12 18.75V21m-4.773-4.227-1.591 1.591M5.25 12H3m4.227-4.773L5.636 5.636M15.75 12a3.75 3.75 0 1 1-7.5 0 3.75 3.75 0 0 1 7.5 0Z"></path></svg></button><div class="block sm:hidden"></div><div class="hidden sm:block"></div></div></nav></div><div class="fixed xl:article-grid grid-gap xl:w-screen xl:pointer-events-none overflow-auto max-xl:min-w-[300px] hidden z-10" style="top:60px"><div class="pointer-events-auto xl:col-margin-left flex-col overflow-hidden hidden xl:flex"><div class="flex-grow py-6 overflow-y-auto primary-scrollbar"><nav aria-label="Navigation" class="overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px] lg:hidden"><div class="w-full px-1 dark:text-white font-medium"></div></nav><div class="my-3 border-b-2 lg:hidden"></div><nav aria-label="Table of Contents" class="flex-grow overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px]"><div class="w-full px-1 dark:text-white"><a title="Computational and Inferential Thinking" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30 font-bold" href="/">Computational and Inferential Thinking</a><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="1 What is Data Science?" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/01/what-is-data-science">1 What is Data Science?</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rmp8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:Rmp8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="2 Causality and Experiments" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/02/causality-and-experiments">2 Causality and Experiments</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rup8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:Rup8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="3 Programming in Python" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/03/programming-in-python">3 Programming in Python</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R16p8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R16p8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="4 Data Types" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/04/data-types">4 Data Types</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R1ep8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R1ep8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="5 Sequences" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/05/sequences">5 Sequences</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R1mp8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R1mp8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="6 Tables" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/06/tables">6 Tables</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R1up8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R1up8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="7 Visualization" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/07/visualization">7 Visualization</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R26p8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R26p8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="8 Functions and Tables" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/08/functions-and-tables">8 Functions and Tables</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R2ep8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R2ep8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="9 Randomness" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/09/randomness">9 Randomness</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R2mp8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R2mp8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="10 Sampling and Empirical Distributions" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/10/sampling-and-empirical-distributions">10 Sampling and Empirical Distributions</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R2up8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R2up8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="open" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="11 Testing Hypotheses" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow font-semibold text-blue-800 dark:text-blue-200" href="/chapters/11/testing-hypotheses">11 Testing Hypotheses</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R36p8p:" aria-expanded="true" data-state="open"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="open" id="radix-:R36p8p:" class="pl-3 pr-[2px] collapsible-content"><a title="11.1 Assessing a Model" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/chapters/11/1/assessing-a-model">11.1 Assessing a Model</a><a title="11.2 Multiple Categories" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/chapters/11/2/multiple-categories">11.2 Multiple Categories</a><a title="11.3 Decisions and Uncertainty" aria-current="page" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg bg-blue-300/30 active" href="/chapters/11/3/decisions-and-uncertainty">11.3 Decisions and Uncertainty</a><a title="11.4 Error Probabilities" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/chapters/11/4/error-probabilities">11.4 Error Probabilities</a></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="12 Comparing Two Samples" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/12/comparing-two-samples">12 Comparing Two Samples</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R3ep8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R3ep8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="13 Estimation" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/13/estimation">13 Estimation</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R3mp8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R3mp8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="14 Why the Mean Matters" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/14/why-the-mean-matters">14 Why the Mean Matters</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R3up8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R3up8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="15 Prediction" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/15/prediction">15 Prediction</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R46p8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R46p8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="16 Inference for Regression" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/16/inference-for-regression">16 Inference for Regression</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R4ep8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R4ep8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="17 Classification" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/17/classification">17 Classification</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R4mp8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R4mp8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="18 Updating Predictions" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/chapters/18/updating-predictions">18 Updating Predictions</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R4up8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R4up8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div></div></nav></div><div class="flex-none py-6 transition-all duration-700 translate-y-6 opacity-0"><a class="flex mx-auto text-gray-700 w-fit hover:text-blue-700 dark:text-gray-200 dark:hover:text-blue-400" href="https://mystmd.org/made-with-myst" target="_blank" rel="noreferrer"><svg style="width:24px;height:24px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" stroke="none"><g id="icon"><path fill="currentColor" d="M23.8,54.8v-3.6l4.7-0.8V17.5l-4.7-0.8V13H36l13.4,31.7h0.2l13-31.7h12.6v3.6l-4.7,0.8v32.9l4.7,0.8v3.6h-15
          v-3.6l4.9-0.8V20.8H65L51.4,53.3h-3.8l-14-32.5h-0.1l0.2,17.4v12.1l5,0.8v3.6H23.8z"></path><path fill="#F37726" d="M47,86.9c0-5.9-3.4-8.8-10.1-8.8h-8.4c-5.2,0-9.4-1.3-12.5-3.8c-3.1-2.5-5.4-6.2-6.8-11l4.8-1.6
          c1.8,5.6,6.4,8.6,13.8,8.8h9.2c6.4,0,10.8,2.5,13.1,7.5c2.3-5,6.7-7.5,13.1-7.5h8.4c7.8,0,12.7-2.9,14.6-8.7l4.8,1.6
          c-1.4,4.9-3.6,8.6-6.8,11.1c-3.1,2.5-7.3,3.7-12.4,3.8H63c-6.7,0-10,2.9-10,8.8"></path></g></svg><span class="self-center ml-2 text-sm">Made with MyST</span></a></div></div></div><main class="article-grid grid-gap"><article class="article-grid subgrid-gap col-screen article content"><div class="hidden"></div><div id="skip-to-frontmatter" aria-label="article frontmatter" class="mb-8 pt-9"><div class="flex items-center mb-5 h-6 text-sm font-light"><div class="flex-grow"></div><a href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" rel="noopener noreferrer" class="opacity-50 hover:opacity-100 text-inherit hover:text-inherit" aria-label="Content License: Creative Commons Attribution Non Commercial No Derivatives 4.0 International (CC-BY-NC-ND-4.0)"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mx-1"><title>Content License: Creative Commons Attribution Non Commercial No Derivatives 4.0 International (CC-BY-NC-ND-4.0)</title><path d="M12 2.2c2.7 0 5 1 7 2.9.9.9 1.6 2 2.1 3.1.5 1.2.7 2.4.7 3.8 0 1.3-.2 2.6-.7 3.8-.5 1.2-1.2 2.2-2.1 3.1-1 .9-2 1.7-3.2 2.2-1.2.5-2.5.7-3.7.7s-2.6-.3-3.8-.8c-1.2-.5-2.2-1.2-3.2-2.1s-1.6-2-2.1-3.2-.8-2.4-.8-3.7c0-1.3.2-2.5.7-3.7S4.2 6 5.1 5.1C7 3.2 9.3 2.2 12 2.2zM12 4c-2.2 0-4.1.8-5.6 2.3C5.6 7.1 5 8 4.6 9c-.4 1-.6 2-.6 3s.2 2.1.6 3c.4 1 1 1.8 1.8 2.6S8 19 9 19.4c1 .4 2 .6 3 .6s2.1-.2 3-.6c1-.4 1.9-1 2.7-1.8 1.5-1.5 2.3-3.3 2.3-5.6 0-1.1-.2-2.1-.6-3.1-.4-1-1-1.8-1.7-2.6C16.1 4.8 14.2 4 12 4zm-.1 6.4l-1.3.7c-.1-.3-.3-.5-.5-.6-.2-.1-.4-.2-.6-.2-.9 0-1.3.6-1.3 1.7 0 .5.1.9.3 1.3.2.3.5.5 1 .5.6 0 1-.3 1.2-.8l1.2.6c-.3.5-.6.9-1.1 1.1-.5.3-1 .4-1.5.4-.9 0-1.6-.3-2.1-.8-.5-.6-.8-1.3-.8-2.3 0-.9.3-1.7.8-2.2.6-.6 1.3-.8 2.1-.8 1.2 0 2.1.4 2.6 1.4zm5.6 0l-1.3.7c-.1-.3-.3-.5-.5-.6-.2-.1-.4-.2-.6-.2-.9 0-1.3.6-1.3 1.7 0 .5.1.9.3 1.3.2.3.5.5 1 .5.6 0 1-.3 1.2-.8l1.2.6c-.3.5-.6.9-1.1 1.1-.4.2-.9.3-1.4.3-.9 0-1.6-.3-2.1-.8s-.8-1.3-.8-2.2c0-.9.3-1.7.8-2.2.5-.5 1.2-.8 2-.8 1.2 0 2.1.4 2.6 1.4z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1"><title>Credit must be given to the creator</title><path d="M12 2.2c2.7 0 5 .9 6.9 2.8 1.9 1.9 2.8 4.2 2.8 6.9s-.9 5-2.8 6.8c-2 1.9-4.3 2.9-7 2.9-2.6 0-4.9-1-6.9-2.9-1.8-1.7-2.8-4-2.8-6.7s1-5 2.9-6.9C7 3.2 9.3 2.2 12 2.2zM12 4c-2.2 0-4.1.8-5.6 2.3C4.8 8 4 9.9 4 12c0 2.2.8 4 2.4 5.6C8 19.2 9.8 20 12 20c2.2 0 4.1-.8 5.7-2.4 1.5-1.5 2.3-3.3 2.3-5.6 0-2.2-.8-4.1-2.3-5.7C16.1 4.8 14.2 4 12 4zm2.6 5.6v4h-1.1v4.7h-3v-4.7H9.4v-4c0-.2.1-.3.2-.4.1-.2.2-.2.4-.2h4c.2 0 .3.1.4.2.2.1.2.2.2.4zm-4-2.5c0-.9.5-1.4 1.4-1.4s1.4.5 1.4 1.4c0 .9-.5 1.4-1.4 1.4s-1.4-.5-1.4-1.4z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1"><title>Only noncommercial uses of the work are permitted</title><path d="M12 2.2c2.7 0 5 .9 6.9 2.8 1.9 1.9 2.8 4.2 2.8 6.9s-.9 5-2.8 6.8c-2 1.9-4.3 2.9-7 2.9-2.6 0-4.9-1-6.9-2.9-1.9-1.9-2.9-4.2-2.9-6.9s1-5 2.9-6.9c2-1.7 4.3-2.7 7-2.7zM4.4 9.4C4.2 10.2 4 11 4 12c0 2.2.8 4 2.4 5.6C8 19.2 9.8 20 12 20c2.2 0 4.1-.8 5.7-2.4.6-.5 1-1.1 1.3-1.7l-3.7-1.6c-.1.6-.4 1.1-.9 1.5-.5.4-1.1.6-1.8.7V18h-1.1v-1.5c-1.1 0-2.1-.4-3-1.2l1.3-1.4c.6.6 1.4.9 2.2.9.3 0 .6-.1.9-.2.2-.2.4-.4.4-.7 0-.2-.1-.4-.3-.6l-.9-.4-1.1-.6-1.5-.7-5.1-2.2zM12 4c-2.2 0-4.1.8-5.6 2.3-.4.4-.7.9-1.1 1.3L9 9.3c.2-.5.5-.9 1-1.2.5-.3 1-.5 1.6-.5V6.1h1.1v1.5c.9 0 1.7.3 2.4.9l-1.3 1.3c-.5-.4-1.1-.6-1.7-.6-.3 0-.6.1-.8.2-.2.1-.3.3-.3.6 0 .1 0 .2.1.2l1.2.6.9.4 1.6.7 5 2.2c.2-.7.2-1.4.2-2.1 0-2.2-.8-4.1-2.3-5.7C16.1 4.8 14.2 4 12 4z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1"><title>No derivatives or adaptations of the work are permitted</title><path d="M12 2.2c2.7 0 5 .9 6.9 2.8 1.9 1.9 2.8 4.2 2.8 6.9s-.9 5-2.8 6.9c-2 1.9-4.3 2.9-7 2.9-2.6 0-4.9-1-6.9-2.9C3.2 17 2.2 14.7 2.2 12s1-5 2.9-6.9C7 3.2 9.3 2.2 12 2.2zM12 4c-2.2 0-4.1.8-5.6 2.4C4.8 8 4 9.9 4 12c0 2.2.8 4 2.4 5.6C8 19.2 9.8 20 12 20c2.2 0 4.1-.8 5.7-2.4 1.5-1.5 2.3-3.3 2.3-5.6 0-2.2-.8-4.1-2.3-5.6C16.1 4.8 14.2 4 12 4zm3.7 5.7v1.7H8.6V9.7h7.1zm0 3.1v1.7H8.6v-1.7h7.1z"></path></svg></a><a href="https://github.com/data-8/textbook" title="GitHub Repository: data-8/textbook" target="_blank" rel="noopener noreferrer" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1 opacity-60 hover:opacity-100"><path d="M12 2.5c-5.4 0-9.8 4.4-9.8 9.7 0 4.3 2.8 8 6.7 9.2.5.1.7-.2.7-.5v-1.8c-2.4.5-3.1-.6-3.3-1.1-.1-.3-.6-1.1-1-1.4-.3-.2-.8-.6 0-.6s1.3.7 1.5 1c.9 1.5 2.3 1.1 2.8.8.1-.6.3-1.1.6-1.3-2.2-.2-4.4-1.1-4.4-4.8 0-1.1.4-1.9 1-2.6-.1-.2-.4-1.2.1-2.6 0 0 .8-.3 2.7 1 .8-.2 1.6-.3 2.4-.3.8 0 1.7.1 2.4.3 1.9-1.3 2.7-1 2.7-1 .5 1.3.2 2.3.1 2.6.6.7 1 1.5 1 2.6 0 3.7-2.3 4.6-4.4 4.8.4.3.7.9.7 1.8V21c0 .3.2.6.7.5 3.9-1.3 6.6-4.9 6.6-9.2 0-5.4-4.4-9.8-9.8-9.8z"></path></svg></a><a href="https://github.com/data-8/textbook/edit/main/chapters/11/3/Decisions_and_Uncertainty.ipynb" title="Edit This Page" target="_blank" rel="noopener noreferrer" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem" class="inline-block mr-1 opacity-60 hover:opacity-100"><path stroke-linecap="round" stroke-linejoin="round" d="m16.862 4.487 1.687-1.688a1.875 1.875 0 1 1 2.652 2.652L10.582 16.07a4.5 4.5 0 0 1-1.897 1.13L6 18l.8-2.685a4.5 4.5 0 0 1 1.13-1.897l8.932-8.931Zm0 0L19.5 7.125M18 14v4.75A2.25 2.25 0 0 1 15.75 21H5.25A2.25 2.25 0 0 1 3 18.75V8.25A2.25 2.25 0 0 1 5.25 6H10"></path></svg></a><div class="relative flex inline-block mx-1 grow-0" data-headlessui-state=""><button class="relative ml-2 -mr-1" id="headlessui-menu-button-:Rs8top:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Downloads</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem"><title>Download</title><path stroke-linecap="round" stroke-linejoin="round" d="M3 16.5v2.25A2.25 2.25 0 0 0 5.25 21h13.5A2.25 2.25 0 0 0 21 18.75V16.5M16.5 12 12 16.5m0 0L7.5 12m4.5 4.5V3"></path></svg></button></div></div><h1 class="mb-0"><span class="mr-3 select-none">11.3</span>Decisions and Uncertainty</h1></div><div class="block my-10 lg:sticky lg:z-10 lg:h-0 lg:pt-0 lg:my-0 lg:ml-10 lg:col-margin-right" style="top:60px"><nav></nav></div><div id="skip-to-article"></div><div id="c7mIP6pCoZ" class="relative group/block"><p>The statistical and computational methodology that we developed for assessing models about jury selection fit into a general framework of decision making called <em>statistical tests of hypotheses</em>. Using statistical tests as a way of making decisions is standard in many fields and has a standard terminology.</p><p>In this section we will describe the general sequence of the steps used in statistical tests, along with some terminology.</p><p>Though our example is from the biological sciences, you will see that the statistical and computational steps in the process are consistent with the corresponding steps in our analyses of data from the legal system. However, the biological data are about plants, not human beings and injustice. So the context and interpretation of the calculations below are far more simple.</p></div><div id="SYH48Mp6Vl" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose hidden my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">from datascience import *
%matplotlib inline
path_data = &#x27;../../../assets/data/&#x27;
import matplotlib.pyplot as plots
plots.style.use(&#x27;fivethirtyeight&#x27;)
import numpy as np</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="BcugCiwzUcYcGQyoW16CN" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="ZFBW4K9ujp" class="relative group/block"><p><a href="https://en.wikipedia.org/wiki/Gregor_Mendel" class="italic" target="_blank" rel="noreferrer" data-state="closed">Gregor Mendel</a> (1822-1884) was an Austrian monk who is widely recognized as the founder of the modern field of genetics. Mendel performed careful and large-scale experiments on plants to come up with fundamental laws of genetics.</p><p>Many of his experiments were on varieties of pea plants. He formulated sets of assumptions about each variety; these were his models. He then tested the validity of his models by growing the plants and gathering data.</p><p>For pea plants of a particular variety, Mendel proposed the following model.</p><h2 id="mendels-model" class="relative group"><span class="heading-text">Mendel’s Model</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#mendels-model" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>For every plant, there is a 75% chance that it will have purple flowers, and a 25% chance that the flowers will be white, regardless of the colors in all the other plants.</p><p>To see whether his model was valid, Mendel grew 929 pea plants of this variety. Among these 929 plants, 705 had purple flowers.</p><p>We will use these data to perform a test of hypotheses and see if Mendel’s model looks good.</p></div><div id="CTtEHyqogO" class="relative group/block"><h2 id="step-1-the-hypotheses" class="relative group"><span class="heading-text">Step 1: The Hypotheses</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#step-1-the-hypotheses" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>All statistical tests attempt to choose between two views of the world. Specifically, the choice is between two views about how the data were generated. These two views are called <em>hypotheses</em>.</p><p><strong>The null hypothesis.</strong> This is a clearly defined model about chances. It says that the data were generated at random under clearly specified assumptions about the randomness. The word “null” reinforces the idea that if the data look different from what the null hypothesis predicts, the difference is due to <em>nothing</em> but chance.</p><p>From a practical perspective, <strong>the null hypothesis is a hypothesis under which you can simulate data.</strong></p><p>In the example about Mendel’s model for the colors of pea plants, the null hypothesis is that the assumptions of his model are good: each plant has a 75% chance of having purple flowers, independent of all other plants.</p><p>Under this hypothesis, we can simulate random samples by using <code>sample_proportions</code>.</p><p><strong>The alternative hypothesis.</strong> This says that some reason other than chance made the data differ from the predictions of the model in the null hypothesis.</p><p>In the example about Mendel’s plants, the alternative hypothesis is simply that his model isn’t good.</p><p>Keep in mind that the alternative doesn’t say how or why the model isn’t good. It just says the model isn’t good.</p></div><div id="yYQj5wlPLu" class="relative group/block"><h2 id="step-2-the-test-statistic" class="relative group"><span class="heading-text">Step 2: The Test Statistic</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#step-2-the-test-statistic" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>In order to decide between the two hypothesis, we must choose a statistic that we can use to make the decision. This is called the <strong>test statistic</strong>.</p><p>We will be comparing two categorical distributions: the one in Mendel’s model and the one we will get in our random sample. We want to see if these two distributions are close to each other or far apart. So a natural test statistic is the total variation distance (TVD) developed in the previous section.</p><p>It turns out that with just two categories, the TVD is rather simple and easy to interpret. Let’s look at an example. Mendel’s model says that the “purple, white” distribution is [0.75, 0.25]. Suppose the distribution in our sample came out to be [0.7, 0.3].</p><p>Because there are only two categories, something interesting happens when we calculate the TVD. First notice that</p><div id="n5mW0n6DPn" class="flex my-5 group"><div class="flex-grow overflow-x-auto overflow-y-hidden"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="normal">∣</mi><mn>0.7</mn><mo>−</mo><mn>0.75</mn><mi mathvariant="normal">∣</mi><mo>=</mo><mn>0.05</mn><mo>=</mo><mi mathvariant="normal">∣</mi><mn>0.3</mn><mo>−</mo><mn>0.25</mn><mi mathvariant="normal">∣</mi></mrow><annotation encoding="application/x-tex">\vert 0.7 - 0.75 \vert = 0.05 = \vert 0.3 - 0.25 \vert</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∣0.7</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">0.75∣</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.05</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∣0.3</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">0.25∣</span></span></span></span></span></div><div class="relative self-center flex-none pl-2 m-0 text-right select-none"><a class="no-underline text-inherit hover:text-inherit text-inherit hover:text-inherit select-none hover:underline" href="#n5mW0n6DPn" title="Link to this Equation" aria-label="Link to this Equation">(<!-- -->1<!-- -->)</a></div></div><p>So the TVD is</p><div id="K2NoFTpxCc" class="flex my-5 group"><div class="flex-grow overflow-x-auto overflow-y-hidden"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac><mo fence="false" stretchy="true" minsize="1.8em" maxsize="1.8em">(</mo><mi mathvariant="normal">∣</mi><mn>0.7</mn><mo>−</mo><mn>0.75</mn><mi mathvariant="normal">∣</mi><mo>+</mo><mi mathvariant="normal">∣</mi><mn>0.3</mn><mo>−</mo><mn>0.25</mn><mi mathvariant="normal">∣</mi><mo fence="false" stretchy="true" minsize="1.8em" maxsize="1.8em">)</mo><mo>=</mo><mn>0.05</mn><mo>=</mo><mi mathvariant="normal">∣</mi><mn>0.7</mn><mo>−</mo><mn>0.75</mn><mi mathvariant="normal">∣</mi></mrow><annotation encoding="application/x-tex">\frac{1}{2}\Big( \vert 0.7 - 0.75 \vert + \vert 0.3 - 0.25 \vert \Big) = 0.05 
= \vert 0.7 - 0.75 \vert</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.0074em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="delimsizing size2">(</span></span><span class="mord">∣0.7</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">0.75∣</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∣0.3</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.8em;vertical-align:-0.65em;"></span><span class="mord">0.25∣</span><span class="mord"><span class="delimsizing size2">)</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.05</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∣0.7</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">0.75∣</span></span></span></span></span></div><div class="relative self-center flex-none pl-2 m-0 text-right select-none"><a class="no-underline text-inherit hover:text-inherit text-inherit hover:text-inherit select-none hover:underline" href="#K2NoFTpxCc" title="Link to this Equation" aria-label="Link to this Equation">(<!-- -->2<!-- -->)</a></div></div><p>That’s just the distance between the two proportions of purple-flowering plants. It is also just the distance between the two proportions of white-flowering plants.</p><p>By a bit of math that we won’t do here, this is true whenever there are just two categories: the TVD is equal to the distance between the two proportions in one category.</p><p>So a perfectly fine test statistic would be the distance between the sample proportion of purple plants and 0.75 which is the corresponding proportion in Mendel’s model.</p><p>Since percents are easier to interpret than proportions, we will work with percents instead.</p><p>Our test statistic will be the distance between the sample percent of purple plants and 75% which is the corresponding percent in Mendel’s model.</p><div id="po74M70T94" class="flex my-5 group"><div class="flex-grow overflow-x-auto overflow-y-hidden"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo fence="false" stretchy="true" minsize="1.8em" maxsize="1.8em">∣</mo><mtext>sample percent of purple-flowering plants</mtext><mo>−</mo><mn>75</mn><mo fence="false" stretchy="true" minsize="1.8em" maxsize="1.8em">∣</mo></mrow><annotation encoding="application/x-tex">\Big\vert \text{sample percent of purple-flowering plants} - 75 \Big\vert</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.812em;vertical-align:-0.65em;"></span><span class="mord"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.162em;"><span style="top:-1.966em;"><span class="pstrut" style="height:2.616em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.564em;"><span class="pstrut" style="height:2.616em;"></span><span style="height:0.616em;width:0.3333em;"><svg xmlns="http://www.w3.org/2000/svg" width='0.3333em' height='0.616em' style='width:0.3333em' viewBox='0 0 333.33000000000004 616' preserveAspectRatio='xMinYMin'><path d='M145 0 H188 V616 H145z M145 0 H188 V616 H145z'/></svg></span></span><span style="top:-3.172em;"><span class="pstrut" style="height:2.616em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.65em;"><span></span></span></span></span></span></span><span class="mord text"><span class="mord">sample percent of purple-flowering plants</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.812em;vertical-align:-0.65em;"></span><span class="mord">75</span><span class="mord"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.162em;"><span style="top:-1.966em;"><span class="pstrut" style="height:2.616em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.564em;"><span class="pstrut" style="height:2.616em;"></span><span style="height:0.616em;width:0.3333em;"><svg xmlns="http://www.w3.org/2000/svg" width='0.3333em' height='0.616em' style='width:0.3333em' viewBox='0 0 333.33000000000004 616' preserveAspectRatio='xMinYMin'><path d='M145 0 H188 V616 H145z M145 0 H188 V616 H145z'/></svg></span></span><span style="top:-3.172em;"><span class="pstrut" style="height:2.616em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.65em;"><span></span></span></span></span></span></span></span></span></span></span></div><div class="relative self-center flex-none pl-2 m-0 text-right select-none"><a class="no-underline text-inherit hover:text-inherit text-inherit hover:text-inherit select-none hover:underline" href="#po74M70T94" title="Link to this Equation" aria-label="Link to this Equation">(<!-- -->3<!-- -->)</a></div></div><p>This test statistic is a <em>distance</em> between the two distributions. It makes sense and is easy to use. A sample percent of around 75% will be consistent with the model, but percents much bigger or much less than 75 will make you think that the model isn’t good. Therefore, small values of the distance will make you lean towards the null hypothesis. Big values of the statistic will make you lean towards the alternative.</p><p>To choose a test statistic in other situations, look at the alternative hypothesis. What values of the statistic will make you think that the alternative hypothesis is a better choice than the null?</p><ul><li><p>If the answer is “big values,” you have a good choice of statistic.</p></li><li><p>So also if the answer is “small values.”</p></li><li><p>But if the answer is “both big values and small values,” we recommend that you look again at your statistic. See if using a distance instead of a difference can change the answer to just “big values”.</p></li></ul><h3 id="observed-value-of-the-test-statistic" class="relative group"><span class="heading-text">Observed Value of the Test Statistic</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#observed-value-of-the-test-statistic" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>The <em>observed value of the test statistic</em> is the value of the statistic you get from the data in the study, not a simulated value. Among Mendel’s 929 plants, 705 had purple flowers. The observed value of the test statistic was therefore</p></div><div id="MKvV9BGeQi" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">observed_statistic = abs ( 100 * (705 / 929) - 75)
observed_statistic</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="c3BqzHssXkIqgciUx9gCs" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><div class="font-mono text-sm whitespace-pre-wrap"><code><span>0.8880516684607045</span></code></div></div></div><div id="GjH4StTpQN" class="relative group/block"><h2 id="step-3-the-distribution-of-the-test-statistic-under-the-null-hypothesis" class="relative group"><span class="heading-text">Step 3: The Distribution of the Test Statistic, Under the Null Hypothesis</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#step-3-the-distribution-of-the-test-statistic-under-the-null-hypothesis" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>The main computational aspect of a test of hypotheses is figuring out what the model in the null hypothesis predicts. Specifically, we have to figure out <em>what the values of the test statistic might be if the null hypothesis were true</em>.</p><p>The test statistic is simulated based on the assumptions of the model in the null hypothesis. That model involves chance, so the statistic comes out differently when you simulate it multiple times.</p><p>By simulating the statistic repeatedly, we get a good sense of its possible values and which ones are more likely than others. In other words, we get a good approximation to the probability distribution of the statistic, as predicted by the model in the null hypothesis.</p><p>As with all distributions, it is very useful to visualize this distribution by a histogram, as we have done in our previous examples. Let’s go through the entire process here.</p><p>We will start by assigning some known quantities to names.</p></div><div id="gR7VIDM9fJ" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">mendel_proportions = make_array(0.75, 0.25)
mendel_proportion_purple = mendel_proportions.item(0)
sample_size = 929</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="YqW6kTcfK6BbQiSTRpzhk" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="f1irMgTPRL" class="relative group/block"><p>Next, we will define a function that returns one simulated value of the test statistic. Then we will use a <code>for</code> loop to collect 10,000 simulated values in an array.</p></div><div id="vtgBGIZTpn" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def one_simulated_distance():
    sample_proportion_purple = sample_proportions(929, mendel_proportions).item(0)
    return 100 * abs(sample_proportion_purple - mendel_proportion_purple)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="VNHWW2D6Mm_QRAjF7NDnK" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="v76tiQkni4" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">repetitions = 10000
distances = make_array()
for i in np.arange(repetitions):
    distances = np.append(distances, one_simulated_distance())</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="aE_3AFVA7owcX8mM4aNp5" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="gSlUgqeTCx" class="relative group/block"><p>Now we can draw the histogram of these values. This is the histogram of the <em>distribution of the test statistic predicted by the null hypothesis</em>.</p></div><div id="Iruzr2nU7r" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">Table().with_column(
    &#x27;Distance between Sample % and 75%&#x27;, distances
).hist()
plots.title(&#x27;Prediction Made by the Null Hypothesis&#x27;);</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="rfJ79q2y5aJlsrRoxClUX" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><img src="/build/13d013e2d7add783baa6357462dac117.png" alt="&lt;Figure size 432x288 with 1 Axes&gt;"/></div></div><div id="lTpjoAe4cu" class="relative group/block"><p>Look on the horizontal axis to see the typical values of the distance, as predicted by the model. They are rather small. For example, a high proportion of the distances are in the range 0 to 1, meaning that for a high proportion of the samples, the percent of purple-flowering plants is in the range 75% <!-- -->±<!-- --> 1%. That is, the sample percent is in the range 74% to 76%.</p><p>Also note that this prediction was made using Mendel’s model only, not the proportions observed by Mendel in the plants that he grew. It is time now to compare the predictions and Mendel’s observation.</p></div><div id="BJfHpdyM8r" class="relative group/block"><h2 id="step-4-the-conclusion-of-the-test" class="relative group"><span class="heading-text">Step 4. The Conclusion of the Test</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#step-4-the-conclusion-of-the-test" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>The choice between the null and alternative hypotheses depends on the comparison between what you computed in Steps 2 and 3: the observed value of the test statistic and its distribution as predicted by the null hypothesis.</p><p>If the two are not consistent with each other, then the data do not support the null hypothesis. In other words, the alternative hypothesis is better supported by the data. We say that the test <em>rejects</em> the null hypothesis.</p><p>If the two are consistent with each other, then the observed test statistic is in line with what the null hypothesis predicts. In other words, the null hypothesis is better supported by the data. We say that the data are <em>consistent with</em> the null hypothesis.</p><p>In our example, the observed value of the test statistic is about 0.89, as computed in Step 2 above. Just by eye, locate roughly where 0.89 is on the horizontal axis of the histogram. You will see that it is clearly in the heart of the distribution predicted by Mendel’s model.</p><p>The cell below redraws the histogram with the observed value plotted on the horizontal axis.</p></div><div id="dnUkuEZ78j" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">Table().with_column(
    &#x27;Distance between Sample % and 75%&#x27;, distances
).hist()
plots.ylim(-0.02, 0.5)
plots.title(&#x27;Prediction Made by the Null Hypothesis&#x27;)
plots.scatter(observed_statistic, 0, color=&#x27;red&#x27;, s=40);</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="OftuuSUFWXgy_F4Ek1LaS" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><img src="/build/c327e7992d1d201993ece90ea4c16d52.png" alt="&lt;Figure size 432x288 with 1 Axes&gt;"/></div></div><div id="brhh5FfMAX" class="relative group/block"><p>The observed statistic is like a typical distance predicted by the null hypothesis. The null hypothesis is Mendel’s model. So our test concludes that the data are consistent with Mendel’s model.</p><p>Based on our data, Mendel’s model looks good.</p></div><div id="oUjP85bWv4" class="relative group/block"><h2 id="the-meaning-of-consistent" class="relative group"><span class="heading-text">The Meaning of “Consistent”</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#the-meaning-of-consistent" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>In all of our examples of assessing models there has been no doubt about whether the data were consistent with the model’s predictions. They were either very far from what the model predicted, as in the examples about jury panels, or similar to what the model predicted, as in the example about Mendel’s model.</p><p>But outcomes are not always so clear cut. How far is “far”? Exactly what should “similar” mean? While these questions don’t have universal answers, there are some guidelines and conventions that you can follow.</p><p>But first, it is important to understand that whether the observed test statistic is consistent with its predicted distribution under the null hypothesis is a matter of subjective opinion and judgment. We recommend that you provide your judgment along with the value of the test statistic and a graph of its predicted distribution under the null. That will allow your readers to make their own judgment about whether the two are consistent.</p></div><div id="ha8jHmyd4U" class="relative group/block"><p>In the example above, the judgment is clear. But suppose someone grew another 929 plants of some related variety and wanted to see if Mendel’s model worked for plants of that variety too. What would you conclude if their observed distance came out to be 3.2 as shown below?</p></div><div id="rE5p9klVnw" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">different_observed_statistic = 3.2
Table().with_column(
    &#x27;Distance between Sample % and 75%&#x27;, distances
).hist()
plots.ylim(-0.02, 0.5)
plots.title(&#x27;Prediction Made by the Null Hypothesis&#x27;)
plots.scatter(different_observed_statistic, 0, color=&#x27;red&#x27;, s=40);</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="MthF_BS7KmxcaJ1BNUrbw" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><img src="/build/fb681c2c86d7e02a03905a71a4657ba1.png" alt="&lt;Figure size 432x288 with 1 Axes&gt;"/></div></div><div id="FX3plxeQ6F" class="relative group/block"><p>Is the observation based on the new variety of plants consistent with the predictions in the histogram, or not?</p><p>Now the answer is not so clear. It depends on whether you think the red dot is too far from the bulk of the predicted values to be consistent with the prediction based on Mendel’s model.</p></div><div id="Lk9XcKQsn6" class="relative group/block"><h2 id="conventional-cut-offs-and-the-p-value" class="relative group"><span class="heading-text">Conventional Cut-offs and the P-value</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#conventional-cut-offs-and-the-p-value" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>If you don’t want to use your own judgment, there are conventions that you can follow. These conventions tell us how far out into the tails is conventionally considered “too far”.</p><p>The conventions are based on the area in the tail, <strong>starting at the observed statistic (the red dot) and looking in the direction that makes us lean toward the alternative.</strong> In this example that’s the right side, because big distances favor the alternative which says that the model isn’t good.</p><p>If the area of the tail is small, the observed statistic is far away from the values most commonly predicted by the null hypothesis.</p><p>Remember that in a histogram, area represents percent. To find the area in the tail, we have to find the percent of distances that were greater than or equal to 3.2, where the red dot is. The array <code>distances</code> contains the averages for all 10,000 repetitions of random sampling under Mendel’s model, and <code>different_observed_statistic</code> is 3.2.</p></div><div id="tu7RpVOgJ2" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">np.count_nonzero(distances &gt;= different_observed_statistic) / repetitions</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="65zl6Vw22idEMwADyYc6s" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><div class="font-mono text-sm whitespace-pre-wrap"><code><span>0.0243</span></code></div></div></div><div id="i97cMekgHp" class="relative group/block"><p>About 2.4% of the distances simulated under Mendel’s model were 3.2 or greater. By the law of averages, we can conclude that if Mendel’s model were correct for these new plants, then there is about a 2.4% chance that the test statistic would be 3.2 or more.</p><p>That doesn’t seem like a big chance. If Mendel’s model is true for these plants, something quite unlikely has happened. This idea gives rise to the conventions.</p><h3 id="the-p-value" class="relative group"><span class="heading-text">The p-Value</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#the-p-value" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>This chance has an impressive name. It is called the <em>observed significance level</em> of the test. That’s a mouthful, and so it is commonly called the <em>p-value</em> of the test.</p><p><strong>Definition:</strong> The p-value of a test is the chance, based on the model in the null hypothesis, that the test statistic will be equal to the observed value in the sample or even further in the direction that supports the alternative.</p><p>If a p-value is small, that means the tail beyond the observed statistic is small and so the observed statistic is far away from what the null predicts. This implies that the data support the alternative hypothesis more than they support the null.</p><p>How small is “small”? According to the conventions:</p><ul><li><p>If the p-value is less than 5%, it is considered small and the result is called “statistically significant.”</p></li><li><p>If the p-value is even smaller – less than 1% – the result is called “highly statistically significant.”</p></li></ul><p>By this convention, our p-value of 2.4% is considered small. So the conventional conclusion would be to reject the null hypothesis and say that Mendel’s model does not look good for the new plants. Formally, the result of the test is statistically significant.</p><p>When you make a conclusion in this way, we recommend that you don’t just say whether or not the result is statistically significant. Along with your conclusion, provide the observed statistic and the p-value as well, so that readers can use their own judgment.</p></div><div id="q3gkLNAtqS" class="relative group/block"><h2 id="historical-note-on-the-conventions" class="relative group"><span class="heading-text">Historical Note on the Conventions</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#historical-note-on-the-conventions" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>The determination of statistical significance, as defined above, has become standard in statistical analyses in all fields of application. When a convention is so universally followed, it is interesting to examine how it arose.</p><p>The method of statistical testing – choosing between hypotheses based on data in random samples – was developed by Sir Ronald Fisher in the early 20th century. Sir Ronald might have set the convention for statistical significance somewhat unwittingly, in the following statement in his 1925 book <em>Statistical Methods for Research Workers</em>. About the 5% level, he wrote, “It is convenient to take this point as a limit in judging whether a deviation is to be considered significant or not.”</p><p>What was “convenient” for Sir Ronald became a cutoff that has acquired the status of a universal constant. No matter that Sir Ronald himself made the point that the value was his personal choice from among many: in an article in 1926, he wrote, “If one in twenty does not seem high enough odds, we may, if we prefer it draw the line at one in fifty (the 2 percent point), or one in a hundred (the 1 percent point). Personally, the author prefers to set a low standard of significance at the 5 percent point ...”</p><p>Fisher knew that “low” is a matter of judgment and has no unique definition. We suggest that you too keep this in mind. Provide your data, make your judgment, and explain why you made it.</p><p>Whether you use a conventional cutoff or your own judgment, it is important to keep the following points in mind.</p><ul><li><p>Always provide the observed value of the test statistic and the p-value, so that readers can decide whether or not they think the p-value is small.</p></li><li><p>Don’t look to defy convention only when the conventionally derived result is not to your liking.</p></li><li><p>Even if a test concludes that the data don’t support the chance model in the null hypothesis, it typically doesn’t explain <em>why</em> the model doesn’t work. Don’t make causal conclusions without further analysis, unless you are running a randomized controlled trial. We will analyze those in a later section.</p></li></ul></div><div></div><div class="flex pt-10 mb-10 space-x-4"><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/chapters/11/2/multiple-categories"><div class="flex h-full align-middle"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:-translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M10.5 19.5 3 12m0 0 7.5-7.5M3 12h18"></path></svg><div class="flex-grow text-right"><div class="text-xs text-gray-500 dark:text-gray-400">Computational and Inferential Thinking</div>Multiple Categories</div></div></a><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/chapters/11/4/error-probabilities"><div class="flex h-full align-middle"><div class="flex-grow"><div class="text-xs text-gray-500 dark:text-gray-400">Computational and Inferential Thinking</div>Error Probabilities</div><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 4.5 21 12m0 0-7.5 7.5M21 12H3"></path></svg></div></a></div></article></main><footer class="article footer article-grid bg-white dark:bg-slate-950 mt-10 shadow-2xl shadow py-10"><p>By Ani Adhikari and John DeNero and David Wagner</p><p><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>©</mtext></mrow><annotation encoding="application/x-tex">\copyright</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;"></span><span class="mord text"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8889em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">c</span></span></span><span style="top:-3.1944em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body accent-full" style="left:0em;top:.2em;"><span class="mord">◯</span></span></span></span></span></span></span></span></span></span></span></span> Copyright 2022.</p></footer><script>((a,d)=>{if(!window.history.state||!window.history.state.key){let h=Math.random().toString(32).slice(2);window.history.replaceState({key:h},"")}try{let f=JSON.parse(sessionStorage.getItem(a)||"{}")[d||window.history.state.key];typeof f=="number"&&window.scrollTo(0,f)}catch(h){console.error(h),sessionStorage.removeItem(a)}})("positions", null)</script><link rel="modulepreload" href="/build/entry.client-UNPC4GT3.js"/><link rel="modulepreload" href="/build/_shared/chunk-OCTKKCIL.js"/><link rel="modulepreload" href="/build/_shared/chunk-UAI5KRM7.js"/><link rel="modulepreload" href="/build/_shared/chunk-2NH4LW52.js"/><link rel="modulepreload" href="/build/_shared/chunk-F7G67JTZ.js"/><link rel="modulepreload" href="/build/_shared/chunk-HBJK6BW3.js"/><link rel="modulepreload" href="/build/_shared/chunk-HYMQ7M2K.js"/><link rel="modulepreload" href="/build/_shared/chunk-OHOXABTA.js"/><link rel="modulepreload" href="/build/_shared/chunk-OCWQY3HK.js"/><link rel="modulepreload" href="/build/_shared/chunk-CPTH56EW.js"/><link rel="modulepreload" href="/build/_shared/chunk-3CVK3PYF.js"/><link rel="modulepreload" href="/build/_shared/chunk-J6FHCSRC.js"/><link rel="modulepreload" href="/build/_shared/chunk-S4SWV34C.js"/><link rel="modulepreload" href="/build/_shared/chunk-GUCIBHGO.js"/><link rel="modulepreload" href="/build/root-7TUVC4ZT.js"/><link rel="modulepreload" href="/build/_shared/chunk-INOWNUZ6.js"/><link rel="modulepreload" href="/build/routes/$-P6PGXPYX.js"/><script>window.__remixContext = {"url":"/chapters/11/3/decisions-and-uncertainty","state":{"loaderData":{"root":{"config":{"version":2,"myst":"1.6.4","options":{"favicon":"/build/favicon-2fbdc42294f4645ad891f4555e15e981.ico","logo":"/build/data8logo-6c1a7214071a38e61e471875d935bde1.png","logo_text":"Computational and Inferential Thinking","analytics_google":"UA-148221575-1","folders":true},"parts":{"footer":{"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"By Ani Adhikari and John DeNero and David Wagner","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"G8wkMkeRtz"}],"key":"KOIhB7teEO"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"inlineMath","value":"\\copyright","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmtext\u003e©\u003c/mtext\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\copyright\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8889em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord accent\"\u003e\u003cspan class=\"vlist-t\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.8889em;\"\u003e\u003cspan style=\"top:-3em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord\"\u003ec\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.1944em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"accent-body accent-full\" style=\"left:0em;top:.2em;\"\u003e\u003cspan class=\"mord\"\u003e◯\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"vApwPicYML"},{"type":"text","value":" Copyright 2022.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"ynwuY0u471"}],"key":"igXukeefvf"}],"key":"xbRJngqurf"}],"key":"WTjhcVt4zT"},"frontmatter":{"parts":{},"license":{"content":{"id":"CC-BY-NC-ND-4.0","url":"https://creativecommons.org/licenses/by-nc-nd/4.0/","name":"Creative Commons Attribution Non Commercial No Derivatives 4.0 International","CC":true}},"github":"https://github.com/data-8/textbook","numbering":{"title":{"enabled":true}},"source_url":"https://github.com/data-8/textbook/blob/main/footer.md","edit_url":"https://github.com/data-8/textbook/edit/main/footer.md","enumerator":"19"}}},"nav":[],"actions":[],"projects":[{"license":{"content":{"id":"CC-BY-NC-ND-4.0","url":"https://creativecommons.org/licenses/by-nc-nd/4.0/","name":"Creative Commons Attribution Non Commercial No Derivatives 4.0 International","CC":true}},"numbering":{"title":{"enabled":true}},"title":"Computational and Inferential Thinking","authors":[{"nameParsed":{"literal":"Ani Adhikari","given":"Ani","family":"Adhikari"},"name":"Ani Adhikari","id":"contributors-myst-generated-uid-0"},{"nameParsed":{"literal":"John DeNero","given":"John","family":"DeNero"},"name":"John DeNero","id":"contributors-myst-generated-uid-1"},{"nameParsed":{"literal":"David Wagner","given":"David","family":"Wagner"},"name":"David Wagner","id":"contributors-myst-generated-uid-2"}],"github":"https://github.com/data-8/textbook","toc":[{"file":"chapters/intro.md"},{"children":[{"children":[{"file":"chapters/01/1/1/computational-tools.md"},{"file":"chapters/01/1/2/statistical-techniques.md"}],"file":"chapters/01/1/intro.md"},{"file":"chapters/01/2/why-data-science.md"},{"children":[{"file":"chapters/01/3/1/Literary_Characters.ipynb"},{"file":"chapters/01/3/2/Another_Kind_Of_Character.ipynb"}],"file":"chapters/01/3/Plotting_the_Classics.ipynb"}],"file":"chapters/01/what-is-data-science.md"},{"children":[{"file":"chapters/02/1/observation-and-visualization-john-snow-and-the-broad-street-pump.md","title":"John Snow and the Broad Street Pump"},{"file":"chapters/02/2/snow-s-grand-experiment.md"},{"file":"chapters/02/3/establishing-causality.md"},{"file":"chapters/02/4/randomization.md"},{"file":"chapters/02/5/endnote.md"}],"file":"chapters/02/causality-and-experiments.md"},{"children":[{"file":"chapters/03/1/Expressions.ipynb"},{"children":[{"file":"chapters/03/2/1/Growth.ipynb"}],"file":"chapters/03/2/Names.ipynb"},{"file":"chapters/03/3/Calls.ipynb"},{"file":"chapters/03/4/Introduction_to_Tables.ipynb"}],"file":"chapters/03/programming-in-python.md"},{"children":[{"file":"chapters/04/1/Numbers.ipynb"},{"children":[{"file":"chapters/04/2/1/String_Methods.ipynb"}],"file":"chapters/04/2/Strings.ipynb"},{"file":"chapters/04/3/Comparison.ipynb"}],"file":"chapters/04/Data_Types.ipynb"},{"children":[{"file":"chapters/05/1/Arrays.ipynb"},{"file":"chapters/05/2/Ranges.ipynb"},{"file":"chapters/05/3/More_on_Arrays.ipynb"}],"file":"chapters/05/Sequences.ipynb"},{"children":[{"file":"chapters/06/1/Sorting_Rows.ipynb"},{"file":"chapters/06/2/Selecting_Rows.ipynb"},{"file":"chapters/06/3/Example_Population_Trends.ipynb"},{"file":"chapters/06/4/Example_Sex_Ratios.ipynb"}],"file":"chapters/06/Tables.ipynb"},{"children":[{"file":"chapters/07/1/Visualizing_Categorical_Distributions.ipynb"},{"file":"chapters/07/2/Visualizing_Numerical_Distributions.ipynb"},{"file":"chapters/07/3/Overlaid_Graphs.ipynb"}],"file":"chapters/07/Visualization.ipynb"},{"children":[{"file":"chapters/08/1/Applying_a_Function_to_a_Column.ipynb"},{"file":"chapters/08/2/Classifying_by_One_Variable.ipynb"},{"file":"chapters/08/3/Cross-Classifying_by_More_than_One_Variable.ipynb"},{"file":"chapters/08/4/Joining_Tables_by_Columns.ipynb"},{"file":"chapters/08/5/Bike_Sharing_in_the_Bay_Area.ipynb"}],"file":"chapters/08/Functions_and_Tables.ipynb"},{"children":[{"file":"chapters/09/1/Conditional_Statements.ipynb"},{"file":"chapters/09/2/Iteration.ipynb"},{"file":"chapters/09/3/Simulation.ipynb"},{"file":"chapters/09/4/Monty_Hall_Problem.ipynb"},{"file":"chapters/09/5/Finding_Probabilities.ipynb"}],"file":"chapters/09/Randomness.ipynb"},{"children":[{"file":"chapters/10/1/Empirical_Distributions.ipynb"},{"file":"chapters/10/2/Sampling_from_a_Population.ipynb"},{"file":"chapters/10/3/Empirical_Distribution_of_a_Statistic.ipynb"},{"file":"chapters/10/4/Random_Sampling_in_Python.ipynb"}],"file":"chapters/10/Sampling_and_Empirical_Distributions.ipynb"},{"children":[{"file":"chapters/11/1/Assessing_a_Model.ipynb"},{"file":"chapters/11/2/Multiple_Categories.ipynb"},{"file":"chapters/11/3/Decisions_and_Uncertainty.ipynb"},{"file":"chapters/11/4/Error_Probabilities.ipynb"}],"file":"chapters/11/Testing_Hypotheses.md"},{"children":[{"file":"chapters/12/1/AB_Testing.ipynb"},{"file":"chapters/12/2/Causality.ipynb"},{"file":"chapters/12/3/Deflategate.ipynb"}],"file":"chapters/12/Comparing_Two_Samples.md"},{"children":[{"file":"chapters/13/1/Percentiles.ipynb"},{"file":"chapters/13/2/Bootstrap.ipynb"},{"file":"chapters/13/3/Confidence_Intervals.ipynb"},{"file":"chapters/13/4/Using_Confidence_Intervals.ipynb"}],"file":"chapters/13/Estimation.md"},{"children":[{"file":"chapters/14/1/Properties_of_the_Mean.ipynb"},{"file":"chapters/14/2/Variability.ipynb"},{"file":"chapters/14/3/SD_and_the_Normal_Curve.ipynb"},{"file":"chapters/14/4/Central_Limit_Theorem.ipynb"},{"file":"chapters/14/5/Variability_of_the_Sample_Mean.ipynb"},{"file":"chapters/14/6/Choosing_a_Sample_Size.ipynb"}],"file":"chapters/14/Why_the_Mean_Matters.md"},{"children":[{"file":"chapters/15/1/Correlation.ipynb"},{"file":"chapters/15/2/Regression_Line.ipynb"},{"file":"chapters/15/3/Method_of_Least_Squares.ipynb"},{"file":"chapters/15/4/Least_Squares_Regression.ipynb"},{"file":"chapters/15/5/Visual_Diagnostics.ipynb"},{"file":"chapters/15/6/Numerical_Diagnostics.ipynb"}],"file":"chapters/15/Prediction.ipynb"},{"children":[{"file":"chapters/16/1/Regression_Model.ipynb"},{"file":"chapters/16/2/Inference_for_the_True_Slope.ipynb"},{"file":"chapters/16/3/Prediction_Intervals.ipynb"}],"file":"chapters/16/Inference_for_Regression.md"},{"children":[{"file":"chapters/17/1/Nearest_Neighbors.ipynb"},{"file":"chapters/17/2/Training_and_Testing.ipynb"},{"file":"chapters/17/3/Rows_of_Tables.ipynb"},{"file":"chapters/17/4/Implementing_the_Classifier.ipynb"},{"file":"chapters/17/5/Accuracy_of_the_Classifier.ipynb"},{"file":"chapters/17/6/Multiple_Regression.ipynb"}],"file":"chapters/17/Classification.md"},{"children":[{"file":"chapters/18/1/More_Likely_than_Not_Binary_Classifier.ipynb"},{"file":"chapters/18/2/Making_Decisions.ipynb"}],"file":"chapters/18/Updating_Predictions.md"}],"exports":[],"bibliography":[],"index":"index","pages":[{"slug":"chapters.01.what-is-data-science","title":"What is Data Science?","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"1"},{"slug":"chapters.01.1.intro","title":"Introduction","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.1"},{"slug":"chapters.01.1.1.computational-tools","title":"Computational Tools","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.1.1"},{"slug":"chapters.01.1.2.statistical-techniques","title":"Statistical Techniques","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.1.2"},{"slug":"chapters.01.2.why-data-science","title":"Why Data Science?","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.2"},{"slug":"chapters.01.3.plotting-the-classics","title":"Plotting the Classics","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.3"},{"slug":"chapters.01.3.1.literary-characters","title":"Literary Characters","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.3.1"},{"slug":"chapters.01.3.2.another-kind-of-character","title":"Another Kind of Character","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.3.2"},{"slug":"chapters.02.causality-and-experiments","title":"Causality and Experiments","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"2"},{"slug":"chapters.02.1.observation-and-visualization-john-snow-and-the-br","title":"Observation and Visualization: John Snow and the Broad Street Pump","description":"","date":"","thumbnail":"/build/snow_map-9be9c77d11b013df10497ffbee0ca76d.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.1"},{"slug":"chapters.02.2.snow-s-grand-experiment","title":"Snow’s “Grand Experiment”","description":"","date":"","thumbnail":"/build/snow_map2-f75a5aba77138374632e80ff82e9af4b.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.2"},{"slug":"chapters.02.3.establishing-causality","title":"Establishing Causality","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.3"},{"slug":"chapters.02.4.randomization","title":"Randomization","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.4"},{"slug":"chapters.02.5.endnote","title":"Endnote","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.5"},{"slug":"chapters.03.programming-in-python","title":"Programming in Python","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"3"},{"slug":"chapters.03.1.expressions","title":"Expressions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.1"},{"slug":"chapters.03.2.names","title":"Names","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.2"},{"slug":"chapters.03.2.1.growth","title":"Example: Growth Rates","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"3.2.1"},{"slug":"chapters.03.3.calls","title":"Call Expressions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.3"},{"slug":"chapters.03.4.introduction-to-tables","title":"Introduction to Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.4"},{"slug":"chapters.04.data-types","title":"Data Types","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"4"},{"slug":"chapters.04.1.numbers","title":"Numbers","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.1"},{"slug":"chapters.04.2.strings","title":"Strings","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.2"},{"slug":"chapters.04.2.1.string-methods","title":"String Methods","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"4.2.1"},{"slug":"chapters.04.3.comparison","title":"Comparisons","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.3"},{"slug":"chapters.05.sequences","title":"Sequences","description":"","date":"","thumbnail":"/build/global-land-TMAX-Tre-a1d96b55e17296bcd62cc35fde52492c.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"5"},{"slug":"chapters.05.1.arrays","title":"Arrays","description":"","date":"","thumbnail":"/build/array_arithmetic-cb99217ba09c50b9cf0ecd7d98b2724b.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.1"},{"slug":"chapters.05.2.ranges","title":"Ranges","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.2"},{"slug":"chapters.05.3.more-on-arrays","title":"More on Arrays","description":"","date":"","thumbnail":"/build/array_subtraction-2450867ecc561d266ac2d5b7388eb4ff.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.3"},{"slug":"chapters.06.tables","title":"Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"6"},{"slug":"chapters.06.1.sorting-rows","title":"Sorting Rows","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.1"},{"slug":"chapters.06.2.selecting-rows","title":"Selecting Rows","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.2"},{"slug":"chapters.06.3.example-population-trends","title":"Example: Population Trends","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.3"},{"slug":"chapters.06.4.example-sex-ratios","title":"Example: Sex Ratios","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.4"},{"slug":"chapters.07.visualization","title":"Visualization","description":"","date":"","thumbnail":"/build/C-3PO_droid-1de6c45533e0c051c7885e633eb79b8a.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"7"},{"slug":"chapters.07.1.visualizing-categorical-distributions","title":"Visualizing Categorical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.1"},{"slug":"chapters.07.2.visualizing-numerical-distributions","title":"Visualizing Numerical Distributions","description":"","date":"","thumbnail":"/build/ipad_battery-2699f3d5f6485ab02cc7ebd9be84e6e8.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.2"},{"slug":"chapters.07.3.overlaid-graphs","title":"Overlaid Graphs","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.3"},{"slug":"chapters.08.functions-and-tables","title":"Functions and Tables","description":"","date":"","thumbnail":"/build/function_definition-ff771b748c1385635a19840a538b8e5c.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"8"},{"slug":"chapters.08.1.applying-a-function-to-a-column","title":"Applying a Function to a Column","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.1"},{"slug":"chapters.08.2.classifying-by-one-variable","title":"Classifying by One Variable","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.2"},{"slug":"chapters.08.3.cross-classifying-by-more-than-one-variable","title":"Cross-Classifying by More than One Variable","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.3"},{"slug":"chapters.08.4.joining-tables-by-columns","title":"Joining Tables by Columns","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.4"},{"slug":"chapters.08.5.bike-sharing-in-the-bay-area","title":"Bike Sharing in the Bay Area","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.5"},{"slug":"chapters.09.randomness","title":"Randomness","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"9"},{"slug":"chapters.09.1.conditional-statements","title":"Conditional Statements","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.1"},{"slug":"chapters.09.2.iteration","title":"Iteration","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.2"},{"slug":"chapters.09.3.simulation","title":"Simulation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.3"},{"slug":"chapters.09.4.monty-hall-problem","title":"The Monty Hall Problem","description":"","date":"","thumbnail":"/build/monty_hall_goat-7e5fab787f7742cd117c40cfa5d207ed.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.4"},{"slug":"chapters.09.5.finding-probabilities","title":"Finding Probabilities","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.5"},{"slug":"chapters.10.sampling-and-empirical-distributions","title":"Sampling and Empirical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"10"},{"slug":"chapters.10.1.empirical-distributions","title":"Empirical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.1"},{"slug":"chapters.10.2.sampling-from-a-population","title":"Sampling from a Population","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.2"},{"slug":"chapters.10.3.empirical-distribution-of-a-statistic","title":"Empirical Distribution of a Statistic","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.3"},{"slug":"chapters.10.4.random-sampling-in-python","title":"Random Sampling in Python","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.4"},{"slug":"chapters.11.testing-hypotheses","title":"Testing Hypotheses","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"11"},{"slug":"chapters.11.1.assessing-a-model","title":"Assessing a Model","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.1"},{"slug":"chapters.11.2.multiple-categories","title":"Multiple Categories","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.2"},{"slug":"chapters.11.3.decisions-and-uncertainty","title":"Decisions and Uncertainty","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.3"},{"slug":"chapters.11.4.error-probabilities","title":"Error Probabilities","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.4"},{"slug":"chapters.12.comparing-two-samples","title":"Comparing Two Samples","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"12"},{"slug":"chapters.12.1.ab-testing","title":"A/B Testing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.1"},{"slug":"chapters.12.2.causality","title":"Causality","description":"","date":"","thumbnail":"/build/causality1-70e3fc349d7008faae240dae6ae45395.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.2"},{"slug":"chapters.12.3.deflategate","title":"Deflategate","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.3"},{"slug":"chapters.13.estimation","title":"Estimation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"13"},{"slug":"chapters.13.1.percentiles","title":"Percentiles","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.1"},{"slug":"chapters.13.2.bootstrap","title":"The Bootstrap","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.2"},{"slug":"chapters.13.3.confidence-intervals","title":"Confidence Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.3"},{"slug":"chapters.13.4.using-confidence-intervals","title":"Using Confidence Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.4"},{"slug":"chapters.14.why-the-mean-matters","title":"Why the Mean Matters","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"14"},{"slug":"chapters.14.1.properties-of-the-mean","title":"Properties of the Mean","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.1"},{"slug":"chapters.14.2.variability","title":"Variability","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.2"},{"slug":"chapters.14.3.sd-and-the-normal-curve","title":"The SD and the Normal Curve","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.3"},{"slug":"chapters.14.4.central-limit-theorem","title":"The Central Limit Theorem","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.4"},{"slug":"chapters.14.5.variability-of-the-sample-mean","title":"The Variability of the Sample Mean","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.5"},{"slug":"chapters.14.6.choosing-a-sample-size","title":"Choosing a Sample Size","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.6"},{"slug":"chapters.15.prediction","title":"Prediction","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"15"},{"slug":"chapters.15.1.correlation","title":"Correlation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.1"},{"slug":"chapters.15.2.regression-line","title":"The Regression Line","description":"","date":"","thumbnail":"/build/regline-8ab3d562019696a0ab296159f45ba68d.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.2"},{"slug":"chapters.15.3.method-of-least-squares","title":"The Method of Least Squares","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.3"},{"slug":"chapters.15.4.least-squares-regression","title":"Least Squares Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.4"},{"slug":"chapters.15.5.visual-diagnostics","title":"Visual Diagnostics","description":"","date":"","thumbnail":"/build/5f819b0045c6e81a4265dd506d7aaff9.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.5"},{"slug":"chapters.15.6.numerical-diagnostics","title":"Numerical Diagnostics","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.6"},{"slug":"chapters.16.inference-for-regression","title":"Inference for Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"16"},{"slug":"chapters.16.1.regression-model","title":"A Regression Model","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.1"},{"slug":"chapters.16.2.inference-for-the-true-slope","title":"Inference for the True Slope","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.2"},{"slug":"chapters.16.3.prediction-intervals","title":"Prediction Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.3"},{"slug":"chapters.17.classification","title":"Classification","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"17"},{"slug":"chapters.17.1.nearest-neighbors","title":"Nearest Neighbors","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.1"},{"slug":"chapters.17.2.training-and-testing","title":"Training and Testing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.2"},{"slug":"chapters.17.3.rows-of-tables","title":"Rows of Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.3"},{"slug":"chapters.17.4.implementing-the-classifier","title":"Implementing the Classifier","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.4"},{"slug":"chapters.17.5.accuracy-of-the-classifier","title":"The Accuracy of the Classifier","description":"","date":"","thumbnail":"/build/5e548385d4da863b59d51148bd5d0eeb.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.5"},{"slug":"chapters.17.6.multiple-regression","title":"Multiple Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.6"},{"slug":"chapters.18.updating-predictions","title":"Updating Predictions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"18"},{"slug":"chapters.18.1.more-likely-than-not-binary-classifier","title":"A “More Likely Than Not” Binary Classifier","description":"","date":"","thumbnail":"/build/tree_students-4ccb9c869896157f61e1e9813b831cd3.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"18.1"},{"slug":"chapters.18.2.making-decisions","title":"Making Decisions","description":"","date":"","thumbnail":"/build/tree_disease_rare-d452fe72cc02977983ec76505172c440.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"18.2"}]}]},"CONTENT_CDN_PORT":"3100","MODE":"static"},"routes/$":{"config":{"version":2,"myst":"1.6.4","options":{"favicon":"/build/favicon-2fbdc42294f4645ad891f4555e15e981.ico","logo":"/build/data8logo-6c1a7214071a38e61e471875d935bde1.png","logo_text":"Computational and Inferential Thinking","analytics_google":"UA-148221575-1","folders":true},"parts":{"footer":{"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"By Ani Adhikari and John DeNero and David Wagner","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"G8wkMkeRtz"}],"key":"KOIhB7teEO"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"inlineMath","value":"\\copyright","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmtext\u003e©\u003c/mtext\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\copyright\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8889em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord accent\"\u003e\u003cspan class=\"vlist-t\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.8889em;\"\u003e\u003cspan style=\"top:-3em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord\"\u003ec\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.1944em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"accent-body accent-full\" style=\"left:0em;top:.2em;\"\u003e\u003cspan class=\"mord\"\u003e◯\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"vApwPicYML"},{"type":"text","value":" Copyright 2022.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"ynwuY0u471"}],"key":"igXukeefvf"}],"key":"xbRJngqurf"}],"key":"WTjhcVt4zT"},"frontmatter":{"parts":{},"license":{"content":{"id":"CC-BY-NC-ND-4.0","url":"https://creativecommons.org/licenses/by-nc-nd/4.0/","name":"Creative Commons Attribution Non Commercial No Derivatives 4.0 International","CC":true}},"github":"https://github.com/data-8/textbook","numbering":{"title":{"enabled":true}},"source_url":"https://github.com/data-8/textbook/blob/main/footer.md","edit_url":"https://github.com/data-8/textbook/edit/main/footer.md","enumerator":"19"}}},"nav":[],"actions":[],"projects":[{"license":{"content":{"id":"CC-BY-NC-ND-4.0","url":"https://creativecommons.org/licenses/by-nc-nd/4.0/","name":"Creative Commons Attribution Non Commercial No Derivatives 4.0 International","CC":true}},"numbering":{"title":{"enabled":true}},"title":"Computational and Inferential Thinking","authors":[{"nameParsed":{"literal":"Ani Adhikari","given":"Ani","family":"Adhikari"},"name":"Ani Adhikari","id":"contributors-myst-generated-uid-0"},{"nameParsed":{"literal":"John DeNero","given":"John","family":"DeNero"},"name":"John DeNero","id":"contributors-myst-generated-uid-1"},{"nameParsed":{"literal":"David Wagner","given":"David","family":"Wagner"},"name":"David Wagner","id":"contributors-myst-generated-uid-2"}],"github":"https://github.com/data-8/textbook","toc":[{"file":"chapters/intro.md"},{"children":[{"children":[{"file":"chapters/01/1/1/computational-tools.md"},{"file":"chapters/01/1/2/statistical-techniques.md"}],"file":"chapters/01/1/intro.md"},{"file":"chapters/01/2/why-data-science.md"},{"children":[{"file":"chapters/01/3/1/Literary_Characters.ipynb"},{"file":"chapters/01/3/2/Another_Kind_Of_Character.ipynb"}],"file":"chapters/01/3/Plotting_the_Classics.ipynb"}],"file":"chapters/01/what-is-data-science.md"},{"children":[{"file":"chapters/02/1/observation-and-visualization-john-snow-and-the-broad-street-pump.md","title":"John Snow and the Broad Street Pump"},{"file":"chapters/02/2/snow-s-grand-experiment.md"},{"file":"chapters/02/3/establishing-causality.md"},{"file":"chapters/02/4/randomization.md"},{"file":"chapters/02/5/endnote.md"}],"file":"chapters/02/causality-and-experiments.md"},{"children":[{"file":"chapters/03/1/Expressions.ipynb"},{"children":[{"file":"chapters/03/2/1/Growth.ipynb"}],"file":"chapters/03/2/Names.ipynb"},{"file":"chapters/03/3/Calls.ipynb"},{"file":"chapters/03/4/Introduction_to_Tables.ipynb"}],"file":"chapters/03/programming-in-python.md"},{"children":[{"file":"chapters/04/1/Numbers.ipynb"},{"children":[{"file":"chapters/04/2/1/String_Methods.ipynb"}],"file":"chapters/04/2/Strings.ipynb"},{"file":"chapters/04/3/Comparison.ipynb"}],"file":"chapters/04/Data_Types.ipynb"},{"children":[{"file":"chapters/05/1/Arrays.ipynb"},{"file":"chapters/05/2/Ranges.ipynb"},{"file":"chapters/05/3/More_on_Arrays.ipynb"}],"file":"chapters/05/Sequences.ipynb"},{"children":[{"file":"chapters/06/1/Sorting_Rows.ipynb"},{"file":"chapters/06/2/Selecting_Rows.ipynb"},{"file":"chapters/06/3/Example_Population_Trends.ipynb"},{"file":"chapters/06/4/Example_Sex_Ratios.ipynb"}],"file":"chapters/06/Tables.ipynb"},{"children":[{"file":"chapters/07/1/Visualizing_Categorical_Distributions.ipynb"},{"file":"chapters/07/2/Visualizing_Numerical_Distributions.ipynb"},{"file":"chapters/07/3/Overlaid_Graphs.ipynb"}],"file":"chapters/07/Visualization.ipynb"},{"children":[{"file":"chapters/08/1/Applying_a_Function_to_a_Column.ipynb"},{"file":"chapters/08/2/Classifying_by_One_Variable.ipynb"},{"file":"chapters/08/3/Cross-Classifying_by_More_than_One_Variable.ipynb"},{"file":"chapters/08/4/Joining_Tables_by_Columns.ipynb"},{"file":"chapters/08/5/Bike_Sharing_in_the_Bay_Area.ipynb"}],"file":"chapters/08/Functions_and_Tables.ipynb"},{"children":[{"file":"chapters/09/1/Conditional_Statements.ipynb"},{"file":"chapters/09/2/Iteration.ipynb"},{"file":"chapters/09/3/Simulation.ipynb"},{"file":"chapters/09/4/Monty_Hall_Problem.ipynb"},{"file":"chapters/09/5/Finding_Probabilities.ipynb"}],"file":"chapters/09/Randomness.ipynb"},{"children":[{"file":"chapters/10/1/Empirical_Distributions.ipynb"},{"file":"chapters/10/2/Sampling_from_a_Population.ipynb"},{"file":"chapters/10/3/Empirical_Distribution_of_a_Statistic.ipynb"},{"file":"chapters/10/4/Random_Sampling_in_Python.ipynb"}],"file":"chapters/10/Sampling_and_Empirical_Distributions.ipynb"},{"children":[{"file":"chapters/11/1/Assessing_a_Model.ipynb"},{"file":"chapters/11/2/Multiple_Categories.ipynb"},{"file":"chapters/11/3/Decisions_and_Uncertainty.ipynb"},{"file":"chapters/11/4/Error_Probabilities.ipynb"}],"file":"chapters/11/Testing_Hypotheses.md"},{"children":[{"file":"chapters/12/1/AB_Testing.ipynb"},{"file":"chapters/12/2/Causality.ipynb"},{"file":"chapters/12/3/Deflategate.ipynb"}],"file":"chapters/12/Comparing_Two_Samples.md"},{"children":[{"file":"chapters/13/1/Percentiles.ipynb"},{"file":"chapters/13/2/Bootstrap.ipynb"},{"file":"chapters/13/3/Confidence_Intervals.ipynb"},{"file":"chapters/13/4/Using_Confidence_Intervals.ipynb"}],"file":"chapters/13/Estimation.md"},{"children":[{"file":"chapters/14/1/Properties_of_the_Mean.ipynb"},{"file":"chapters/14/2/Variability.ipynb"},{"file":"chapters/14/3/SD_and_the_Normal_Curve.ipynb"},{"file":"chapters/14/4/Central_Limit_Theorem.ipynb"},{"file":"chapters/14/5/Variability_of_the_Sample_Mean.ipynb"},{"file":"chapters/14/6/Choosing_a_Sample_Size.ipynb"}],"file":"chapters/14/Why_the_Mean_Matters.md"},{"children":[{"file":"chapters/15/1/Correlation.ipynb"},{"file":"chapters/15/2/Regression_Line.ipynb"},{"file":"chapters/15/3/Method_of_Least_Squares.ipynb"},{"file":"chapters/15/4/Least_Squares_Regression.ipynb"},{"file":"chapters/15/5/Visual_Diagnostics.ipynb"},{"file":"chapters/15/6/Numerical_Diagnostics.ipynb"}],"file":"chapters/15/Prediction.ipynb"},{"children":[{"file":"chapters/16/1/Regression_Model.ipynb"},{"file":"chapters/16/2/Inference_for_the_True_Slope.ipynb"},{"file":"chapters/16/3/Prediction_Intervals.ipynb"}],"file":"chapters/16/Inference_for_Regression.md"},{"children":[{"file":"chapters/17/1/Nearest_Neighbors.ipynb"},{"file":"chapters/17/2/Training_and_Testing.ipynb"},{"file":"chapters/17/3/Rows_of_Tables.ipynb"},{"file":"chapters/17/4/Implementing_the_Classifier.ipynb"},{"file":"chapters/17/5/Accuracy_of_the_Classifier.ipynb"},{"file":"chapters/17/6/Multiple_Regression.ipynb"}],"file":"chapters/17/Classification.md"},{"children":[{"file":"chapters/18/1/More_Likely_than_Not_Binary_Classifier.ipynb"},{"file":"chapters/18/2/Making_Decisions.ipynb"}],"file":"chapters/18/Updating_Predictions.md"}],"exports":[],"bibliography":[],"index":"index","pages":[{"slug":"chapters.01.what-is-data-science","title":"What is Data Science?","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"1"},{"slug":"chapters.01.1.intro","title":"Introduction","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.1"},{"slug":"chapters.01.1.1.computational-tools","title":"Computational Tools","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.1.1"},{"slug":"chapters.01.1.2.statistical-techniques","title":"Statistical Techniques","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.1.2"},{"slug":"chapters.01.2.why-data-science","title":"Why Data Science?","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.2"},{"slug":"chapters.01.3.plotting-the-classics","title":"Plotting the Classics","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.3"},{"slug":"chapters.01.3.1.literary-characters","title":"Literary Characters","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.3.1"},{"slug":"chapters.01.3.2.another-kind-of-character","title":"Another Kind of Character","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.3.2"},{"slug":"chapters.02.causality-and-experiments","title":"Causality and Experiments","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"2"},{"slug":"chapters.02.1.observation-and-visualization-john-snow-and-the-br","title":"Observation and Visualization: John Snow and the Broad Street Pump","description":"","date":"","thumbnail":"/build/snow_map-9be9c77d11b013df10497ffbee0ca76d.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.1"},{"slug":"chapters.02.2.snow-s-grand-experiment","title":"Snow’s “Grand Experiment”","description":"","date":"","thumbnail":"/build/snow_map2-f75a5aba77138374632e80ff82e9af4b.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.2"},{"slug":"chapters.02.3.establishing-causality","title":"Establishing Causality","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.3"},{"slug":"chapters.02.4.randomization","title":"Randomization","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.4"},{"slug":"chapters.02.5.endnote","title":"Endnote","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.5"},{"slug":"chapters.03.programming-in-python","title":"Programming in Python","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"3"},{"slug":"chapters.03.1.expressions","title":"Expressions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.1"},{"slug":"chapters.03.2.names","title":"Names","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.2"},{"slug":"chapters.03.2.1.growth","title":"Example: Growth Rates","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"3.2.1"},{"slug":"chapters.03.3.calls","title":"Call Expressions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.3"},{"slug":"chapters.03.4.introduction-to-tables","title":"Introduction to Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.4"},{"slug":"chapters.04.data-types","title":"Data Types","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"4"},{"slug":"chapters.04.1.numbers","title":"Numbers","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.1"},{"slug":"chapters.04.2.strings","title":"Strings","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.2"},{"slug":"chapters.04.2.1.string-methods","title":"String Methods","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"4.2.1"},{"slug":"chapters.04.3.comparison","title":"Comparisons","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.3"},{"slug":"chapters.05.sequences","title":"Sequences","description":"","date":"","thumbnail":"/build/global-land-TMAX-Tre-a1d96b55e17296bcd62cc35fde52492c.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"5"},{"slug":"chapters.05.1.arrays","title":"Arrays","description":"","date":"","thumbnail":"/build/array_arithmetic-cb99217ba09c50b9cf0ecd7d98b2724b.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.1"},{"slug":"chapters.05.2.ranges","title":"Ranges","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.2"},{"slug":"chapters.05.3.more-on-arrays","title":"More on Arrays","description":"","date":"","thumbnail":"/build/array_subtraction-2450867ecc561d266ac2d5b7388eb4ff.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.3"},{"slug":"chapters.06.tables","title":"Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"6"},{"slug":"chapters.06.1.sorting-rows","title":"Sorting Rows","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.1"},{"slug":"chapters.06.2.selecting-rows","title":"Selecting Rows","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.2"},{"slug":"chapters.06.3.example-population-trends","title":"Example: Population Trends","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.3"},{"slug":"chapters.06.4.example-sex-ratios","title":"Example: Sex Ratios","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.4"},{"slug":"chapters.07.visualization","title":"Visualization","description":"","date":"","thumbnail":"/build/C-3PO_droid-1de6c45533e0c051c7885e633eb79b8a.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"7"},{"slug":"chapters.07.1.visualizing-categorical-distributions","title":"Visualizing Categorical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.1"},{"slug":"chapters.07.2.visualizing-numerical-distributions","title":"Visualizing Numerical Distributions","description":"","date":"","thumbnail":"/build/ipad_battery-2699f3d5f6485ab02cc7ebd9be84e6e8.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.2"},{"slug":"chapters.07.3.overlaid-graphs","title":"Overlaid Graphs","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.3"},{"slug":"chapters.08.functions-and-tables","title":"Functions and Tables","description":"","date":"","thumbnail":"/build/function_definition-ff771b748c1385635a19840a538b8e5c.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"8"},{"slug":"chapters.08.1.applying-a-function-to-a-column","title":"Applying a Function to a Column","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.1"},{"slug":"chapters.08.2.classifying-by-one-variable","title":"Classifying by One Variable","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.2"},{"slug":"chapters.08.3.cross-classifying-by-more-than-one-variable","title":"Cross-Classifying by More than One Variable","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.3"},{"slug":"chapters.08.4.joining-tables-by-columns","title":"Joining Tables by Columns","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.4"},{"slug":"chapters.08.5.bike-sharing-in-the-bay-area","title":"Bike Sharing in the Bay Area","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.5"},{"slug":"chapters.09.randomness","title":"Randomness","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"9"},{"slug":"chapters.09.1.conditional-statements","title":"Conditional Statements","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.1"},{"slug":"chapters.09.2.iteration","title":"Iteration","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.2"},{"slug":"chapters.09.3.simulation","title":"Simulation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.3"},{"slug":"chapters.09.4.monty-hall-problem","title":"The Monty Hall Problem","description":"","date":"","thumbnail":"/build/monty_hall_goat-7e5fab787f7742cd117c40cfa5d207ed.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.4"},{"slug":"chapters.09.5.finding-probabilities","title":"Finding Probabilities","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.5"},{"slug":"chapters.10.sampling-and-empirical-distributions","title":"Sampling and Empirical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"10"},{"slug":"chapters.10.1.empirical-distributions","title":"Empirical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.1"},{"slug":"chapters.10.2.sampling-from-a-population","title":"Sampling from a Population","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.2"},{"slug":"chapters.10.3.empirical-distribution-of-a-statistic","title":"Empirical Distribution of a Statistic","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.3"},{"slug":"chapters.10.4.random-sampling-in-python","title":"Random Sampling in Python","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.4"},{"slug":"chapters.11.testing-hypotheses","title":"Testing Hypotheses","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"11"},{"slug":"chapters.11.1.assessing-a-model","title":"Assessing a Model","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.1"},{"slug":"chapters.11.2.multiple-categories","title":"Multiple Categories","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.2"},{"slug":"chapters.11.3.decisions-and-uncertainty","title":"Decisions and Uncertainty","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.3"},{"slug":"chapters.11.4.error-probabilities","title":"Error Probabilities","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.4"},{"slug":"chapters.12.comparing-two-samples","title":"Comparing Two Samples","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"12"},{"slug":"chapters.12.1.ab-testing","title":"A/B Testing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.1"},{"slug":"chapters.12.2.causality","title":"Causality","description":"","date":"","thumbnail":"/build/causality1-70e3fc349d7008faae240dae6ae45395.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.2"},{"slug":"chapters.12.3.deflategate","title":"Deflategate","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.3"},{"slug":"chapters.13.estimation","title":"Estimation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"13"},{"slug":"chapters.13.1.percentiles","title":"Percentiles","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.1"},{"slug":"chapters.13.2.bootstrap","title":"The Bootstrap","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.2"},{"slug":"chapters.13.3.confidence-intervals","title":"Confidence Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.3"},{"slug":"chapters.13.4.using-confidence-intervals","title":"Using Confidence Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.4"},{"slug":"chapters.14.why-the-mean-matters","title":"Why the Mean Matters","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"14"},{"slug":"chapters.14.1.properties-of-the-mean","title":"Properties of the Mean","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.1"},{"slug":"chapters.14.2.variability","title":"Variability","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.2"},{"slug":"chapters.14.3.sd-and-the-normal-curve","title":"The SD and the Normal Curve","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.3"},{"slug":"chapters.14.4.central-limit-theorem","title":"The Central Limit Theorem","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.4"},{"slug":"chapters.14.5.variability-of-the-sample-mean","title":"The Variability of the Sample Mean","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.5"},{"slug":"chapters.14.6.choosing-a-sample-size","title":"Choosing a Sample Size","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.6"},{"slug":"chapters.15.prediction","title":"Prediction","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"15"},{"slug":"chapters.15.1.correlation","title":"Correlation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.1"},{"slug":"chapters.15.2.regression-line","title":"The Regression Line","description":"","date":"","thumbnail":"/build/regline-8ab3d562019696a0ab296159f45ba68d.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.2"},{"slug":"chapters.15.3.method-of-least-squares","title":"The Method of Least Squares","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.3"},{"slug":"chapters.15.4.least-squares-regression","title":"Least Squares Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.4"},{"slug":"chapters.15.5.visual-diagnostics","title":"Visual Diagnostics","description":"","date":"","thumbnail":"/build/5f819b0045c6e81a4265dd506d7aaff9.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.5"},{"slug":"chapters.15.6.numerical-diagnostics","title":"Numerical Diagnostics","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.6"},{"slug":"chapters.16.inference-for-regression","title":"Inference for Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"16"},{"slug":"chapters.16.1.regression-model","title":"A Regression Model","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.1"},{"slug":"chapters.16.2.inference-for-the-true-slope","title":"Inference for the True Slope","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.2"},{"slug":"chapters.16.3.prediction-intervals","title":"Prediction Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.3"},{"slug":"chapters.17.classification","title":"Classification","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"17"},{"slug":"chapters.17.1.nearest-neighbors","title":"Nearest Neighbors","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.1"},{"slug":"chapters.17.2.training-and-testing","title":"Training and Testing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.2"},{"slug":"chapters.17.3.rows-of-tables","title":"Rows of Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.3"},{"slug":"chapters.17.4.implementing-the-classifier","title":"Implementing the Classifier","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.4"},{"slug":"chapters.17.5.accuracy-of-the-classifier","title":"The Accuracy of the Classifier","description":"","date":"","thumbnail":"/build/5e548385d4da863b59d51148bd5d0eeb.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.5"},{"slug":"chapters.17.6.multiple-regression","title":"Multiple Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.6"},{"slug":"chapters.18.updating-predictions","title":"Updating Predictions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"18"},{"slug":"chapters.18.1.more-likely-than-not-binary-classifier","title":"A “More Likely Than Not” Binary Classifier","description":"","date":"","thumbnail":"/build/tree_students-4ccb9c869896157f61e1e9813b831cd3.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"18.1"},{"slug":"chapters.18.2.making-decisions","title":"Making Decisions","description":"","date":"","thumbnail":"/build/tree_disease_rare-d452fe72cc02977983ec76505172c440.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"18.2"}]}]},"page":{"version":2,"kind":"Notebook","sha256":"128a73c9d0b107abd386ad055e56bc795783718ffabd3dacaf1784ec0d64cd87","slug":"chapters.11.3.decisions-and-uncertainty","location":"/chapters/11/3/Decisions_and_Uncertainty.ipynb","dependencies":[],"frontmatter":{"title":"Decisions and Uncertainty","content_includes_title":false,"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"license":{"content":{"id":"CC-BY-NC-ND-4.0","url":"https://creativecommons.org/licenses/by-nc-nd/4.0/","name":"Creative Commons Attribution Non Commercial No Derivatives 4.0 International","CC":true}},"github":"https://github.com/data-8/textbook","numbering":{"title":{"enabled":true,"offset":1}},"source_url":"https://github.com/data-8/textbook/blob/main/chapters/11/3/Decisions_and_Uncertainty.ipynb","edit_url":"https://github.com/data-8/textbook/edit/main/chapters/11/3/Decisions_and_Uncertainty.ipynb","enumerator":"11.3","exports":[{"format":"ipynb","filename":"Decisions_and_Uncertainty.ipynb","url":"/build/Decisions_and_Uncert-4e8087d846aee0e01ae4bbfd7a1dabb7.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"The statistical and computational methodology that we developed for assessing models about jury selection fit into a general framework of decision making called ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"i68cKMJVcr"},{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"statistical tests of hypotheses","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"srUuUkFKVV"}],"key":"GSS2FFTHM4"},{"type":"text","value":". Using statistical tests as a way of making decisions is standard in many fields and has a standard terminology.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"A8L2WfW1K7"}],"key":"cJS1112qX6"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"In this section we will describe the general sequence of the steps used in statistical tests, along with some terminology.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"D4KdlmXOGe"}],"key":"hCIjCeOWP3"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Though our example is from the biological sciences, you will see that the statistical and computational steps in the process are consistent with the corresponding steps in our analyses of data from the legal system. However, the biological data are about plants, not human beings and injustice. So the context and interpretation of the calculations below are far more simple.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"u0eWQyannE"}],"key":"UnfjGI1GJx"}],"key":"c7mIP6pCoZ"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"from datascience import *\n%matplotlib inline\npath_data = '../../../assets/data/'\nimport matplotlib.pyplot as plots\nplots.style.use('fivethirtyeight')\nimport numpy as np","visibility":"remove","key":"KOsKl4je6i"},{"type":"output","id":"BcugCiwzUcYcGQyoW16CN","data":[],"visibility":"show","key":"IgjDWa639s"}],"visibility":"show","key":"SYH48Mp6Vl"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Gregor_Mendel","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Gregor Mendel","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Sg1uy5yhYT"}],"urlSource":"https://en.wikipedia.org/wiki/Gregor_Mendel","data":{"page":"Gregor_Mendel","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"J3CW5EFCe1"},{"type":"text","value":" (1822-1884) was an Austrian monk who is widely recognized as the founder of the modern field of genetics. Mendel performed careful and large-scale experiments on plants to come up with fundamental laws of genetics.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"b8YbZfiNIs"}],"key":"tVAE38jxkI"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Many of his experiments were on varieties of pea plants. He formulated sets of assumptions about each variety; these were his models. He then tested the validity of his models by growing the plants and gathering data.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"LEHiLfjfYC"}],"key":"CUm2CNG4Kk"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"For pea plants of a particular variety, Mendel proposed the following model.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"X9YVP5g2Ya"}],"key":"rdjCfeFLYj"},{"type":"heading","depth":2,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Mendel’s Model","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"xS4MYhacdj"}],"identifier":"mendels-model","label":"Mendel’s Model","html_id":"mendels-model","implicit":true,"key":"qgkZZPIyee"},{"type":"paragraph","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"For every plant, there is a 75% chance that it will have purple flowers, and a 25% chance that the flowers will be white, regardless of the colors in all the other plants.","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"JNeil2jVst"}],"key":"IKCILWeM4f"},{"type":"paragraph","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"To see whether his model was valid, Mendel grew 929 pea plants of this variety. Among these 929 plants, 705 had purple flowers.","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"QWQU3EJxxD"}],"key":"lbdwZilFgX"},{"type":"paragraph","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"We will use these data to perform a test of hypotheses and see if Mendel’s model looks good.","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"lJWW49PfPp"}],"key":"haX4hdVTpm"}],"key":"ZFBW4K9ujp"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Step 1: The Hypotheses","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"NI83qiwGtW"}],"identifier":"step-1-the-hypotheses","label":"Step 1: The Hypotheses","html_id":"step-1-the-hypotheses","implicit":true,"key":"YqlCIFPJc7"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"All statistical tests attempt to choose between two views of the world. Specifically, the choice is between two views about how the data were generated. These two views are called ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"hE0BR39Dus"},{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"hypotheses","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"VLASBdj0LI"}],"key":"VEk2lJkUh1"},{"type":"text","value":".","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"ii019vFUGy"}],"key":"EqAU0xvxG6"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"strong","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"The null hypothesis.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"W3tcVGZv0X"}],"key":"AbLcSIvVQl"},{"type":"text","value":" This is a clearly defined model about chances. It says that the data were generated at random under clearly specified assumptions about the randomness. The word “null” reinforces the idea that if the data look different from what the null hypothesis predicts, the difference is due to ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"L2sEmpkpd9"},{"type":"emphasis","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"nothing","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"VX7iz6WFEx"}],"key":"pikfAyt6gk"},{"type":"text","value":" but chance.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"PGW1dPVHFt"}],"key":"SDhngOugvL"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"From a practical perspective, ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"RiEI3KD1Yz"},{"type":"strong","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"the null hypothesis is a hypothesis under which you can simulate data.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"tAsyCCE7aO"}],"key":"WH8omKTc5K"}],"key":"q0ZxCIsg9R"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"In the example about Mendel’s model for the colors of pea plants, the null hypothesis is that the assumptions of his model are good: each plant has a 75% chance of having purple flowers, independent of all other plants.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"irHuonPjZb"}],"key":"ycvgrmrkVH"},{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"Under this hypothesis, we can simulate random samples by using ","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"UsokRYJb4n"},{"type":"inlineCode","value":"sample_proportions","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"lSQGdPyjip"},{"type":"text","value":".","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"VIgGCw4wYr"}],"key":"BtGFNvmvz2"},{"type":"paragraph","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"strong","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"The alternative hypothesis.","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"Vjr5nh8APk"}],"key":"QioFtvQU4L"},{"type":"text","value":" This says that some reason other than chance made the data differ from the predictions of the model in the null hypothesis.","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"o91tS4ox2d"}],"key":"IO2iKyqIfw"},{"type":"paragraph","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"In the example about Mendel’s plants, the alternative hypothesis is simply that his model isn’t good.","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"tdjk1DNurR"}],"key":"uMfnLO5RGn"},{"type":"paragraph","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"Keep in mind that the alternative doesn’t say how or why the model isn’t good. It just says the model isn’t good.","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"O8t3w6fpsu"}],"key":"ueKcGoRMah"}],"key":"CTtEHyqogO"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Step 2: The Test Statistic","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"U9N6t0owgp"}],"identifier":"step-2-the-test-statistic","label":"Step 2: The Test Statistic","html_id":"step-2-the-test-statistic","implicit":true,"key":"dNZ69J9kzm"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"In order to decide between the two hypothesis, we must choose a statistic that we can use to make the decision. This is called the ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"TaUInjFB5D"},{"type":"strong","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"test statistic","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Vmjysb27hZ"}],"key":"OKuBjxdwUr"},{"type":"text","value":".","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"XZ6D83KdFc"}],"key":"y6BUczVRt4"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"We will be comparing two categorical distributions: the one in Mendel’s model and the one we will get in our random sample. We want to see if these two distributions are close to each other or far apart. So a natural test statistic is the total variation distance (TVD) developed in the previous section.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"SakmDWuFVP"}],"key":"d5laQs5kQl"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"It turns out that with just two categories, the TVD is rather simple and easy to interpret. Let’s look at an example. Mendel’s model says that the “purple, white” distribution is [0.75, 0.25]. Suppose the distribution in our sample came out to be [0.7, 0.3].","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"nZkRjm54dm"}],"key":"OOO7zyaWW0"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Because there are only two categories, something interesting happens when we calculate the TVD. First notice that","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"auVpJRwieN"}],"key":"PJeFyRjqzY"},{"type":"math","value":"\\vert 0.7 - 0.75 \\vert = 0.05 = \\vert 0.3 - 0.25 \\vert","position":{"start":{"line":11,"column":1},"end":{"line":13,"column":1}},"html":"\u003cspan class=\"katex-display\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi mathvariant=\"normal\"\u003e∣\u003c/mi\u003e\u003cmn\u003e0.7\u003c/mn\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmn\u003e0.75\u003c/mn\u003e\u003cmi mathvariant=\"normal\"\u003e∣\u003c/mi\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmn\u003e0.05\u003c/mn\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmi mathvariant=\"normal\"\u003e∣\u003c/mi\u003e\u003cmn\u003e0.3\u003c/mn\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmn\u003e0.25\u003c/mn\u003e\u003cmi mathvariant=\"normal\"\u003e∣\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\vert 0.7 - 0.75 \\vert = 0.05 = \\vert 0.3 - 0.25 \\vert\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e∣0.7\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e−\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e0.75∣\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e0.05\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e∣0.3\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e−\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e0.25∣\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","enumerator":"1","key":"n5mW0n6DPn"},{"type":"paragraph","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"So the TVD is","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"cwWpAUUF3p"}],"key":"llj7WAT6pt"},{"type":"math","value":"\\frac{1}{2}\\Big( \\vert 0.7 - 0.75 \\vert + \\vert 0.3 - 0.25 \\vert \\Big) = 0.05 \n= \\vert 0.7 - 0.75 \\vert","position":{"start":{"line":17,"column":1},"end":{"line":20,"column":1}},"html":"\u003cspan class=\"katex-display\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmfrac\u003e\u003cmn\u003e1\u003c/mn\u003e\u003cmn\u003e2\u003c/mn\u003e\u003c/mfrac\u003e\u003cmo fence=\"false\" stretchy=\"true\" minsize=\"1.8em\" maxsize=\"1.8em\"\u003e(\u003c/mo\u003e\u003cmi mathvariant=\"normal\"\u003e∣\u003c/mi\u003e\u003cmn\u003e0.7\u003c/mn\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmn\u003e0.75\u003c/mn\u003e\u003cmi mathvariant=\"normal\"\u003e∣\u003c/mi\u003e\u003cmo\u003e+\u003c/mo\u003e\u003cmi mathvariant=\"normal\"\u003e∣\u003c/mi\u003e\u003cmn\u003e0.3\u003c/mn\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmn\u003e0.25\u003c/mn\u003e\u003cmi mathvariant=\"normal\"\u003e∣\u003c/mi\u003e\u003cmo fence=\"false\" stretchy=\"true\" minsize=\"1.8em\" maxsize=\"1.8em\"\u003e)\u003c/mo\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmn\u003e0.05\u003c/mn\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmi mathvariant=\"normal\"\u003e∣\u003c/mi\u003e\u003cmn\u003e0.7\u003c/mn\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmn\u003e0.75\u003c/mn\u003e\u003cmi mathvariant=\"normal\"\u003e∣\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\frac{1}{2}\\Big( \\vert 0.7 - 0.75 \\vert + \\vert 0.3 - 0.25 \\vert \\Big) = 0.05 \n= \\vert 0.7 - 0.75 \\vert\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:2.0074em;vertical-align:-0.686em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mopen nulldelimiter\"\u003e\u003c/span\u003e\u003cspan class=\"mfrac\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:1.3214em;\"\u003e\u003cspan style=\"top:-2.314em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord\"\u003e2\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.23em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"frac-line\" style=\"border-bottom-width:0.04em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.677em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.686em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose nulldelimiter\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"delimsizing size2\"\u003e(\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e∣0.7\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e−\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e0.75∣\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e+\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e∣0.3\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e−\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1.8em;vertical-align:-0.65em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e0.25∣\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"delimsizing size2\"\u003e)\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e0.05\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e∣0.7\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e−\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e0.75∣\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","enumerator":"2","key":"K2NoFTpxCc"},{"type":"paragraph","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"children":[{"type":"text","value":"That’s just the distance between the two proportions of purple-flowering plants. It is also just the distance between the two proportions of white-flowering plants.","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"NzNW0Axzul"}],"key":"PXieZFR0ap"},{"type":"paragraph","position":{"start":{"line":24,"column":1},"end":{"line":24,"column":1}},"children":[{"type":"text","value":"By a bit of math that we won’t do here, this is true whenever there are just two categories: the TVD is equal to the distance between the two proportions in one category.","position":{"start":{"line":24,"column":1},"end":{"line":24,"column":1}},"key":"vVlvH3oXuc"}],"key":"eNefrwutrn"},{"type":"paragraph","position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"children":[{"type":"text","value":"So a perfectly fine test statistic would be the distance between the sample proportion of purple plants and 0.75 which is the corresponding proportion in Mendel’s model.","position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"key":"TADeIKpfeD"}],"key":"RaA5ofcGU4"},{"type":"paragraph","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"children":[{"type":"text","value":"Since percents are easier to interpret than proportions, we will work with percents instead.","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"key":"PLMSInXggX"}],"key":"oPavvMG6GN"},{"type":"paragraph","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"children":[{"type":"text","value":"Our test statistic will be the distance between the sample percent of purple plants and 75% which is the corresponding percent in Mendel’s model.","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"key":"koJT2hoUkW"}],"key":"A1I1dwiNHm"},{"type":"math","value":"\\Big\\vert \\text{sample percent of purple-flowering plants} - 75 \\Big\\vert","position":{"start":{"line":32,"column":1},"end":{"line":34,"column":1}},"html":"\u003cspan class=\"katex-display\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmo fence=\"false\" stretchy=\"true\" minsize=\"1.8em\" maxsize=\"1.8em\"\u003e∣\u003c/mo\u003e\u003cmtext\u003esample percent of purple-flowering plants\u003c/mtext\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmn\u003e75\u003c/mn\u003e\u003cmo fence=\"false\" stretchy=\"true\" minsize=\"1.8em\" maxsize=\"1.8em\"\u003e∣\u003c/mo\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\Big\\vert \\text{sample percent of purple-flowering plants} - 75 \\Big\\vert\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1.812em;vertical-align:-0.65em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"delimsizing mult\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:1.162em;\"\u003e\u003cspan style=\"top:-1.966em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.616em;\"\u003e\u003c/span\u003e\u003cspan class=\"delimsizinginner delim-size1\"\u003e\u003cspan\u003e∣\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-2.564em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.616em;\"\u003e\u003c/span\u003e\u003cspan style=\"height:0.616em;width:0.3333em;\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" width='0.3333em' height='0.616em' style='width:0.3333em' viewBox='0 0 333.33000000000004 616' preserveAspectRatio='xMinYMin'\u003e\u003cpath d='M145 0 H188 V616 H145z M145 0 H188 V616 H145z'/\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.172em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.616em;\"\u003e\u003c/span\u003e\u003cspan class=\"delimsizinginner delim-size1\"\u003e\u003cspan\u003e∣\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.65em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord\"\u003esample percent of purple-flowering plants\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e−\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1.812em;vertical-align:-0.65em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e75\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"delimsizing mult\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:1.162em;\"\u003e\u003cspan style=\"top:-1.966em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.616em;\"\u003e\u003c/span\u003e\u003cspan class=\"delimsizinginner delim-size1\"\u003e\u003cspan\u003e∣\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-2.564em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.616em;\"\u003e\u003c/span\u003e\u003cspan style=\"height:0.616em;width:0.3333em;\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" width='0.3333em' height='0.616em' style='width:0.3333em' viewBox='0 0 333.33000000000004 616' preserveAspectRatio='xMinYMin'\u003e\u003cpath d='M145 0 H188 V616 H145z M145 0 H188 V616 H145z'/\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.172em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.616em;\"\u003e\u003c/span\u003e\u003cspan class=\"delimsizinginner delim-size1\"\u003e\u003cspan\u003e∣\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.65em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","enumerator":"3","key":"po74M70T94"},{"type":"paragraph","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"children":[{"type":"text","value":"This test statistic is a ","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"key":"XRDDtqqt4x"},{"type":"emphasis","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"children":[{"type":"text","value":"distance","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"key":"VdGyFZaRTO"}],"key":"nTbXWKaNmC"},{"type":"text","value":" between the two distributions. It makes sense and is easy to use. A sample percent of around 75% will be consistent with the model, but percents much bigger or much less than 75 will make you think that the model isn’t good. Therefore, small values of the distance will make you lean towards the null hypothesis. Big values of the statistic will make you lean towards the alternative.","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"key":"V8gHv2PRhz"}],"key":"XyaUCZ1Gx9"},{"type":"paragraph","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"children":[{"type":"text","value":"To choose a test statistic in other situations, look at the alternative hypothesis. What values of the statistic will make you think that the alternative hypothesis is a better choice than the null?","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"key":"JxDegz5zRK"}],"key":"BJNQqakLmZ"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":39,"column":1},"end":{"line":42,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"If the answer is “big values,” you have a good choice of statistic.","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"key":"Ed93r2Bllo"}],"key":"XMHTOZ7rZY"}],"key":"SzSB0m67qj"},{"type":"listItem","spread":true,"position":{"start":{"line":40,"column":1},"end":{"line":40,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"So also if the answer is “small values.”","position":{"start":{"line":40,"column":1},"end":{"line":40,"column":1}},"key":"ZlN70hlTbg"}],"key":"eywYrDo6fC"}],"key":"tAzZpPsQr1"},{"type":"listItem","spread":true,"position":{"start":{"line":41,"column":1},"end":{"line":42,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"But if the answer is “both big values and small values,” we recommend that you look again at your statistic. See if using a distance instead of a difference can change the answer to just “big values”.","position":{"start":{"line":41,"column":1},"end":{"line":41,"column":1}},"key":"nRy96pIEr3"}],"key":"u9Mk5bxsyh"}],"key":"MfqkSzpb5S"}],"key":"sKJIzQ1Ndj"},{"type":"heading","depth":3,"position":{"start":{"line":43,"column":1},"end":{"line":43,"column":1}},"children":[{"type":"text","value":"Observed Value of the Test Statistic","position":{"start":{"line":43,"column":1},"end":{"line":43,"column":1}},"key":"mPWOP0eIxg"}],"identifier":"observed-value-of-the-test-statistic","label":"Observed Value of the Test Statistic","html_id":"observed-value-of-the-test-statistic","implicit":true,"key":"zEI4sl5YdJ"},{"type":"paragraph","position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"children":[{"type":"text","value":"The ","position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"key":"t3rw3Rk685"},{"type":"emphasis","position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"children":[{"type":"text","value":"observed value of the test statistic","position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"key":"slouIHDQHw"}],"key":"bT5V02T864"},{"type":"text","value":" is the value of the statistic you get from the data in the study, not a simulated value. Among Mendel’s 929 plants, 705 had purple flowers. The observed value of the test statistic was therefore","position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"key":"ZV0YXhtb9v"}],"key":"oBVuwBD6I1"}],"key":"yYQj5wlPLu"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"observed_statistic = abs ( 100 * (705 / 929) - 75)\nobserved_statistic","key":"t2msarloUX"},{"type":"output","id":"c3BqzHssXkIqgciUx9gCs","data":[{"output_type":"execute_result","execution_count":14,"metadata":{},"data":{"text/plain":{"content":"0.8880516684607045","content_type":"text/plain"}}}],"key":"DzYo7oZWz2"}],"key":"MKvV9BGeQi"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Step 3: The Distribution of the Test Statistic, Under the Null Hypothesis","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"l1cUPRr2Rp"}],"identifier":"step-3-the-distribution-of-the-test-statistic-under-the-null-hypothesis","label":"Step 3: The Distribution of the Test Statistic, Under the Null Hypothesis","html_id":"step-3-the-distribution-of-the-test-statistic-under-the-null-hypothesis","implicit":true,"key":"asKPKBd22w"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"The main computational aspect of a test of hypotheses is figuring out what the model in the null hypothesis predicts. Specifically, we have to figure out ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"IjPt1PGbln"},{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"what the values of the test statistic might be if the null hypothesis were true","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"TyegCyVGKe"}],"key":"TNumBtnTmy"},{"type":"text","value":".","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"PS2mmaeFWU"}],"key":"wIDZTMcxjB"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"The test statistic is simulated based on the assumptions of the model in the null hypothesis. That model involves chance, so the statistic comes out differently when you simulate it multiple times.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"rqiDQeAZML"}],"key":"TzanKhXbhc"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"By simulating the statistic repeatedly, we get a good sense of its possible values and which ones are more likely than others. In other words, we get a good approximation to the probability distribution of the statistic, as predicted by the model in the null hypothesis.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"FjnVljEs7U"}],"key":"lMxfyBCeg7"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"As with all distributions, it is very useful to visualize this distribution by a histogram, as we have done in our previous examples. Let’s go through the entire process here.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"hT7VbpAHUT"}],"key":"vyLYccJXnD"},{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"We will start by assigning some known quantities to names.","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"Z74uI3K1dj"}],"key":"kWAipILrrw"}],"key":"GjH4StTpQN"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"mendel_proportions = make_array(0.75, 0.25)\nmendel_proportion_purple = mendel_proportions.item(0)\nsample_size = 929","key":"FRFiZTRTcP"},{"type":"output","id":"YqW6kTcfK6BbQiSTRpzhk","data":[],"key":"SiqBWDjioG"}],"key":"gR7VIDM9fJ"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Next, we will define a function that returns one simulated value of the test statistic. Then we will use a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Qeg1LbXYQm"},{"type":"inlineCode","value":"for","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"JCnQRRc4Ei"},{"type":"text","value":" loop to collect 10,000 simulated values in an array.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"MIxAcCpenh"}],"key":"N9PM0DmOLe"}],"key":"f1irMgTPRL"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def one_simulated_distance():\n    sample_proportion_purple = sample_proportions(929, mendel_proportions).item(0)\n    return 100 * abs(sample_proportion_purple - mendel_proportion_purple)","key":"f4Gx6CXrVD"},{"type":"output","id":"VNHWW2D6Mm_QRAjF7NDnK","data":[],"key":"NLGiqdOQNM"}],"key":"vtgBGIZTpn"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"repetitions = 10000\ndistances = make_array()\nfor i in np.arange(repetitions):\n    distances = np.append(distances, one_simulated_distance())","key":"tph1io6Lac"},{"type":"output","id":"aE_3AFVA7owcX8mM4aNp5","data":[],"key":"iGmW3aEDap"}],"key":"v76tiQkni4"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Now we can draw the histogram of these values. This is the histogram of the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"U5dv9745iN"},{"type":"emphasis","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"distribution of the test statistic predicted by the null hypothesis","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"CgoH46gIHW"}],"key":"iQGwITSrkp"},{"type":"text","value":".","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"haEfn5ylDH"}],"key":"fyk4qK9iqj"}],"key":"gSlUgqeTCx"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"Table().with_column(\n    'Distance between Sample % and 75%', distances\n).hist()\nplots.title('Prediction Made by the Null Hypothesis');","key":"MoLe1mBxmY"},{"type":"output","id":"rfJ79q2y5aJlsrRoxClUX","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"13d013e2d7add783baa6357462dac117","path":"/build/13d013e2d7add783baa6357462dac117.png"},"text/plain":{"content":"\u003cFigure size 432x288 with 1 Axes\u003e","content_type":"text/plain"}}}],"key":"Xew9Tdh1n6"}],"key":"Iruzr2nU7r"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Look on the horizontal axis to see the typical values of the distance, as predicted by the model. They are rather small. For example, a high proportion of the distances are in the range 0 to 1, meaning that for a high proportion of the samples, the percent of purple-flowering plants is in the range 75% ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"uLgMzEerzI"},{"type":"text","value":"±","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"JUrCHg9lNd"},{"type":"text","value":" 1%. That is, the sample percent is in the range 74% to 76%.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"aTh3lYnj2l"}],"key":"FxQqfr3Lrk"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Also note that this prediction was made using Mendel’s model only, not the proportions observed by Mendel in the plants that he grew. It is time now to compare the predictions and Mendel’s observation.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"fgFray37AJ"}],"key":"yPtRNJVcoq"}],"key":"lTpjoAe4cu"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Step 4. The Conclusion of the Test","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"px3CkUWtrU"}],"identifier":"step-4-the-conclusion-of-the-test","label":"Step 4. The Conclusion of the Test","html_id":"step-4-the-conclusion-of-the-test","implicit":true,"key":"gNCl1KpoCg"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"The choice between the null and alternative hypotheses depends on the comparison between what you computed in Steps 2 and 3: the observed value of the test statistic and its distribution as predicted by the null hypothesis.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"INtMM3aODg"}],"key":"fdgJmqcSWO"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"If the two are not consistent with each other, then the data do not support the null hypothesis. In other words, the alternative hypothesis is better supported by the data. We say that the test ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"nslbdYEr57"},{"type":"emphasis","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"rejects","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"aPPnfgrRSC"}],"key":"QDzUKFLE7v"},{"type":"text","value":" the null hypothesis.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"YJsDQdBIza"}],"key":"zBjbNkRJC6"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"If the two are consistent with each other, then the observed test statistic is in line with what the null hypothesis predicts. In other words, the null hypothesis is better supported by the data. We say that the data are ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"pw9cdjBjbO"},{"type":"emphasis","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"consistent with","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"B975uNNGYz"}],"key":"bSCk8zZ1ou"},{"type":"text","value":" the null hypothesis.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"YMZ6rRBvw4"}],"key":"Vclaf7u1s3"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"In our example, the observed value of the test statistic is about 0.89, as computed in Step 2 above. Just by eye, locate roughly where 0.89 is on the horizontal axis of the histogram. You will see that it is clearly in the heart of the distribution predicted by Mendel’s model.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"ZIgCUlOOiA"}],"key":"u6W6q99Ofk"},{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"The cell below redraws the histogram with the observed value plotted on the horizontal axis.","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"fCP0hS6uLa"}],"key":"EWjzHXC0bI"}],"key":"BJfHpdyM8r"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"Table().with_column(\n    'Distance between Sample % and 75%', distances\n).hist()\nplots.ylim(-0.02, 0.5)\nplots.title('Prediction Made by the Null Hypothesis')\nplots.scatter(observed_statistic, 0, color='red', s=40);","key":"EUOE48RC5a"},{"type":"output","id":"OftuuSUFWXgy_F4Ek1LaS","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"c327e7992d1d201993ece90ea4c16d52","path":"/build/c327e7992d1d201993ece90ea4c16d52.png"},"text/plain":{"content":"\u003cFigure size 432x288 with 1 Axes\u003e","content_type":"text/plain"}}}],"key":"Gak6u73aSi"}],"key":"dnUkuEZ78j"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The observed statistic is like a typical distance predicted by the null hypothesis. The null hypothesis is Mendel’s model. So our test concludes that the data are consistent with Mendel’s model.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"LXIwN5xwx4"}],"key":"T534pkN7NU"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Based on our data, Mendel’s model looks good.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"rlFGaiSKh2"}],"key":"ryrLNjCo9B"}],"key":"brhh5FfMAX"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The Meaning of “Consistent”","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"UDYJu7lOKS"}],"identifier":"the-meaning-of-consistent","label":"The Meaning of “Consistent”","html_id":"the-meaning-of-consistent","implicit":true,"key":"LdZYpGs1on"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"In all of our examples of assessing models there has been no doubt about whether the data were consistent with the model’s predictions. They were either very far from what the model predicted, as in the examples about jury panels, or similar to what the model predicted, as in the example about Mendel’s model.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"DYHUkadZw1"}],"key":"k5cC9RXbaO"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"But outcomes are not always so clear cut. How far is “far”? Exactly what should “similar” mean? While these questions don’t have universal answers, there are some guidelines and conventions that you can follow.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"BBE8Klcs7G"}],"key":"yHGvWPL2oE"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"But first, it is important to understand that whether the observed test statistic is consistent with its predicted distribution under the null hypothesis is a matter of subjective opinion and judgment. We recommend that you provide your judgment along with the value of the test statistic and a graph of its predicted distribution under the null. That will allow your readers to make their own judgment about whether the two are consistent.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"P39TsNJBSC"}],"key":"TxbQ1zuiIx"}],"key":"oUjP85bWv4"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"In the example above, the judgment is clear. But suppose someone grew another 929 plants of some related variety and wanted to see if Mendel’s model worked for plants of that variety too. What would you conclude if their observed distance came out to be 3.2 as shown below?","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"rpVhgneeNq"}],"key":"dx9UoHncGj"}],"key":"ha8jHmyd4U"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"different_observed_statistic = 3.2\nTable().with_column(\n    'Distance between Sample % and 75%', distances\n).hist()\nplots.ylim(-0.02, 0.5)\nplots.title('Prediction Made by the Null Hypothesis')\nplots.scatter(different_observed_statistic, 0, color='red', s=40);","key":"TiP3aEIn4o"},{"type":"output","id":"MthF_BS7KmxcaJ1BNUrbw","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"fb681c2c86d7e02a03905a71a4657ba1","path":"/build/fb681c2c86d7e02a03905a71a4657ba1.png"},"text/plain":{"content":"\u003cFigure size 432x288 with 1 Axes\u003e","content_type":"text/plain"}}}],"key":"KMIGEPaIhi"}],"key":"rE5p9klVnw"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Is the observation based on the new variety of plants consistent with the predictions in the histogram, or not?","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"EvM32yFX6O"}],"key":"dbDeRkIYUz"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Now the answer is not so clear. It depends on whether you think the red dot is too far from the bulk of the predicted values to be consistent with the prediction based on Mendel’s model.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Ge52m98jgZ"}],"key":"Sgt8L3ZkGF"}],"key":"FX3plxeQ6F"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Conventional Cut-offs and the P-value","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"MQ8GCwp6UM"}],"identifier":"conventional-cut-offs-and-the-p-value","label":"Conventional Cut-offs and the P-value","html_id":"conventional-cut-offs-and-the-p-value","implicit":true,"key":"ioXVwAIQbc"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"If you don’t want to use your own judgment, there are conventions that you can follow. These conventions tell us how far out into the tails is conventionally considered “too far”.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"jlfRqoK2Hn"}],"key":"AyHK6M7cih"},{"type":"paragraph","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"The conventions are based on the area in the tail, ","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"wDQF4j39NH"},{"type":"strong","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"starting at the observed statistic (the red dot) and looking in the direction that makes us lean toward the alternative.","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"G6xjp7ACoM"}],"key":"jAfw750amk"},{"type":"text","value":" In this example that’s the right side, because big distances favor the alternative which says that the model isn’t good.","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"yhDQJgk3jm"}],"key":"yPpFN2cuyT"},{"type":"paragraph","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"If the area of the tail is small, the observed statistic is far away from the values most commonly predicted by the null hypothesis.","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"gNdkLkeerl"}],"key":"cbGJAEdz3Y"},{"type":"paragraph","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"Remember that in a histogram, area represents percent. To find the area in the tail, we have to find the percent of distances that were greater than or equal to 3.2, where the red dot is. The array ","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"sMpljWXnaX"},{"type":"inlineCode","value":"distances","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"T7l3Z9f4ck"},{"type":"text","value":" contains the averages for all 10,000 repetitions of random sampling under Mendel’s model, and ","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"Qa5mEwPEnB"},{"type":"inlineCode","value":"different_observed_statistic","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"J2gQNLKfgh"},{"type":"text","value":" is 3.2.","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"B20rOUY7DX"}],"key":"yi9if9t1V1"}],"key":"Lk9XcKQsn6"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"np.count_nonzero(distances \u003e= different_observed_statistic) / repetitions","key":"CWikvAa4h5"},{"type":"output","id":"65zl6Vw22idEMwADyYc6s","data":[{"output_type":"execute_result","execution_count":25,"metadata":{},"data":{"text/plain":{"content":"0.0243","content_type":"text/plain"}}}],"key":"gPJUlTuWyY"}],"key":"tu7RpVOgJ2"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"About 2.4% of the distances simulated under Mendel’s model were 3.2 or greater. By the law of averages, we can conclude that if Mendel’s model were correct for these new plants, then there is about a 2.4% chance that the test statistic would be 3.2 or more.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"L2UoTzyc7w"}],"key":"xAcvYxW1fe"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"That doesn’t seem like a big chance. If Mendel’s model is true for these plants, something quite unlikely has happened. This idea gives rise to the conventions.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"pyTLL6o2dB"}],"key":"qmTrYBLTpM"},{"type":"heading","depth":3,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"The p-Value","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"Py9XJMuGpG"}],"identifier":"the-p-value","label":"The p-Value","html_id":"the-p-value","implicit":true,"key":"NCYIZnsby6"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"This chance has an impressive name. It is called the ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"J65ph0Xg5H"},{"type":"emphasis","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"observed significance level","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"apCdmsISes"}],"key":"F49J9iSVCB"},{"type":"text","value":" of the test. That’s a mouthful, and so it is commonly called the ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"qCVwEEjcLs"},{"type":"emphasis","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"p-value","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"s1XYPi07Fy"}],"key":"VDp5oz6Qkp"},{"type":"text","value":" of the test.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"Tdv9rOeZ5p"}],"key":"PFNfecoHRM"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"strong","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Definition:","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"mvIgHizCmC"}],"key":"hwEXxfdHtF"},{"type":"text","value":" The p-value of a test is the chance, based on the model in the null hypothesis, that the test statistic will be equal to the observed value in the sample or even further in the direction that supports the alternative.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"zE7BSmE4B8"}],"key":"hZJWSF8g2l"},{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"If a p-value is small, that means the tail beyond the observed statistic is small and so the observed statistic is far away from what the null predicts. This implies that the data support the alternative hypothesis more than they support the null.","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"ptSPq1rZmP"}],"key":"xpzrKa0Nlz"},{"type":"paragraph","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"How small is “small”? According to the conventions:","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"pi5cfmi9bH"}],"key":"g4p7QE4OyI"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":15,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":15,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"If the p-value is less than 5%, it is considered small and the result is called “statistically significant.”","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"aysZAn9OTe"}],"key":"iGs9RR5SeK"}],"key":"Lsxo5eNTte"},{"type":"listItem","spread":true,"position":{"start":{"line":17,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"If the p-value is even smaller – less than 1% – the result is called “highly statistically significant.”","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"oJSp6Eyjfn"}],"key":"bk7o9Hq8F9"}],"key":"lKTOGIJmqS"}],"key":"gTfnHXmtyd"},{"type":"paragraph","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"By this convention, our p-value of 2.4% is considered small. So the conventional conclusion would be to reject the null hypothesis and say that Mendel’s model does not look good for the new plants. Formally, the result of the test is statistically significant.","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"V16Cm1J3xN"}],"key":"Oq5HDSIqoB"},{"type":"paragraph","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"text","value":"When you make a conclusion in this way, we recommend that you don’t just say whether or not the result is statistically significant. Along with your conclusion, provide the observed statistic and the p-value as well, so that readers can use their own judgment.","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"gZ0BLTHFVs"}],"key":"yk2SFqvJg1"}],"key":"i97cMekgHp"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Historical Note on the Conventions","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"MgbbDDIpEu"}],"identifier":"historical-note-on-the-conventions","label":"Historical Note on the Conventions","html_id":"historical-note-on-the-conventions","implicit":true,"key":"RHdOOUt8J9"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"The determination of statistical significance, as defined above, has become standard in statistical analyses in all fields of application. When a convention is so universally followed, it is interesting to examine how it arose.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"ut802LRpqw"}],"key":"c7wVU2ZrGd"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"The method of statistical testing – choosing between hypotheses based on data in random samples – was developed by Sir Ronald Fisher in the early 20th century. Sir Ronald might have set the convention for statistical significance somewhat unwittingly, in the following statement in his 1925 book ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"qzcYGhgnvi"},{"type":"emphasis","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Statistical Methods for Research Workers","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"MNAwMwUYIV"}],"key":"cW72iWfkXd"},{"type":"text","value":". About the 5% level, he wrote, “It is convenient to take this point as a limit in judging whether a deviation is to be considered significant or not.”","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"MgZyvUzdP4"}],"key":"jce5Gjgbon"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"What was “convenient” for Sir Ronald became a cutoff that has acquired the status of a universal constant. No matter that Sir Ronald himself made the point that the value was his personal choice from among many: in an article in 1926, he wrote, “If one in twenty does not seem high enough odds, we may, if we prefer it draw the line at one in fifty (the 2 percent point), or one in a hundred (the 1 percent point). Personally, the author prefers to set a low standard of significance at the 5 percent point ...”","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"S1AgBbV5D8"}],"key":"JAIWQVhTXt"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Fisher knew that “low” is a matter of judgment and has no unique definition. We suggest that you too keep this in mind. Provide your data, make your judgment, and explain why you made it.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"TeGXDgEkQj"}],"key":"cvYAZYVb5p"},{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"Whether you use a conventional cutoff or your own judgment, it is important to keep the following points in mind.","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"rLKxuQ0FN5"}],"key":"tAXwzdZp9v"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":13,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Always provide the observed value of the test statistic and the p-value, so that readers can decide whether or not they think the p-value is small.","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"n5egbJsiJs"}],"key":"I6dsQ0l9Lb"}],"key":"yht3j8cLHd"},{"type":"listItem","spread":true,"position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Don’t look to defy convention only when the conventionally derived result is not to your liking.","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"DDklPOVPlb"}],"key":"DA4FdcKog0"}],"key":"qG3w9fPYJf"},{"type":"listItem","spread":true,"position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Even if a test concludes that the data don’t support the chance model in the null hypothesis, it typically doesn’t explain ","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"wUy1GNS7rq"},{"type":"emphasis","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"why","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"vLuGcQMBjj"}],"key":"B9ofvhIq5v"},{"type":"text","value":" the model doesn’t work. Don’t make causal conclusions without further analysis, unless you are running a randomized controlled trial. We will analyze those in a later section.","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"WrJfc9wpji"}],"key":"MbLi4IgzcI"}],"key":"qufNOeX9bP"}],"key":"cAgG5HOUVc"}],"key":"q3gkLNAtqS"}],"key":"dZVMTOqqVq"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"Multiple Categories","url":"/chapters/11/2/multiple-categories","group":"Computational and Inferential Thinking"},"next":{"title":"Error Probabilities","url":"/chapters/11/4/error-probabilities","group":"Computational and Inferential Thinking"}}},"domain":"http://localhost:3000"},"project":{"license":{"content":{"id":"CC-BY-NC-ND-4.0","url":"https://creativecommons.org/licenses/by-nc-nd/4.0/","name":"Creative Commons Attribution Non Commercial No Derivatives 4.0 International","CC":true}},"numbering":{"title":{"enabled":true}},"title":"Computational and Inferential Thinking","authors":[{"nameParsed":{"literal":"Ani Adhikari","given":"Ani","family":"Adhikari"},"name":"Ani Adhikari","id":"contributors-myst-generated-uid-0"},{"nameParsed":{"literal":"John DeNero","given":"John","family":"DeNero"},"name":"John DeNero","id":"contributors-myst-generated-uid-1"},{"nameParsed":{"literal":"David Wagner","given":"David","family":"Wagner"},"name":"David Wagner","id":"contributors-myst-generated-uid-2"}],"github":"https://github.com/data-8/textbook","toc":[{"file":"chapters/intro.md"},{"children":[{"children":[{"file":"chapters/01/1/1/computational-tools.md"},{"file":"chapters/01/1/2/statistical-techniques.md"}],"file":"chapters/01/1/intro.md"},{"file":"chapters/01/2/why-data-science.md"},{"children":[{"file":"chapters/01/3/1/Literary_Characters.ipynb"},{"file":"chapters/01/3/2/Another_Kind_Of_Character.ipynb"}],"file":"chapters/01/3/Plotting_the_Classics.ipynb"}],"file":"chapters/01/what-is-data-science.md"},{"children":[{"file":"chapters/02/1/observation-and-visualization-john-snow-and-the-broad-street-pump.md","title":"John Snow and the Broad Street Pump"},{"file":"chapters/02/2/snow-s-grand-experiment.md"},{"file":"chapters/02/3/establishing-causality.md"},{"file":"chapters/02/4/randomization.md"},{"file":"chapters/02/5/endnote.md"}],"file":"chapters/02/causality-and-experiments.md"},{"children":[{"file":"chapters/03/1/Expressions.ipynb"},{"children":[{"file":"chapters/03/2/1/Growth.ipynb"}],"file":"chapters/03/2/Names.ipynb"},{"file":"chapters/03/3/Calls.ipynb"},{"file":"chapters/03/4/Introduction_to_Tables.ipynb"}],"file":"chapters/03/programming-in-python.md"},{"children":[{"file":"chapters/04/1/Numbers.ipynb"},{"children":[{"file":"chapters/04/2/1/String_Methods.ipynb"}],"file":"chapters/04/2/Strings.ipynb"},{"file":"chapters/04/3/Comparison.ipynb"}],"file":"chapters/04/Data_Types.ipynb"},{"children":[{"file":"chapters/05/1/Arrays.ipynb"},{"file":"chapters/05/2/Ranges.ipynb"},{"file":"chapters/05/3/More_on_Arrays.ipynb"}],"file":"chapters/05/Sequences.ipynb"},{"children":[{"file":"chapters/06/1/Sorting_Rows.ipynb"},{"file":"chapters/06/2/Selecting_Rows.ipynb"},{"file":"chapters/06/3/Example_Population_Trends.ipynb"},{"file":"chapters/06/4/Example_Sex_Ratios.ipynb"}],"file":"chapters/06/Tables.ipynb"},{"children":[{"file":"chapters/07/1/Visualizing_Categorical_Distributions.ipynb"},{"file":"chapters/07/2/Visualizing_Numerical_Distributions.ipynb"},{"file":"chapters/07/3/Overlaid_Graphs.ipynb"}],"file":"chapters/07/Visualization.ipynb"},{"children":[{"file":"chapters/08/1/Applying_a_Function_to_a_Column.ipynb"},{"file":"chapters/08/2/Classifying_by_One_Variable.ipynb"},{"file":"chapters/08/3/Cross-Classifying_by_More_than_One_Variable.ipynb"},{"file":"chapters/08/4/Joining_Tables_by_Columns.ipynb"},{"file":"chapters/08/5/Bike_Sharing_in_the_Bay_Area.ipynb"}],"file":"chapters/08/Functions_and_Tables.ipynb"},{"children":[{"file":"chapters/09/1/Conditional_Statements.ipynb"},{"file":"chapters/09/2/Iteration.ipynb"},{"file":"chapters/09/3/Simulation.ipynb"},{"file":"chapters/09/4/Monty_Hall_Problem.ipynb"},{"file":"chapters/09/5/Finding_Probabilities.ipynb"}],"file":"chapters/09/Randomness.ipynb"},{"children":[{"file":"chapters/10/1/Empirical_Distributions.ipynb"},{"file":"chapters/10/2/Sampling_from_a_Population.ipynb"},{"file":"chapters/10/3/Empirical_Distribution_of_a_Statistic.ipynb"},{"file":"chapters/10/4/Random_Sampling_in_Python.ipynb"}],"file":"chapters/10/Sampling_and_Empirical_Distributions.ipynb"},{"children":[{"file":"chapters/11/1/Assessing_a_Model.ipynb"},{"file":"chapters/11/2/Multiple_Categories.ipynb"},{"file":"chapters/11/3/Decisions_and_Uncertainty.ipynb"},{"file":"chapters/11/4/Error_Probabilities.ipynb"}],"file":"chapters/11/Testing_Hypotheses.md"},{"children":[{"file":"chapters/12/1/AB_Testing.ipynb"},{"file":"chapters/12/2/Causality.ipynb"},{"file":"chapters/12/3/Deflategate.ipynb"}],"file":"chapters/12/Comparing_Two_Samples.md"},{"children":[{"file":"chapters/13/1/Percentiles.ipynb"},{"file":"chapters/13/2/Bootstrap.ipynb"},{"file":"chapters/13/3/Confidence_Intervals.ipynb"},{"file":"chapters/13/4/Using_Confidence_Intervals.ipynb"}],"file":"chapters/13/Estimation.md"},{"children":[{"file":"chapters/14/1/Properties_of_the_Mean.ipynb"},{"file":"chapters/14/2/Variability.ipynb"},{"file":"chapters/14/3/SD_and_the_Normal_Curve.ipynb"},{"file":"chapters/14/4/Central_Limit_Theorem.ipynb"},{"file":"chapters/14/5/Variability_of_the_Sample_Mean.ipynb"},{"file":"chapters/14/6/Choosing_a_Sample_Size.ipynb"}],"file":"chapters/14/Why_the_Mean_Matters.md"},{"children":[{"file":"chapters/15/1/Correlation.ipynb"},{"file":"chapters/15/2/Regression_Line.ipynb"},{"file":"chapters/15/3/Method_of_Least_Squares.ipynb"},{"file":"chapters/15/4/Least_Squares_Regression.ipynb"},{"file":"chapters/15/5/Visual_Diagnostics.ipynb"},{"file":"chapters/15/6/Numerical_Diagnostics.ipynb"}],"file":"chapters/15/Prediction.ipynb"},{"children":[{"file":"chapters/16/1/Regression_Model.ipynb"},{"file":"chapters/16/2/Inference_for_the_True_Slope.ipynb"},{"file":"chapters/16/3/Prediction_Intervals.ipynb"}],"file":"chapters/16/Inference_for_Regression.md"},{"children":[{"file":"chapters/17/1/Nearest_Neighbors.ipynb"},{"file":"chapters/17/2/Training_and_Testing.ipynb"},{"file":"chapters/17/3/Rows_of_Tables.ipynb"},{"file":"chapters/17/4/Implementing_the_Classifier.ipynb"},{"file":"chapters/17/5/Accuracy_of_the_Classifier.ipynb"},{"file":"chapters/17/6/Multiple_Regression.ipynb"}],"file":"chapters/17/Classification.md"},{"children":[{"file":"chapters/18/1/More_Likely_than_Not_Binary_Classifier.ipynb"},{"file":"chapters/18/2/Making_Decisions.ipynb"}],"file":"chapters/18/Updating_Predictions.md"}],"exports":[],"bibliography":[],"index":"index","pages":[{"slug":"chapters.01.what-is-data-science","title":"What is Data Science?","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"1"},{"slug":"chapters.01.1.intro","title":"Introduction","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.1"},{"slug":"chapters.01.1.1.computational-tools","title":"Computational Tools","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.1.1"},{"slug":"chapters.01.1.2.statistical-techniques","title":"Statistical Techniques","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.1.2"},{"slug":"chapters.01.2.why-data-science","title":"Why Data Science?","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.2"},{"slug":"chapters.01.3.plotting-the-classics","title":"Plotting the Classics","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"1.3"},{"slug":"chapters.01.3.1.literary-characters","title":"Literary Characters","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.3.1"},{"slug":"chapters.01.3.2.another-kind-of-character","title":"Another Kind of Character","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"1.3.2"},{"slug":"chapters.02.causality-and-experiments","title":"Causality and Experiments","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"2"},{"slug":"chapters.02.1.observation-and-visualization-john-snow-and-the-br","title":"Observation and Visualization: John Snow and the Broad Street Pump","description":"","date":"","thumbnail":"/build/snow_map-9be9c77d11b013df10497ffbee0ca76d.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.1"},{"slug":"chapters.02.2.snow-s-grand-experiment","title":"Snow’s “Grand Experiment”","description":"","date":"","thumbnail":"/build/snow_map2-f75a5aba77138374632e80ff82e9af4b.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.2"},{"slug":"chapters.02.3.establishing-causality","title":"Establishing Causality","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.3"},{"slug":"chapters.02.4.randomization","title":"Randomization","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.4"},{"slug":"chapters.02.5.endnote","title":"Endnote","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"2.5"},{"slug":"chapters.03.programming-in-python","title":"Programming in Python","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"3"},{"slug":"chapters.03.1.expressions","title":"Expressions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.1"},{"slug":"chapters.03.2.names","title":"Names","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.2"},{"slug":"chapters.03.2.1.growth","title":"Example: Growth Rates","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"3.2.1"},{"slug":"chapters.03.3.calls","title":"Call Expressions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.3"},{"slug":"chapters.03.4.introduction-to-tables","title":"Introduction to Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"3.4"},{"slug":"chapters.04.data-types","title":"Data Types","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"4"},{"slug":"chapters.04.1.numbers","title":"Numbers","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.1"},{"slug":"chapters.04.2.strings","title":"Strings","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.2"},{"slug":"chapters.04.2.1.string-methods","title":"String Methods","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3,"enumerator":"4.2.1"},{"slug":"chapters.04.3.comparison","title":"Comparisons","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"4.3"},{"slug":"chapters.05.sequences","title":"Sequences","description":"","date":"","thumbnail":"/build/global-land-TMAX-Tre-a1d96b55e17296bcd62cc35fde52492c.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"5"},{"slug":"chapters.05.1.arrays","title":"Arrays","description":"","date":"","thumbnail":"/build/array_arithmetic-cb99217ba09c50b9cf0ecd7d98b2724b.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.1"},{"slug":"chapters.05.2.ranges","title":"Ranges","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.2"},{"slug":"chapters.05.3.more-on-arrays","title":"More on Arrays","description":"","date":"","thumbnail":"/build/array_subtraction-2450867ecc561d266ac2d5b7388eb4ff.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"5.3"},{"slug":"chapters.06.tables","title":"Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"6"},{"slug":"chapters.06.1.sorting-rows","title":"Sorting Rows","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.1"},{"slug":"chapters.06.2.selecting-rows","title":"Selecting Rows","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.2"},{"slug":"chapters.06.3.example-population-trends","title":"Example: Population Trends","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.3"},{"slug":"chapters.06.4.example-sex-ratios","title":"Example: Sex Ratios","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"6.4"},{"slug":"chapters.07.visualization","title":"Visualization","description":"","date":"","thumbnail":"/build/C-3PO_droid-1de6c45533e0c051c7885e633eb79b8a.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"7"},{"slug":"chapters.07.1.visualizing-categorical-distributions","title":"Visualizing Categorical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.1"},{"slug":"chapters.07.2.visualizing-numerical-distributions","title":"Visualizing Numerical Distributions","description":"","date":"","thumbnail":"/build/ipad_battery-2699f3d5f6485ab02cc7ebd9be84e6e8.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.2"},{"slug":"chapters.07.3.overlaid-graphs","title":"Overlaid Graphs","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"7.3"},{"slug":"chapters.08.functions-and-tables","title":"Functions and Tables","description":"","date":"","thumbnail":"/build/function_definition-ff771b748c1385635a19840a538b8e5c.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"8"},{"slug":"chapters.08.1.applying-a-function-to-a-column","title":"Applying a Function to a Column","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.1"},{"slug":"chapters.08.2.classifying-by-one-variable","title":"Classifying by One Variable","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.2"},{"slug":"chapters.08.3.cross-classifying-by-more-than-one-variable","title":"Cross-Classifying by More than One Variable","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.3"},{"slug":"chapters.08.4.joining-tables-by-columns","title":"Joining Tables by Columns","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.4"},{"slug":"chapters.08.5.bike-sharing-in-the-bay-area","title":"Bike Sharing in the Bay Area","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"8.5"},{"slug":"chapters.09.randomness","title":"Randomness","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"9"},{"slug":"chapters.09.1.conditional-statements","title":"Conditional Statements","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.1"},{"slug":"chapters.09.2.iteration","title":"Iteration","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.2"},{"slug":"chapters.09.3.simulation","title":"Simulation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.3"},{"slug":"chapters.09.4.monty-hall-problem","title":"The Monty Hall Problem","description":"","date":"","thumbnail":"/build/monty_hall_goat-7e5fab787f7742cd117c40cfa5d207ed.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.4"},{"slug":"chapters.09.5.finding-probabilities","title":"Finding Probabilities","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"9.5"},{"slug":"chapters.10.sampling-and-empirical-distributions","title":"Sampling and Empirical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"10"},{"slug":"chapters.10.1.empirical-distributions","title":"Empirical Distributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.1"},{"slug":"chapters.10.2.sampling-from-a-population","title":"Sampling from a Population","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.2"},{"slug":"chapters.10.3.empirical-distribution-of-a-statistic","title":"Empirical Distribution of a Statistic","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.3"},{"slug":"chapters.10.4.random-sampling-in-python","title":"Random Sampling in Python","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"10.4"},{"slug":"chapters.11.testing-hypotheses","title":"Testing Hypotheses","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"11"},{"slug":"chapters.11.1.assessing-a-model","title":"Assessing a Model","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.1"},{"slug":"chapters.11.2.multiple-categories","title":"Multiple Categories","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.2"},{"slug":"chapters.11.3.decisions-and-uncertainty","title":"Decisions and Uncertainty","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.3"},{"slug":"chapters.11.4.error-probabilities","title":"Error Probabilities","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"11.4"},{"slug":"chapters.12.comparing-two-samples","title":"Comparing Two Samples","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"12"},{"slug":"chapters.12.1.ab-testing","title":"A/B Testing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.1"},{"slug":"chapters.12.2.causality","title":"Causality","description":"","date":"","thumbnail":"/build/causality1-70e3fc349d7008faae240dae6ae45395.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.2"},{"slug":"chapters.12.3.deflategate","title":"Deflategate","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"12.3"},{"slug":"chapters.13.estimation","title":"Estimation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"13"},{"slug":"chapters.13.1.percentiles","title":"Percentiles","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.1"},{"slug":"chapters.13.2.bootstrap","title":"The Bootstrap","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.2"},{"slug":"chapters.13.3.confidence-intervals","title":"Confidence Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.3"},{"slug":"chapters.13.4.using-confidence-intervals","title":"Using Confidence Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"13.4"},{"slug":"chapters.14.why-the-mean-matters","title":"Why the Mean Matters","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"14"},{"slug":"chapters.14.1.properties-of-the-mean","title":"Properties of the Mean","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.1"},{"slug":"chapters.14.2.variability","title":"Variability","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.2"},{"slug":"chapters.14.3.sd-and-the-normal-curve","title":"The SD and the Normal Curve","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.3"},{"slug":"chapters.14.4.central-limit-theorem","title":"The Central Limit Theorem","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.4"},{"slug":"chapters.14.5.variability-of-the-sample-mean","title":"The Variability of the Sample Mean","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.5"},{"slug":"chapters.14.6.choosing-a-sample-size","title":"Choosing a Sample Size","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"14.6"},{"slug":"chapters.15.prediction","title":"Prediction","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"15"},{"slug":"chapters.15.1.correlation","title":"Correlation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.1"},{"slug":"chapters.15.2.regression-line","title":"The Regression Line","description":"","date":"","thumbnail":"/build/regline-8ab3d562019696a0ab296159f45ba68d.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.2"},{"slug":"chapters.15.3.method-of-least-squares","title":"The Method of Least Squares","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.3"},{"slug":"chapters.15.4.least-squares-regression","title":"Least Squares Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.4"},{"slug":"chapters.15.5.visual-diagnostics","title":"Visual Diagnostics","description":"","date":"","thumbnail":"/build/5f819b0045c6e81a4265dd506d7aaff9.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.5"},{"slug":"chapters.15.6.numerical-diagnostics","title":"Numerical Diagnostics","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"15.6"},{"slug":"chapters.16.inference-for-regression","title":"Inference for Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"16"},{"slug":"chapters.16.1.regression-model","title":"A Regression Model","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.1"},{"slug":"chapters.16.2.inference-for-the-true-slope","title":"Inference for the True Slope","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.2"},{"slug":"chapters.16.3.prediction-intervals","title":"Prediction Intervals","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"16.3"},{"slug":"chapters.17.classification","title":"Classification","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"17"},{"slug":"chapters.17.1.nearest-neighbors","title":"Nearest Neighbors","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.1"},{"slug":"chapters.17.2.training-and-testing","title":"Training and Testing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.2"},{"slug":"chapters.17.3.rows-of-tables","title":"Rows of Tables","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.3"},{"slug":"chapters.17.4.implementing-the-classifier","title":"Implementing the Classifier","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.4"},{"slug":"chapters.17.5.accuracy-of-the-classifier","title":"The Accuracy of the Classifier","description":"","date":"","thumbnail":"/build/5e548385d4da863b59d51148bd5d0eeb.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.5"},{"slug":"chapters.17.6.multiple-regression","title":"Multiple Regression","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"17.6"},{"slug":"chapters.18.updating-predictions","title":"Updating Predictions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1,"enumerator":"18"},{"slug":"chapters.18.1.more-likely-than-not-binary-classifier","title":"A “More Likely Than Not” Binary Classifier","description":"","date":"","thumbnail":"/build/tree_students-4ccb9c869896157f61e1e9813b831cd3.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"18.1"},{"slug":"chapters.18.2.making-decisions","title":"Making Decisions","description":"","date":"","thumbnail":"/build/tree_disease_rare-d452fe72cc02977983ec76505172c440.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2,"enumerator":"18.2"}]}}},"actionData":null,"errors":null},"future":{"unstable_dev":false,"unstable_postcss":false,"unstable_tailwind":false,"v2_errorBoundary":true,"v2_headers":true,"v2_meta":true,"v2_normalizeFormMethod":true,"v2_routeConvention":true}};</script><script type="module" async="">import "/build/manifest-3481E987.js";
import * as route0 from "/build/root-7TUVC4ZT.js";
import * as route1 from "/build/routes/$-P6PGXPYX.js";
window.__remixRouteModules = {"root":route0,"routes/$":route1};

import("/build/entry.client-UNPC4GT3.js");</script></body></html>