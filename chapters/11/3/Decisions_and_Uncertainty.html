
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>11.3. Decisions and Uncertainty &#8212; Computational and Inferential Thinking</title>
    
  <link rel="stylesheet" href="../../../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/sphinx-book-theme.e7340bb3dbd8dde6db86f25597f54a1b.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/book.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/togglebutton.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/sphinx-book-theme.7d483ff0a819d6edff12ce0b1ead3928.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="canonical" href="https://inferentialthinking.org/chapters/11/3/Decisions_and_Uncertainty.html" />
    <link rel="shortcut icon" href="../../../_static/favicon.png"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="11.4. Error Probabilities" href="../4/Error_Probabilities.html" />
    <link rel="prev" title="11.2. Multiple Categories" href="../2/Multiple_Categories.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />


<!-- Opengraph tags -->
<meta property="og:url"         content="https://inferentialthinking.org/chapters/11/3/Decisions_and_Uncertainty.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="Decisions and Uncertainty" />
<meta property="og:description" content="Decisions and Uncertainty  We have seen several examples of assessing models that involve chance, by comparing observed data to the predictions made by the mode" />
<meta property="og:image"       content="https://inferentialthinking.org/_static/favicon.png" />

<meta name="twitter:card" content="summary" />


  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../../index.html">
  
  <img src="../../../_static/favicon.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Computational and Inferential Thinking</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="current nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../01/what-is-data-science.html">
   1. Data Science
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2 collapsible-parent">
    <a class="reference internal" href="../../01/1/intro.html">
     1.1. Introduction
    </a>
    <ul class="collapse-ul">
     <li class="toctree-l3">
      <a class="reference internal" href="../../01/1/1/computational-tools.html">
       1.1.1. Computational Tools
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../01/1/2/statistical-techniques.html">
       1.1.2. Statistical Techniques
      </a>
     </li>
    </ul>
    <i class="fas fa-chevron-down">
    </i>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../01/2/why-data-science.html">
     1.2. Why Data Science?
    </a>
   </li>
   <li class="toctree-l2 collapsible-parent">
    <a class="reference internal" href="../../01/3/Plotting_the_Classics.html">
     1.3. Plotting the Classics
    </a>
    <ul class="collapse-ul">
     <li class="toctree-l3">
      <a class="reference internal" href="../../01/3/1/Literary_Characters.html">
       1.3.1. Literary Characters
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../01/3/2/Another_Kind_Of_Character.html">
       1.3.2. Another Kind of Character
      </a>
     </li>
    </ul>
    <i class="fas fa-chevron-down">
    </i>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../02/causality-and-experiments.html">
   2. Causality and Experiments
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../02/1/observation-and-visualization-john-snow-and-the-broad-street-pump.html">
     2.1. John Snow and the Broad Street Pump
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../02/2/snow-s-grand-experiment.html">
     2.2. Snow’s “Grand Experiment”
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../02/3/establishing-causality.html">
     2.3. Establishing Causality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../02/4/randomization.html">
     2.4. Randomization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../02/5/endnote.html">
     2.5. Endnote
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../03/programming-in-python.html">
   3. Programming in Python
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../03/1/Expressions.html">
     3.1. Expressions
    </a>
   </li>
   <li class="toctree-l2 collapsible-parent">
    <a class="reference internal" href="../../03/2/Names.html">
     3.2. Names
    </a>
    <ul class="collapse-ul">
     <li class="toctree-l3">
      <a class="reference internal" href="../../03/2/1/Growth.html">
       3.2.1. Example: Growth Rates
      </a>
     </li>
    </ul>
    <i class="fas fa-chevron-down">
    </i>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../03/3/Calls.html">
     3.3. Call Expressions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../03/4/Introduction_to_Tables.html">
     3.4. Introduction to Tables
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../04/Data_Types.html">
   4. Data Types
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../04/1/Numbers.html">
     4.1. Numbers
    </a>
   </li>
   <li class="toctree-l2 collapsible-parent">
    <a class="reference internal" href="../../04/2/Strings.html">
     4.2. Strings
    </a>
    <ul class="collapse-ul">
     <li class="toctree-l3">
      <a class="reference internal" href="../../04/2/1/String_Methods.html">
       4.2.1. String Methods
      </a>
     </li>
    </ul>
    <i class="fas fa-chevron-down">
    </i>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../04/3/Comparison.html">
     4.3. Comparisons
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../05/Sequences.html">
   5. Sequences
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../05/1/Arrays.html">
     5.1. Arrays
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../05/2/Ranges.html">
     5.2. Ranges
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../05/3/More_on_Arrays.html">
     5.3. More on Arrays
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../06/Tables.html">
   6. Tables
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../06/1/Sorting_Rows.html">
     6.1. Sorting Rows
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../06/2/Selecting_Rows.html">
     6.2. Selecting Rows
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../06/3/Example_Trends_in_the_Population_of_the_United_States.html">
     6.3. Example: Population Trends
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../06/4/Example_Gender_Ratio_in_the_US_Population.html">
     6.4. Example: Trends in Gender
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../07/Visualization.html">
   7. Visualization
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../07/1/Visualizing_Categorical_Distributions.html">
     7.1. Categorical Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../07/2/Visualizing_Numerical_Distributions.html">
     7.2. Numerical Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../07/3/Overlaid_Graphs.html">
     7.3. Overlaid Graphs
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../08/Functions_and_Tables.html">
   8. Functions and Tables
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../08/1/Applying_a_Function_to_a_Column.html">
     8.1. Applying Functions to Columns
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../08/2/Classifying_by_One_Variable.html">
     8.2. Classifying by One Variable
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../08/3/Cross-Classifying_by_More_than_One_Variable.html">
     8.3. Cross-Classifying
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../08/4/Joining_Tables_by_Columns.html">
     8.4. Joining Tables by Columns
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../08/5/Bike_Sharing_in_the_Bay_Area.html">
     8.5. Bike Sharing in the Bay Area
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../09/Randomness.html">
   9. Randomness
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../09/1/Conditional_Statements.html">
     9.1. Conditional Statements
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../09/2/Iteration.html">
     9.2. Iteration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../09/3/Simulation.html">
     9.3. Simulation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../09/4/Monty_Hall_Problem.html">
     9.4. The Monty Hall Problem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../09/5/Finding_Probabilities.html">
     9.5. Finding Probabilities
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../10/Sampling_and_Empirical_Distributions.html">
   10. Sampling and Empirical Distributions
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../10/1/Empirical_Distributions.html">
     10.1. Empirical Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../10/2/Sampling_from_a_Population.html">
     10.2. Sampling from a Population
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../10/3/Empirical_Distribution_of_a_Statistic.html">
     10.3. Empirical Distibution of a Statistic
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="../Testing_Hypotheses.html">
   11. Testing Hypotheses
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../1/Assessing_Models.html">
     11.1. Assessing Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2/Multiple_Categories.html">
     11.2. Multiple Categories
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     11.3. Decisions and Uncertainty
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../4/Error_Probabilities.html">
     11.4. Error Probabilities
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../12/Comparing_Two_Samples.html">
   12. Comparing Two Samples
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../12/1/AB_Testing.html">
     12.1. A/B Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../12/2/Deflategate.html">
     12.2. Deflategate
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../12/3/Causality.html">
     12.3. Causality
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../13/Estimation.html">
   13. Estimation
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../13/1/Percentiles.html">
     13.1. Percentiles
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../13/2/Bootstrap.html">
     13.2. The Bootstrap
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../13/3/Confidence_Intervals.html">
     13.3. Confidence Intervals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../13/4/Using_Confidence_Intervals.html">
     13.4. Using Confidence Intervals
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../14/Why_the_Mean_Matters.html">
   14. Why the Mean Matters
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../14/1/Properties_of_the_Mean.html">
     14.1. Properties of the Mean
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../14/2/Variability.html">
     14.2. Variability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../14/3/SD_and_the_Normal_Curve.html">
     14.3. The SD and the Normal Curve
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../14/4/Central_Limit_Theorem.html">
     14.4. The Central Limit Theorem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../14/5/Variability_of_the_Sample_Mean.html">
     14.5. The Variability of the Sample Mean
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../14/6/Choosing_a_Sample_Size.html">
     14.6. Choosing a Sample Size
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../15/Prediction.html">
   15. Prediction
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../15/1/Correlation.html">
     15.1. Correlation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../15/2/Regression_Line.html">
     15.2. The Regression Line
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../15/3/Method_of_Least_Squares.html">
     15.3. The Method of Least Squares
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../15/4/Least_Squares_Regression.html">
     15.4. Least Squares Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../15/5/Visual_Diagnostics.html">
     15.5. Visual Diagnostics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../15/6/Numerical_Diagnostics.html">
     15.6. Numerical Diagnostics
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../16/Inference_for_Regression.html">
   16. Inference for Regression
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../16/1/Regression_Model.html">
     16.1. A Regression Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../16/2/Inference_for_the_True_Slope.html">
     16.2. Inference for the True Slope
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../16/3/Prediction_Intervals.html">
     16.3. Prediction Intervals
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../17/Classification.html">
   17. Classification
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../17/1/Nearest_Neighbors.html">
     17.1. Nearest Neighbors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../17/2/Training_and_Testing.html">
     17.2. Training and Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../17/3/Rows_of_Tables.html">
     17.3. Rows of Tables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../17/4/Implementing_the_Classifier.html">
     17.4. Implementing the Classifier
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../17/5/Accuracy_of_the_Classifier.html">
     17.5. The Accuracy of the Classifier
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../17/6/Multiple_Regression.html">
     17.6. Multiple Regression
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../18/Updating_Predictions.html">
   18. Updating Predictions
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../18/1/More_Likely_than_Not_Binary_Classifier.html">
     18.1. A "More Likely Than Not" Binary Classifier
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../18/2/Making_Decisions.html">
     18.2. Making Decisions
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../../_sources/chapters/11/3/Decisions_and_Uncertainty.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/data-8/textbook"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>


            <!-- Full screen (wrap in <a> to have style consistency -->
            <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                    data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                    title="Fullscreen mode"><i
                        class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/data-8/textbook/main?urlpath=tree/chapters/11/3/Decisions_and_Uncertainty.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        <a class="jupyterhub-button" href="https://datahub.berkeley.edu/hub/user-redirect/git-pull?repo=https://github.com/data-8/textbook&urlpath=tree/textbook/chapters/11/3/Decisions_and_Uncertainty.ipynb&branch=main"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch JupyterHub" data-toggle="tooltip"
                data-placement="left"><img class="jupyterhub-button-logo"
                    src="../../../_static/images/logo_jupyterhub.svg"
                    alt="Interact on JupyterHub">JupyterHub</button></a>
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i>
            Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-1-the-hypotheses">
   11.3.1. Step 1: The Hypotheses
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-2-the-test-statistic">
   11.3.2. Step 2: The Test Statistic
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-3-the-distribution-of-the-test-statistic-under-the-null-hypothesis">
   11.3.3. Step 3: The Distribution of the Test Statistic, Under the Null Hypothesis
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-4-the-conclusion-of-the-test">
   11.3.4. Step 4. The Conclusion of the Test
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-meaning-of-consistent">
   11.3.5. The Meaning of “Consistent”
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-gsi-s-defense">
   11.3.6. The GSI’s Defense
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conventional-cut-offs-and-the-p-value">
   11.3.7. Conventional Cut-offs and the P-value
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#historical-note-on-the-conventions">
   11.3.8. Historical Note on the Conventions
  </a>
 </li>
</ul>

        </nav>
        
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="cell tag_remove-input docutils container">
</div>
<div class="section" id="decisions-and-uncertainty">
<h1><span class="section-number">11.3. </span>Decisions and Uncertainty<a class="headerlink" href="#decisions-and-uncertainty" title="Permalink to this headline">¶</a></h1>
<p>We have seen several examples of assessing models that involve chance, by comparing observed data to the predictions made by the models. In all of our examples, there has been no doubt about whether the data were consistent with the model’s predictions. The data were either very far away from the predictions, or very close to them.</p>
<p>But outcomes are not always so clear cut. How far is “far”? Exactly what does “close” mean? While these questions don’t have universal answers, there are guidelines and conventions that you can follow. In this section we will describe some of them.</p>
<p>But first let us develop a general framework of decision making, into which all our examples will fit.</p>
<p>What we have developed while assessing models are some of the fundamental concepts of statistical tests of hypotheses. Using statistical tests as a way of making decisions is standard in many fields and has a standard terminology. Here is the sequence of the steps in most statistical tests, along with some terminology and examples. You will see that they are consistent with the sequence of steps we have used for assessing models.</p>
<div class="section" id="step-1-the-hypotheses">
<h2><span class="section-number">11.3.1. </span>Step 1: The Hypotheses<a class="headerlink" href="#step-1-the-hypotheses" title="Permalink to this headline">¶</a></h2>
<p>All statistical tests attempt to choose between two views of the world. Specifically, the choice is between two views about how the data were generated. These two views are called <em>hypotheses</em>.</p>
<p><strong>The null hypothesis.</strong> This is a clearly defined model about chances. It says that the data were generated at random under clearly specified assumptions about the randomness. The word “null” reinforces the idea that if the data look different from what the null hypothesis predicts, the difference is due to <em>nothing</em> but chance.</p>
<p>From a practical perspective, <strong>the null hypothesis is a hypothesis under which you can simulate data.</strong></p>
<p>In the example about Mendel’s model for the colors of pea plants, the null hypothesis is that the assumptions of his model are good: each plant has a 75% chance of having purple flowers, independent of all other plants.</p>
<p>Under this hypothesis, we were able to simulate random samples, by using <code class="docutils literal notranslate"><span class="pre">sample_proportions(929,</span> <span class="pre">[0.75,</span> <span class="pre">0.25])</span></code>. We used a sample size of 929 because that’s the number of plants Mendel grew.</p>
<p><strong>The alternative hypothesis.</strong> This says that some reason other than chance made the data differ from the predictions of the model in the null hypothesis.</p>
<p>In the example about Mendel’s plants, the alternative hypothesis is simply that his model isn’t good.</p>
</div>
<div class="section" id="step-2-the-test-statistic">
<h2><span class="section-number">11.3.2. </span>Step 2: The Test Statistic<a class="headerlink" href="#step-2-the-test-statistic" title="Permalink to this headline">¶</a></h2>
<p>In order to decide between the two hypothesis, we must choose a statistic that we can use to make the decision. This is called the <strong>test statistic</strong>.</p>
<p>In the example of Mendel’s plants, our statistic was the absolute difference between the sample percent and 75% which was predicted by his model.</p>
<div class="math notranslate nohighlight">
\[
\big{\vert} \text{sample percent of purple-flowering plants} - 75 \big{\vert}
\]</div>
<p>To see how to make the choice in general, look at the alternative hypothesis. What values of the statistic will make you think that the alternative hypothesis is a better choice than the null?</p>
<ul class="simple">
<li><p>If the answer is “big values,” you might have a good choice of statistic.</p></li>
<li><p>So also if the answer is “small values.”</p></li>
<li><p>But if the answer is “both big values and small values,” we recommend that you look again at your statistic and see if taking an absolute value can change the answer to just “big values”.</p></li>
</ul>
<p>In the case of the pea plants, a sample percent of around 75% will be consistent with the model, but percents much bigger or much less than 75 will make you think that the model isn’t good. This indicates that the statistic should be the <em>distance</em> between the sample percent and 75, that is, the absolute value of the difference between them. Big values of the distance will make you lean towards the alternative.</p>
<p>The <strong>observed value of the test statistic</strong> is the value of the statistic you get from the data in the study, not a simulated value. Among Mendel’s 929 plants, 705 had purple flowers. The observed value of the test statistic was therefore</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">abs</span> <span class="p">(</span> <span class="mi">100</span> <span class="o">*</span> <span class="p">(</span><span class="mi">705</span> <span class="o">/</span> <span class="mi">929</span><span class="p">)</span> <span class="o">-</span> <span class="mi">75</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.8880516684607045
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="step-3-the-distribution-of-the-test-statistic-under-the-null-hypothesis">
<h2><span class="section-number">11.3.3. </span>Step 3: The Distribution of the Test Statistic, Under the Null Hypothesis<a class="headerlink" href="#step-3-the-distribution-of-the-test-statistic-under-the-null-hypothesis" title="Permalink to this headline">¶</a></h2>
<p>The main computational aspect of a test of hypotheses is figuring out <em>what the values of the test statistic might be if the null hypothesis were true</em>.</p>
<p>The test statistic is simulated based on the assumptions of the model in the null hypothesis. That model involves chance, so the statistic comes out differently when you simulate it multiple times.</p>
<p>By simulating the statistic repeatedly, we get a good sense of its possible values and which ones are more likely than others. In other words, we get a good approximation to the probability distribution of the statistic, as predicted by the model in the null hypothesis.</p>
<p>As with all distributions, it is very useful to visualize this distribution by a histogram. We have done so in all our examples.</p>
</div>
<div class="section" id="step-4-the-conclusion-of-the-test">
<h2><span class="section-number">11.3.4. </span>Step 4. The Conclusion of the Test<a class="headerlink" href="#step-4-the-conclusion-of-the-test" title="Permalink to this headline">¶</a></h2>
<p>The choice between the null and alternative hypotheses depends on the comparison between what you computed in Steps 2 and 3: the observed value of the test statistic and its distribution as predicted by the null hypothesis.</p>
<p>If the two are consistent with each other, then the observed test statistic is in line with what the null hypothesis predicts. In other words, the test does not point towards the alternative hypothesis; the null hypothesis is better supported by the data. This was the case with the assessment of Mendel’s model.</p>
<p>But if the two are not consistent with each other, as is the case in our example about Alameda County jury panels, then the data do not support the null hypothesis. That is why we concluded that the jury panels were not selected at random. Something other than chance affected their composition.</p>
<p>If the data do not support the null hypothesis, we say that the test <em>rejects</em> the null hypothesis.</p>
</div>
<div class="section" id="the-meaning-of-consistent">
<h2><span class="section-number">11.3.5. </span>The Meaning of “Consistent”<a class="headerlink" href="#the-meaning-of-consistent" title="Permalink to this headline">¶</a></h2>
<p>In the example about Alameda County juries, it was apparent that our observed test statistic was far from what was predicted by the null hypothesis. In the example about pea flowers, it is just as clear that the observed statistic is consistent with the distribution that the null predicts. So in both of the examples, it is clear which hypothesis to choose.</p>
<p>But sometimes the decision is not so clear. Whether the observed test statistic is consistent with its predicted distribution under the null hypothesis is a matter of judgment. We recommend that you provide your judgment along with the value of the test statistic and a graph of its predicted distribution under the null. That will allow your reader to make his or her own judgment about whether the two are consistent.</p>
<p>Here is an example where the decision requires judgment.</p>
</div>
<div class="section" id="the-gsi-s-defense">
<h2><span class="section-number">11.3.6. </span>The GSI’s Defense<a class="headerlink" href="#the-gsi-s-defense" title="Permalink to this headline">¶</a></h2>
<p>A Berkeley Statistics class of about 350 students was divided into 12 discussion sections led by Graduate Student Instructors (GSIs). After the midterm, students in Section 3 noticed that their scores were on average lower than the rest of the class.</p>
<p>In such situations, students tend to grumble about the section’s GSI. Surely, they feel, there must have been something wrong with the GSI’s teaching. Or else why would their section have done worse than others?</p>
<p>The GSI, typically more experienced about statistical variation, often has a different perspective: if you simply draw a section of students at random from the whole class, their average score could resemble the score that the students are unhappy about, just by chance.</p>
<p>The GSI’s position is a clearly stated chance model. We can simulate data under this model. Let’s test it out.</p>
<p><strong>Null Hypothesis.</strong> The average score of the students in Section 3 is like the average score of the same number of students picked at random from the class.</p>
<p><strong>Alternative Hypothesis.</strong> No, it’s too low.</p>
<p>A natural statistic here is the average of the scores. Low values of the average will make us lean towards the alternative.</p>
<p>Let’s take a look at the data.</p>
<p>The table <code class="docutils literal notranslate"><span class="pre">scores</span></code> contains the section number and midterm score for each student in the class. The midterm scores were integers in the range 0 through 25; 0 means that the student didn’t take the test.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scores</span> <span class="o">=</span> <span class="n">Table</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span><span class="n">path_data</span> <span class="o">+</span> <span class="s1">&#39;scores_by_section.csv&#39;</span><span class="p">)</span>
<span class="n">scores</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table border="1" class="dataframe">
    <thead>
        <tr>
            <th>Section</th> <th>Midterm</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>1      </td> <td>22     </td>
        </tr>
        <tr>
            <td>2      </td> <td>12     </td>
        </tr>
        <tr>
            <td>2      </td> <td>23     </td>
        </tr>
        <tr>
            <td>2      </td> <td>14     </td>
        </tr>
        <tr>
            <td>1      </td> <td>20     </td>
        </tr>
        <tr>
            <td>3      </td> <td>25     </td>
        </tr>
        <tr>
            <td>4      </td> <td>19     </td>
        </tr>
        <tr>
            <td>1      </td> <td>24     </td>
        </tr>
        <tr>
            <td>5      </td> <td>8      </td>
        </tr>
        <tr>
            <td>6      </td> <td>14     </td>
        </tr>
    </tbody>
</table>
<p>... (349 rows omitted)</p></div></div>
</div>
<p>To find the average score in each section, we will use <code class="docutils literal notranslate"><span class="pre">group</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">section_averages</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="s1">&#39;Section&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">)</span>
<span class="n">section_averages</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table border="1" class="dataframe">
    <thead>
        <tr>
            <th>Section</th> <th>Midterm average</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>1      </td> <td>15.5938        </td>
        </tr>
        <tr>
            <td>2      </td> <td>15.125         </td>
        </tr>
        <tr>
            <td>3      </td> <td>13.6667        </td>
        </tr>
        <tr>
            <td>4      </td> <td>14.7667        </td>
        </tr>
        <tr>
            <td>5      </td> <td>17.4545        </td>
        </tr>
        <tr>
            <td>6      </td> <td>15.0312        </td>
        </tr>
        <tr>
            <td>7      </td> <td>16.625         </td>
        </tr>
        <tr>
            <td>8      </td> <td>16.3103        </td>
        </tr>
        <tr>
            <td>9      </td> <td>14.5667        </td>
        </tr>
        <tr>
            <td>10     </td> <td>15.2353        </td>
        </tr>
        <tr>
            <td>11     </td> <td>15.8077        </td>
        </tr>
        <tr>
            <td>12     </td> <td>15.7333        </td>
        </tr>
    </tbody>
</table></div></div>
</div>
<p>The average score of Section 3 is 13.667, which does look low compared to the other section averages. But is it lower than the average of a section of the same size selected at random from the class?</p>
<p>To answer this, we can select a section at random from the class and find its average. To select a section at random to we need to know how big Section 3 is, which we can by once again using <code class="docutils literal notranslate"><span class="pre">group</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scores</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="s1">&#39;Section&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table border="1" class="dataframe">
    <thead>
        <tr>
            <th>Section</th> <th>count</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>1      </td> <td>32   </td>
        </tr>
        <tr>
            <td>2      </td> <td>32   </td>
        </tr>
        <tr>
            <td>3      </td> <td>27   </td>
        </tr>
        <tr>
            <td>4      </td> <td>30   </td>
        </tr>
        <tr>
            <td>5      </td> <td>33   </td>
        </tr>
        <tr>
            <td>6      </td> <td>32   </td>
        </tr>
        <tr>
            <td>7      </td> <td>24   </td>
        </tr>
        <tr>
            <td>8      </td> <td>29   </td>
        </tr>
        <tr>
            <td>9      </td> <td>30   </td>
        </tr>
        <tr>
            <td>10     </td> <td>34   </td>
        </tr>
    </tbody>
</table>
<p>... (2 rows omitted)</p></div></div>
</div>
<p>Section 3 had 27 students.</p>
<p>Now we can figure out how to create one simulated value of our test statistic, the random sample average.</p>
<p>First we have to select 27 scores at random without replacement. Since the data are already in a table, we will use the Table method <code class="docutils literal notranslate"><span class="pre">sample</span></code>.</p>
<p>Remember that by default, <code class="docutils literal notranslate"><span class="pre">sample</span></code> draws with replacement. The optional argument <code class="docutils literal notranslate"><span class="pre">with_replacement</span> <span class="pre">=</span> <span class="pre">False</span></code> produces a random sample drawn without replacement.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scores_only</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;Section&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">random_sample</span> <span class="o">=</span> <span class="n">scores_only</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">27</span><span class="p">,</span> <span class="n">with_replacement</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">random_sample</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table border="1" class="dataframe">
    <thead>
        <tr>
            <th>Midterm</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>16     </td>
        </tr>
        <tr>
            <td>24     </td>
        </tr>
        <tr>
            <td>14     </td>
        </tr>
        <tr>
            <td>23     </td>
        </tr>
        <tr>
            <td>7      </td>
        </tr>
        <tr>
            <td>16     </td>
        </tr>
        <tr>
            <td>9      </td>
        </tr>
        <tr>
            <td>13     </td>
        </tr>
        <tr>
            <td>10     </td>
        </tr>
        <tr>
            <td>25     </td>
        </tr>
    </tbody>
</table>
<p>... (17 rows omitted)</p></div></div>
</div>
<p>The average of these 27 randomly selected scores is</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">random_sample</span><span class="o">.</span><span class="n">column</span><span class="p">(</span><span class="s1">&#39;Midterm&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>17.666666666666668
</pre></div>
</div>
</div>
</div>
<p>That’s the average of 27 randomly selected scores. The cell below collects the code necessary for generating this random average.</p>
<p>Now we can simulate the random sample average by repeating the calculation multple times.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">random_sample_average</span><span class="p">():</span>
    <span class="n">random_sample</span> <span class="o">=</span> <span class="n">scores_only</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">27</span><span class="p">,</span> <span class="n">with_replacement</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">random_sample</span><span class="o">.</span><span class="n">column</span><span class="p">(</span><span class="s1">&#39;Midterm&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample_averages</span> <span class="o">=</span> <span class="n">make_array</span><span class="p">()</span>

<span class="n">repetitions</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">repetitions</span><span class="p">):</span>
    <span class="n">sample_averages</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample_averages</span><span class="p">,</span> <span class="n">random_sample_average</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<p>Here is the histogram of the simulated averages. It shows the distribution of what the Section 3 average might have been, if Section 3 had been selected at random from the class.</p>
<p>The observed Section 3 average score of 13.667 is shown as a red dot on the horizontal axis. You can ignore the last line of code; it just draws the dot.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">averages_tbl</span> <span class="o">=</span> <span class="n">Table</span><span class="p">()</span><span class="o">.</span><span class="n">with_column</span><span class="p">(</span><span class="s1">&#39;Sample Average&#39;</span><span class="p">,</span> <span class="n">sample_averages</span><span class="p">)</span>
<span class="n">averages_tbl</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

<span class="n">observed_statistic</span> <span class="o">=</span> <span class="mf">13.667</span>
<span class="n">plots</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">observed_statistic</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">30</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/Decisions_and_Uncertainty_24_0.png" src="../../../_images/Decisions_and_Uncertainty_24_0.png" />
</div>
</div>
<p>As we said earlier, small values of the test statistic will make us lean towards the alternative hypothesis, that the average score in the section is too low for it to look like a random sample from the class.</p>
<p>Is the observed statistic of 13.667 “too low” in relation to this distribution? In other words, is the red far enough out into the left hand tail of the histogram for you to think that it is “too far”?</p>
<p>It’s up to you to decide! Use your judgment. Go ahead – it’s OK to do so.</p>
</div>
<div class="section" id="conventional-cut-offs-and-the-p-value">
<h2><span class="section-number">11.3.7. </span>Conventional Cut-offs and the P-value<a class="headerlink" href="#conventional-cut-offs-and-the-p-value" title="Permalink to this headline">¶</a></h2>
<p>If you don’t want to make your own judgment, there are conventions that you can follow. These conventions tell us how far out into the tails is considered “too far”.</p>
<p>The conventions are based on the area in the tail, starting at the observed statistic (the red dot) and looking in the direction that makes us lean toward the alternative (the left side, in this example). If the area of the tail is small, the observed statistic is far away from the values most commonly predicted by the null hypothesis.</p>
<p>Remember that in a histogram, area represents percent. To find the area in the tail, we have to find the percent of sample averages that were less than or equal to the average score of Section 3, where the red dot is. The array <code class="docutils literal notranslate"><span class="pre">sample_averages</span></code> contains the averages for all 10,000 repetitions of the random sampling, and <code class="docutils literal notranslate"><span class="pre">observed_statistic</span></code> is 13.667, the average score of Section 3.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">sample_averages</span> <span class="o">&lt;=</span> <span class="n">observed_statistic</span><span class="p">)</span> <span class="o">/</span> <span class="n">repetitions</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.0541
</pre></div>
</div>
</div>
</div>
<p>About 5.7% of the simulated random sample averages were 13.667 or below. If we had drawn the students of Section 3 at random from the whole class, the chance that their average would be 13.667 or lower is about 5.7%.</p>
<p>This chance has an impressive name. It is called the <em>observed significance level</em> of the test. That’s a mouthful, and so it is commonly called the <em>P-value</em> of the test.</p>
<p><strong>Definition:</strong> The P-value of a test is the chance, based on the model in the null hypothesis, that the test statistic will be equal to the observed value in the sample or even further in the direction that supports the alternative.**</p>
<p>If a P-value is small, that means the tail beyond the observed statistic is small and so the observed statistic is far away from what the null predicts. This implies that the data support the alternative hypothesis better than they support the null.</p>
<p>How small is “small”? According to the conventions:</p>
<ul class="simple">
<li><p>If the P-value is less than 5%, it is considered small and the result is called “statistically significant.”</p></li>
<li><p>If the P-value is even smaller – less than 1% – the result is called “highly statistically significant.”</p></li>
</ul>
<p>By this convention, our P-value of 5.7% is not considered small. So we have to conclude that the GSI’s defense holds good – the average score of Section 3 is like those generated by random chance. Formally, the result of the test is not statistically significant.</p>
<p>When you make a conclusion in this way, we recommend that you don’t just say whether or not the result is statistically significant. Along with your conclusion, provide the observed statistic and the P-value as well, so that readers can use their own judgment.</p>
</div>
<div class="section" id="historical-note-on-the-conventions">
<h2><span class="section-number">11.3.8. </span>Historical Note on the Conventions<a class="headerlink" href="#historical-note-on-the-conventions" title="Permalink to this headline">¶</a></h2>
<p>The determination of statistical significance, as defined above, has become standard in statistical analyses in all fields of application. When a convention is so universally followed, it is interesting to examine how it arose.</p>
<p>The method of statistical testing – choosing between hypotheses based on data in random samples – was developed by Sir Ronald Fisher in the early 20th century. Sir Ronald might have set the convention for statistical significance somewhat unwittingly, in the following statement in his 1925 book <em>Statistical Methods for Research Workers</em>. About the 5% level, he wrote, “It is convenient to take this point as a limit in judging whether a deviation is to be considered significant or not.”</p>
<p>What was “convenient” for Sir Ronald became a cutoff that has acquired the status of a universal constant. No matter that Sir Ronald himself made the point that the value was his personal choice from among many: in an article in 1926, he wrote, “If one in twenty does not seem high enough odds, we may, if we prefer it draw the line at one in fifty (the 2 percent point), or one in a hundred (the 1 percent point). Personally, the author prefers to set a low standard of significance at the 5 percent point …”</p>
<p>Fisher knew that “low” is a matter of judgment and has no unique definition. We suggest that you follow his excellent example. Provide your data, make your judgment, and explain why you made it.</p>
<p>Whether you use a conventional cutoff or your own judgment, it is important to keep the following points in mind.</p>
<ul class="simple">
<li><p>Always provide the observed value of the test statistic and the P-value, so that readers can decide whether or not they think the P-value is small.</p></li>
<li><p>Don’t look to defy convention only when the conventionally derived result is not to your liking.</p></li>
<li><p>Even if a test concludes that the data don’t support the chance model in the null hypothesis, it typically doesn’t explain <em>why</em> the model doesn’t work.</p></li>
</ul>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./chapters/11/3"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="../2/Multiple_Categories.html" title="previous page"><span class="section-number">11.2. </span>Multiple Categories</a>
    <a class='right-next' id="next-link" href="../4/Error_Probabilities.html" title="next page"><span class="section-number">11.4. </span>Error Probabilities</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Ani Adhikari and John DeNero<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../../../_static/js/index.d3f166471bb80abb5163.js"></script>


    
    <!-- Google Analytics -->
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-148221575-1', 'auto');
      ga('set', 'anonymizeIp', true);
      ga('send', 'pageview');
    </script>
    <script async src='https://www.google-analytics.com/analytics.js'></script>
    <!-- End Google Analytics -->
    
  </body>
</html>