{"version":2,"kind":"Notebook","sha256":"4f4fe17c085c5f9b0e14c84ffb5d27e819e94a7f7012c7868e1760ecfe667638","slug":"chapters.17.4.implementing-the-classifier","location":"/chapters/17/4/Implementing_the_Classifier.ipynb","dependencies":[],"frontmatter":{"title":"Implementing the Classifier","content_includes_title":false,"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"license":{"content":{"id":"CC-BY-NC-ND-4.0","url":"https://creativecommons.org/licenses/by-nc-nd/4.0/","name":"Creative Commons Attribution Non Commercial No Derivatives 4.0 International","CC":true}},"github":"https://github.com/data-8/textbook","numbering":{"title":{"enabled":true,"offset":1}},"source_url":"https://github.com/data-8/textbook/blob/main/chapters/17/4/Implementing_the_Classifier.ipynb","edit_url":"https://github.com/data-8/textbook/edit/main/chapters/17/4/Implementing_the_Classifier.ipynb","enumerator":"17.4","exports":[{"format":"ipynb","filename":"Implementing_the_Classifier.ipynb","url":"/build/Implementing_the_Cla-5cbc4bab85f2e1bd81b15b43aad8774e.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"We are now ready to implement a ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"jn0IRlQD2W"},{"type":"inlineMath","value":"k","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span>","key":"BqK9YWWmuz"},{"type":"text","value":"-nearest neighbor classifier based on multiple attributes. We have used only two attributes so far, for ease of visualization. But usually predictions will be based on many attributes. Here is an example that shows how multiple attributes can be better than pairs.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"DoLuFr7n1v"}],"key":"JKY4KvueRO"}],"key":"NUv6mnZqzT"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"import matplotlib\n#matplotlib.use('Agg')\npath_data = '../../../assets/data/'\nfrom datascience import *\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport numpy as np\nimport math\nimport scipy.stats as stats\nplt.style.use('fivethirtyeight')","visibility":"remove","key":"S9c6LQ3zz3"},{"type":"output","id":"jkQ1rADVd-TL1A3S80QgD","data":[],"visibility":"show","key":"JncdAC7CTv"}],"visibility":"show","key":"fj1uDrr9oo"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Banknote authentication","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"XYoovuGrzG"}],"identifier":"banknote-authentication","label":"Banknote authentication","html_id":"banknote-authentication","implicit":true,"key":"ClraX3yyno"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"This time we’ll look at predicting whether a banknote (e.g., a $20 bill) is counterfeit or legitimate.  Researchers have put together a data set for us, based on photographs of many individual banknotes: some counterfeit, some legitimate.  They computed a few numbers from each image, using techniques that we won’t worry about for this course.  So, for each banknote, we know a few numbers that were computed from a photograph of it as well as its class (whether it is counterfeit or not).  Let’s load it into a table and take a look.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"fpwmQEnZZk"}],"key":"PSevGGC09M"}],"key":"ozotFDZXG7"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"banknotes = Table.read_table(path_data + 'banknote.csv')\nbanknotes","key":"J2QvGWCdnq"},{"type":"output","id":"yRE5G38RWjlyrkHkSdCu_","data":[{"output_type":"execute_result","execution_count":2,"metadata":{},"data":{"text/html":{"content":"<table border=\"1\" class=\"dataframe\">\n    <thead>\n        <tr>\n            <th>WaveletVar</th> <th>WaveletSkew</th> <th>WaveletCurt</th> <th>Entropy</th> <th>Class</th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr>\n            <td>3.6216    </td> <td>8.6661     </td> <td>-2.8073    </td> <td>-0.44699</td> <td>0    </td>\n        </tr>\n        <tr>\n            <td>4.5459    </td> <td>8.1674     </td> <td>-2.4586    </td> <td>-1.4621 </td> <td>0    </td>\n        </tr>\n        <tr>\n            <td>3.866     </td> <td>-2.6383    </td> <td>1.9242     </td> <td>0.10645 </td> <td>0    </td>\n        </tr>\n        <tr>\n            <td>3.4566    </td> <td>9.5228     </td> <td>-4.0112    </td> <td>-3.5944 </td> <td>0    </td>\n        </tr>\n        <tr>\n            <td>0.32924   </td> <td>-4.4552    </td> <td>4.5718     </td> <td>-0.9888 </td> <td>0    </td>\n        </tr>\n        <tr>\n            <td>4.3684    </td> <td>9.6718     </td> <td>-3.9606    </td> <td>-3.1625 </td> <td>0    </td>\n        </tr>\n        <tr>\n            <td>3.5912    </td> <td>3.0129     </td> <td>0.72888    </td> <td>0.56421 </td> <td>0    </td>\n        </tr>\n        <tr>\n            <td>2.0922    </td> <td>-6.81      </td> <td>8.4636     </td> <td>-0.60216</td> <td>0    </td>\n        </tr>\n        <tr>\n            <td>3.2032    </td> <td>5.7588     </td> <td>-0.75345   </td> <td>-0.61251</td> <td>0    </td>\n        </tr>\n        <tr>\n            <td>1.5356    </td> <td>9.1772     </td> <td>-2.2718    </td> <td>-0.73535</td> <td>0    </td>\n        </tr>\n    </tbody>\n</table>\n<p>... (1362 rows omitted)</p>","content_type":"text/html"},"text/plain":{"content":"WaveletVar | WaveletSkew | WaveletCurt | Entropy  | Class\n3.6216     | 8.6661      | -2.8073     | -0.44699 | 0\n4.5459     | 8.1674      | -2.4586     | -1.4621  | 0\n3.866      | -2.6383     | 1.9242      | 0.10645  | 0\n3.4566     | 9.5228      | -4.0112     | -3.5944  | 0\n0.32924    | -4.4552     | 4.5718      | -0.9888  | 0\n4.3684     | 9.6718      | -3.9606     | -3.1625  | 0\n3.5912     | 3.0129      | 0.72888     | 0.56421  | 0\n2.0922     | -6.81       | 8.4636      | -0.60216 | 0\n3.2032     | 5.7588      | -0.75345    | -0.61251 | 0\n1.5356     | 9.1772      | -2.2718     | -0.73535 | 0\n... (1362 rows omitted)","content_type":"text/plain"}}}],"key":"dTxzosZ1KL"}],"key":"PIoEwrBsp0"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Let’s look at whether the first two numbers tell us anything about whether the banknote is counterfeit or not.  Here’s a scatterplot:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"jaIcCYBDD1"}],"key":"IrsxgqLDsP"}],"key":"JnuNAHop4m"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"color_table = Table().with_columns(\n    'Class', make_array(1, 0),\n    'Color', make_array('darkblue', 'gold')\n)","key":"XSkUQ9iCi4"},{"type":"output","id":"5E7P0CxhGk9QfnOSDEkxX","data":[],"key":"MyK64YcYKg"}],"key":"QPdeJEM1uI"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"banknotes = banknotes.join('Class', color_table)","key":"uXdDiheaTt"},{"type":"output","id":"Y_0D8Kw_zEc250qh01etK","data":[],"key":"RbsWU2mcVv"}],"key":"UAeBTqkOYi"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"banknotes.scatter('WaveletVar', 'WaveletCurt', group='Color')","key":"LTRzkiHcct"},{"type":"output","id":"rBN9BtypyZ9CuiSnXVFJs","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"60e4ae764725667dce462e3f02ad1796","path":"/build/60e4ae764725667dce462e3f02ad1796.png"},"text/plain":{"content":"<Figure size 360x360 with 1 Axes>","content_type":"text/plain"}}}],"key":"FDckv3grqJ"}],"key":"qJMP1TDtce"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Pretty interesting!  Those two measurements do seem helpful for predicting whether the banknote is counterfeit or not.  However, in this example you can now see that there is some overlap between the blue cluster and the gold cluster.  This indicates that there will be some images where it’s hard to tell whether the banknote is legitimate based on just these two numbers.  Still, you could use a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dwFuwV9IPk"},{"type":"inlineMath","value":"k","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span>","key":"qBrikelSbC"},{"type":"text","value":"-nearest neighbor classifier to predict the legitimacy of a banknote.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"oBxdIQ4vgD"}],"key":"IY38pgl5Pm"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Take a minute and think it through: Suppose we used ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"vNB9tdfBy6"},{"type":"inlineMath","value":"k=11","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi><mo>=</mo><mn>11</mn></mrow><annotation encoding=\"application/x-tex\">k=11</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">11</span></span></span></span>","key":"xSbtcbHJct"},{"type":"text","value":" (say).  What parts of the plot would the classifier get right, and what parts would it make errors on?  What would the decision boundary look like?","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"lgTyLhXrRu"}],"key":"pE8q5HrF7J"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"The patterns that show up in the data can get pretty wild.  For instance, here’s what we’d get if used a different pair of measurements from the images:","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"qy3Fq5lZw3"}],"key":"KBm4qF6nAq"}],"key":"X6rur3ECge"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"banknotes.scatter('WaveletSkew', 'Entropy', group='Color')","key":"Qp7JM7Twu0"},{"type":"output","id":"rXohlwfcvT-ztaEH_Q_lA","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"e711de26d6b1184d058cdffafff61f4c","path":"/build/e711de26d6b1184d058cdffafff61f4c.png"},"text/plain":{"content":"<Figure size 360x360 with 1 Axes>","content_type":"text/plain"}}}],"key":"jmCb7swH9L"}],"key":"nS9xo0h2vJ"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"There does seem to be a pattern, but it’s a pretty complex one.  Nonetheless, the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"u96o5UcdJD"},{"type":"inlineMath","value":"k","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span>","key":"HWqhNs8Qgg"},{"type":"text","value":"-nearest neighbors classifier can still be used and will effectively “discover” patterns out of this.  This illustrates how powerful machine learning can be: it can effectively take advantage of even patterns that we would not have anticipated, or that we would have thought to “program into” the computer.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"zkUSmb8uGg"}],"key":"NlPyvqXljN"}],"key":"o6bAVG2oyL"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Multiple attributes","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"k1cLev8QAw"}],"identifier":"multiple-attributes","label":"Multiple attributes","html_id":"multiple-attributes","implicit":true,"key":"p7pigJ1gVI"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"So far I’ve been assuming that we have exactly 2 attributes that we can use to help us make our prediction.  What if we have more than 2?  For instance, what if we have 3 attributes?","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"UUEm7SYZFu"}],"key":"J277rihURJ"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Here’s the cool part: you can use the same ideas for this case, too.  All you have to do is make a 3-dimensional scatterplot, instead of a 2-dimensional plot.  You can still use the ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"UJLWBCE41n"},{"type":"inlineMath","value":"k","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span>","key":"y4Seu6I5m9"},{"type":"text","value":"-nearest neighbors classifier, but now computing distances in 3 dimensions instead of just 2.  It just works.  Very cool!","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"I8ehIXMzRP"}],"key":"qbU1d1cNw7"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"In fact, there’s nothing special about 2 or 3.  If you have 4 attributes, you can use the ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"XxCG8DIFAD"},{"type":"inlineMath","value":"k","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span>","key":"sIFGFcvAmo"},{"type":"text","value":"-nearest neighbors classifier in 4 dimensions.  5 attributes?  Work in 5-dimensional space.  And no need to stop there!  This all works for arbitrarily many attributes; you just work in a very high dimensional space.  It gets wicked-impossible to visualize, but that’s OK.  The computer algorithm generalizes very nicely: all you need is the ability to compute the distance, and that’s not hard.  Mind-blowing stuff!","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"Z43CkYBrTJ"}],"key":"ngURupJ1gZ"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"For instance, let’s see what happens if we try to predict whether a banknote is counterfeit or not using 3 of the measurements, instead of just 2.  Here’s what you get:","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"pXligNpEJi"}],"key":"spsebCMBPS"}],"key":"zLoeshoHWR"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"ax = plt.figure(figsize=(8,8)).add_subplot(111, projection='3d')\nax.scatter(banknotes.column('WaveletSkew'), \n           banknotes.column('WaveletVar'), \n           banknotes.column('WaveletCurt'), \n           c=banknotes.column('Color'));","key":"lphAHfkAK9"},{"type":"output","id":"OqOkVtceLQvmeTUHWsNLB","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"481c8787dbba0ed2089b1295d96bfc0a","path":"/build/481c8787dbba0ed2089b1295d96bfc0a.png"},"text/plain":{"content":"<Figure size 576x576 with 1 Axes>","content_type":"text/plain"}}}],"key":"oYcMsZz64I"}],"key":"Gh2hVoAwOq"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Awesome!  With just 2 attributes, there was some overlap between the two clusters (which means that the classifier was bound to make some mistakes for pointers in the overlap).  But when we use these 3 attributes, the two clusters have almost no overlap.  In other words, a classifier that uses these 3 attributes will be more accurate than one that only uses the 2 attributes.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ZERMhAXsgx"}],"key":"cLwbD27dXK"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"This is a general phenomenom in classification.  Each attribute can potentially give you new information, so more attributes sometimes helps you build a better classifier.  Of course, the cost is that now we have to gather more information to measure the value of each attribute, but this cost may be well worth it if it significantly improves the accuracy of our classifier.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"LzNBKubbrx"}],"key":"ixWYmB9lMU"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"To sum up: you now know how to use ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"tLZNG04cK5"},{"type":"inlineMath","value":"k","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span>","key":"JWD09O1bBC"},{"type":"text","value":"-nearest neighbor classification to predict the answer to a yes/no question, based on the values of some attributes, assuming you have a training set with examples where the correct prediction is known.  The general roadmap is this:","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"mO69pKqyHw"}],"key":"ZdPYR3tGsw"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":7,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"identify some attributes that you think might help you predict the answer to the question.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"N2YXdEfMKr"}],"key":"pDdg2jH6oe"}],"key":"Ok4imCK0K0"},{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Gather a training set of examples where you know the values of the attributes as well as the correct prediction.","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"u5wxZ4IseM"}],"key":"fxCK7oNRdf"}],"key":"mpYEFirL6y"},{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"To make predictions in the future, measure the value of the attributes and then use ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"sw1NYh8bov"},{"type":"inlineMath","value":"k","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span>","key":"EDezlQXfS2"},{"type":"text","value":"-nearest neighbor classification to predict the answer to the question.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"vYVjLchAdd"}],"key":"CwbhPAr6vt"}],"key":"uHJQQixWEf"}],"key":"ONgYoz83Fa"}],"key":"wU1jgLz0G1"},{"type":"block","kind":"notebook-content","data":{"collapsed":true},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Distance in Multiple Dimensions","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"zkdmux1kRk"}],"identifier":"distance-in-multiple-dimensions","label":"Distance in Multiple Dimensions","html_id":"distance-in-multiple-dimensions","implicit":true,"key":"y93U4LxKIh"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"We know how to compute distance in 2-dimensional space. If we have a point at coordinates ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"EYSRCgqDbU"},{"type":"inlineMath","value":"(x_0,y_0)","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo separator=\"true\">,</mo><msub><mi>y</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(x_0,y_0)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>","key":"sT9V6w9fZs"},{"type":"text","value":" and another at ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"h6hu01BuM8"},{"type":"inlineMath","value":"(x_1,y_1)","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>y</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(x_1,y_1)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>","key":"IhemD8B5cA"},{"type":"text","value":", the distance between them is","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"RuwRoNnNsO"}],"key":"rpUhKWdLP2"},{"type":"math","value":"D = \\sqrt{(x_0-x_1)^2 + (y_0-y_1)^2}.","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"html":"<span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>D</mi><mo>=</mo><msqrt><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo>−</mo><msub><mi>x</mi><mn>1</mn></msub><msup><mo stretchy=\"false\">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy=\"false\">(</mo><msub><mi>y</mi><mn>0</mn></msub><mo>−</mo><msub><mi>y</mi><mn>1</mn></msub><msup><mo stretchy=\"false\">)</mo><mn>2</mn></msup></mrow></msqrt><mi mathvariant=\"normal\">.</mi></mrow><annotation encoding=\"application/x-tex\">D = \\sqrt{(x_0-x_1)^2 + (y_0-y_1)^2}.</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">D</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.24em;vertical-align:-0.2561em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9839em;\"><span class=\"svg-align\" style=\"top:-3.2em;\"><span class=\"pstrut\" style=\"height:3.2em;\"></span><span class=\"mord\" style=\"padding-left:1em;\"><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\"><span class=\"mclose\">)</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7401em;\"><span style=\"top:-2.989em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\"><span class=\"mclose\">)</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7401em;\"><span style=\"top:-2.989em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span></span><span style=\"top:-2.9439em;\"><span class=\"pstrut\" style=\"height:3.2em;\"></span><span class=\"hide-tail\" style=\"min-width:1.02em;height:1.28em;\"><svg xmlns=\"http://www.w3.org/2000/svg\" width='400em' height='1.28em' viewBox='0 0 400000 1296' preserveAspectRatio='xMinYMin slice'><path d='M263,681c0.7,0,18,39.7,52,119\nc34,79.3,68.167,158.7,102.5,238c34.3,79.3,51.8,119.3,52.5,120\nc340,-704.7,510.7,-1060.3,512,-1067\nl0 -0\nc4.7,-7.3,11,-11,19,-11\nH40000v40H1012.3\ns-271.3,567,-271.3,567c-38.7,80.7,-84,175,-136,283c-52,108,-89.167,185.3,-111.5,232\nc-22.3,46.7,-33.8,70.3,-34.5,71c-4.7,4.7,-12.3,7,-23,7s-12,-1,-12,-1\ns-109,-253,-109,-253c-72.7,-168,-109.3,-252,-110,-252c-10.7,8,-22,16.7,-34,26\nc-22,17.3,-33.3,26,-34,26s-26,-26,-26,-26s76,-59,76,-59s76,-60,76,-60z\nM1001 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2561em;\"><span></span></span></span></span></span><span class=\"mord\">.</span></span></span></span></span>","enumerator":"1","key":"wxGHdrM9dy"},{"type":"paragraph","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"In 3-dimensional space, the points are ","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"I60asjZywa"},{"type":"inlineMath","value":"(x_0, y_0, z_0)","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo separator=\"true\">,</mo><msub><mi>y</mi><mn>0</mn></msub><mo separator=\"true\">,</mo><msub><mi>z</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(x_0, y_0, z_0)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.044em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>","key":"Ip4Cb9oCse"},{"type":"text","value":" and ","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"IV2PtWsjaJ"},{"type":"inlineMath","value":"(x_1, y_1, z_1)","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>y</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>z</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(x_1, y_1, z_1)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.044em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>","key":"Apj0OsIgQE"},{"type":"text","value":", and the formula for the distance between them is","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"ore6ZSRFbc"}],"key":"mxUztfOZbO"},{"type":"math","value":"D = \\sqrt{(x_0-x_1)^2 + (y_0-y_1)^2 + (z_0-z_1)^2}","position":{"start":{"line":8,"column":1},"end":{"line":10,"column":1}},"html":"<span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>D</mi><mo>=</mo><msqrt><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo>−</mo><msub><mi>x</mi><mn>1</mn></msub><msup><mo stretchy=\"false\">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy=\"false\">(</mo><msub><mi>y</mi><mn>0</mn></msub><mo>−</mo><msub><mi>y</mi><mn>1</mn></msub><msup><mo stretchy=\"false\">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy=\"false\">(</mo><msub><mi>z</mi><mn>0</mn></msub><mo>−</mo><msub><mi>z</mi><mn>1</mn></msub><msup><mo stretchy=\"false\">)</mo><mn>2</mn></msup></mrow></msqrt></mrow><annotation encoding=\"application/x-tex\">D = \\sqrt{(x_0-x_1)^2 + (y_0-y_1)^2 + (z_0-z_1)^2}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">D</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.24em;vertical-align:-0.2561em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9839em;\"><span class=\"svg-align\" style=\"top:-3.2em;\"><span class=\"pstrut\" style=\"height:3.2em;\"></span><span class=\"mord\" style=\"padding-left:1em;\"><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\"><span class=\"mclose\">)</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7401em;\"><span style=\"top:-2.989em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\"><span class=\"mclose\">)</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7401em;\"><span style=\"top:-2.989em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.044em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.044em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\"><span class=\"mclose\">)</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7401em;\"><span style=\"top:-2.989em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span></span><span style=\"top:-2.9439em;\"><span class=\"pstrut\" style=\"height:3.2em;\"></span><span class=\"hide-tail\" style=\"min-width:1.02em;height:1.28em;\"><svg xmlns=\"http://www.w3.org/2000/svg\" width='400em' height='1.28em' viewBox='0 0 400000 1296' preserveAspectRatio='xMinYMin slice'><path d='M263,681c0.7,0,18,39.7,52,119\nc34,79.3,68.167,158.7,102.5,238c34.3,79.3,51.8,119.3,52.5,120\nc340,-704.7,510.7,-1060.3,512,-1067\nl0 -0\nc4.7,-7.3,11,-11,19,-11\nH40000v40H1012.3\ns-271.3,567,-271.3,567c-38.7,80.7,-84,175,-136,283c-52,108,-89.167,185.3,-111.5,232\nc-22.3,46.7,-33.8,70.3,-34.5,71c-4.7,4.7,-12.3,7,-23,7s-12,-1,-12,-1\ns-109,-253,-109,-253c-72.7,-168,-109.3,-252,-110,-252c-10.7,8,-22,16.7,-34,26\nc-22,17.3,-33.3,26,-34,26s-26,-26,-26,-26s76,-59,76,-59s76,-60,76,-60z\nM1001 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2561em;\"><span></span></span></span></span></span></span></span></span></span>","enumerator":"2","key":"LuZ2NKK17L"},{"type":"paragraph","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"In ","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"FAIAGKqZIk"},{"type":"inlineMath","value":"n","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">n</span></span></span></span>","key":"oy4V6SGZgj"},{"type":"text","value":"-dimensional space, things are a bit harder to visualize, but I think you can see how the formula generalized: we sum up the squares of the differences between each individual coordinate, and then take the square root of that.","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"e9GljRceS2"}],"key":"QW1VAZT9gx"}],"key":"BrQHYQgiYV"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"In the last section, we defined the function ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hXgNWkJDS5"},{"type":"inlineCode","value":"distance","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"QetPml1UWC"},{"type":"text","value":" which returned the distance between two points. We used it in two-dimensions, but the great news is that the function doesn’t care how many dimensions there are! It just subtracts the two arrays of coordinates (no matter how long the arrays are), squares the differences and adds up, and then takes the square root. To work in multiple dimensions, we don’t have to change the code at all.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"gD1cQF9GBz"}],"key":"Xfpti49rcU"}],"key":"ryhDPteqQ2"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def distance(point1, point2):\n    \"\"\"Returns the distance between point1 and point2\n    where each argument is an array \n    consisting of the coordinates of the point\"\"\"\n    return np.sqrt(np.sum((point1 - point2)**2))","key":"L8jZ9zcdEU"},{"type":"output","id":"-JIUjeJk-w4XjzK6Ss0fU","data":[],"key":"OLH1c9OHf9"}],"key":"pxovyxhSwd"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Let’s use this on a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"CCBEHLaiX4"},{"type":"link","url":"https://archive.ics.uci.edu/ml/datasets/Wine","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"new dataset","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"lGXciKhn1t"}],"urlSource":"https://archive.ics.uci.edu/ml/datasets/Wine","key":"i8Lak7JIUy"},{"type":"text","value":". The table ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"YWCh1zx27U"},{"type":"inlineCode","value":"wine","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"b7Jzpfi1hP"},{"type":"text","value":" contains the chemical composition of 178 different Italian wines. The classes are the grape species, called cultivars. There are three classes but let’s just see whether we can tell Class 1 apart from the other two.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"BXtKsV9gSp"}],"key":"qXeKxQAisN"}],"key":"vcj7X0K0Qm"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"wine = Table.read_table(path_data + 'wine.csv')\n\n# For converting Class to binary\n\ndef is_one(x):\n    if x == 1:\n        return 1\n    else:\n        return 0\n    \nwine = wine.with_column('Class', wine.apply(is_one, 0))","key":"fgpENUqH9A"},{"type":"output","id":"apLbfwUaY9KAxH8yDY9cn","data":[],"key":"nSKvSyYZHO"}],"key":"YwMSgddFdG"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"wine","key":"nFgwoF9C2n"},{"type":"output","id":"IP4Fwxwy_EjqcBw-5FeVF","data":[{"output_type":"execute_result","execution_count":10,"metadata":{},"data":{"text/html":{"content":"<table border=\"1\" class=\"dataframe\">\n    <thead>\n        <tr>\n            <th>Class</th> <th>Alcohol</th> <th>Malic Acid</th> <th>Ash</th> <th>Alcalinity of Ash</th> <th>Magnesium</th> <th>Total Phenols</th> <th>Flavanoids</th> <th>Nonflavanoid phenols</th> <th>Proanthocyanins</th> <th>Color Intensity</th> <th>Hue</th> <th>OD280/OD315 of diulted wines</th> <th>Proline</th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr>\n            <td>1    </td> <td>14.23  </td> <td>1.71      </td> <td>2.43</td> <td>15.6             </td> <td>127      </td> <td>2.8          </td> <td>3.06      </td> <td>0.28                </td> <td>2.29           </td> <td>5.64           </td> <td>1.04</td> <td>3.92                        </td> <td>1065   </td>\n        </tr>\n        <tr>\n            <td>1    </td> <td>13.2   </td> <td>1.78      </td> <td>2.14</td> <td>11.2             </td> <td>100      </td> <td>2.65         </td> <td>2.76      </td> <td>0.26                </td> <td>1.28           </td> <td>4.38           </td> <td>1.05</td> <td>3.4                         </td> <td>1050   </td>\n        </tr>\n        <tr>\n            <td>1    </td> <td>13.16  </td> <td>2.36      </td> <td>2.67</td> <td>18.6             </td> <td>101      </td> <td>2.8          </td> <td>3.24      </td> <td>0.3                 </td> <td>2.81           </td> <td>5.68           </td> <td>1.03</td> <td>3.17                        </td> <td>1185   </td>\n        </tr>\n        <tr>\n            <td>1    </td> <td>14.37  </td> <td>1.95      </td> <td>2.5 </td> <td>16.8             </td> <td>113      </td> <td>3.85         </td> <td>3.49      </td> <td>0.24                </td> <td>2.18           </td> <td>7.8            </td> <td>0.86</td> <td>3.45                        </td> <td>1480   </td>\n        </tr>\n        <tr>\n            <td>1    </td> <td>13.24  </td> <td>2.59      </td> <td>2.87</td> <td>21               </td> <td>118      </td> <td>2.8          </td> <td>2.69      </td> <td>0.39                </td> <td>1.82           </td> <td>4.32           </td> <td>1.04</td> <td>2.93                        </td> <td>735    </td>\n        </tr>\n        <tr>\n            <td>1    </td> <td>14.2   </td> <td>1.76      </td> <td>2.45</td> <td>15.2             </td> <td>112      </td> <td>3.27         </td> <td>3.39      </td> <td>0.34                </td> <td>1.97           </td> <td>6.75           </td> <td>1.05</td> <td>2.85                        </td> <td>1450   </td>\n        </tr>\n        <tr>\n            <td>1    </td> <td>14.39  </td> <td>1.87      </td> <td>2.45</td> <td>14.6             </td> <td>96       </td> <td>2.5          </td> <td>2.52      </td> <td>0.3                 </td> <td>1.98           </td> <td>5.25           </td> <td>1.02</td> <td>3.58                        </td> <td>1290   </td>\n        </tr>\n        <tr>\n            <td>1    </td> <td>14.06  </td> <td>2.15      </td> <td>2.61</td> <td>17.6             </td> <td>121      </td> <td>2.6          </td> <td>2.51      </td> <td>0.31                </td> <td>1.25           </td> <td>5.05           </td> <td>1.06</td> <td>3.58                        </td> <td>1295   </td>\n        </tr>\n        <tr>\n            <td>1    </td> <td>14.83  </td> <td>1.64      </td> <td>2.17</td> <td>14               </td> <td>97       </td> <td>2.8          </td> <td>2.98      </td> <td>0.29                </td> <td>1.98           </td> <td>5.2            </td> <td>1.08</td> <td>2.85                        </td> <td>1045   </td>\n        </tr>\n        <tr>\n            <td>1    </td> <td>13.86  </td> <td>1.35      </td> <td>2.27</td> <td>16               </td> <td>98       </td> <td>2.98         </td> <td>3.15      </td> <td>0.22                </td> <td>1.85           </td> <td>7.22           </td> <td>1.01</td> <td>3.55                        </td> <td>1045   </td>\n        </tr>\n    </tbody>\n</table>\n<p>... (168 rows omitted)</p>","content_type":"text/html"},"text/plain":{"content":"Class | Alcohol | Malic Acid | Ash  | Alcalinity of Ash | Magnesium | Total Phenols | Flavanoids | Nonflavanoid phenols | Proanthocyanins | Color Intensity | Hue  | OD280/OD315 of diulted wines | Proline\n1     | 14.23   | 1.71       | 2.43 | 15.6              | 127       | 2.8           | 3.06       | 0.28                 | 2.29            | 5.64            | 1.04 | 3.92                         | 1065\n1     | 13.2    | 1.78       | 2.14 | 11.2              | 100       | 2.65          | 2.76       | 0.26                 | 1.28            | 4.38            | 1.05 | 3.4                          | 1050\n1     | 13.16   | 2.36       | 2.67 | 18.6              | 101       | 2.8           | 3.24       | 0.3                  | 2.81            | 5.68            | 1.03 | 3.17                         | 1185\n1     | 14.37   | 1.95       | 2.5  | 16.8              | 113       | 3.85          | 3.49       | 0.24                 | 2.18            | 7.8             | 0.86 | 3.45                         | 1480\n1     | 13.24   | 2.59       | 2.87 | 21                | 118       | 2.8           | 2.69       | 0.39                 | 1.82            | 4.32            | 1.04 | 2.93                         | 735\n1     | 14.2    | 1.76       | 2.45 | 15.2              | 112       | 3.27          | 3.39       | 0.34                 | 1.97            | 6.75            | 1.05 | 2.85                         | 1450\n1     | 14.39   | 1.87       | 2.45 | 14.6              | 96        | 2.5           | 2.52       | 0.3                  | 1.98            | 5.25            | 1.02 | 3.58                         | 1290\n1     | 14.06   | 2.15       | 2.61 | 17.6              | 121       | 2.6           | 2.51       | 0.31                 | 1.25            | 5.05            | 1.06 | 3.58                         | 1295\n1     | 14.83   | 1.64       | 2.17 | 14                | 97        | 2.8           | 2.98       | 0.29                 | 1.98            | 5.2             | 1.08 | 2.85                         | 1045\n1     | 13.86   | 1.35       | 2.27 | 16                | 98        | 2.98          | 3.15       | 0.22                 | 1.85            | 7.22            | 1.01 | 3.55                         | 1045\n... (168 rows omitted)","content_type":"text/plain"}}}],"key":"UQKkk8e0XD"}],"key":"SVSH5otJUT"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The first two wines are both in Class 1. To find the distance between them, we first need a table of just the attributes:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"XaZwJ0LroO"}],"key":"nzOf5am0sh"}],"key":"PtRxJnf74R"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"wine_attributes = wine.drop('Class')","key":"LjEvYajykJ"},{"type":"output","id":"1P-ICBF4gE2lJRylVVzs0","data":[],"key":"Apq4vv7xG0"}],"key":"QelKuUjcwu"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"distance(np.array(wine_attributes.row(0)), np.array(wine_attributes.row(1)))","key":"LU24lKZpTF"},{"type":"output","id":"7SJijg7gTRfzyAMJ6BalM","data":[{"output_type":"execute_result","execution_count":12,"metadata":{},"data":{"text/plain":{"content":"31.265012394048398","content_type":"text/plain"}}}],"key":"FoMkh0u6RS"}],"key":"m3aRN4K5Ev"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The last wine in the table is of Class 0. Its distance from the first wine is:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"qkxVzKeZvQ"}],"key":"UtQlOpJuBK"}],"key":"zXlGE177gO"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"distance(np.array(wine_attributes.row(0)), np.array(wine_attributes.row(177)))","key":"DDVzPpwIDL"},{"type":"output","id":"sQQ1Ain1BOY6l0WdTxsgB","data":[{"output_type":"execute_result","execution_count":13,"metadata":{},"data":{"text/plain":{"content":"506.05936766351834","content_type":"text/plain"}}}],"key":"g4jrqW6jj6"}],"key":"yWrLNjYEQU"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"That’s quite a bit bigger! Let’s do some visualization to see if Class 1 really looks different from Class 0.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"lYqJsycv2X"}],"key":"xYSLy2li5J"}],"key":"RACotuYk2c"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"wine_with_colors = wine.join('Class', color_table)","key":"A6bfTtoOmN"},{"type":"output","id":"qgW3kPntd4SqrTwPhqHIA","data":[],"key":"SCtqfvepAj"}],"key":"hAhZXnWJn3"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"wine_with_colors.scatter('Flavanoids', 'Alcohol', group='Color')","key":"XlX98QAut1"},{"type":"output","id":"os6oT0e77XQ4AwHhYev-f","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"6b7569e2c0a2a48969041c0b61f10b84","path":"/build/6b7569e2c0a2a48969041c0b61f10b84.png"},"text/plain":{"content":"<Figure size 360x360 with 1 Axes>","content_type":"text/plain"}}}],"key":"tPyGkHPl3b"}],"key":"LG3MpwjIxr"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The blue points (Class 1) are almost entirely separate from the gold ones. That is one indication of why the distance between two Class 1 wines would be smaller than the distance between wines of two different classes. We can see a similar phenomenon with a different pair of attributes too:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dg46d5cFPy"}],"key":"WZ5RwpEyZg"}],"key":"mIfuWFgnI2"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"wine_with_colors.scatter('Alcalinity of Ash', 'Ash', group='Color')","key":"ydv9JpRSgN"},{"type":"output","id":"BKCn9ghAaZk5R0D3OPiXh","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"5beb887674f22ae4a41ab3ebcf223c0c","path":"/build/5beb887674f22ae4a41ab3ebcf223c0c.png"},"text/plain":{"content":"<Figure size 360x360 with 1 Axes>","content_type":"text/plain"}}}],"key":"ZtPvIwUDqA"}],"key":"BtzWqTAwNN"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"But for some pairs the picture is more murky.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"a24TAYFU9S"}],"key":"r9bMtNHtaU"}],"key":"ErfCKKUuMJ"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"wine_with_colors.scatter('Magnesium', 'Total Phenols', group='Color')","key":"TFjiJQydkU"},{"type":"output","id":"uzU9EXgyF9nvbyb7l94Dy","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"51f0eb4630fe37ece5d4a17f2c8fcc6c","path":"/build/51f0eb4630fe37ece5d4a17f2c8fcc6c.png"},"text/plain":{"content":"<Figure size 360x360 with 1 Axes>","content_type":"text/plain"}}}],"key":"JlcjOVOQWP"}],"key":"SgnrjEpEjh"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Let’s see if we can implement a classifier based on all of the attributes. After that, we’ll see how accurate it is.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"TFYDBN8ab7"}],"key":"HlatGSQLX2"}],"key":"HHz4xbMjXj"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"A Plan for the Implementation","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"xqpfzld3J4"}],"identifier":"a-plan-for-the-implementation","label":"A Plan for the Implementation","html_id":"a-plan-for-the-implementation","implicit":true,"key":"e2FNVarxGJ"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"It’s time to write some code to implement the classifier.  The input is a ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"grOp6XVSpk"},{"type":"inlineCode","value":"point","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"Smk3xdvaST"},{"type":"text","value":" that we want to classify.  The classifier works by finding the ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"aVt0fOpGKs"},{"type":"inlineMath","value":"k","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span>","key":"rAoGDgbR6I"},{"type":"text","value":" nearest neighbors of ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"zD3MRy7Tga"},{"type":"inlineCode","value":"point","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"LkbeVsPBEG"},{"type":"text","value":" from the training set.  So, our approach will go like this:","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"wT0s1UB441"}],"key":"ntAfHvMDxi"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":4,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":4,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"Find the closest ","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"pCVmNShEk5"},{"type":"inlineMath","value":"k","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span>","key":"kRvBoUnvPN"},{"type":"text","value":" neighbors of ","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"xApWjpTM5Z"},{"type":"inlineCode","value":"point","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"cZGedkV5kW"},{"type":"text","value":", i.e., the ","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"jNqiDgathd"},{"type":"inlineMath","value":"k","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span>","key":"lX5ylzAuWL"},{"type":"text","value":" wines from the training set that are most similar to ","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"L2HxzxH9Bo"},{"type":"inlineCode","value":"point","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"GrRLTTWBe7"},{"type":"text","value":".","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"qn3BohQEzc"}],"key":"zOU6SIXitu"}],"key":"gYYOSVuUeV"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"Look at the classes of those ","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"q1ALCJ8Vcj"},{"type":"inlineMath","value":"k","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span>","key":"JXpv0J5UVv"},{"type":"text","value":" neighbors, and take the majority vote to find the most-common class of wine.  Use that as our predicted class for ","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"vCmVtKjvH4"},{"type":"inlineCode","value":"point","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"tu3TqtCkBg"},{"type":"text","value":".","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"QJKxmtMXPl"}],"key":"BYz9wr23Rv"}],"key":"Lt0NQL7wPN"}],"key":"Ynesylkc8I"},{"type":"paragraph","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"So that will guide the structure of our Python code.","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"js946q0vXQ"}],"key":"YeeWSR5cD7"}],"key":"d40NUC5JWZ"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def closest(training, p, k):\n    ...\n\ndef majority(topkclasses):\n    ...\n\ndef classify(training, p, k):\n    kclosest = closest(training, p, k)\n    kclosest.classes = kclosest.select('Class')\n    return majority(kclosest)","key":"zD7XrbB4uH"},{"type":"output","id":"afAo30RpMJ1ke77mWr6Wt","data":[],"key":"BQRcnIthxB"}],"key":"MEiWaU35f6"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Implementation Step 1","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ez6jN325Et"}],"identifier":"implementation-step-1","label":"Implementation Step 1","html_id":"implementation-step-1","implicit":true,"key":"OhlqQ63BbY"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"To implement the first step for the kidney disease data, we had to compute the distance from each patient in the training set to ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"yi7Z9XR8GY"},{"type":"inlineCode","value":"point","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"y98AvcpnyY"},{"type":"text","value":", sort them by distance, and take the ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"gopCHsA8RS"},{"type":"inlineMath","value":"k","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span>","key":"hype6hj9OQ"},{"type":"text","value":" closest patients in the training set.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"WR2D0rpNqM"}],"key":"tYQWTOaiud"},{"type":"paragraph","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"That’s what we did in the previous section with the point corresponding to Alice. Let’s generalize that code. We’ll redefine ","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"sfN7fOCoRe"},{"type":"inlineCode","value":"distance","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"St57cO8xp2"},{"type":"text","value":" here, just for convenience.","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"JvyEw8XRiJ"}],"key":"NUeKL1y2QM"}],"key":"uyKOk3NfR4"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def distance(point1, point2):\n    \"\"\"Returns the distance between point1 and point2\n    where each argument is an array \n    consisting of the coordinates of the point\"\"\"\n    return np.sqrt(np.sum((point1 - point2)**2))\n\ndef all_distances(training, new_point):\n    \"\"\"Returns an array of distances\n    between each point in the training set\n    and the new point (which is a row of attributes)\"\"\"\n    attributes = training.drop('Class')\n    def distance_from_point(row):\n        return distance(np.array(new_point), np.array(row))\n    return attributes.apply(distance_from_point)\n\ndef table_with_distances(training, new_point):\n    \"\"\"Augments the training table \n    with a column of distances from new_point\"\"\"\n    return training.with_column('Distance', all_distances(training, new_point))\n\ndef closest(training, new_point, k):\n    \"\"\"Returns a table of the k rows of the augmented table\n    corresponding to the k smallest distances\"\"\"\n    with_dists = table_with_distances(training, new_point)\n    sorted_by_distance = with_dists.sort('Distance')\n    topk = sorted_by_distance.take(np.arange(k))\n    return topk","key":"JI98DL1LpF"},{"type":"output","id":"dnPpNmGthBQWy5mZjrmvK","data":[],"key":"siXIc2i7rB"}],"key":"IKaZ7W15mu"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Let’s see how this works on our ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"jXJ942VD33"},{"type":"inlineCode","value":"wine","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IhJJsv3LkW"},{"type":"text","value":" data. We’ll just take the first wine and find its five nearest neighbors among all the wines. Remember that since this wine is part of the dataset, it is its own nearest neighbor. So we should expect to see it at the top of the list, followed by four others.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"wZBmEdtqkq"}],"key":"p6oftyslSF"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"First let’s extract its attributes:","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"A4FQ2HQp0L"}],"key":"xHVORQko68"}],"key":"GTa7zR3DDc"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"special_wine = wine.drop('Class').row(0)","key":"eB15IBcads"},{"type":"output","id":"wkipsQ2bMXTVlfzWSs2FR","data":[],"key":"EaqtcRGnul"}],"key":"lg4S2hr2fH"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"And now let’s find its 5 nearest neighbors.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"puuMPmyP0B"}],"key":"ayEOvvkRCK"}],"key":"WYRlA7Bavu"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"closest(wine, special_wine, 5)","key":"EdooJrztBN"},{"type":"output","id":"dHBVgQMV5OCtL_7Jt_m8I","data":[{"output_type":"execute_result","execution_count":21,"metadata":{},"data":{"text/html":{"content":"<table border=\"1\" class=\"dataframe\">\n    <thead>\n        <tr>\n            <th>Class</th> <th>Alcohol</th> <th>Malic Acid</th> <th>Ash</th> <th>Alcalinity of Ash</th> <th>Magnesium</th> <th>Total Phenols</th> <th>Flavanoids</th> <th>Nonflavanoid phenols</th> <th>Proanthocyanins</th> <th>Color Intensity</th> <th>Hue</th> <th>OD280/OD315 of diulted wines</th> <th>Proline</th> <th>Distance</th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr>\n            <td>1    </td> <td>14.23  </td> <td>1.71      </td> <td>2.43</td> <td>15.6             </td> <td>127      </td> <td>2.8          </td> <td>3.06      </td> <td>0.28                </td> <td>2.29           </td> <td>5.64           </td> <td>1.04</td> <td>3.92                        </td> <td>1065   </td> <td>0       </td>\n        </tr>\n        <tr>\n            <td>1    </td> <td>13.74  </td> <td>1.67      </td> <td>2.25</td> <td>16.4             </td> <td>118      </td> <td>2.6          </td> <td>2.9       </td> <td>0.21                </td> <td>1.62           </td> <td>5.85           </td> <td>0.92</td> <td>3.2                         </td> <td>1060   </td> <td>10.3928 </td>\n        </tr>\n        <tr>\n            <td>1    </td> <td>14.21  </td> <td>4.04      </td> <td>2.44</td> <td>18.9             </td> <td>111      </td> <td>2.85         </td> <td>2.65      </td> <td>0.3                 </td> <td>1.25           </td> <td>5.24           </td> <td>0.87</td> <td>3.33                        </td> <td>1080   </td> <td>22.3407 </td>\n        </tr>\n        <tr>\n            <td>1    </td> <td>14.1   </td> <td>2.02      </td> <td>2.4 </td> <td>18.8             </td> <td>103      </td> <td>2.75         </td> <td>2.92      </td> <td>0.32                </td> <td>2.38           </td> <td>6.2            </td> <td>1.07</td> <td>2.75                        </td> <td>1060   </td> <td>24.7602 </td>\n        </tr>\n        <tr>\n            <td>1    </td> <td>14.38  </td> <td>3.59      </td> <td>2.28</td> <td>16               </td> <td>102      </td> <td>3.25         </td> <td>3.17      </td> <td>0.27                </td> <td>2.19           </td> <td>4.9            </td> <td>1.04</td> <td>3.44                        </td> <td>1065   </td> <td>25.0947 </td>\n        </tr>\n    </tbody>\n</table>","content_type":"text/html"},"text/plain":{"content":"Class | Alcohol | Malic Acid | Ash  | Alcalinity of Ash | Magnesium | Total Phenols | Flavanoids | Nonflavanoid phenols | Proanthocyanins | Color Intensity | Hue  | OD280/OD315 of diulted wines | Proline | Distance\n1     | 14.23   | 1.71       | 2.43 | 15.6              | 127       | 2.8           | 3.06       | 0.28                 | 2.29            | 5.64            | 1.04 | 3.92                         | 1065    | 0\n1     | 13.74   | 1.67       | 2.25 | 16.4              | 118       | 2.6           | 2.9        | 0.21                 | 1.62            | 5.85            | 0.92 | 3.2                          | 1060    | 10.3928\n1     | 14.21   | 4.04       | 2.44 | 18.9              | 111       | 2.85          | 2.65       | 0.3                  | 1.25            | 5.24            | 0.87 | 3.33                         | 1080    | 22.3407\n1     | 14.1    | 2.02       | 2.4  | 18.8              | 103       | 2.75          | 2.92       | 0.32                 | 2.38            | 6.2             | 1.07 | 2.75                         | 1060    | 24.7602\n1     | 14.38   | 3.59       | 2.28 | 16                | 102       | 3.25          | 3.17       | 0.27                 | 2.19            | 4.9             | 1.04 | 3.44                         | 1065    | 25.0947","content_type":"text/plain"}}}],"key":"LrQ79r6a5r"}],"key":"Le9JssQcYZ"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Bingo! The first row is the nearest neighbor, which is itself – there’s a 0 in the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"wyxxjFurl7"},{"type":"inlineCode","value":"Distance","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"WieTcBtaMM"},{"type":"text","value":" column as expected. All five nearest neighbors are of Class 1, which is consistent with our earlier observation that Class 1 wines appear to be clumped together in some dimensions.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"vGZlUNlgRc"}],"key":"il0RJ41FAx"}],"key":"EJA7jD6Zb4"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Implementation Steps 2 and 3","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ei9ln924vB"}],"identifier":"implementation-steps-2-and-3","label":"Implementation Steps 2 and 3","html_id":"implementation-steps-2-and-3","implicit":true,"key":"CWn84Z1wOx"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Next we need to take a “majority vote” of the nearest neighbors and assign our point the same class as the majority.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"IdnD4ElZl8"}],"key":"JpzySnVMgh"}],"key":"lsUbUwzmjr"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def majority(topkclasses):\n    ones = topkclasses.where('Class', are.equal_to(1)).num_rows\n    zeros = topkclasses.where('Class', are.equal_to(0)).num_rows\n    if ones > zeros:\n        return 1\n    else:\n        return 0\n\ndef classify(training, new_point, k):\n    closestk = closest(training, new_point, k)\n    topkclasses = closestk.select('Class')\n    return majority(topkclasses)","key":"KIDZyw7AQW"},{"type":"output","id":"2zSw_ijPh1SEhYDNSPIem","data":[],"key":"V33rVGPz3N"}],"key":"kDyrqE8BgC"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"classify(wine, special_wine, 5)","key":"CE3fWSVsP1"},{"type":"output","id":"W_Wo5fqAZV5RLTX5V7d-E","data":[{"output_type":"execute_result","execution_count":23,"metadata":{},"data":{"text/plain":{"content":"1","content_type":"text/plain"}}}],"key":"fNqPwfOfuy"}],"key":"C61bdzHrLa"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"If we change ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"pU3LEpe7RA"},{"type":"inlineCode","value":"special_wine","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"CmOn6kgPRK"},{"type":"text","value":" to be the last one in the dataset, is our classifier able to tell that it’s in Class 0?","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"wJJhoncjMr"}],"key":"h8I6Gsrgvs"}],"key":"pYm6HUKTBQ"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"special_wine = wine.drop('Class').row(177)\nclassify(wine, special_wine, 5)","key":"wVQIwZ3g9B"},{"type":"output","id":"GS8u6MYrgJpLFQC1hw0EV","data":[{"output_type":"execute_result","execution_count":24,"metadata":{},"data":{"text/plain":{"content":"0","content_type":"text/plain"}}}],"key":"qI9FCsN3EB"}],"key":"wytb44cIZQ"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Yes! The classifier gets this one right too.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"njtyTF33KF"}],"key":"WRbnU4p2oV"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"But we don’t yet know how it does with all the other wines, and in any case we know that testing on wines that are already part of the training set might be over-optimistic. In the final section of this chapter, we will separate the wines into a training and test set and then measure the accuracy of our classifier on the test set.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"z2djvh2n13"}],"key":"WLSN8tOHoB"}],"key":"A3rQmM96Bl"}],"key":"IHRT0jBqJ8"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"Rows of Tables","url":"/chapters/17/3/rows-of-tables","group":"Computational and Inferential Thinking"},"next":{"title":"The Accuracy of the Classifier","url":"/chapters/17/5/accuracy-of-the-classifier","group":"Computational and Inferential Thinking"}}},"domain":"http://localhost:3000"}